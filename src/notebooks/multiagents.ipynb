{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Researcher\n",
    "\n",
    "This notebook demonstrates the multi-agent research approach, which uses a supervisor-researcher collaborative pattern to create comprehensive reports. The system consists of:\n",
    "\n",
    "1. A **Supervisor Agent** that plans the overall report structure and coordinates work\n",
    "2. Multiple **Research Agents** that investigate specific topics in parallel\n",
    "3. A workflow that produces a structured report with introduction, body sections, and conclusion\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll switch to the src directory and load in our environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robertxu/Desktop/Projects/eng/open_deep_research/src\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the helpers we'll need to build our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.multiagents.graph import (\n",
    "    get_research_tools, \n",
    "    get_supervisor_tools, \n",
    "    get_search_tool, \n",
    "    _load_mcp_tools\n",
    ")\n",
    "\n",
    "from agents.multiagents.graph import (\n",
    "    Section,\n",
    "    Sections,\n",
    "    Introduction,\n",
    "    Conclusion,\n",
    "    Question,\n",
    "    FinishResearch,\n",
    "    FinishReport,\n",
    ")\n",
    "\n",
    "from agents.multiagents.utils import (\n",
    "    get_config_value,\n",
    "    tavily_search,\n",
    "    duckduckgo_search,\n",
    "    get_today_str,\n",
    ")\n",
    "\n",
    "from agents.multiagents.prompts import SUPERVISOR_INSTRUCTIONS, RESEARCH_INSTRUCTIONS\n",
    "from agents.multiagents.configuration import MultiAgentConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervisor Agent\n",
    "\n",
    "We'll start by defining the supervisor agent in our multiagent system.\n",
    "\n",
    "### State\n",
    "\n",
    "We'll track the building blocks of our report in our state. We'll assume our research will be broken down into sections, each with research sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import MessagesState\n",
    "import operator\n",
    "\n",
    "class ReportStateOutput(MessagesState):\n",
    "    final_report: str # Final report\n",
    "    # for evaluation purposes only\n",
    "    # this is included only if configurable.include_source_str is True\n",
    "    source_str: str # String of formatted source content from web search\n",
    "\n",
    "class ReportState(MessagesState):\n",
    "    sections: list[str] # List of report sections \n",
    "    completed_sections: Annotated[list[Section], operator.add] # Send() API key\n",
    "    final_report: str # Final report\n",
    "    # for evaluation purposes only\n",
    "    # this is included only if configurable.include_source_str is True\n",
    "    source_str: Annotated[str, operator.add] # String of formatted source content from web search\n",
    "\n",
    "class SectionState(MessagesState):\n",
    "    section: str # Report section  \n",
    "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
    "    # for evaluation purposes only\n",
    "    # this is included only if configurable.include_source_str is True\n",
    "    source_str: str # String of formatted source content from web search\n",
    "\n",
    "class SectionOutputState(TypedDict):\n",
    "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
    "    # for evaluation purposes only\n",
    "    # this is included only if configurable.include_source_str is True\n",
    "    source_str: str # String of formatted source content from web search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "Next, we'll define our supervisor. This will follow the classic ReAct agent architecture, with a reasoning step and a tools step. However, the tools will serve to handoff control to a dedicated team of subagents.\n",
    "\n",
    "First, the reasoning node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "async def supervisor(state: ReportState, config: RunnableConfig):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    # Messages\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = MultiAgentConfiguration.from_runnable_config(config)\n",
    "    supervisor_model = get_config_value(configurable.supervisor_model)\n",
    "\n",
    "    # Initialize the model\n",
    "    llm = init_chat_model(model=supervisor_model)\n",
    "    \n",
    "    # If sections have been completed, but we don't yet have the final report, then we need to initiate writing the introduction and conclusion\n",
    "    if state.get(\"completed_sections\") and not state.get(\"final_report\"):\n",
    "        research_complete_message = {\"role\": \"user\", \"content\": \"Research is complete. Now write the introduction and conclusion for the report. Here are the completed main body sections: \\n\\n\" + \"\\n\\n\".join([s.content for s in state[\"completed_sections\"]])}\n",
    "        messages = messages + [research_complete_message]\n",
    "\n",
    "    # Get tools based on configuration\n",
    "    supervisor_tool_list = await get_supervisor_tools(config)\n",
    "    \n",
    "    \n",
    "    llm_with_tools = (\n",
    "        llm\n",
    "        .bind_tools(\n",
    "            supervisor_tool_list,\n",
    "            parallel_tool_calls=False,\n",
    "            # force at least one tool call\n",
    "            tool_choice=\"any\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get system prompt\n",
    "    system_prompt = SUPERVISOR_INSTRUCTIONS.format(today=get_today_str())\n",
    "    if configurable.mcp_prompt:\n",
    "        system_prompt += f\"\\n\\n{configurable.mcp_prompt}\"\n",
    "\n",
    "    # Invoke\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            await llm_with_tools.ainvoke(\n",
    "                [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt\n",
    "                    }\n",
    "                ]\n",
    "                + messages\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the tools node to implement handoffs and routing. Note that we use Command to directly handoff to subagents, and update their State. \n",
    "\n",
    "We also utilize the Send method, which allows us to utilize map reduce functionality within LangGraph. This will spin up an arbitrary number of subagents depending on the need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, cast\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import Command, Send\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "async def supervisor_tools(state: ReportState, config: RunnableConfig)  -> Command[Literal[\"supervisor\", \"research_team\", \"__end__\"]]:\n",
    "    \"\"\"Performs the tool call and sends to the research agent\"\"\"\n",
    "    configurable = MultiAgentConfiguration.from_runnable_config(config)\n",
    "\n",
    "    result = []\n",
    "    sections_list = []\n",
    "    intro_content = None\n",
    "    conclusion_content = None\n",
    "    source_str = \"\"\n",
    "\n",
    "    # Get tools based on configuration\n",
    "    supervisor_tool_list = await get_supervisor_tools(config)\n",
    "    supervisor_tools_by_name = {tool.name: tool for tool in supervisor_tool_list}\n",
    "    search_tool_names = {\n",
    "        tool.name\n",
    "        for tool in supervisor_tool_list\n",
    "        if tool.metadata is not None and tool.metadata.get(\"type\") == \"search\"\n",
    "    }\n",
    "\n",
    "    # First process all tool calls to ensure we respond to each one (required for OpenAI)\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Get the tool\n",
    "        tool = supervisor_tools_by_name[tool_call[\"name\"]]\n",
    "        # Perform the tool call - use ainvoke for async tools\n",
    "        try:\n",
    "            observation = await tool.ainvoke(tool_call[\"args\"], config)\n",
    "        except NotImplementedError:\n",
    "            observation = tool.invoke(tool_call[\"args\"], config)\n",
    "\n",
    "        # Append to messages \n",
    "        result.append({\"role\": \"tool\", \n",
    "                       \"content\": observation, \n",
    "                       \"name\": tool_call[\"name\"], \n",
    "                       \"tool_call_id\": tool_call[\"id\"]})\n",
    "        \n",
    "        # Store special tool results for processing after all tools have been called\n",
    "        if tool_call[\"name\"] == \"Question\":\n",
    "            # Question tool was called - return to supervisor to ask the question\n",
    "            question_obj = cast(Question, observation)\n",
    "            result.append({\"role\": \"assistant\", \"content\": question_obj.question})\n",
    "            return Command(goto=END, update={\"messages\": result})\n",
    "        elif tool_call[\"name\"] == \"FinishReport\":\n",
    "            result.append({\"role\": \"user\", \"content\": \"Report is Finish\"})\n",
    "            return Command(goto=END, update={\"messages\": result})\n",
    "        elif tool_call[\"name\"] == \"Sections\":\n",
    "            sections_list = cast(Sections, observation).sections\n",
    "        elif tool_call[\"name\"] == \"Introduction\":\n",
    "            # Format introduction with proper H1 heading if not already formatted\n",
    "            observation = cast(Introduction, observation)\n",
    "            if not observation.content.startswith(\"# \"):\n",
    "                intro_content = f\"# {observation.name}\\n\\n{observation.content}\"\n",
    "            else:\n",
    "                intro_content = observation.content\n",
    "        elif tool_call[\"name\"] == \"Conclusion\":\n",
    "            # Format conclusion with proper H2 heading if not already formatted\n",
    "            observation = cast(Conclusion, observation)\n",
    "            if not observation.content.startswith(\"## \"):\n",
    "                conclusion_content = f\"## {observation.name}\\n\\n{observation.content}\"\n",
    "            else:\n",
    "                conclusion_content = observation.content\n",
    "        elif tool_call[\"name\"] in search_tool_names and configurable.include_source_str:\n",
    "            source_str += cast(str, observation)\n",
    "\n",
    "    # After processing all tool calls, decide what to do next\n",
    "    if sections_list:\n",
    "        # Send the sections to the research agents\n",
    "        return Command(goto=[Send(\"research_team\", {\"section\": s}) for s in sections_list], update={\"messages\": result})\n",
    "    elif intro_content:\n",
    "        # Store introduction while waiting for conclusion\n",
    "        # Append to messages to guide the LLM to write conclusion next\n",
    "        result.append({\"role\": \"user\", \"content\": \"Introduction written. Now write a conclusion section.\"})\n",
    "        state_update = {\n",
    "            \"final_report\": intro_content,\n",
    "            \"messages\": result,\n",
    "        }\n",
    "    elif conclusion_content:\n",
    "        # Get all sections and combine in proper order: Introduction, Body Sections, Conclusion\n",
    "        intro = state.get(\"final_report\", \"\")\n",
    "        body_sections = \"\\n\\n\".join([s.content for s in state[\"completed_sections\"]])\n",
    "        \n",
    "        # Assemble final report in correct order\n",
    "        complete_report = f\"{intro}\\n\\n{body_sections}\\n\\n{conclusion_content}\"\n",
    "        \n",
    "        # Append to messages to indicate completion\n",
    "        result.append({\"role\": \"user\", \"content\": \"Report is now complete with introduction, body sections, and conclusion.\"})\n",
    "\n",
    "        state_update = {\n",
    "            \"final_report\": complete_report,\n",
    "            \"messages\": result,\n",
    "        }\n",
    "    else:\n",
    "        # Default case (for search tools, etc.)\n",
    "        state_update = {\"messages\": result}\n",
    "\n",
    "    # Include source string for evaluation\n",
    "    if configurable.include_source_str and source_str:\n",
    "        state_update[\"source_str\"] = source_str\n",
    "\n",
    "    return Command(goto=\"supervisor\", update=state_update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges\n",
    "\n",
    "The edges for our supervisor will follow the traditional ReAct agent architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def supervisor_should_continue(state: ReportState) -> str:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # End because the supervisor asked a question or is finished\n",
    "    if not last_message.tool_calls:\n",
    "        # Exit the graph\n",
    "        return END\n",
    "\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    return \"supervisor_tools\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Team\n",
    "\n",
    "Next, we'll define individual subagents that our supervisor agent can handoff to.\n",
    "\n",
    "### Nodes\n",
    "\n",
    "Like the supervisor, each subagent will use a modified ReAct architecture, with a reasoning step and a tools step.\n",
    "\n",
    "Reasoning step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def research_agent(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "    \n",
    "    # Get configuration\n",
    "    configurable = MultiAgentConfiguration.from_runnable_config(config)\n",
    "    researcher_model = get_config_value(configurable.researcher_model)\n",
    "    \n",
    "    # Initialize the model\n",
    "    llm = init_chat_model(model=researcher_model)\n",
    "\n",
    "    # Get tools based on configuration\n",
    "    research_tool_list = await get_research_tools(config)\n",
    "    system_prompt = RESEARCH_INSTRUCTIONS.format(\n",
    "        section_description=state[\"section\"],\n",
    "        number_of_queries=configurable.number_of_queries,\n",
    "        today=get_today_str(),\n",
    "    )\n",
    "    if configurable.mcp_prompt:\n",
    "        system_prompt += f\"\\n\\n{configurable.mcp_prompt}\"\n",
    "\n",
    "    # Ensure we have at least one user message (required by Anthropic)\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        messages = [{\"role\": \"user\", \"content\": f\"Please research and write the section: {state['section']}\"}]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            # Enforce tool calling to either perform more search or call the Section tool to write the section\n",
    "            await llm.bind_tools(research_tool_list,             \n",
    "                                 parallel_tool_calls=False,\n",
    "                                 # force at least one tool call\n",
    "                                 tool_choice=\"any\").ainvoke(\n",
    "                [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt\n",
    "                    }\n",
    "                ]\n",
    "                + messages\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def research_agent_tools(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"Performs the tool call and route to supervisor or continue the research loop\"\"\"\n",
    "    configurable = MultiAgentConfiguration.from_runnable_config(config)\n",
    "\n",
    "    result = []\n",
    "    completed_section = None\n",
    "    source_str = \"\"\n",
    "    \n",
    "    # Get tools based on configuration\n",
    "    research_tool_list = await get_research_tools(config)\n",
    "    research_tools_by_name = {tool.name: tool for tool in research_tool_list}\n",
    "    search_tool_names = {\n",
    "        tool.name\n",
    "        for tool in research_tool_list\n",
    "        if tool.metadata is not None and tool.metadata.get(\"type\") == \"search\"\n",
    "    }\n",
    "    \n",
    "    # Process all tool calls first (required for OpenAI)\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Get the tool\n",
    "        tool = research_tools_by_name[tool_call[\"name\"]]\n",
    "        # Perform the tool call - use ainvoke for async tools\n",
    "        try:\n",
    "            observation = await tool.ainvoke(tool_call[\"args\"], config)\n",
    "        except NotImplementedError:\n",
    "            observation = tool.invoke(tool_call[\"args\"], config)\n",
    "\n",
    "        # Append to messages \n",
    "        result.append({\"role\": \"tool\", \n",
    "                       \"content\": observation, \n",
    "                       \"name\": tool_call[\"name\"], \n",
    "                       \"tool_call_id\": tool_call[\"id\"]})\n",
    "        \n",
    "        # Store the section observation if a Section tool was called\n",
    "        if tool_call[\"name\"] == \"Section\":\n",
    "            completed_section = cast(Section, observation)\n",
    "\n",
    "        # Store the source string if a search tool was called\n",
    "        if tool_call[\"name\"] in search_tool_names and configurable.include_source_str:\n",
    "            source_str += cast(str, observation)\n",
    "    \n",
    "    # After processing all tools, decide what to do next\n",
    "    state_update = {\"messages\": result}\n",
    "    if completed_section:\n",
    "        # Write the completed section to state and return to the supervisor\n",
    "        state_update[\"completed_sections\"] = [completed_section]\n",
    "    if configurable.include_source_str and source_str:\n",
    "        state_update[\"source_str\"] = source_str\n",
    "\n",
    "    return state_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def research_agent_should_continue(state: SectionState) -> str:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    if last_message.tool_calls[0][\"name\"] == \"FinishResearch\":\n",
    "        # Research is done - return to supervisor\n",
    "        return END\n",
    "    else:\n",
    "        return \"research_agent_tools\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_66983/3715570504.py:4: LangGraphDeprecatedSinceV10: `config_schema` is deprecated and will be removed. Please use `context_schema` instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  research_builder = StateGraph(SectionState, output=SectionOutputState, config_schema=MultiAgentConfiguration)\n",
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_66983/3715570504.py:4: LangGraphDeprecatedSinceV05: `output` is deprecated and will be removed. Please use `output_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  research_builder = StateGraph(SectionState, output=SectionOutputState, config_schema=MultiAgentConfiguration)\n",
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_66983/3715570504.py:16: LangGraphDeprecatedSinceV10: `config_schema` is deprecated and will be removed. Please use `context_schema` instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  supervisor_builder = StateGraph(ReportState, input=MessagesState, output=ReportStateOutput, config_schema=MultiAgentConfiguration)\n",
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_66983/3715570504.py:16: LangGraphDeprecatedSinceV05: `input` is deprecated and will be removed. Please use `input_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  supervisor_builder = StateGraph(ReportState, input=MessagesState, output=ReportStateOutput, config_schema=MultiAgentConfiguration)\n",
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_66983/3715570504.py:16: LangGraphDeprecatedSinceV05: `output` is deprecated and will be removed. Please use `output_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  supervisor_builder = StateGraph(ReportState, input=MessagesState, output=ReportStateOutput, config_schema=MultiAgentConfiguration)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Research agent workflow\n",
    "research_builder = StateGraph(SectionState, output=SectionOutputState, config_schema=MultiAgentConfiguration)\n",
    "research_builder.add_node(\"research_agent\", research_agent)\n",
    "research_builder.add_node(\"research_agent_tools\", research_agent_tools)\n",
    "research_builder.add_edge(START, \"research_agent\") \n",
    "research_builder.add_conditional_edges(\n",
    "    \"research_agent\",\n",
    "    research_agent_should_continue,\n",
    "    [\"research_agent_tools\", END]\n",
    ")\n",
    "research_builder.add_edge(\"research_agent_tools\", \"research_agent\")\n",
    "\n",
    "# Supervisor workflow\n",
    "supervisor_builder = StateGraph(ReportState, input=MessagesState, output=ReportStateOutput, config_schema=MultiAgentConfiguration)\n",
    "supervisor_builder.add_node(\"supervisor\", supervisor)\n",
    "supervisor_builder.add_node(\"supervisor_tools\", supervisor_tools)\n",
    "supervisor_builder.add_node(\"research_team\", research_builder.compile())\n",
    "\n",
    "# Flow of the supervisor agent\n",
    "supervisor_builder.add_edge(START, \"supervisor\")\n",
    "supervisor_builder.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    supervisor_should_continue,\n",
    "    [\"supervisor_tools\", END]\n",
    ")\n",
    "supervisor_builder.add_edge(\"research_team\", \"supervisor\")\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = supervisor_builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png(max_retries=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running our Agent\n",
    "\n",
    "We can run our agent using the code below. NOTE that it does take several minutes to run, and consumes a large amount of tokens. \n",
    "\n",
    "As such, we've also included a sample trace of a successful run.\n",
    "\n",
    "**Public Trace**: https://smith.langchain.com/public/407cd7fd-f3bc-45a8-9bea-38d9d84985e4/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "# Configure and run the multi-agent system\n",
    "# This sets up the model configuration and executes the research workflow\n",
    "\n",
    "# Configure models and search API for both supervisor and researcher roles\n",
    "config = {\n",
    "    \"thread_id\": str(uuid.uuid4()),\n",
    "    \"search_api\": \"tavily\",\n",
    "    \"supervisor_model\": \"openai:gpt-4o-mini\",\n",
    "    \"researcher_model\": \"openai:gpt-4o-mini\",\n",
    "}\n",
    "\n",
    "# Set up thread configuration with the specified parameters\n",
    "thread_config = {\"configurable\": config}\n",
    "\n",
    "# Define the research topic as a user message\n",
    "msg = [{\"role\": \"user\", \"content\": \"What is model context protocol?\"}]\n",
    "\n",
    "# Run the multi-agent workflow with the specified configuration\n",
    "response = await graph.ainvoke({\"messages\": msg}, config=thread_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is model context protocol?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_d3clJQ3BDzxwDjoWy2QtnWNQ)\n",
      " Call ID: call_d3clJQ3BDzxwDjoWy2QtnWNQ\n",
      "  Args:\n",
      "    queries: ['model context protocol']\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "Search results: \n",
      "\n",
      "\n",
      "\n",
      "--- SOURCE 1: Model Context Protocol ---\n",
      "URL: https://modelcontextprotocol.io/\n",
      "\n",
      "SUMMARY:\n",
      "[Model Context Protocol home page![Image 1: light logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/light.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=4498cb8a57d574005f3dca62bdd49c95)![Image 2: dark logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/dark.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=c0687c003f8f2cbdb24772ab4c8a522c)](https://modelcontextprotocol.io/) [Documentation](https://modelcontextprotocol.io/docs/getting-started/intro)[Specification](https://modelcontextprotocol.io/specification/2025-06-18)[Community](https://modelcontextprotocol.io/community/communication)[About MCP](https://modelcontextprotocol.io/about) *   [What is MCP?](https://modelcontextprotocol.io/docs/getting-started/intro) *   [Architecture](https://modelcontextprotocol.io/docs/learn/architecture) *   [Servers](https://modelcontextprotocol.io/docs/learn/server-concepts) *   [Clients](https://modelcontextprotocol.io/docs/learn/client-concepts) *   [Connect to local MCP servers](https://modelcontextprotocol.io/docs/develop/connect-local-servers) *   [Connect to remote MCP Servers](https://modelcontextprotocol.io/docs/develop/connect-remote-servers) *   [Build an MCP server](https://modelcontextprotocol.io/docs/develop/build-server) *   [Build an MCP client](https://modelcontextprotocol.io/docs/develop/build-client) *   [SDKs](https://modelcontextprotocol.io/docs/sdk) *   [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) *   [What can MCP enable?](https://modelcontextprotocol.io/#what-can-mcp-enable%3F) *   [Why does MCP matter?](https://modelcontextprotocol.io/#why-does-mcp-matter%3F) *   [Start Building](https://modelcontextprotocol.io/#start-building) *   [Learn more](https://modelcontextprotocol.io/#learn-more) [](https://modelcontextprotocol.io/#what-can-mcp-enable%3F) [](https://modelcontextprotocol.io/#why-does-mcp-matter%3F) [](https://modelcontextprotocol.io/#start-building) [Build servers ------------- Create MCP servers to expose your data and tools](https://modelcontextprotocol.io/docs/develop/build-server)[Build clients ------------- Develop applications that connect to MCP servers](https://modelcontextprotocol.io/docs/develop/build-client) [](https://modelcontextprotocol.io/#learn-more) [Understand concepts ------------------- Learn the core concepts and architecture of MCP](https://modelcontextprotocol.io/docs/learn/architecture) [Architecture](https://modelcontextprotocol.io/docs/learn/architecture)\n",
      "\n",
      "FULL CONTENT:\n",
      "What is the Model Context Protocol (MCP)? - Model Context Protocol\n",
      "\n",
      "===============\n",
      "\n",
      "[Skip to main content](https://modelcontextprotocol.io/#content-area)\n",
      "\n",
      "[Model Context Protocol home page![Image 1: light logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/light.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=4498cb8a57d574005f3dca62bdd49c95)![Image 2: dark logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/dark.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=c0687c003f8f2cbdb24772ab4c8a522c)](https://modelcontextprotocol.io/)\n",
      "\n",
      "Search...\n",
      "\n",
      "Ctrl K\n",
      "\n",
      "*   [Blog](https://blog.modelcontextprotocol.io/)\n",
      "*   [GitHub](https://github.com/modelcontextprotocol)\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Get started\n",
      "\n",
      "What is the Model Context Protocol (MCP)?\n",
      "\n",
      "[Documentation](https://modelcontextprotocol.io/docs/getting-started/intro)[Specification](https://modelcontextprotocol.io/specification/2025-06-18)[Community](https://modelcontextprotocol.io/community/communication)[About MCP](https://modelcontextprotocol.io/about)\n",
      "\n",
      "##### Get started\n",
      "\n",
      "*   [What is MCP?](https://modelcontextprotocol.io/docs/getting-started/intro)\n",
      "\n",
      "##### About MCP\n",
      "\n",
      "*   [Architecture](https://modelcontextprotocol.io/docs/learn/architecture)\n",
      "*   [Servers](https://modelcontextprotocol.io/docs/learn/server-concepts)\n",
      "*   [Clients](https://modelcontextprotocol.io/docs/learn/client-concepts)\n",
      "*   [Versioning](https://modelcontextprotocol.io/specification/versioning)\n",
      "\n",
      "##### Develop with MCP\n",
      "\n",
      "*   [Connect to local MCP servers](https://modelcontextprotocol.io/docs/develop/connect-local-servers)\n",
      "*   [Connect to remote MCP Servers](https://modelcontextprotocol.io/docs/develop/connect-remote-servers)\n",
      "*   [Build an MCP server](https://modelcontextprotocol.io/docs/develop/build-server)\n",
      "*   [Build an MCP client](https://modelcontextprotocol.io/docs/develop/build-client)\n",
      "*   [SDKs](https://modelcontextprotocol.io/docs/sdk)\n",
      "*   Security \n",
      "\n",
      "##### Developer tools\n",
      "\n",
      "*   [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector)\n",
      "\n",
      "On this page\n",
      "*   [What can MCP enable?](https://modelcontextprotocol.io/#what-can-mcp-enable%3F)\n",
      "*   [Why does MCP matter?](https://modelcontextprotocol.io/#why-does-mcp-matter%3F)\n",
      "*   [Start Building](https://modelcontextprotocol.io/#start-building)\n",
      "*   [Learn more](https://modelcontextprotocol.io/#learn-more)\n",
      "\n",
      "Get started\n",
      "\n",
      "What is the Model Context Protocol (MCP)?\n",
      "=========================================\n",
      "\n",
      "Copy page\n",
      "\n",
      "Copy page\n",
      "\n",
      "MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)enabling them to access key information and perform tasks.Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\n",
      "\n",
      "![Image 3](https://mintcdn.com/mcp/bEUxYpZqie0DsluH/images/mcp-simple-diagram.png?fit=max&auto=format&n=bEUxYpZqie0DsluH&q=85&s=35268aa0ad50b8c385913810e7604550)\n",
      "\n",
      "[](https://modelcontextprotocol.io/#what-can-mcp-enable%3F)\n",
      "\n",
      "What can MCP enable?\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "*   Agents can access your Google Calendar and Notion, acting as a more personalized AI assistant.\n",
      "*   Claude Code can generate an entire web app using a Figma design.\n",
      "*   Enterprise chatbots can connect to multiple databases across an organization, empowering users to analyze data using chat.\n",
      "*   AI models can create 3D designs on Blender and print them out using a 3D printer.\n",
      "\n",
      "[](https://modelcontextprotocol.io/#why-does-mcp-matter%3F)\n",
      "\n",
      "Why does MCP matter?\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Depending on where you sit in the ecosystem, MCP can have a range of benefits.\n",
      "*   **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent.\n",
      "*   **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience.\n",
      "*   **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary.\n",
      "\n",
      "[](https://modelcontextprotocol.io/#start-building)\n",
      "\n",
      "Start Building\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "[Build servers ------------- Create MCP servers to expose your data and tools](https://modelcontextprotocol.io/docs/develop/build-server)[Build clients ------------- Develop applications that connect to MCP servers](https://modelcontextprotocol.io/docs/develop/build-client)\n",
      "\n",
      "[](https://modelcontextprotocol.io/#learn-more)\n",
      "\n",
      "Learn more\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Understand concepts ------------------- Learn the core concepts and architecture of MCP](https://modelcontextprotocol.io/docs/learn/architecture)\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Yes No\n",
      "\n",
      "[Architecture](https://modelcontextprotocol.io/docs/learn/architecture)\n",
      "\n",
      "Ctrl+I\n",
      "\n",
      "[github](https://github.com/modelcontextprotocol)\n",
      "\n",
      "Assistant\n",
      "\n",
      "Responses are generated using AI and may contain mistakes.\n",
      "\n",
      "![Image 4](https://mintcdn.com/mcp/bEUxYpZqie0DsluH/images/mcp-simple-diagram.png?w=560&fit=max&auto=format&n=bEUxYpZqie0DsluH&q=85&s=2391513484df96fa7203739dae5e53b0)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- SOURCE 2: Introducing the Model Context Protocol ---\n",
      "URL: https://www.anthropic.com/news/model-context-protocol\n",
      "\n",
      "SUMMARY:\n",
      "[Skip to main content](https://www.anthropic.com/news/model-context-protocol#main-content)[Skip to footer](https://www.anthropic.com/news/model-context-protocol#footer) [](https://www.anthropic.com/) *   [Research](https://www.anthropic.com/research) *   [News](https://www.anthropic.com/news) Today, we're open-sourcing the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. [News ### Anthropic officially opens Tokyo office, signs Memorandum of Cooperation with the Japan AI Safety Institute Oct 29, 2025](https://www.anthropic.com/news/opening-our-tokyo-office)[News ### Advancing Claude for Financial Services Oct 27, 2025](https://www.anthropic.com/news/advancing-claude-for-financial-services)[News ### Seoul becomes Anthropics third office in Asia-Pacific as we continue our international growth Oct 23, 2025](https://www.anthropic.com/news/seoul-becomes-third-anthropic-office-in-asia-pacific) [](https://www.anthropic.com/) *   [Claude](https://claude.com/product/overview) *   [Pricing](https://claude.com/pricing) *   [Opus](https://www.anthropic.com/claude/opus) *   [Sonnet](https://www.anthropic.com/claude/sonnet) *   [Haiku](https://www.anthropic.com/claude/haiku) *   [AI agents](https://claude.com/solutions/agents) *   [Coding](https://claude.com/solutions/coding) *   [Education](https://claude.com/solutions/education) *   [Government](https://claude.com/solutions/government) *   [Courses](https://www.anthropic.com/learn) *   [Connectors](https://claude.com/partners/mcp) *   [Events](https://www.anthropic.com/events) *   [Anthropic](https://www.anthropic.com/company) *   [Careers](https://www.anthropic.com/careers) *   [Research](https://www.anthropic.com/research) *   [News](https://www.anthropic.com/news) *   [Responsible Scaling Policy](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy) *   [Transparency](https://www.anthropic.com/transparency) *   [Privacy policy](https://www.anthropic.com/legal/privacy) *   [Usage policy](https://www.anthropic.com/legal/aup) *   [](https://www.youtube.com/@anthropic-ai)\n",
      "\n",
      "FULL CONTENT:\n",
      "Introducing the Model Context Protocol \\ Anthropic\n",
      "\n",
      "===============\n",
      "\n",
      "[Skip to main content](https://www.anthropic.com/news/model-context-protocol#main-content)[Skip to footer](https://www.anthropic.com/news/model-context-protocol#footer)\n",
      "\n",
      "[](https://www.anthropic.com/)\n",
      "\n",
      "*   [Research](https://www.anthropic.com/research)\n",
      "*   [Economic Futures](https://www.anthropic.com/economic-futures)\n",
      "*   Commitments\n",
      "*   Learn\n",
      "*   [News](https://www.anthropic.com/news)\n",
      "\n",
      "[Try Claude](https://claude.ai/)\n",
      "\n",
      "Announcements\n",
      "\n",
      "Introducing the Model Context Protocol\n",
      "======================================\n",
      "\n",
      "Nov 25, 20243 min read\n",
      "\n",
      "![Image 1: An abstract illustration of critical context connecting to a central hub](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3aabd8804251c0364cbde9d2e4be6dc8e8c2faec-2880x1620.png&w=3840&q=75)\n",
      "\n",
      "Today, we're open-sourcing the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses.\n",
      "\n",
      "As AI assistants gain mainstream adoption, the industry has invested heavily in model capabilities, achieving rapid advances in reasoning and quality. Yet even the most sophisticated models are constrained by their isolation from datatrapped behind information silos and legacy systems. Every new data source requires its own custom implementation, making truly connected systems difficult to scale.\n",
      "\n",
      "MCP addresses this challenge. It provides a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. The result is a simpler, more reliable way to give AI systems access to the data they need.\n",
      "\n",
      "Model Context Protocol\n",
      "----------------------\n",
      "\n",
      "The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. The architecture is straightforward: developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers.\n",
      "\n",
      "Today, we're introducing three major components of the Model Context Protocol for developers:\n",
      "\n",
      "*   The Model Context Protocol [specification and SDKs](https://github.com/modelcontextprotocol)\n",
      "*   Local MCP server support in the [Claude Desktop apps](https://claude.ai/redirect/website.v1.fa7be63b-072d-4a81-a419-32844a7522d0/download)\n",
      "*   An [open-source repository](https://github.com/modelcontextprotocol/servers) of MCP servers\n",
      "\n",
      "Claude 3.5 Sonnet is adept at quickly building MCP server implementations, making it easy for organizations and individuals to rapidly connect their most important datasets with a range of AI-powered tools. To help developers start exploring, were sharing pre-built MCP servers for popular enterprise systems like Google Drive, Slack, GitHub, Git, Postgres, and Puppeteer.\n",
      "\n",
      "Early adopters like Block and Apollo have integrated MCP into their systems, while development tools companies including Zed, Replit, Codeium, and Sourcegraph are working with MCP to enhance their platformsenabling AI agents to better retrieve relevant information to further understand the context around a coding task and produce more nuanced and functional code with fewer attempts.\n",
      "\n",
      "\"At Block, open source is more than a development modelits the foundation of our work and a commitment to creating technology that drives meaningful change and serves as a public good for all, said Dhanji R. Prasanna, Chief Technology Officer at Block. Open technologies like the Model Context Protocol are the bridges that connect AI to real-world applications, ensuring innovation is accessible, transparent, and rooted in collaboration. We are excited to partner on a protocol and use it to build agentic systems, which remove the burden of the mechanical so people can focus on the creative.\n",
      "\n",
      "Instead of maintaining separate connectors for each data source, developers can now build against a standard protocol. As the ecosystem matures, AI systems will maintain context as they move between different tools and datasets, replacing today's fragmented integrations with a more sustainable architecture.\n",
      "\n",
      "Getting started\n",
      "---------------\n",
      "\n",
      "Developers can start building and testing MCP connectors today. All [Claude.ai](http://claude.ai/redirect/website.v1.fa7be63b-072d-4a81-a419-32844a7522d0) plans support connecting MCP servers to the Claude Desktop app.\n",
      "\n",
      "Claude for Work customers can begin testing MCP servers locally, connecting Claude to internal systems and datasets. We'll soon provide developer toolkits for deploying remote production MCP servers that can serve your entire Claude for Work organization.\n",
      "\n",
      "To start building:\n",
      "\n",
      "*   Install pre-built MCP servers through the [Claude Desktop app](https://claude.ai/redirect/website.v1.fa7be63b-072d-4a81-a419-32844a7522d0/download)\n",
      "*   Follow our [quickstart guide](https://modelcontextprotocol.io/quickstart) to build your first MCP server\n",
      "*   Contribute to our [open-source repositories](https://github.com/modelcontextprotocol) of connectors and implementations\n",
      "\n",
      "An open community\n",
      "-----------------\n",
      "\n",
      "Were committed to building MCP as a collaborative, open-source project and ecosystem, and were eager to hear your feedback. Whether youre an AI tool developer, an enterprise looking to leverage existing data, or an early adopter exploring the frontier, we invite you to build the future of context-aware AI together.\n",
      "\n",
      "[](https://twitter.com/intent/tweet?text=https://www.anthropic.com/news/model-context-protocol)[](https://www.linkedin.com/shareArticle?mini=true&url=https://www.anthropic.com/news/model-context-protocol)\n",
      "\n",
      "[News ### Anthropic officially opens Tokyo office, signs Memorandum of Cooperation with the Japan AI Safety Institute Oct 29, 2025](https://www.anthropic.com/news/opening-our-tokyo-office)[News ### Advancing Claude for Financial Services Oct 27, 2025](https://www.anthropic.com/news/advancing-claude-for-financial-services)[News ### Seoul becomes Anthropics third office in Asia-Pacific as we continue our international growth Oct 23, 2025](https://www.anthropic.com/news/seoul-becomes-third-anthropic-office-in-asia-pacific)\n",
      "\n",
      "[](https://www.anthropic.com/)\n",
      "\n",
      "### Products\n",
      "\n",
      "*   [Claude](https://claude.com/product/overview)\n",
      "*   [Claude Code](https://claude.com/product/claude-code)\n",
      "*   [Claude and Slack](https://claude.com/claude-and-slack)\n",
      "*   [Claude in Excel](https://claude.com/claude-for-excel)\n",
      "*   [Max plan](https://claude.com/pricing/max)\n",
      "*   [Team plan](https://claude.com/pricing/team)\n",
      "*   [Enterprise plan](https://claude.com/pricing/enterprise)\n",
      "*   [Download app](https://claude.ai/download)\n",
      "*   [Pricing](https://claude.com/pricing)\n",
      "*   [Log in to Claude](https://claude.ai/)\n",
      "\n",
      "### Models\n",
      "\n",
      "*   [Opus](https://www.anthropic.com/claude/opus)\n",
      "*   [Sonnet](https://www.anthropic.com/claude/sonnet)\n",
      "*   [Haiku](https://www.anthropic.com/claude/haiku)\n",
      "\n",
      "### Solutions\n",
      "\n",
      "*   [AI agents](https://claude.com/solutions/agents)\n",
      "*   [Code modernization](https://claude.com/solutions/code-modernization)\n",
      "*   [Coding](https://claude.com/solutions/coding)\n",
      "*   [Customer support](https://claude.com/solutions/customer-support)\n",
      "*   [Education](https://claude.com/solutions/education)\n",
      "*   [Financial services](https://claude.com/solutions/financial-services)\n",
      "*   [Government](https://claude.com/solutions/government)\n",
      "*   [Life sciences](https://claude.com/solutions/life-sciences)\n",
      "\n",
      "### Claude Developer Platform\n",
      "\n",
      "*   [Overview](https://claude.com/platform/api)\n",
      "*   [Developer docs](https://docs.claude.com/en/home)\n",
      "*   [Pricing](https://claude.com/pricing#api)\n",
      "*   [Amazon Bedrock](https://claude.com/partners/amazon-bedrock)\n",
      "*   [Google Clouds Vertex AI](https://claude.com/partners/google-cloud-vertex-ai)\n",
      "*   [Console login](http://console.anthropic.com/)\n",
      "\n",
      "### Learn\n",
      "\n",
      "*   [Courses](https://www.anthropic.com/learn)\n",
      "*   [Connectors](https://claude.com/partners/mcp)\n",
      "*   [Customer stories](https://claude.com/customers)\n",
      "*   [Engineering at Anthropic](https://www.anthropic.com/engineering)\n",
      "*   [Events](https://www.anthropic.com/events)\n",
      "*   [Powered by Claude](https://claude.com/partners/powered-by-claude)\n",
      "*   [Service partners](https://claude.com/partners/services)\n",
      "*   [Startups program](https://claude.com/programs/startups)\n",
      "\n",
      "### Company\n",
      "\n",
      "*   [Anthropic](https://www.anthropic.com/company)\n",
      "*   [Careers](https://www.anthropic.com/careers)\n",
      "*   [Economic Futures](https://www.anthropic.com/economic-index)\n",
      "*   [Research](https://www.anthropic.com/research)\n",
      "*   [News](https://www.anthropic.com/news)\n",
      "*   [Responsible Scaling Policy](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)\n",
      "*   [Security and compliance](https://trust.anthropic.com/)\n",
      "*   [Transparency](https://www.anthropic.com/transparency)\n",
      "\n",
      "### Help and security\n",
      "\n",
      "*   [Availability](https://www.anthropic.com/supported-countries)\n",
      "*   [Status](https://status.anthropic.com/)\n",
      "*   [Support center](https://support.claude.com/en/)\n",
      "\n",
      "### Terms and policies\n",
      "\n",
      "*   [Privacy policy](https://www.anthropic.com/legal/privacy)\n",
      "*   [Responsible disclosure policy](https://www.anthropic.com/responsible-disclosure-policy)\n",
      "*   [Terms of service: Commercial](https://www.anthropic.com/legal/commercial-terms)\n",
      "*   [Terms of service: Consumer](https://www.anthropic.com/legal/consumer-terms)\n",
      "*   [Usage policy](https://www.anthropic.com/legal/aup)\n",
      "\n",
      " 2025 Anthropic PBC\n",
      "*   [](https://www.linkedin.com/company/anthropicresearch)\n",
      "*   [](https://x.com/AnthropicAI)\n",
      "*   [](https://www.youtube.com/@anthropic-ai)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- SOURCE 3: Model Context Protocol ---\n",
      "URL: https://en.wikipedia.org/wiki/Model_Context_Protocol\n",
      "\n",
      "SUMMARY:\n",
      "The **Model Context Protocol** (**MCP**) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. The protocol was announced by Anthropic in November 2024 as an open standard for connecting AI assistants to data systems such as content repositories, business management tools, and development environments. Key components of the protocol include a formal protocol specification and software development kits (SDKs), local MCP server support in Claude \"Claude (language model)\") Desktop applications, and an open-source repository \"Repository (version control)\") of MCP server implementations. \"Introducing Model Context Protocol (MCP) in Copilot Studio: Simplified Integration with AI Apps and Agents\".\n",
      "\n",
      "FULL CONTENT:\n",
      "[Jump to content](#bodyContent)\n",
      "\n",
      "[Search](/wiki/Special:Search \"Search Wikipedia [f]\")\n",
      "\n",
      "## Contents\n",
      "\n",
      "* [(Top)](#)\n",
      "* [1 Background](#Background)\n",
      "* [2 Features](#Features)\n",
      "* [3 Applications](#Applications)\n",
      "* [4 Implementation](#Implementation)\n",
      "* [5 Adoption](#Adoption)\n",
      "* [6 Reception](#Reception)\n",
      "* [7 See also](#See_also)\n",
      "* [8 References](#References)\n",
      "* [9 Further reading](#Further_reading)\n",
      "* [10 External links](#External_links)\n",
      "\n",
      "# Model Context Protocol\n",
      "\n",
      "* [Catal](https://ca.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Catalan\")\n",
      "* [Deutsch](https://de.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  German\")\n",
      "* [Espaol](https://es.wikipedia.org/wiki/Protocolo_de_Contexto_de_Modelo \"Protocolo de Contexto de Modelo  Spanish\")\n",
      "* [](https://fa.wikipedia.org/wiki/%D9%BE%D8%B1%D9%88%D8%AA%DA%A9%D9%84_%D8%B2%D9%85%DB%8C%D9%86%D9%87_%D9%85%D8%AF%D9%84 \"    Persian\")\n",
      "* [Franais](https://fr.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  French\")\n",
      "* [](https://ko.wikipedia.org/wiki/%EB%AA%A8%EB%8D%B8_%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8_%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C \"    Korean\")\n",
      "* [Italiano](https://it.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Italian\")\n",
      "* [](https://he.wikipedia.org/wiki/%D7%A4%D7%A8%D7%95%D7%98%D7%95%D7%A7%D7%95%D7%9C_%D7%94%D7%A7%D7%A9%D7%A8_%D7%9E%D7%95%D7%93%D7%9C \"    Hebrew\")\n",
      "* [Nederlands](https://nl.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Dutch\")\n",
      "* [](https://ja.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Japanese\")\n",
      "* [Norsk bokml](https://no.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Norwegian Bokml\")\n",
      "* [Polski](https://pl.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Polish\")\n",
      "* [](https://ru.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Russian\")\n",
      "* [Trke](https://tr.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Turkish\")\n",
      "* [Ting Vit](https://vi.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol  Vietnamese\")\n",
      "* [](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE \"  Chinese\")\n",
      "* [ ](https://zgh.wikipedia.org/wiki/%E2%B4%B0%E2%B4%B1%E2%B5%94%E2%B5%93%E2%B5%9C%E2%B5%93%E2%B4%BD%E2%B5%93%E2%B5%8D_%E2%B5%8F_%E2%B5%93%E2%B5%8E%E2%B5%8F%E2%B4%B0%E2%B4%B9_%E2%B5%8F_%E2%B5%93%E2%B5%A3%E2%B5%93%E2%B5%94%E2%B5%9C \"      Standard Moroccan Tamazight\")\n",
      "\n",
      "[Edit links](https://www.wikidata.org/wiki/Special:EntityPage/Q133436854#sitelinks-wikipedia \"Edit interlanguage links\")\n",
      "\n",
      "* [Article](/wiki/Model_Context_Protocol \"View the content page [c]\")\n",
      "* [Talk](/wiki/Talk:Model_Context_Protocol \"Discuss improvements to the content page [t]\")\n",
      "\n",
      "* [Read](/wiki/Model_Context_Protocol)\n",
      "* [Edit](/w/index.php?title=Model_Context_Protocol&action=edit \"Edit this page [e]\")\n",
      "* [View history](/w/index.php?title=Model_Context_Protocol&action=history \"Past revisions of this page [h]\")\n",
      "\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "Actions\n",
      "\n",
      "* [Read](/wiki/Model_Context_Protocol)\n",
      "* [Edit](/w/index.php?title=Model_Context_Protocol&action=edit \"Edit this page [e]\")\n",
      "* [View history](/w/index.php?title=Model_Context_Protocol&action=history)\n",
      "\n",
      "General\n",
      "\n",
      "* [What links here](/wiki/Special:WhatLinksHere/Model_Context_Protocol \"List of all English Wikipedia pages containing links to this page [j]\")\n",
      "* [Related changes](/wiki/Special:RecentChangesLinked/Model_Context_Protocol \"Recent changes in pages linked from this page [k]\")\n",
      "* [Upload file](//en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard \"Upload files [u]\")\n",
      "* [Permanent link](/w/index.php?title=Model_Context_Protocol&oldid=1317185791 \"Permanent link to this revision of this page\")\n",
      "* [Page information](/w/index.php?title=Model_Context_Protocol&action=info \"More information about this page\")\n",
      "* [Cite this page](/w/index.php?title=Special:CiteThisPage&page=Model_Context_Protocol&id=1317185791&wpFormIdentifier=titleform \"Information on how to cite this page\")\n",
      "* [Get shortened URL](/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FModel_Context_Protocol)\n",
      "* [Download QR code](/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FModel_Context_Protocol)\n",
      "\n",
      "Print/export\n",
      "\n",
      "* [Download as PDF](/w/index.php?title=Special:DownloadAsPdf&page=Model_Context_Protocol&action=show-download-screen \"Download this page as a PDF file\")\n",
      "* [Printable version](/w/index.php?title=Model_Context_Protocol&printable=yes \"Printable version of this page [p]\")\n",
      "\n",
      "In other projects\n",
      "\n",
      "* [Wikimedia Commons](https://commons.wikimedia.org/wiki/Category:Model_Context_Protocol)\n",
      "* [Wikidata item](https://www.wikidata.org/wiki/Special:EntityPage/Q133436854 \"Structured data on this page hosted by Wikidata [g]\")\n",
      "\n",
      "Appearance\n",
      "\n",
      "From Wikipedia, the free encyclopedia\n",
      "\n",
      "Protocol for communicating between LLMs and applications\n",
      "\n",
      "Model Context Protocol\n",
      "\n",
      "| Developed by | [Anthropic](/wiki/Anthropic \"Anthropic\") |\n",
      "| Introduced | November25, 2024; 11 months ago(2024-11-25) |\n",
      "| Industry | [Artificial intelligence](/wiki/Artificial_intelligence \"Artificial intelligence\") |\n",
      "| Connector type | * [TypeScript](/wiki/TypeScript \"TypeScript\") * [Python](/wiki/Python_(programming_language) \"Python (programming language)\") * [Java](/wiki/Java_(programming_language) \"Java (programming language)\") * [Kotlin](/wiki/Kotlin_(programming_language) \"Kotlin (programming language)\") * [C#](/wiki/C_Sharp_(programming_language) \"C Sharp (programming language)\") * [Go](/wiki/Go_(programming_language) \"Go (programming language)\") * [PHP](/wiki/PHP \"PHP\") * [Ruby](/wiki/Ruby_(programming_language) \"Ruby (programming language)\") * [Rust](/wiki/Rust_(programming_language) \"Rust (programming language)\") * [Swift](/wiki/Swift_(programming_language) \"Swift (programming language)\") |\n",
      "| Website | [modelcontextprotocol.io](https://modelcontextprotocol.io) |\n",
      "\n",
      "The **Model Context Protocol** (**MCP**) is an [open standard](/wiki/Open_standard \"Open standard\"), [open-source](/wiki/Open-source \"Open-source\") [framework](/wiki/Software_framework \"Software framework\") introduced by [Anthropic](/wiki/Anthropic \"Anthropic\") in November 2024 to standardize the way [artificial intelligence](/wiki/Artificial_intelligence \"Artificial intelligence\") (AI) systems like [large language models](/wiki/Large_language_model \"Large language model\") (LLMs) integrate and share data with external tools, systems, and data sources.[[1]](#cite_note-venturebeat-2024-11-25-1) MCP provides a universal interface for reading files, executing functions, and handling contextual prompts.[[2]](#cite_note-venturebeat_2025-03-27-2) Following its announcement, the protocol was adopted by major AI providers, including [OpenAI](/wiki/OpenAI \"OpenAI\") and [Google DeepMind](/wiki/Google_DeepMind \"Google DeepMind\").[[3]](#cite_note-TechCrunch_2025-03-25-3)[[4]](#cite_note-TechCrunch_2025-04-09-4)\n",
      "\n",
      "## Background\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=1 \"Edit section: Background\")]\n",
      "\n",
      "The protocol was announced by [Anthropic](/wiki/Anthropic \"Anthropic\") in November 2024 as an open standard[[5]](#cite_note-verge_2024-11-25-5) for connecting AI assistants to data systems such as [content repositories](/wiki/Content_repository \"Content repository\"), [business management tools](/wiki/Business_management_tools \"Business management tools\"), and [development environments](/wiki/Deployment_environment#Development \"Deployment environment\").[[6]](#cite_note-anthropic_2024-11-6) It aims to address the challenge of [information silos](/wiki/Information_silo \"Information silo\") and [legacy systems](/wiki/Legacy_system \"Legacy system\").[[6]](#cite_note-anthropic_2024-11-6) Before MCP, developers often had to build custom connectors for each data source or tool, resulting in what Anthropic described as an \"NM\" [data integration](/wiki/Data_integration \"Data integration\") problem.[[6]](#cite_note-anthropic_2024-11-6)\n",
      "\n",
      "Earlier stop-gap approachessuch as OpenAI's 2023 \"function-calling\" [API](/wiki/API \"API\") and the [ChatGPT](/wiki/ChatGPT \"ChatGPT\") plug-in frameworksolved similar problems but required vendor-specific connectors.[[7]](#cite_note-ars-usbc-7) MCP's authors note that the protocol deliberately re-uses the message-flow ideas of the [Language Server Protocol](/wiki/Language_Server_Protocol \"Language Server Protocol\") (LSP) and is transported over [JSON-RPC](/wiki/JSON-RPC \"JSON-RPC\") 2.0.[[8]](#cite_note-:1-8) MCP formally specifies [stdio](/wiki/Standard_streams \"Standard streams\") and [HTTP](/wiki/HTTP \"HTTP\") (optionally with [SSE](/wiki/Server-sent_events \"Server-sent events\")) as its standard transport mechanisms.[[9]](#cite_note-9)\n",
      "\n",
      "## Features\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=2 \"Edit section: Features\")]\n",
      "\n",
      "MCP defines a standardized framework for integrating AI systems with external data sources and tools.[[2]](#cite_note-venturebeat_2025-03-27-2) It includes specifications for [data ingestion](/wiki/Data_preparation \"Data preparation\") and [transformation](/wiki/Data_transformation_(computing) \"Data transformation (computing)\"), contextual [metadata](/wiki/Metadata \"Metadata\") [tagging](/wiki/Tag_(metadata) \"Tag (metadata)\"), and AI interoperability across different platforms. The protocol also supports secure, bidirectional connections between data sources and AI-powered tools.[[6]](#cite_note-anthropic_2024-11-6)\n",
      "\n",
      "MCP enables developers to expose their data via MCP servers or to develop AI applicationsreferred to as MCP clientsthat connect to these servers.[[6]](#cite_note-anthropic_2024-11-6) Key components of the protocol include a formal protocol specification and software development kits (SDKs), local MCP server support in [Claude](/wiki/Claude_(language_model) \"Claude (language model)\") Desktop applications, and an open-source [repository](/wiki/Repository_(version_control) \"Repository (version control)\") of MCP server implementations.[[6]](#cite_note-anthropic_2024-11-6)\n",
      "\n",
      "## Applications\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=3 \"Edit section: Applications\")]\n",
      "\n",
      "In the field of natural language data access, MCP enables applications such as AI2SQL to bridge language models with structured databases, allowing plain-language queries.[[8]](#cite_note-:1-8)\n",
      "\n",
      "The protocol is used in [AI-assisted software development](/wiki/AI-assisted_software_development \"AI-assisted software development\") tools. [Integrated development environments](/wiki/Integrated_development_environment \"Integrated development environment\") (IDEs), coding platforms such as [Replit](/wiki/Replit \"Replit\"), and code intelligence tools like [Sourcegraph](/wiki/Sourcegraph \"Sourcegraph\") have adopted MCP to grant AI coding assistants real-time access to project context.[[5]](#cite_note-verge_2024-11-25-5)\n",
      "\n",
      "## Implementation\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=4 \"Edit section: Implementation\")]\n",
      "\n",
      "The protocol was released with [software development kits](/wiki/Software_development_kits \"Software development kits\") (SDKs) in [programming languages](/wiki/Programming_languages \"Programming languages\") including [Python](/wiki/Python_(programming_language) \"Python (programming language)\"), [TypeScript](/wiki/TypeScript \"TypeScript\"), [C#](/wiki/C_Sharp_(programming_language) \"C Sharp (programming language)\") and [Java](/wiki/Java_(programming_language) \"Java (programming language)\").[[8]](#cite_note-:1-8)[[10]](#cite_note-10) Anthropic maintains an open-source repository of reference MCP server implementations for popular enterprise systems including [Google Drive](/wiki/Google_Drive \"Google Drive\"), [Slack](/wiki/Slack_(software) \"Slack (software)\"), [GitHub](/wiki/GitHub \"GitHub\"), [Git](/wiki/Git \"Git\"), [Postgres](/wiki/PostgreSQL \"PostgreSQL\"), [Puppeteer](/wiki/Puppeteer_(software) \"Puppeteer (software)\") and [Stripe](/wiki/Stripe,_Inc. \"Stripe, Inc.\").[[11]](#cite_note-:0-11) Developers can create custom MCP servers to connect [proprietary systems](/wiki/Proprietary_software \"Proprietary software\") or specialized data sources to AI systems.[[11]](#cite_note-:0-11)\n",
      "\n",
      "The protocol's open standard allows organizations to build tailored connections while maintaining compatibility with the broader MCP ecosystem. AI systems can then leverage these custom connections to provide [domain](/wiki/Domain_(software_engineering) \"Domain (software engineering)\")-specific assistance while respecting data access permissions.[[6]](#cite_note-anthropic_2024-11-6)\n",
      "\n",
      "## Adoption\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=5 \"Edit section: Adoption\")]\n",
      "\n",
      "In March 2025, [OpenAI](/wiki/OpenAI \"OpenAI\") officially adopted the MCP, following a decision to integrate the standard across its products, including the [ChatGPT](/wiki/ChatGPT \"ChatGPT\") desktop app, OpenAI's Agents SDK, and the Responses API.[[3]](#cite_note-TechCrunch_2025-03-25-3)[[2]](#cite_note-venturebeat_2025-03-27-2)\n",
      "\n",
      "MCP can be integrated with [Microsoft](/wiki/Microsoft \"Microsoft\") Semantic Kernel,[[12]](#cite_note-12) and [Azure](/wiki/Microsoft_Azure \"Microsoft Azure\") OpenAI.[[13]](#cite_note-13) MCP servers can be deployed to [Cloudflare](/wiki/Cloudflare \"Cloudflare\").[[14]](#cite_note-14)\n",
      "\n",
      "[Demis Hassabis](/wiki/Demis_Hassabis \"Demis Hassabis\"), CEO of [Google DeepMind](/wiki/Google_DeepMind \"Google DeepMind\"), confirmed in April 2025 MCP support in the upcoming [Gemini](/wiki/Gemini_(chatbot) \"Gemini (chatbot)\") models and related infrastructure.[[4]](#cite_note-TechCrunch_2025-04-09-4)\n",
      "\n",
      "## Reception\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=6 \"Edit section: Reception\")]\n",
      "\n",
      "*[The Verge](/wiki/The_Verge \"The Verge\")* reported that MCP addresses a growing demand for AI agents that are contextually aware and capable of securely pulling from diverse sources.[[5]](#cite_note-verge_2024-11-25-5) The protocol's rapid uptake by OpenAI, Google DeepMind, and toolmakers like Zed and Sourcegraph suggests growing consensus around its utility.[[3]](#cite_note-TechCrunch_2025-03-25-3)[[15]](#cite_note-beebom_mcp-15)\n",
      "\n",
      "In April 2025, security researchers released analysis that there are multiple outstanding security issues with MCP, including [prompt injection](/wiki/Prompt_injection \"Prompt injection\"),[[16]](#cite_note-16) tool permissions where combining tools can exfiltrate files,[[17]](#cite_note-17) and lookalike tools can silently replace trusted ones.[[18]](#cite_note-18)\n",
      "\n",
      "It has been likened to [OpenAPI](/wiki/OpenAPI_Specification \"OpenAPI Specification\"), a similar specification that aims to describe APIs.[[19]](#cite_note-19)[[20]](#cite_note-20)\n",
      "\n",
      "## See also\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=7 \"Edit section: See also\")]\n",
      "\n",
      "* [AI governance](/wiki/AI_governance \"AI governance\") Guidelines and laws to regulate AIPages displaying short descriptions of redirect targets\n",
      "* [Application programming interface](/wiki/Application_programming_interface \"Application programming interface\") Connection between computers or programsPages displaying short descriptions of redirect targets\n",
      "* [LangChain](/wiki/LangChain \"LangChain\") Language model application development framework\n",
      "* [Machine learning](/wiki/Machine_learning \"Machine learning\") Study of algorithms that improve automatically through experience\n",
      "* [Software agent](/wiki/Software_agent \"Software agent\") Computer program acting for a user\n",
      "\n",
      "## References\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=8 \"Edit section: References\")]\n",
      "\n",
      "1. **[^](#cite_ref-venturebeat-2024-11-25_1-0)** David, Emilia (November 25, 2024). [\"Anthropic releases Model Context Protocol to standardize AI-data integration\"](https://venturebeat.com/data-infrastructure/anthropic-releases-model-context-protocol-to-standardize-ai-data-integration/). [VentureBeat](/wiki/VentureBeat \"VentureBeat\"). Retrieved 2025-05-12.\n",
      "2. ^ [***a***](#cite_ref-venturebeat_2025-03-27_2-0) [***b***](#cite_ref-venturebeat_2025-03-27_2-1) [***c***](#cite_ref-venturebeat_2025-03-27_2-2) Kumar, Vinay (March 26, 2025). [\"The open source Model Context Protocol was just updated  here's why it's a big deal\"](https://venturebeat.com/ai/the-open-source-model-context-protocol-was-just-updated-heres-why-its-a-big-deal/). [VentureBeat](/wiki/VentureBeat \"VentureBeat\"). Retrieved 2025-05-12.\n",
      "3. ^ [***a***](#cite_ref-TechCrunch_2025-03-25_3-0) [***b***](#cite_ref-TechCrunch_2025-03-25_3-1) [***c***](#cite_ref-TechCrunch_2025-03-25_3-2) Wiggers, Kyle (March 25, 2025). [\"OpenAI adopts rival Anthropic's standard for connecting AI models to data\"](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/). [TechCrunch](/wiki/TechCrunch \"TechCrunch\").\n",
      "4. ^ [***a***](#cite_ref-TechCrunch_2025-04-09_4-0) [***b***](#cite_ref-TechCrunch_2025-04-09_4-1) Wiggers, Kyle (April 9, 2025). [\"Google to embrace Anthropic's standard for connecting AI models to data\"](https://techcrunch.com/2025/04/09/google-says-itll-embrace-anthropics-standard-for-connecting-ai-models-to-data/). TechCrunch. Retrieved 2025-05-12.\n",
      "5. ^ [***a***](#cite_ref-verge_2024-11-25_5-0) [***b***](#cite_ref-verge_2024-11-25_5-1) [***c***](#cite_ref-verge_2024-11-25_5-2) Roth, Emma (November 25, 2024). [\"Anthropic launches tool to connect AI systems directly to datasets\"](https://www.theverge.com/2024/11/25/24305774/anthropic-model-context-protocol-data-sources). [The Verge](/wiki/The_Verge \"The Verge\").\n",
      "6. ^ [***a***](#cite_ref-anthropic_2024-11_6-0) [***b***](#cite_ref-anthropic_2024-11_6-1) [***c***](#cite_ref-anthropic_2024-11_6-2) [***d***](#cite_ref-anthropic_2024-11_6-3) [***e***](#cite_ref-anthropic_2024-11_6-4) [***f***](#cite_ref-anthropic_2024-11_6-5) [***g***](#cite_ref-anthropic_2024-11_6-6) [\"Introducing the Model Context Protocol\"](https://www.anthropic.com/news/model-context-protocol). Anthropic. November 25, 2024. Retrieved 2025-05-12.[*[non-primary source needed](/wiki/Wikipedia:No_original_research#Primary,_secondary_and_tertiary_sources \"Wikipedia:No original research\")*]\n",
      "7. **[^](#cite_ref-ars-usbc_7-0)** Edwards, Benj (1 April 2025). [\"MCP: The new \"USB-C for AI\" that's bringing fierce rivals together\"](https://arstechnica.com/information-technology/2025/04/mcp-the-new-usb-c-for-ai-thats-bringing-fierce-rivals-together/). *Ars Technica*. Retrieved 2025-05-24.\n",
      "8. ^ [***a***](#cite_ref-:1_8-0) [***b***](#cite_ref-:1_8-1) [***c***](#cite_ref-:1_8-2) Ouellette, Michael (2025-05-09). [\"Model context protocol: the next big step in generating value from AI\"](https://www.engineering.com/model-context-protocol-the-next-big-step-in-generating-value-from-ai/). *Engineering.com*. Retrieved 2025-06-23.\n",
      "9. **[^](#cite_ref-9)** [\"Transports  Model Context Protocol\"](https://contextprotocol.dev/specification/2025-03-26/basic/transports). Retrieved 2025-08-07.\n",
      "10. **[^](#cite_ref-10)** [\"Model Context Protocol\"](https://github.com/modelcontextprotocol). *GitHub*. Retrieved 2025-06-20.\n",
      "11. ^ [***a***](#cite_ref-:0_11-0) [***b***](#cite_ref-:0_11-1) Bastian, Matthias (2024-11-25). [\"Anthropic's new open protocol lets AI systems tap into any data source\"](https://the-decoder.com/anthropics-new-open-protocol-lets-ai-systems-tap-into-any-data-source/). *The Decoder*. Retrieved 2025-06-14.\n",
      "12. **[^](#cite_ref-12)**  Wallace, Mark (March 5, 2025). [\"Integrating Model Context Protocol Tools with Semantic Kernel: A Step-by-Step Guide\"](https://devblogs.microsoft.com/semantic-kernel/integrating-model-context-protocol-tools-with-semantic-kernel-a-step-by-step-guide/). *Semantic Kernel Dev Blog, Microsoft*. Retrieved 2025-05-12.\n",
      "13. **[^](#cite_ref-13)**  mrajguru (March 16, 2025). [\"Model Context Protocol (MCP): Integrating Azure OpenAI for Enhanced Tool Integration and Prompting\"](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/model-context-protocol-mcp-integrating-azure-openai-for-enhanced-tool-integratio/4393788). *AI - Azure AI services Blog, Microsoft*. Retrieved 2025-05-12.\n",
      "14. **[^](#cite_ref-14)** Brendan Irvine-Broque; Dina Kozlov; Glen Maddern (March 25, 2025). [\"Build and deploy Remote Model Context Protocol (MCP) servers to Cloudflare\"](https://blog.cloudflare.com/remote-model-context-protocol-servers-mcp/). [Cloudflare](/wiki/Cloudflare \"Cloudflare\"). Retrieved 2025-05-12.\n",
      "15. **[^](#cite_ref-beebom_mcp_15-0)** Sha, Arjun (April 14, 2025). [\"What is Model Context Protocol (MCP) Explained\"](https://beebom.com/model-context-protocol-mcp-explained/). *Beebom.com*.\n",
      "16. **[^](#cite_ref-16)** Lakshmanan, Ravie (30 April 2025). [\"Researchers Demonstrate How MCP Prompt Injection Can Be Used for Both Attack and Defense\"](https://thehackernews.com/2025/04/experts-uncover-critical-mcp-and-a2a.html). thehackernews.com.\n",
      "17. **[^](#cite_ref-17)** Beurer-Kellner, Luca; Fischer, Marc (1 April 2025). [\"MCP Security Notification: Tool Poisoning Attacks\"](https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks). InvariantLabs.\n",
      "18. **[^](#cite_ref-18)** Schulz, Kasimir; Martin, Jason; Kan, Marcus; Yeung, Kenneth; McCauley, Conor; Ring, Leo (10 April 2025). [\"MCP: Model Context Pitfalls in an Agentic World\"](https://hiddenlayer.com/innovation-hub/mcp-model-context-pitfalls-in-an-agentic-world/). hiddenlayer.com.\n",
      "19. **[^](#cite_ref-19)** MacManus, Richard (13 March 2025). [\"MCP: The Missing Link Between AI Agents and APIs\"](https://thenewstack.io/mcp-the-missing-link-between-ai-agents-and-apis/). *The New Stack*. Retrieved 29 May 2025.\n",
      "20. **[^](#cite_ref-20)** Fanelli, Alessio. [\"Why MCP Won\"](https://www.latent.space/p/why-mcp-won). *www.latent.space*. Retrieved 29 May 2025.\n",
      "\n",
      "## Further reading\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=9 \"Edit section: Further reading\")]\n",
      "\n",
      "* Hou, Xinyi; Zhao, Yanjie; Wang, Shenao; Wang, Haoyu (2025). \"Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions\". [arXiv](/wiki/ArXiv_(identifier) \"ArXiv (identifier)\"):[2503.23278](https://arxiv.org/abs/2503.23278) [[cs.CR](https://arxiv.org/archive/cs.CR)].\n",
      "* Edwards, Benj (April 1, 2025). [\"MCP: The new \"USB-C for AI\" that's bringing fierce rivals together\"](https://arstechnica.com/information-technology/2025/04/mcp-the-new-usb-c-for-ai-thats-bringing-fierce-rivals-together). [Ars Technica](/wiki/Ars_Technica \"Ars Technica\").\n",
      "* Jackson, Fiona (March 28, 2025). [\"OpenAI Agents Now Support Rival Anthropic's Protocol, Making Data Access 'Simpler, More Reliable'\"](https://www.techrepublic.com/article/news-openai-anthropic-model-context-protocol/). [TechRepublic](/wiki/TechRepublic \"TechRepublic\").\n",
      "* Masson, Colin (March 25, 2025). [\"Context Is the Missing Link: The Emergence of the Model Context Protocol in Industrial AI\"](https://www.arcweb.com/blog/context-missing-link-emergence-model-context-protocol-industrial-ai). ARC Advisory Group.\n",
      "* Jimin Kim; Anita Lewis; Justin Lewis; Laith Al-Saadoon; Paul Vincent; Pranjali Bhandari (April 1, 2025). [\"Introducing AWS MCP Servers for code assistants (Part 1)\"](https://aws.amazon.com/blogs/machine-learning/introducing-aws-mcp-servers-for-code-assistants-part-1/). [Amazon AWS](/wiki/Amazon_AWS \"Amazon AWS\").\n",
      "* Desai, Zankar (March 19, 2025). [\"Introducing Model Context Protocol (MCP) in Copilot Studio: Simplified Integration with AI Apps and Agents\"](https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio/introducing-model-context-protocol-mcp-in-copilot-studio-simplified-integration-with-ai-apps-and-agents/). Microsoft Copilot Studio Blog, [Microsoft](/wiki/Microsoft \"Microsoft\").\n",
      "* Wagner, Tim (May 13, 2025). [\"Understanding Model Context Protocol (MCP)\"](https://www.vendia.com/blog/understanding-model-context-protocol-mcp/). *Vendia*.\n",
      "\n",
      "## External links\n",
      "\n",
      "[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=10 \"Edit section: External links\")]\n",
      "\n",
      "* [Official website](https://modelcontextprotocol.io)\n",
      "* [modelcontextprotocol](https://github.com/modelcontextprotocol) on [GitHub](/wiki/GitHub \"GitHub\")\n",
      "\n",
      "| * [v](/wiki/Template:Generative_AI \"Template:Generative AI\") * [t](/wiki/Template_talk:Generative_AI \"Template talk:Generative AI\") * [e](/wiki/Special:EditPage/Template:Generative_AI \"Special:EditPage/Template:Generative AI\")  [Generative AI](/wiki/Generative_artificial_intelligence \"Generative artificial intelligence\") |\n",
      "| --- |\n",
      "| Concepts | * [Autoencoder](/wiki/Autoencoder \"Autoencoder\") * [Deep learning](/wiki/Deep_learning \"Deep learning\") * [Fine-tuning](/wiki/Fine-tuning_(deep_learning) \"Fine-tuning (deep learning)\") * [Foundation model](/wiki/Foundation_model \"Foundation model\") * [Generative adversarial network](/wiki/Generative_adversarial_network \"Generative adversarial network\") * [Generative pre-trained transformer](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\") * [Large language model](/wiki/Large_language_model \"Large language model\") * Model Context Protocol * [Neural network](/wiki/Neural_network_(machine_learning) \"Neural network (machine learning)\") * [Prompt engineering](/wiki/Prompt_engineering \"Prompt engineering\") * [Reinforcement learning from human feedback](/wiki/Reinforcement_learning_from_human_feedback \"Reinforcement learning from human feedback\") * [Retrieval-augmented generation](/wiki/Retrieval-augmented_generation \"Retrieval-augmented generation\") * [Self-supervised learning](/wiki/Self-supervised_learning \"Self-supervised learning\") * [Stochastic parrot](/wiki/Stochastic_parrot \"Stochastic parrot\") * [Synthetic data](/wiki/Synthetic_data \"Synthetic data\") * [Top-p sampling](/wiki/Top-p_sampling \"Top-p sampling\") * [Transformer](/wiki/Transformer_(deep_learning_architecture) \"Transformer (deep learning architecture)\") * [Variational autoencoder](/wiki/Variational_autoencoder \"Variational autoencoder\") * [Vibe coding](/wiki/Vibe_coding \"Vibe coding\") * [Vision transformer](/wiki/Vision_transformer \"Vision transformer\") * [Waluigi effect](/wiki/Waluigi_effect \"Waluigi effect\") * [Word embedding](/wiki/Word_embedding \"Word embedding\") |\n",
      "| Models | |  |  | | --- | --- | | Text | * [Character.ai](/wiki/Character.ai \"Character.ai\") * [ChatGPT](/wiki/ChatGPT \"ChatGPT\") * [Command A](/wiki/Cohere#Products \"Cohere\") * [Claude](/wiki/Claude_(language_model) \"Claude (language model)\") * [DeepSeek](/wiki/DeepSeek_(chatbot) \"DeepSeek (chatbot)\") * [Ernie](/wiki/Ernie_Bot \"Ernie Bot\") * [Gemini](/wiki/Google_Gemini \"Google Gemini\") * [Gemma](/wiki/Gemma_(language_model) \"Gemma (language model)\") * [GLM](/wiki/Z.ai#GLM \"Z.ai\") * [GPT](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\")   + [1](/wiki/GPT-1 \"GPT-1\")   + [2](/wiki/GPT-2 \"GPT-2\")   + [3](/wiki/GPT-3 \"GPT-3\")   + [J](/wiki/GPT-J \"GPT-J\")   + [3.5](/wiki/GPT-3.5 \"GPT-3.5\")   + [4](/wiki/GPT-4 \"GPT-4\")   + [4o](/wiki/GPT-4o \"GPT-4o\")   + [o1](/wiki/OpenAI_o1 \"OpenAI o1\")   + [o3](/wiki/OpenAI_o3 \"OpenAI o3\")   + [4.5](/wiki/GPT-4.5 \"GPT-4.5\")   + [4.1](/wiki/GPT-4.1 \"GPT-4.1\")   + [o4-mini](/wiki/OpenAI_o4-mini \"OpenAI o4-mini\")   + [OSS](/wiki/GPT-OSS \"GPT-OSS\")   + [5](/wiki/GPT-5 \"GPT-5\") * [Grok](/wiki/Grok_(chatbot) \"Grok (chatbot)\") * [Hunyuan T1](/wiki/Tencent#2021present:_Regulatory_scrutiny \"Tencent\") * [Kimi](/wiki/Kimi_(chatbot) \"Kimi (chatbot)\") * [Llama](/wiki/Llama_(language_model) \"Llama (language model)\") * [Microsoft Copilot](/wiki/Microsoft_Copilot \"Microsoft Copilot\") * [MiniMax M2](/wiki/MiniMax_(company)#Technology \"MiniMax (company)\") * [Mistral Medium](/wiki/Mistral_AI#Mistral_Medium_3 \"Mistral AI\") * [Qwen](/wiki/Qwen \"Qwen\") * [Velvet](/wiki/Velvet_AI \"Velvet AI\") * [Solar Pro](/wiki/Upstage_(company)#Models \"Upstage (company)\") | | Coding | * [Base44](/wiki/Base44 \"Base44\") * [Claude Code](/wiki/Anthropic#Additional_funding_and_partnerships_(2025) \"Anthropic\") * [Cursor](/wiki/Cursor_(code_editor) \"Cursor (code editor)\") * [Devstral](/wiki/Mistral_AI \"Mistral AI\") * [GitHub Copilot](/wiki/GitHub_Copilot \"GitHub Copilot\") * [Grok Code Fast 1](/wiki/Grok_(chatbot) \"Grok (chatbot)\") * [Kimi-Dev](/wiki/Moonshot_AI \"Moonshot AI\") * [Qwen3-Coder](/wiki/Qwen \"Qwen\") * [Replit](/wiki/Replit \"Replit\") * [Xcode](/wiki/Xcode \"Xcode\") | | [Image](/wiki/Text-to-image_model \"Text-to-image model\") | * [Aurora](/wiki/Aurora_(text-to-image_model) \"Aurora (text-to-image model)\") * [Firefly](/wiki/Adobe_Firefly \"Adobe Firefly\") * [Flux](/wiki/Flux_(text-to-image_model) \"Flux (text-to-image model)\") * [GPT Image 1](/wiki/GPT-4o#GPT_Image_1 \"GPT-4o\") * [Ideogram](/wiki/Ideogram_(text-to-image_model) \"Ideogram (text-to-image model)\") * [Imagen](/wiki/Imagen_(text-to-image_model) \"Imagen (text-to-image model)\") * [Leonardo](/wiki/Canva#Acquisitions \"Canva\") * [Midjourney](/wiki/Midjourney \"Midjourney\") * [Qwen-Image](/wiki/Qwen \"Qwen\") * [Recraft](/wiki/Recraft \"Recraft\") * [Seedream](/wiki/Seedream \"Seedream\") * [Stable Diffusion](/wiki/Stable_Diffusion \"Stable Diffusion\") | | [Video](/wiki/Text-to-video_model \"Text-to-video model\") | * [Dream Machine](/wiki/Dream_Machine_(text-to-video_model) \"Dream Machine (text-to-video model)\") * [Hailuo AI](/wiki/MiniMax_(company)#Hailuo_AI \"MiniMax (company)\") * [Kling](/wiki/Kling_(text-to-video_model) \"Kling (text-to-video model)\") * [Runway Gen](/wiki/Runway_(company)#Services_and_technologies \"Runway (company)\") * [Seedance](/wiki/ByteDance \"ByteDance\") * [Sora](/wiki/Sora_(text-to-video_model) \"Sora (text-to-video model)\") * [Veo](/wiki/Veo_(text-to-video_model) \"Veo (text-to-video model)\") * [Wan](/wiki/Alibaba_Group#Cloud_computing_and_artificial_intelligence_technology \"Alibaba Group\") | | [Speech](/wiki/Speech_synthesis#Text-to-speech_systems \"Speech synthesis\") | * [15.ai](/wiki/15.ai \"15.ai\") * [Eleven](/wiki/ElevenLabs#Products \"E\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- SOURCE 4: Model Context Protocol ---\n",
      "URL: https://github.com/modelcontextprotocol\n",
      "\n",
      "SUMMARY:\n",
      "Sign in  # Search code, repositories, users, issues, pull requests... Search syntax tips Sign in Sign up  You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. * docs - User documentation and guides ## Pinned Loading ### Repositories TypeScript   10,548  MIT   1,390  300 (6 issues need help)  87  Updated Nov 1, 2025 Kotlin   1,126  MIT   174  64 (4 issues need help)  15  Updated Oct 31, 2025 TypeScript   7,331  MIT   943  124 (1 issue needs help)  37  Updated Oct 31, 2025 There was an error while loading. Please reload this page.\n",
      "\n",
      "FULL CONTENT:\n",
      "[Skip to content](#start-of-content)   \n",
      "\n",
      "\n",
      "\n",
      "## Navigation Menu\n",
      "\n",
      "[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol) \n",
      "\n",
      "Appearance settings\n",
      "\n",
      "# Search code, repositories, users, issues, pull requests...\n",
      "\n",
      "[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n",
      "\n",
      "[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol)\n",
      "\n",
      " [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Corg-login%3E&source=header) \n",
      "\n",
      "Appearance settings\n",
      "\n",
      "You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n",
      "\n",
      "{{ message }}\n",
      "\n",
      "# Model Context Protocol\n",
      "\n",
      "An open protocol that enables seamless integration between LLM applications and external data sources and tools.\n",
      "\n",
      "* Verified \n",
      "\n",
      "  We've verified that the organization **modelcontextprotocol** controls the domain:\n",
      "\n",
      "  + **modelcontextprotocol.io**\n",
      "\n",
      "  [Learn more about verified organizations](https://docs.github.com/organizations/managing-organization-settings/verifying-or-approving-a-domain-for-your-organization)\n",
      "\n",
      "* [38.8k followers](/orgs/modelcontextprotocol/followers)\n",
      "* [https://modelcontextprotocol.io](https://modelcontextprotocol.io \"https://modelcontextprotocol.io\")\n",
      "\n",
      "[README.md](/modelcontextprotocol/.github/tree/main/profile/README.md)\n",
      "\n",
      "# Model Context Protocol\n",
      "\n",
      "**A protocol for seamless integration between LLM applications and external data sources**\n",
      "\n",
      "[Documentation](https://modelcontextprotocol.io) | [Specification](https://spec.modelcontextprotocol.io) | [Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n",
      "\n",
      "The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you're building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.\n",
      "\n",
      "## Getting Started\n",
      "\n",
      "*  Read the [Documentation](https://modelcontextprotocol.io) for guides and tutorials\n",
      "*  Review the [Specification](https://spec.modelcontextprotocol.io) for protocol details\n",
      "*  Use our SDKs to start building:\n",
      "  + [TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n",
      "  + [Python SDK](https://github.com/modelcontextprotocol/python-sdk)\n",
      "  + [Java SDK](https://github.com/modelcontextprotocol/java-sdk)\n",
      "  + [Kotlin SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\n",
      "  + [C# SDK](https://github.com/modelcontextprotocol/csharp-sdk)\n",
      "  + [Go SDK](https://github.com/modelcontextprotocol/go-sdk)\n",
      "  + [PHP SDK](https://github.com/modelcontextprotocol/php-sdk)\n",
      "  + [Ruby SDK](https://github.com/modelcontextprotocol/ruby-sdk)\n",
      "  + [Rust SDK](https://github.com/modelcontextprotocol/rust-sdk)\n",
      "  + [Swift SDK](https://github.com/modelcontextprotocol/swift-sdk)\n",
      "\n",
      "## Project Structure\n",
      "\n",
      "* [specification](https://github.com/modelcontextprotocol/specification) - Protocol specification and documentation\n",
      "* [typescript-sdk](https://github.com/modelcontextprotocol/typescript-sdk) - TypeScript implementation\n",
      "* [python-sdk](https://github.com/modelcontextprotocol/python-sdk) - Python implementation\n",
      "* [java-sdk](https://github.com/modelcontextprotocol/java-sdk) - Java implementation\n",
      "* [kotlin-sdk](https://github.com/modelcontextprotocol/kotlin-sdk) - Kotlin implementation\n",
      "* [csharp-sdk](https://github.com/modelcontextprotocol/csharp-sdk) - C# implementation\n",
      "* [go-sdk](https://github.com/modelcontextprotocol/go-sdk) - Go implementation\n",
      "* [php-sdk](https://github.com/modelcontextprotocol/php-sdk) - PHP implementation\n",
      "* [ruby-sdk](https://github.com/modelcontextprotocol/ruby-sdk) - Ruby implementation\n",
      "* [rust-sdk](https://github.com/modelcontextprotocol/rust-sdk) - Rust implementation\n",
      "* [swift-sdk](https://github.com/modelcontextprotocol/swift-sdk) - Swift implementation\n",
      "* [docs](https://github.com/modelcontextprotocol/docs) - User documentation and guides\n",
      "* [create-kotlin-server](https://github.com/modelcontextprotocol/kotlin-sdk/tree/main/samples/kotlin-mcp-server) - Kotlin sample server\n",
      "* [servers](https://github.com/modelcontextprotocol/servers) - List of maintained servers\n",
      "\n",
      "## Contributing\n",
      "\n",
      "We welcome contributions of all kinds! Whether you want to fix bugs, improve documentation, or propose new features, please see our [contributing guide](/modelcontextprotocol/.github/blob/main/profile/CONTRIBUTING.md) to get started.\n",
      "\n",
      "Have questions? Join the discussion in our [community forum](https://github.com/orgs/modelcontextprotocol/discussions).\n",
      "\n",
      "## About\n",
      "\n",
      "The Model Context Protocol is an open source project run by [Anthropic, PBC.](https://anthropic.com) and open to contributions from the entire community.\n",
      "\n",
      "## Pinned Loading\n",
      "\n",
      "1. [modelcontextprotocol](/modelcontextprotocol/modelcontextprotocol) modelcontextprotocol Public\n",
      "\n",
      "   Specification anddocumentation for the Model Context Protocol\n",
      "\n",
      "   TypeScript   [6.1k](/modelcontextprotocol/modelcontextprotocol/stargazers)   [1.1k](/modelcontextprotocol/modelcontextprotocol/forks)\n",
      "2. [servers](/modelcontextprotocol/servers) servers Public\n",
      "\n",
      "   Model Context Protocol Servers\n",
      "\n",
      "   TypeScript   [71.8k](/modelcontextprotocol/servers/stargazers)   [8.6k](/modelcontextprotocol/servers/forks)\n",
      "3. [python-sdk](/modelcontextprotocol/python-sdk) python-sdk Public\n",
      "\n",
      "   The official Python SDK for Model Context Protocol servers and clients\n",
      "\n",
      "   Python   [19.8k](/modelcontextprotocol/python-sdk/stargazers)   [2.7k](/modelcontextprotocol/python-sdk/forks)\n",
      "4. [typescript-sdk](/modelcontextprotocol/typescript-sdk) typescript-sdk Public\n",
      "\n",
      "   The official TypeScript SDK for Model Context Protocol servers and clients\n",
      "\n",
      "   TypeScript   [10.5k](/modelcontextprotocol/typescript-sdk/stargazers)   [1.4k](/modelcontextprotocol/typescript-sdk/forks)\n",
      "5. [csharp-sdk](/modelcontextprotocol/csharp-sdk) csharp-sdk Public\n",
      "\n",
      "   The official C# SDK for Model Context Protocol servers and clients. Maintained in collaboration with Microsoft.\n",
      "\n",
      "   C#   [3.5k](/modelcontextprotocol/csharp-sdk/stargazers)   [555](/modelcontextprotocol/csharp-sdk/forks)\n",
      "6. [inspector](/modelcontextprotocol/inspector) inspector Public\n",
      "\n",
      "   Visual testing tool for MCP servers\n",
      "\n",
      "   TypeScript   [7.3k](/modelcontextprotocol/inspector/stargazers)   [943](/modelcontextprotocol/inspector/forks)\n",
      "\n",
      "### Repositories\n",
      "\n",
      "Showing 10 of 27 repositories\n",
      "\n",
      "* [php-sdk](/modelcontextprotocol/php-sdk)  Public \n",
      "\n",
      "  The official PHP SDK for Model Context Protocol servers and clients. Maintained in collaboration with The PHP Foundation.\n",
      "\n",
      "   modelcontextprotocol/php-sdks past year of commit activity\n",
      "\n",
      "  PHP   [1,149](/modelcontextprotocol/php-sdk/stargazers)  MIT   [75](/modelcontextprotocol/php-sdk/forks)  [19](/modelcontextprotocol/php-sdk/issues)  [9](/modelcontextprotocol/php-sdk/pulls)  Updated Nov 1, 2025\n",
      "* [modelcontextprotocol](/modelcontextprotocol/modelcontextprotocol)  Public \n",
      "\n",
      "  Specification anddocumentation for the Model Context Protocol\n",
      "\n",
      "   modelcontextprotocol/modelcontextprotocols past year of commit activity\n",
      "\n",
      "  TypeScript   [6,086](/modelcontextprotocol/modelcontextprotocol/stargazers)  MIT   [1,082](/modelcontextprotocol/modelcontextprotocol/forks)  [253](/modelcontextprotocol/modelcontextprotocol/issues)  [135](/modelcontextprotocol/modelcontextprotocol/pulls)  Updated Nov 1, 2025\n",
      "* [typescript-sdk](/modelcontextprotocol/typescript-sdk)  Public \n",
      "\n",
      "  The official TypeScript SDK for Model Context Protocol servers and clients\n",
      "\n",
      "   modelcontextprotocol/typescript-sdks past year of commit activity\n",
      "\n",
      "  TypeScript   [10,548](/modelcontextprotocol/typescript-sdk/stargazers)  MIT   [1,390](/modelcontextprotocol/typescript-sdk/forks)  [300](/modelcontextprotocol/typescript-sdk/issues) [(6 issues need help)](/modelcontextprotocol/typescript-sdk/issues?q=label%3A%22good+first+issue%22+is%3Aissue+is%3Aopen)  [87](/modelcontextprotocol/typescript-sdk/pulls)  Updated Nov 1, 2025\n",
      "* [kotlin-sdk](/modelcontextprotocol/kotlin-sdk)  Public \n",
      "\n",
      "  The official Kotlin SDK for Model Context Protocol servers and clients. Maintained in collaboration with JetBrains\n",
      "\n",
      "   modelcontextprotocol/kotlin-sdks past year of commit activity\n",
      "\n",
      "  Kotlin   [1,126](/modelcontextprotocol/kotlin-sdk/stargazers)  MIT   [174](/modelcontextprotocol/kotlin-sdk/forks)  [64](/modelcontextprotocol/kotlin-sdk/issues) [(4 issues need help)](/modelcontextprotocol/kotlin-sdk/issues?q=label%3A%22good+first+issue%22+is%3Aissue+is%3Aopen)  [15](/modelcontextprotocol/kotlin-sdk/pulls)  Updated Oct 31, 2025\n",
      "* [registry](/modelcontextprotocol/registry)  Public \n",
      "\n",
      "  A community driven registry service for Model Context Protocol (MCP) servers.\n",
      "\n",
      "   modelcontextprotocol/registrys past year of commit activity\n",
      "\n",
      "  Go   [5,797](/modelcontextprotocol/registry/stargazers)  MIT   [454](/modelcontextprotocol/registry/forks)  [77](/modelcontextprotocol/registry/issues)  [13](/modelcontextprotocol/registry/pulls)  Updated Oct 31, 2025\n",
      "* [csharp-sdk](/modelcontextprotocol/csharp-sdk)  Public \n",
      "\n",
      "  The official C# SDK for Model Context Protocol servers and clients. Maintained in collaboration with Microsoft.\n",
      "\n",
      "   modelcontextprotocol/csharp-sdks past year of commit activity\n",
      "\n",
      "  C#   [3,496](/modelcontextprotocol/csharp-sdk/stargazers)  MIT   [555](/modelcontextprotocol/csharp-sdk/forks)  [135](/modelcontextprotocol/csharp-sdk/issues)  [14](/modelcontextprotocol/csharp-sdk/pulls)  Updated Oct 31, 2025\n",
      "* [python-sdk](/modelcontextprotocol/python-sdk)  Public \n",
      "\n",
      "  The official Python SDK for Model Context Protocol servers and clients\n",
      "\n",
      "   modelcontextprotocol/python-sdks past year of commit activity\n",
      "\n",
      "  Python   [19,780](/modelcontextprotocol/python-sdk/stargazers)  MIT   [2,706](/modelcontextprotocol/python-sdk/forks)  [256](/modelcontextprotocol/python-sdk/issues) [(2 issues need help)](/modelcontextprotocol/python-sdk/issues?q=label%3A%22help+wanted%22+is%3Aissue+is%3Aopen)  [76](/modelcontextprotocol/python-sdk/pulls)  Updated Oct 31, 2025\n",
      "* [inspector](/modelcontextprotocol/inspector)  Public \n",
      "\n",
      "  Visual testing tool for MCP servers\n",
      "\n",
      "   modelcontextprotocol/inspectors past year of commit activity\n",
      "\n",
      "  TypeScript   [7,331](/modelcontextprotocol/inspector/stargazers)  MIT   [943](/modelcontextprotocol/inspector/forks)  [124](/modelcontextprotocol/inspector/issues) [(1 issue needs help)](/modelcontextprotocol/inspector/issues?q=label%3A%22good+first+issue%22+is%3Aissue+is%3Aopen)  [37](/modelcontextprotocol/inspector/pulls)  Updated Oct 31, 2025\n",
      "* [ruby-sdk](/modelcontextprotocol/ruby-sdk)  Public \n",
      "\n",
      "  The official Ruby SDK for the Model Context Protocol. Maintained in collaboration with Shopify.\n",
      "\n",
      "   modelcontextprotocol/ruby-sdks past year of commit activity\n",
      "\n",
      "  Ruby   [595](/modelcontextprotocol/ruby-sdk/stargazers)  MIT   [77](/modelcontextprotocol/ruby-sdk/forks)  [12](/modelcontextprotocol/ruby-sdk/issues)  [7](/modelcontextprotocol/ruby-sdk/pulls)  Updated Oct 30, 2025\n",
      "* [rust-sdk](/modelcontextprotocol/rust-sdk)  Public \n",
      "\n",
      "  The official Rust SDK for the Model Context Protocol\n",
      "\n",
      "   modelcontextprotocol/rust-sdks past year of commit activity\n",
      "\n",
      "  Rust   [2,503](/modelcontextprotocol/rust-sdk/stargazers)  MIT   [393](/modelcontextprotocol/rust-sdk/forks)  [63](/modelcontextprotocol/rust-sdk/issues)  [7](/modelcontextprotocol/rust-sdk/pulls)  Updated Oct 31, 2025\n",
      "\n",
      "[View all repositories](/orgs/modelcontextprotocol/repositories?type=all)\n",
      "\n",
      "[#### People](/orgs/modelcontextprotocol/people)\n",
      "\n",
      "[View all](/orgs/modelcontextprotocol/people)\n",
      "\n",
      "#### Top languages\n",
      "\n",
      " [TypeScript](/orgs/modelcontextprotocol/repositories?language=typescript&type=all)   [JavaScript](/orgs/modelcontextprotocol/repositories?language=javascript&type=all)   [Python](/orgs/modelcontextprotocol/repositories?language=python&type=all)   [Go](/orgs/modelcontextprotocol/repositories?language=go&type=all)   [MDX](/orgs/modelcontextprotocol/repositories?language=mdx&type=all)\n",
      "\n",
      "#### Most used topics\n",
      "\n",
      "### Uh oh!\n",
      "\n",
      "There was an error while loading. Please reload this page.\n",
      "\n",
      "You cant perform that action at this time.\n",
      "\n",
      " \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- SOURCE 5: What is Model Context Protocol (MCP)? A guide ---\n",
      "URL: https://cloud.google.com/discover/what-is-model-context-protocol\n",
      "\n",
      "SUMMARY:\n",
      "Introduced by [Anthropic](https://cloud.google.com/products/model-garden/claude) in November 2024, MCP provides a secure and standardized \"language\" for LLMs to communicate with external data, applications, and services. Both Model Context Protocol (MCP) and [Retrieval-Augmented Generation](https://cloud.google.com/use-cases/retrieval-augmented-generation) (RAG) improve LLMs with outside information, but they do this through different ways and serve distinct purposes. LLMs, by nature, can sometimes make up facts or produce plausible but ultimately incorrect information ([hallucinate](https://cloud.google.com/discover/what-are-ai-hallucinations)) because they predict answers based on training data, not real-time information. *   **Container orchestration (like**[**Google Kubernetes Engine**](https://cloud.google.com/kubernetes-engine)**(GKE)):** For complex, stateful applications that require fine-grained control over networking and resources, a managed Kubernetes environment provides the power and flexibility needed to run sophisticated MCP infrastructure at enterprise scale. *   [Developer Tools](https://cloud.google.com/products/tools) *   [Management Tools](https://cloud.google.com/products/management)\n",
      "\n",
      "FULL CONTENT:\n",
      "What is Model Context Protocol (MCP)? A guide | Google Cloud\n",
      "\n",
      "===============\n",
      "\n",
      "Page Contents\n",
      "\n",
      "*   [Topics](https://cloud.google.com/discover/)\n",
      "\n",
      "*   Model Context Protocol (MCP)\n",
      "\n",
      "What is the MCP and how does it work?\n",
      "=====================================\n",
      "\n",
      "[Large language models](https://cloud.google.com/ai/llms) (LLMs) are powerful, but they have two major limitations: their knowledge is frozen at the time of their training, and they can't interact with the outside world. This means they can't access real-time data or perform actions like booking a meeting or updating a customer record.\n",
      "\n",
      "The Model Context Protocol (MCP) is an open standard designed to solve this. Introduced by [Anthropic](https://cloud.google.com/products/model-garden/claude) in November 2024, MCP provides a secure and standardized \"language\" for LLMs to communicate with external data, applications, and services. It acts as a bridge, allowing AI to move beyond static knowledge and become a dynamic [agent](https://cloud.google.com/discover/what-are-ai-agents) that can retrieve current information and take action, making it more accurate, useful, and automated.\n",
      "\n",
      "Get started for free[](https://console.cloud.google.com/freetrial)\n",
      "\n",
      "Understanding the Model Context Protocol\n",
      "========================================\n",
      "\n",
      "The MCP creates a standardized, two-way connection for AI applications, allowing LLMs to easily connect with various data sources and tools. MCP builds on existing concepts like tool use and function calling but standardizes them. This reduces the need for custom connections for each new AI model and external system. It enables LLMs to use current, real-world data, perform actions, and access specialized features not included in their original training.\n",
      "\n",
      "MCP architecture and components\n",
      "-------------------------------\n",
      "\n",
      "The Model Context Protocol has a clear structure with components that work together to help LLMs and outside systems interact easily.\n",
      "\n",
      "### MCP host\n",
      "\n",
      "The LLM is contained within the MCP host, an AI application or environment such as an AI-powered IDE or conversational AI. This is typically the user's interaction point, where the MCP host uses the LLM to process requests that may require external data or tools.\n",
      "\n",
      "### MCP client\n",
      "\n",
      "The MCP client, located within the MCP host, helps the LLM and MCP server communicate with each other. It translates the LLM's requests for the MCP and converts the MCP's replies for the LLM. It also finds and uses available MCP servers.\n",
      "\n",
      "### MCP server\n",
      "\n",
      "The MCP server is the external service that provides context, data, or capabilities to the LLM. It helps LLMs by connecting to external systems like databases and web services, translating their responses into a format the LLM can understand which helps developers provide diverse functionalities.\n",
      "\n",
      "### Transport layer\n",
      "\n",
      "The transport layer uses JSON-RPC 2.0 messages to communicate between the client and server, mainly through two transport methods:\n",
      "\n",
      "*   **Standard input/output (stdio):** Works well for local resources, offering fast, synchronous message transmission\n",
      "*   **Server-sent events (SSE):**Preferred for remote resources, allowing efficient, real-time data streaming\n",
      "\n",
      "How does the MCP work?\n",
      "----------------------\n",
      "\n",
      "At its core, the Model Context Protocol allows an LLM to request help from external tools to answer a query or complete a task. Imagine you ask an AI assistant: \"Find the latest sales report in our database and email it to my manager.\"\n",
      "\n",
      "Here is a simplified look at how MCP would handle this:\n",
      "\n",
      "1.   **Request and tool discovery:**The LLM understands it cannot access a database or send emails on its own. It uses the MCP client to search for available tools, where it finds two relevant tools registered on MCP servers: a database_query tool and an email_sender tool.\n",
      "2.   **Tool invocation:**The LLM generates a structured request to use these tools. First, it calls the database_query tool, specifying the report name. The MCP client then sends this request to the appropriate MCP server.\n",
      "3.   **External action and data return:**The MCP server receives the request, translates it into a secure SQL query for the company's database, and retrieves the sales report. It then formats this data and sends it back to the LLM.\n",
      "4.   **Second action and response generation:**Now equipped with the report data, the LLM calls the email_sender tool, providing the manager's email address and the report content. After the email is sent, the MCP server confirms the action was completed.\n",
      "5.   **Final confirmation:**The LLM provides a final response to you: \"I have found the latest sales report and emailed it to your manager.\"\n",
      "\n",
      "MCP versus RAG\n",
      "--------------\n",
      "\n",
      "Both Model Context Protocol (MCP) and [Retrieval-Augmented Generation](https://cloud.google.com/use-cases/retrieval-augmented-generation) (RAG) improve LLMs with outside information, but they do this through different ways and serve distinct purposes. RAG finds and uses information for creating text, while MCP is a wider system for interaction and action.\n",
      "\n",
      "**Feature****Model Context Protocol (MCP)****Retrieval-Augmented Generation (RAG)**\n",
      "Primary goal Standardize two-way communication for LLMs to access and _interact_ with external tools, data sources, and services to perform actions alongside information retrieval.Enhance LLM responses by _retrieving relevant information_ from an authoritative knowledge base _before_ generating a response.\n",
      "Mechanism Defines a standardized protocol for LLM applications to _invoke external functions_ or request structured data from specialized servers, enabling actions and dynamic context integration.Incorporates an information retrieval component that uses a user's query to pull information from a knowledge base or data source. This retrieved information then augments the LLM's prompt.\n",
      "Output type Enables LLMs to _generate structured calls_ for tools, receive results, and then generate human-readable text based on those results and actions. Can also involve real-time data and functions.LLMs generate responses based on their training data _augmented_ by text relevant to the query from external documents. Often focuses on factual accuracy.\n",
      "Interaction Designed for _active interaction_ and execution of tasks in external systems, providing a \"grammar\" for LLMs to \"use\" external capabilities.Primarily for _passive retrieval_ of information to inform text generation; not typically for executing actions within external systems.\n",
      "Standardization An open standard for how AI applications provide context to LLMs, standardizing integration and reducing the need for custom APIs.A technique or framework for improving LLMs, but not a universal protocol for tool interaction across different vendors or systems.\n",
      "Use cases AI agents performing tasks (for example, booking flights, updating CRM, running code), fetching real-time data, advanced integrations.Question-answering systems, chatbots providing up-to-date factual information, summarizing documents, reducing hallucinations in text generation.\n",
      "\n",
      "**Feature**\n",
      "\n",
      "**Model Context Protocol (MCP)**\n",
      "\n",
      "**Retrieval-Augmented Generation (RAG)**\n",
      "\n",
      "Primary goal\n",
      "\n",
      "Standardize two-way communication for LLMs to access and _interact_ with external tools, data sources, and services to perform actions alongside information retrieval.\n",
      "\n",
      "Enhance LLM responses by _retrieving relevant information_ from an authoritative knowledge base _before_ generating a response.\n",
      "\n",
      "Mechanism\n",
      "\n",
      "Defines a standardized protocol for LLM applications to _invoke external functions_ or request structured data from specialized servers, enabling actions and dynamic context integration.\n",
      "\n",
      "Incorporates an information retrieval component that uses a user's query to pull information from a knowledge base or data source. This retrieved information then augments the LLM's prompt.\n",
      "\n",
      "Output type\n",
      "\n",
      "Enables LLMs to _generate structured calls_ for tools, receive results, and then generate human-readable text based on those results and actions. Can also involve real-time data and functions.\n",
      "\n",
      "LLMs generate responses based on their training data _augmented_ by text relevant to the query from external documents. Often focuses on factual accuracy.\n",
      "\n",
      "Interaction\n",
      "\n",
      "Designed for _active interaction_ and execution of tasks in external systems, providing a \"grammar\" for LLMs to \"use\" external capabilities.\n",
      "\n",
      "Primarily for _passive retrieval_ of information to inform text generation; not typically for executing actions within external systems.\n",
      "\n",
      "Standardization\n",
      "\n",
      "An open standard for how AI applications provide context to LLMs, standardizing integration and reducing the need for custom APIs.\n",
      "\n",
      "A technique or framework for improving LLMs, but not a universal protocol for tool interaction across different vendors or systems.\n",
      "\n",
      "Use cases\n",
      "\n",
      "AI agents performing tasks (for example, booking flights, updating CRM, running code), fetching real-time data, advanced integrations.\n",
      "\n",
      "Question-answering systems, chatbots providing up-to-date factual information, summarizing documents, reducing hallucinations in text generation.\n",
      "\n",
      "Benefits of using the MCP\n",
      "-------------------------\n",
      "\n",
      "The Model Context Protocol offers several potential advantages for developing and deploying AI-powered applications, making LLMs more versatile, reliable, and capable.\n",
      "\n",
      "### Reduced hallucinations\n",
      "\n",
      "LLMs, by nature, can sometimes make up facts or produce plausible but ultimately incorrect information ([hallucinate](https://cloud.google.com/discover/what-are-ai-hallucinations)) because they predict answers based on training data, not real-time information. The MCP helps reduce this by providing a clear way for LLMs to access external, reliable data sources, making their responses more truthful.\n",
      "\n",
      "### Increased AI utility and automation\n",
      "\n",
      "This protocol helps AI do much more and work on its own. Usually, LLMs only know what they were trained on, which can quickly become outdated. However, with MCP LLMs can connect with many ready-made tools and integrations like business software, content repositories, and development environments. This means AI can handle more complicated jobs that involve interacting with the real world, such as updating customer information in a CRM system, looking up current events online, or running special calculations. By directly connecting to these outside tools, LLMs are no longer just chat programs; they become smart agents that can act independently, which means a lot more can be automated.\n",
      "\n",
      "### Easier connections for AI\n",
      "\n",
      "Before MCP, connecting LLMs to different external data sources and tools was more difficult, usually needing special connections or using methods specific to each vendor. This resulted in a complicated and messy system, often called the \"N x M\" problem, because the number of necessary custom connections grew very quickly with every new model or tool. MCP offers a common, open standard that makes these connections easier, much like how a USB-C port makes connecting devices simple. This simpler method can lower development costs, speed up the creation of AI applications, and create a more connected AI environment. Developers can also more easily switch between LLM providers and add new tools without major changes.\n",
      "\n",
      "MCP and security\n",
      "----------------\n",
      "\n",
      "While the Model Context Protocol improves LLM capabilities by connecting them to outside systems, it also can open up important security considerations. As MCP can access any data and potentially run code through connected tools, strong security is essential.\n",
      "\n",
      "Key security principles for MCP include:\n",
      "\n",
      "*   **User consent and control:** Users need to clearly understand and agree to all actions and data access the LLM performs through MCP. They should be able to control what data is shared and what actions are taken, ideally through easy-to-use authorization screens.\n",
      "*   **Data privacy:** Before exposing user data to MCP servers, hosts must get clear permission from users. Sensitive data should be protected with proper access controls to prevent accidental leaks or sharing, especially since LLMs handle large amounts of data. Using encryption and strong access control rules is essential.\n",
      "*   **Tool safety:** Tools linked through MCP can be used to run code. Developers should not trust tool descriptions unless they come from a reliable server. Users should give permission before any tool is used and understand what the tool does before allowing it to run.\n",
      "*   **Secure output handling:** LLM outputs from MCP interactions must be handled carefully to prevent security problems like cross-site scripting (XSS) or other web application attacks if the output is shown to users. It's important to properly clean up input and filter output, and to avoid including sensitive data in the prompts.\n",
      "*   **Supply chain security:** The reliability of the MCP servers and the external tools they connect to is very important. Organizations should make sure all parts of their LLM supply chain are secure to prevent biased results, security breaches, or failures.\n",
      "*   **Monitoring and auditing:** Regularly checking LLM activity and how it interacts with MCP servers can help find unusual behavior or potential misuse. Setting up strong logging and auditing systems allows tracking of data movement and tool usage, which helps when responding to security incidents.\n",
      "\n",
      "By sticking to these principles, developers can use the power of MCP while protecting against potential risks.\n",
      "\n",
      "Building and deploying an MCP-powered application\n",
      "-------------------------------------------------\n",
      "\n",
      "Implementing the Model Context Protocol requires a robust infrastructure to host the LLM, the MCP servers, and the underlying data sources. A cloud platform provides the scalable and secure components needed to build a complete solution. Heres how you can approach it:\n",
      "\n",
      "### Hosting and scaling your MCP servers\n",
      "\n",
      "MCP servers are the bridge to your external tools. Depending on your needs, you can choose:\n",
      "\n",
      "*   **Serverless environments (like**[**Cloud Run**](https://cloud.google.com/run)**):** Ideal for simple, stateless tools. A serverless platform automatically scales your servers based on demandeven to zeroso you only pay for what you use. This is perfect for deploying individual tools efficiently.\n",
      "*   **Container orchestration (like**[**Google Kubernetes Engine**](https://cloud.google.com/kubernetes-engine)**(GKE)):** For complex, stateful applications that require fine-grained control over networking and resources, a managed Kubernetes environment provides the power and flexibility needed to run sophisticated MCP infrastructure at enterprise scale.\n",
      "\n",
      "### Connecting MCP to your data and tools\n",
      "\n",
      "Much of the value of MCP comes from the tools it can access. You can connect your LLM to:\n",
      "\n",
      "*   **Managed databases (like**[**Cloud SQL**](https://cloud.google.com/sql)**or**[**Spanner**](https://cloud.google.com/spanner)**):** Allow your AI to securely query relational databases for things like customer information, inventory, or operational data\n",
      "*   **Data warehouses (like**[**BigQuery**](https://cloud.google.com/bigquery)**):** For analytical tasks, an LLM can leverage a data warehouse to analyze massive datasets and derive deep, contextual insights in response to a user's query\n",
      "\n",
      "### Orchestrating the end-to-end AI workflow with Vertex AI\n",
      "\n",
      "A unified AI platform is essential for tying everything together. [**Vertex AI**](https://cloud.google.com/vertex-ai?hl=en) helps you manage the entire life cycle of your MCP-powered application:\n",
      "\n",
      "*   **LLM hosting:** Deploy and manage powerful foundation models like Gemini, which serve as the \"brain\" of your application.\n",
      "*   **Agent and orchestration frameworks:** Building an AI agent involves complex workflows. Vertex AI provides tools to streamline the flow of information between the LLM and the context provided by your MCP servers, simplifying the development of sophisticated agents that can reason and act.\n",
      "\n",
      "#### Additional resources\n",
      "\n",
      "*   [Host MCP servers on Cloud Run](https://cloud.google.com/run/docs/host-mcp-servers)\n",
      "*   [Build and deploy a remote MCP Server on Cloud Run](https://cloud.google.com/run/docs/tutorials/deploy-remote-mcp-server)\n",
      "*   [Connect your IDE to Cloud SQL with MCP](https://cloud.google.com/sql/docs/mysql/pre-built-tools-with-mcp-toolbox)\n",
      "\n",
      "#### Take the next step\n",
      "\n",
      "Start building on Google Cloud with $300 in free credits and 20+ always free products.\n",
      "\n",
      "Get started for free[](https://console.cloud.google.com/freetrial)\n",
      "\n",
      "*   ##### Need help getting started?\n",
      "\n",
      "[Contact sales](https://cloud.google.com/contact/)\n",
      "*   ##### Work with a trusted partner\n",
      "\n",
      "[Find a partner](https://cloud.google.com/find-a-partner/)\n",
      "*   ##### Continue browsing\n",
      "\n",
      "[See all products](https://cloud.google.com/products/)\n",
      "\n",
      "menu\n",
      "\n",
      "[![Image 1: Google Cloud](https://www.gstatic.com/cgc/google-cloud-logo.svg)](https://cloud.google.com/)\n",
      "\n",
      "[Overview](https://cloud.google.com/why-google-cloud)[](https://cloud.google.com/discover/what-is-model-context-protocol#)[Solutions](https://cloud.google.com/solutions)[](https://cloud.google.com/discover/what-is-model-context-protocol#)[Products](https://cloud.google.com/products)[](https://cloud.google.com/discover/what-is-model-context-protocol#)[Pricing](https://cloud.google.com/pricing)[](https://cloud.google.com/discover/what-is-model-context-protocol#)[Resources](https://cloud.google.com/docs/get-started)[](https://cloud.google.com/discover/what-is-model-context-protocol#)[Docs](https://cloud.google.com/docs)[Support](https://cloud.google.com/support-hub)[Contact Us](https://cloud.google.com/contact)\n",
      "\n",
      "\n",
      "\n",
      "_search\\_spark_ _send\\_spark_\n",
      "\n",
      "[Docs](https://cloud.google.com/docs)[Support](https://cloud.google.com/support-hub)\n",
      "\n",
      "[Console](https://console.cloud.google.com/)\n",
      "\n",
      "[Sign in](https://cloud.google.com/_d/signin?continue=https%3A%2F%2Fcloud.google.com%2Fdiscover%2Fwhat-is-model-context-protocol&prompt=select_account)\n",
      "\n",
      "Start free[](https://console.cloud.google.com/freetrial)\n",
      "\n",
      "Start free[](https://console.cloud.google.com/freetrial)\n",
      "\n",
      "Contact Us[](https://cloud.google.com/contact)\n",
      "\n",
      "close\n",
      "\n",
      "*   Accelerate your digital transformation\n",
      "*   Whether your business is early in its journey or well on its way to digital transformation, Google Cloud can help solve your toughest challenges.\n",
      "*   [Learn more](https://cloud.google.com/transform) \n",
      "\n",
      "*   Key benefits\n",
      "*   [Why Google Cloud Top reasons businesses choose us.](https://cloud.google.com/why-google-cloud) \n",
      "*   [AI and ML Get enterprise-ready AI.](https://cloud.google.com/ai) \n",
      "*   [Multicloud Run your apps wherever you need them.](https://cloud.google.com/multicloud) \n",
      "*   [Global infrastructure Build on the same infrastructure as Google.](https://cloud.google.com/infrastructure) \n",
      "\n",
      "*   [Data Cloud Make smarter decisions with unified data.](https://cloud.google.com/data-cloud) \n",
      "*   [Modern Infrastructure Cloud Next generation of cloud infrastructure.](https://cloud.google.com/solutions/modern-infrastructure) \n",
      "*   [Security Protect your users, data, and apps.](https://cloud.google.com/security) \n",
      "*   [Productivity and collaboration Connect your teams with AI-powered apps.](https://workspace.google.com/) \n",
      "\n",
      "*   Reports and insights\n",
      "*   [Executive insights Curated C-suite perspectives.](https://cloud.google.com/executive-insights) \n",
      "*   [Analyst reports Read what industry analysts say about us.](https://cloud.google.com/analyst-reports) \n",
      "*   [Whitepapers Browse and download popular whitepapers.](https://cloud.google.com/whitepapers) \n",
      "*   [Customer stories Explore case studies and videos.](https://cloud.google.com/customers) \n",
      "\n",
      "close\n",
      "\n",
      "*   [Industry Solutions](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Application Modernization](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Artificial Intelligence](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [APIs and Applications](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Data Analytics](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Databases](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Infrastructure Modernization](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Productivity and Collaboration](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Security](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "*   [Startups and SMB](https://cloud.google.com/discover/what-is-model-context-protocol#)\n",
      "\n",
      "See all solutions[](https://cloud.google.com/solutions)\n",
      "\n",
      "*   [![Image 2](https://www.gstatic.com/cloud/images/navigation/forward.svg) Industry Solutions Reduce cost, increase operational agility, and capture new market opportunities.](https://cloud.google.com/solutions#industry-solutions)\n",
      "\n",
      "*   [![Image 3](https://www.gstatic.com/cloud/images/navigation/retail.svg) Retail Analytics and collaboration tools for the retail value chain.](https://cloud.google.com/solutions/retail)\n",
      "\n",
      "*   [![Image 4](https://www.gstatic.com/cloud/images/navigation/cpg.svg) Consumer Packaged Goods Solutions for CPG digital transformation and brand growth.](https://cloud.google.com/solutions/cpg)\n",
      "\n",
      "*   [![Image 5](https://www.gstatic.com/cloud/images/navigation/finance.svg) Financial Services Computing, data management, and analytics tools for financial services.](https://cloud.google.com/solutions/financial-services)\n",
      "\n",
      "*   [![Image 6](https://www.gstatic.com/cloud/images/navigation/hcls.svg) Healthcare and Life Sciences Advance research at scale and empower healthcare innovation.](https://cloud.google.com/solutions/healthcare-life-sciences)\n",
      "\n",
      "*   [![Image 7](https://www.gstatic.com/cloud/images/navigation/media.svg) Media and Entertainment Solutions for content production and distribution operations.](https://cloud.google.com/solutions/media-entertainment)\n",
      "\n",
      "*   [![Image 8](https://www.gstatic.com/cloud/images/navigation/telecommunications.svg) Telecommunications Hybrid and multi-cloud services to deploy and monetize 5G.](https://cloud.google.com/solutions/telecommunications)\n",
      "\n",
      "*   [![Image 9](https://www.gstatic.com/cloud/images/navigation/gaming.svg) Games AI-driven solutions to build and scale games faster.](https://cloud.google.com/solutions/games)\n",
      "\n",
      "*   [![Image 10](https://www.gstatic.com/cloud/images/navigation/manufacturing.svg) Manufacturing Migration and AI tools to optimize the manufacturing value chain.](https://cloud.google.com/solutions/manufacturing)\n",
      "\n",
      "*   [![Image 11](https://www.gstatic.com/cloud/images/navigation/supply-chain.svg) Supply Chain and Logistics Enable sustainable, efficient, and resilient data-driven operations across supply chain and logistics operations.](https://cloud.google.com/solutions/supply-chain-logistics)\n",
      "\n",
      "*   [![Image 12](https://www.gstatic.com/cloud/images/navigation/government.svg) Government Data storage, AI, and analytics solutions for government agencies.](https://cloud.google.com/gov)\n",
      "\n",
      "*   [![Image 13](https://www.gstatic.com/cloud/images/navigation/icon-sprite.svg#education) Education Teaching tools to provide more engaging learning experiences.](https://cloud.google.com/edu/higher-education)\n",
      "\n",
      "*   Not seeing what you're looking for?\n",
      "*   [See all industry solutions](https://cloud.google.com/solutions#industry-solutions)\n",
      "\n",
      "*   [![Image 14](https://www.gstatic.com/cloud/images/navigation/forward.svg) Application Modernization Assess, plan, implement, and measure software practices and capabilities to modernize and simplify your organizations business application portfolios.](https://cloud.google.com/solutions/camp)\n",
      "\n",
      "*   [CAMP Program that uses DORA to improve your software delivery capabilities.](https://cloud.google.com/solutions/camp)\n",
      "\n",
      "*   [Modernize Traditional Applications Analyze, categorize, and get started with cloud migration on traditional workloads.](https://cloud.google.com/solutions/modernize-traditional-applications)\n",
      "\n",
      "*   [Migrate from PaaS: Cloud Foundry, Openshift Tools for moving your existing containers into Google's managed container services.](https://cloud.google.com/solutions/migrate-from-paas)\n",
      "\n",
      "*   [Migrate from Mainframe Automated tools and prescriptive guidance for moving your mainframe apps to the cloud.](https://cloud.google.com/solutions/mainframe-modernization)\n",
      "\n",
      "*   [Modernize Software Delivery Software supply chain best practices - innerloop productivity, CI/CD and S3C.](https://cloud.google.com/solutions/software-delivery)\n",
      "\n",
      "*   [DevOps Best Practices Processes and resources for implementing DevOps in your org.](https://cloud.google.com/devops)\n",
      "\n",
      "*   [SRE Principles Tools and resources for adopting SRE in your org.](https://cloud.google.com/sre)\n",
      "\n",
      "*   [Platform Engineering Comprehensive suite of managed services and Golden Paths to build, manage, and scale IDPs.](https://cloud.google.com/solutions/platform-engineering)\n",
      "\n",
      "*   [Run Applications at the Edge Guidance for localized and low latency apps on Googles hardware agnostic edge solution.](https://cloud.google.com/solutions/modernize-with-edge)\n",
      "\n",
      "*   [Architect for Multicloud Manage workloads across multiple clouds with a consistent platform.](https://cloud.google.com/solutions/architect-multicloud)\n",
      "\n",
      "*   [Go Serverless Fully managed environment for developing, deploying and scaling apps.](https://cloud.google.com/solutions/serverless)\n",
      "\n",
      "*   [![Image 15](https://www.gstatic.com/cloud/images/navigation/forward.svg) Artificial Intelligence Add intelligence and efficiency to your business with AI and machine learning.](https://cloud.google.com/solutions/ai)\n",
      "\n",
      "*   [Customer Engagement Suite with Google AI End-to-end application that combines our most advanced conversational AI.](https://cloud.google.com/solutions/customer-engagement-ai)\n",
      "\n",
      "*   [Document AI Document processing and data capture automated at scale.](https://cloud.google.com/document-ai)\n",
      "\n",
      "*   [Vertex AI Search for commerce Google-quality search and product recommendations for retailers.](https://cloud.google.com/solutions/retail-product-discovery)\n",
      "\n",
      "*   [Google Cloud with Gemini AI assistants for application development, coding, and more.](https://cloud.google.com/ai/gemini)\n",
      "\n",
      "*   [Generative AI on Google Cloud Transform content creation and discovery, research, customer service, and developer efficiency with the power of generative AI.](https://cloud.google.com/use-cases/generative-ai)\n",
      "\n",
      "*   [![Image 16](https://www.gstatic.com/cloud/images/navigation/forward.svg) APIs and Applications Speed up the pace of innovation without coding, using APIs, apps, and automation.](https://cloud.google.com/solutions/apis-and-applications)\n",
      "\n",
      "*   [New Business Channels Using APIs Attract and empower an ecosystem of developers and partners.](https://cloud.google.com/solutions/new-channels-using-apis)\n",
      "\n",
      "*   [Unlocking Legacy Applications Using APIs Cloud services for extending and modernizing legacy apps.](https://cloud.google.com/solutions/unlocking-legacy-applications)\n",
      "\n",
      "*   [Open Banking APIx Simplify and accelerate secure delivery of open banking compliant APIs.](https://cloud.google.com/solutions/open-banking-apix)\n",
      "\n",
      "*   [![Image 17](https://www.gstatic.com/cloud/images/navigation/forward.svg) Data Analytics Generate instant insights from data at any scale with a serverless, fully managed analytics platform that significantly simplifies analytics.](https://cloud.google.com/solutions/data-analytics-and-ai)\n",
      "\n",
      "*   [Data Migration Migrate and modernize your data warehouse and data lakes with AI-powered migration services.](https://cloud.google.com/solutions/data-migration)\n",
      "\n",
      "*   [Data Lakehouse Unify and govern your multimodal data with a high-performance and open data lakehouse.](https://cloud.google.com/solutions/data-lakehouse)\n",
      "\n",
      "*   [Real-time Analytics Insights from ingesting, processing, and analyzing event streams.](https://cloud.google.com/solutions/stream-analytics)\n",
      "\n",
      "*   [Marketing Analytics Solutions for collecting, analyzing, and activating customer data.](https://cloud.google.com/solutions/marketing-analytics)\n",
      "\n",
      "*   [Datasets Data from Google, public, and commercial providers to enrich your analytics and AI initiatives.](https://cloud.google.com/datasets)\n",
      "\n",
      "*   [Business Intelligence Solutions for modernizing your BI stack and creating rich data experiences.](https://cloud.google.com/solutions/business-intelligence)\n",
      "\n",
      "*   [AI for Data Analytics Write SQL, build predictive models, and visualize data with AI for data analytics.](https://cloud.google.com/use-cases/ai-data-analytics)\n",
      "\n",
      "*   [Geospatial Analytics A comprehensive platform to solve for geospatial use cases at scale.](https://cloud.google.com/solutions/geospatial)\n",
      "\n",
      "*   [![Image 18](https://www.gstatic.com/cloud/images/navigation/forward.svg) Databases Migrate and manage enterprise data with security, reliability, high availability, and fully managed data services.](https://cloud.google.com/solutions/databases)\n",
      "\n",
      "*   [Database Migration Guides and tools to simplify your database migration life cycle.](https://cloud.google.com/solutions/database-migration)\n",
      "\n",
      "*   [Database Modernization Upgrades to modernize your operational database infrastructure.](https://cloud.google.com/solutions/database-modernization)\n",
      "\n",
      "*   [Databases for Games Build global, live games with Google Cloud databases.](https://cloud.google.com/solutions/databases/games)\n",
      "\n",
      "*   [Google Cloud Databases Database services to migrate, manage, and modernize data.](https://cloud.google.com/products/databases)\n",
      "\n",
      "*   [Migrate Oracle workloads to Google Cloud Rehost, replatform, rewrite your Oracle workloads.](https://cloud.google.com/solutions/oracle)\n",
      "\n",
      "*   [Open Source Databases Fully managed open source databases with enterprise-grade support.](https://cloud.google.com/solutions/open-source-databases)\n",
      "\n",
      "*   [SQL Server on Google Cloud Options for running SQL Server virtual machines on Google Cloud.](https://cloud.google.com/sql-server)\n",
      "\n",
      "*   [Gemini for Databases Supercharge database development and management with AI.](https://cloud.google.com/products/gemini/databases)\n",
      "\n",
      "*   [![Image 19](https://www.gstatic.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Sections (call_YfJaatSnMMo929rKKE6VuEHP)\n",
      " Call ID: call_YfJaatSnMMo929rKKE6VuEHP\n",
      "  Args:\n",
      "    sections: ['Overview of Model Context Protocol', 'Key Features of MCP', 'Applications of MCP', 'Benefits of Using MCP', 'MCP vs. Retrieval-Augmented Generation (RAG)', 'Security Considerations for MCP']\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: Sections\n",
      "\n",
      "sections=['Overview of Model Context Protocol', 'Key Features of MCP', 'Applications of MCP', 'Benefits of Using MCP', 'MCP vs. Retrieval-Augmented Generation (RAG)', 'Security Considerations for MCP']\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Introduction (call_xSseNnIhQPsDuiKzA6hcyud8)\n",
      " Call ID: call_xSseNnIhQPsDuiKzA6hcyud8\n",
      "  Args:\n",
      "    name: Model Context Protocol Report\n",
      "    content: The Model Context Protocol (MCP) represents a significant leap forward in the integration of artificial intelligence (AI) systems with external tools and data sources. Introduced in November 2024 by Anthropic, MCP aims to standardize the communication of AI applications with various services, enabling them to operate more autonomously and efficiently. This report delves into the intricacies of MCP, outlining its architecture, key features, and the transformative applications it supports. Furthermore, we will explore the benefits of adopting MCP, its comparison with the Retrieval-Augmented Generation (RAG) paradigm, and essential security considerations for effectively utilizing this powerful protocol.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: Introduction\n",
      "\n",
      "name='Model Context Protocol Report' content='The Model Context Protocol (MCP) represents a significant leap forward in the integration of artificial intelligence (AI) systems with external tools and data sources. Introduced in November 2024 by Anthropic, MCP aims to standardize the communication of AI applications with various services, enabling them to operate more autonomously and efficiently. This report delves into the intricacies of MCP, outlining its architecture, key features, and the transformative applications it supports. Furthermore, we will explore the benefits of adopting MCP, its comparison with the Retrieval-Augmented Generation (RAG) paradigm, and essential security considerations for effectively utilizing this powerful protocol.'\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Introduction written. Now write a conclusion section.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Conclusion (call_Ii7Ynml6gOla7wlLMzJBT4ze)\n",
      " Call ID: call_Ii7Ynml6gOla7wlLMzJBT4ze\n",
      "  Args:\n",
      "    name: Conclusion on Model Context Protocol\n",
      "    content: The Model Context Protocol (MCP) is paving the way for a new era of AI integration, enabling more seamless communication between advanced AI systems and a multitude of external data sources. Its open standard design not only reduces the complexities associated with connecting AI applications to various tools but also enhances their functionality by facilitating real-time data access and task execution. As organizations continue to adopt MCP, they are likely to see increased efficiency, reduced operational risks, and an overall improvement in AI-driven solutions. Moreover, by addressing security concerns proactively, MCP sets itself up as a robust framework for future advancements in AI technology, allowing it to bridge existing gaps between AI capabilities and real-world applications.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: Conclusion\n",
      "\n",
      "name='Conclusion on Model Context Protocol' content='The Model Context Protocol (MCP) is paving the way for a new era of AI integration, enabling more seamless communication between advanced AI systems and a multitude of external data sources. Its open standard design not only reduces the complexities associated with connecting AI applications to various tools but also enhances their functionality by facilitating real-time data access and task execution. As organizations continue to adopt MCP, they are likely to see increased efficiency, reduced operational risks, and an overall improvement in AI-driven solutions. Moreover, by addressing security concerns proactively, MCP sets itself up as a robust framework for future advancements in AI technology, allowing it to bridge existing gaps between AI capabilities and real-world applications.'\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Report is now complete with introduction, body sections, and conclusion.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  FinishReport (call_LSeBVpuAlMsOuBG2txQCLEZE)\n",
      " Call ID: call_LSeBVpuAlMsOuBG2txQCLEZE\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: FinishReport\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Report is Finish\n"
     ]
    }
   ],
   "source": [
    "messages = graph.get_state(thread_config).values['messages']\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
