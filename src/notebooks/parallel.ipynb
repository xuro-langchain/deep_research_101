{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Researcher\n",
    "\n",
    "This notebook demonstrates the research [workflow](https://langchain-ai.github.io/langgraph/tutorials/workflows/) that creates comprehensive reports through a series of focused steps. The system:\n",
    "\n",
    "1. Uses a **graph workflow** with specialized nodes for each report creation stage\n",
    "2. Enables user **feedback and approval** at critical planning points \n",
    "3. Produces a well-structured report with introduction, researched body sections, and conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by setting our directory and importing our environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robertxu/Desktop/Projects/eng/open_deep_research/src\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import all the helpers we'll need for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.parallel.state import (\n",
    "    ReportStateInput,\n",
    "    ReportStateOutput,\n",
    "    Sections,\n",
    "    ReportState,\n",
    "    SectionState,\n",
    "    SectionOutputState,\n",
    "    Queries,\n",
    "    Feedback\n",
    ")\n",
    "\n",
    "from agents.parallel.prompts import (\n",
    "    report_planner_query_writer_instructions,\n",
    "    report_planner_instructions,\n",
    "    query_writer_instructions, \n",
    "    section_writer_instructions,\n",
    "    final_section_writer_instructions,\n",
    "    section_grader_instructions,\n",
    "    section_writer_inputs\n",
    ")\n",
    "\n",
    "from agents.parallel.configuration import Configuration\n",
    "from agents.parallel.utils import (\n",
    "    format_sections, \n",
    "    get_config_value, \n",
    "    get_search_params, \n",
    "    select_and_execute_search,\n",
    "    get_today_str\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### Nodes\n",
    "\n",
    "#### Planner Module\n",
    "\n",
    "First we'll create a node to generate the structure of our report. We'll load in all our configurations and first generate some web searches to inform our report structure. Based on the results, we'll generate a plan for our research to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "async def generate_report_plan(state: ReportState, config: RunnableConfig):\n",
    "    \"\"\"Generate the initial report plan with sections.\n",
    "    \n",
    "    This node:\n",
    "    1. Gets configuration for the report structure and search parameters\n",
    "    2. Generates search queries to gather context for planning\n",
    "    3. Performs web searches using those queries\n",
    "    4. Uses an LLM to generate a structured plan with sections\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the report topic\n",
    "        config: Configuration for models, search APIs, etc.\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the generated sections\n",
    "    \"\"\"\n",
    "\n",
    "    # Inputs\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Get list of feedback on the report plan\n",
    "    feedback_list = state.get(\"feedback_on_report_plan\", [])\n",
    "\n",
    "    # Concatenate feedback on the report plan into a single string\n",
    "    feedback = \" /// \".join(feedback_list) if feedback_list else \"\"\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    report_structure = configurable.report_structure\n",
    "    number_of_queries = configurable.number_of_queries\n",
    "    search_api = get_config_value(configurable.search_api)\n",
    "    search_api_config = configurable.search_api_config or {}  # Get the config dict, default to empty\n",
    "    params_to_pass = get_search_params(search_api, search_api_config)  # Filter parameters\n",
    "\n",
    "    # Convert JSON object to string if necessary\n",
    "    if isinstance(report_structure, dict):\n",
    "        report_structure = str(report_structure)\n",
    "\n",
    "    # Set writer model (model used for query writing)\n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model_kwargs = get_config_value(configurable.writer_model_kwargs or {})\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, model_kwargs=writer_model_kwargs) \n",
    "    structured_llm = writer_model.with_structured_output(Queries)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions_query = report_planner_query_writer_instructions.format(\n",
    "        topic=topic,\n",
    "        report_organization=report_structure,\n",
    "        number_of_queries=number_of_queries,\n",
    "        today=get_today_str()\n",
    "    )\n",
    "\n",
    "    # Generate queries  \n",
    "    results = await structured_llm.ainvoke([SystemMessage(content=system_instructions_query),\n",
    "                                     HumanMessage(content=\"Generate search queries that will help with planning the sections of the report.\")])\n",
    "\n",
    "    # Web search\n",
    "    query_list = [query.search_query for query in results.queries]\n",
    "\n",
    "    # Search the web with parameters\n",
    "    source_str = await select_and_execute_search(search_api, query_list, params_to_pass)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=report_structure, context=source_str, feedback=feedback)\n",
    "\n",
    "    # Set the planner\n",
    "    planner_provider = get_config_value(configurable.planner_provider)\n",
    "    planner_model = get_config_value(configurable.planner_model)\n",
    "    planner_model_kwargs = get_config_value(configurable.planner_model_kwargs or {})\n",
    "\n",
    "    # Report planner instructions\n",
    "    planner_message = \"\"\"Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. \n",
    "                        Each section must have: name, description, research, and content fields.\"\"\"\n",
    "\n",
    "    # Run the planner\n",
    "    if planner_model == \"claude-3-7-sonnet-latest\":\n",
    "        # Allocate a thinking budget for claude-3-7-sonnet-latest as the planner model\n",
    "        planner_llm = init_chat_model(model=planner_model, \n",
    "                                      model_provider=planner_provider, \n",
    "                                      max_tokens=20_000, \n",
    "                                      thinking={\"type\": \"enabled\", \"budget_tokens\": 16_000})\n",
    "\n",
    "    else:\n",
    "        # With other models, thinking tokens are not specifically allocated\n",
    "        planner_llm = init_chat_model(model=planner_model, \n",
    "                                      model_provider=planner_provider,\n",
    "                                      model_kwargs=planner_model_kwargs)\n",
    "    \n",
    "    # Generate the report sections\n",
    "    structured_llm = planner_llm.with_structured_output(Sections)\n",
    "    report_sections = await structured_llm.ainvoke([SystemMessage(content=system_instructions_sections),\n",
    "                                             HumanMessage(content=planner_message)])\n",
    "\n",
    "    # Get sections\n",
    "    sections = report_sections.sections\n",
    "\n",
    "    return {\"sections\": sections}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll have the human review our research plan to ensure that the structure looks logical and appropriate for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import interrupt, Command, Send\n",
    "\n",
    "\n",
    "def human_feedback(state: ReportState, config: RunnableConfig) -> Command[Literal[\"generate_report_plan\",\"build_section_with_web_research\"]]:\n",
    "    \"\"\"Get human feedback on the report plan and route to next steps.\n",
    "    \n",
    "    This node:\n",
    "    1. Formats the current report plan for human review\n",
    "    2. Gets feedback via an interrupt\n",
    "    3. Routes to either:\n",
    "       - Section writing if plan is approved\n",
    "       - Plan regeneration if feedback is provided\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state with sections to review\n",
    "        config: Configuration for the workflow\n",
    "        \n",
    "    Returns:\n",
    "        Command to either regenerate plan or start section writing\n",
    "    \"\"\"\n",
    "\n",
    "    # Get sections\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state['sections']\n",
    "    sections_str = \"\\n\\n\".join(\n",
    "        f\"Section: {section.name}\\n\"\n",
    "        f\"Description: {section.description}\\n\"\n",
    "        f\"Research needed: {'Yes' if section.research else 'No'}\\n\"\n",
    "        for section in sections\n",
    "    )\n",
    "\n",
    "    # Get feedback on the report plan from interrupt\n",
    "    interrupt_message = f\"\"\"Please provide feedback on the following report plan. \n",
    "                        \\n\\n{sections_str}\\n\n",
    "                        \\nDoes the report plan meet your needs?\\nPass 'true' to approve the report plan.\\nOr, provide feedback to regenerate the report plan:\"\"\"\n",
    "    \n",
    "    feedback = interrupt(interrupt_message)\n",
    "\n",
    "    # If the user approves the report plan, kick off section writing\n",
    "    if isinstance(feedback, bool) and feedback is True:\n",
    "        # Treat this as approve and kick off section writing\n",
    "        return Command(goto=[\n",
    "            Send(\"build_section_with_web_research\", {\"topic\": topic, \"section\": s, \"search_iterations\": 0}) \n",
    "            for s in sections \n",
    "            if s.research\n",
    "        ])\n",
    "    \n",
    "    # If the user provides feedback, regenerate the report plan \n",
    "    elif isinstance(feedback, str):\n",
    "        # Treat this as feedback and append it to the existing list\n",
    "        return Command(goto=\"generate_report_plan\", \n",
    "                       update={\"feedback_on_report_plan\": [feedback]})\n",
    "    else:\n",
    "        raise TypeError(f\"Interrupt value of type {type(feedback)} is not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Researcher Module\n",
    "\n",
    "We'll define a small subagent to generate web queries to research a given section determined by our report structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "async def generate_queries(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"Generate search queries for researching a specific section.\n",
    "    \n",
    "    This node uses an LLM to generate targeted search queries based on the \n",
    "    section topic and description.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing section details\n",
    "        config: Configuration including number of queries to generate\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the generated search queries\n",
    "    \"\"\"\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    number_of_queries = configurable.number_of_queries\n",
    "\n",
    "    # Generate queries \n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model_kwargs = get_config_value(configurable.writer_model_kwargs or {})\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, model_kwargs=writer_model_kwargs) \n",
    "    structured_llm = writer_model.with_structured_output(Queries)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions = query_writer_instructions.format(topic=topic, \n",
    "                                                           section_topic=section.description, \n",
    "                                                           number_of_queries=number_of_queries,\n",
    "                                                           today=get_today_str())\n",
    "\n",
    "    # Generate queries  \n",
    "    queries = await structured_llm.ainvoke([SystemMessage(content=system_instructions),\n",
    "                                     HumanMessage(content=\"Generate search queries on the provided topic.\")])\n",
    "\n",
    "    return {\"search_queries\": queries.queries}\n",
    "\n",
    "async def search_web(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"Execute web searches for the section queries.\n",
    "    \n",
    "    This node:\n",
    "    1. Takes the generated queries\n",
    "    2. Executes searches using configured search API\n",
    "    3. Formats results into usable context\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with search queries\n",
    "        config: Search API configuration\n",
    "        \n",
    "    Returns:\n",
    "        Dict with search results and updated iteration count\n",
    "    \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    search_queries = state[\"search_queries\"]\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    search_api = get_config_value(configurable.search_api)\n",
    "    search_api_config = configurable.search_api_config or {}  # Get the config dict, default to empty\n",
    "    params_to_pass = get_search_params(search_api, search_api_config)  # Filter parameters\n",
    "\n",
    "    # Web search\n",
    "    query_list = [query.search_query for query in search_queries]\n",
    "\n",
    "    # Search the web with parameters\n",
    "    source_str = await select_and_execute_search(search_api, query_list, params_to_pass)\n",
    "\n",
    "    return {\"source_str\": source_str, \"search_iterations\": state[\"search_iterations\"] + 1}\n",
    "\n",
    "async def write_section(state: SectionState, config: RunnableConfig) -> Command[Literal[END, \"search_web\"]]:\n",
    "    \"\"\"Write a section of the report and evaluate if more research is needed.\n",
    "    \n",
    "    This node:\n",
    "    1. Writes section content using search results\n",
    "    2. Evaluates the quality of the section\n",
    "    3. Either:\n",
    "       - Completes the section if quality passes\n",
    "       - Triggers more research if quality fails\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with search results and section info\n",
    "        config: Configuration for writing and evaluation\n",
    "        \n",
    "    Returns:\n",
    "        Command to either complete section or do more research\n",
    "    \"\"\"\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "    source_str = state[\"source_str\"]\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Format system instructions\n",
    "    section_writer_inputs_formatted = section_writer_inputs.format(topic=topic, \n",
    "                                                             section_name=section.name, \n",
    "                                                             section_topic=section.description, \n",
    "                                                             context=source_str, \n",
    "                                                             section_content=section.content)\n",
    "\n",
    "    # Generate section  \n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model_kwargs = get_config_value(configurable.writer_model_kwargs or {})\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, model_kwargs=writer_model_kwargs) \n",
    "\n",
    "    section_content = await writer_model.ainvoke([SystemMessage(content=section_writer_instructions),\n",
    "                                           HumanMessage(content=section_writer_inputs_formatted)])\n",
    "    \n",
    "    # Write content to the section object  \n",
    "    section.content = section_content.content\n",
    "\n",
    "    # Grade prompt \n",
    "    section_grader_message = (\"Grade the report and consider follow-up questions for missing information. \"\n",
    "                              \"If the grade is 'pass', return empty strings for all follow-up queries. \"\n",
    "                              \"If the grade is 'fail', provide specific search queries to gather missing information.\")\n",
    "    \n",
    "    section_grader_instructions_formatted = section_grader_instructions.format(topic=topic, \n",
    "                                                                               section_topic=section.description,\n",
    "                                                                               section=section.content, \n",
    "                                                                               number_of_follow_up_queries=configurable.number_of_queries)\n",
    "\n",
    "    # Use planner model for reflection\n",
    "    planner_provider = get_config_value(configurable.planner_provider)\n",
    "    planner_model = get_config_value(configurable.planner_model)\n",
    "    planner_model_kwargs = get_config_value(configurable.planner_model_kwargs or {})\n",
    "\n",
    "    if planner_model == \"claude-3-7-sonnet-latest\":\n",
    "        # Allocate a thinking budget for claude-3-7-sonnet-latest as the planner model\n",
    "        reflection_model = init_chat_model(model=planner_model, \n",
    "                                           model_provider=planner_provider, \n",
    "                                           max_tokens=20_000, \n",
    "                                           thinking={\"type\": \"enabled\", \"budget_tokens\": 16_000}).with_structured_output(Feedback)\n",
    "    else:\n",
    "        reflection_model = init_chat_model(model=planner_model, \n",
    "                                           model_provider=planner_provider, model_kwargs=planner_model_kwargs).with_structured_output(Feedback)\n",
    "    # Generate feedback\n",
    "    feedback = await reflection_model.ainvoke([SystemMessage(content=section_grader_instructions_formatted),\n",
    "                                        HumanMessage(content=section_grader_message)])\n",
    "\n",
    "    # If the section is passing or the max search depth is reached, publish the section to completed sections \n",
    "    if feedback.grade == \"pass\" or state[\"search_iterations\"] >= configurable.max_search_depth:\n",
    "        # Publish the section to completed sections \n",
    "        update = {\"completed_sections\": [section]}\n",
    "        if configurable.include_source_str:\n",
    "            update[\"source_str\"] = source_str\n",
    "        return Command(update=update, goto=END)\n",
    "\n",
    "    # Update the existing section with new content and update search queries\n",
    "    else:\n",
    "        return Command(\n",
    "            update={\"search_queries\": feedback.follow_up_queries, \"section\": section},\n",
    "            goto=\"search_web\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizer Module\n",
    "\n",
    "We'll finish our implementation by creating a module for summarizing and compressing all the returned research. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_final_sections(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"Write sections that don't require research using completed sections as context.\n",
    "    \n",
    "    This node handles sections like conclusions or summaries that build on\n",
    "    the researched sections rather than requiring direct research.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with completed sections as context\n",
    "        config: Configuration for the writing model\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the newly written section\n",
    "    \"\"\"\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "    completed_report_sections = state[\"report_sections_from_research\"]\n",
    "    \n",
    "    # Format system instructions\n",
    "    system_instructions = final_section_writer_instructions.format(topic=topic, section_name=section.name, section_topic=section.description, context=completed_report_sections)\n",
    "\n",
    "    # Generate section  \n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model_kwargs = get_config_value(configurable.writer_model_kwargs or {})\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, model_kwargs=writer_model_kwargs) \n",
    "    \n",
    "    section_content = await writer_model.ainvoke([SystemMessage(content=system_instructions),\n",
    "                                           HumanMessage(content=\"Generate a report section based on the provided sources.\")])\n",
    "    \n",
    "    # Write content to section \n",
    "    section.content = section_content.content\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section]}\n",
    "\n",
    "def gather_completed_sections(state: ReportState):\n",
    "    \"\"\"Format completed sections as context for writing final sections.\n",
    "    \n",
    "    This node takes all completed research sections and formats them into\n",
    "    a single context string for writing summary sections.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with completed sections\n",
    "        \n",
    "    Returns:\n",
    "        Dict with formatted sections as context\n",
    "    \"\"\"\n",
    "\n",
    "    # List of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_sections = format_sections(completed_sections)\n",
    "\n",
    "    return {\"report_sections_from_research\": completed_report_sections}\n",
    "\n",
    "def compile_final_report(state: ReportState, config: RunnableConfig):\n",
    "    \"\"\"Compile all sections into the final report.\n",
    "    \n",
    "    This node:\n",
    "    1. Gets all completed sections\n",
    "    2. Orders them according to original plan\n",
    "    3. Combines them into the final report\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with all completed sections\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the complete report\n",
    "    \"\"\"\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Get sections\n",
    "    sections = state[\"sections\"]\n",
    "    completed_sections = {s.name: s.content for s in state[\"completed_sections\"]}\n",
    "\n",
    "    # Update sections with completed content while maintaining original order\n",
    "    for section in sections:\n",
    "        section.content = completed_sections[section.name]\n",
    "\n",
    "    # Compile final report\n",
    "    all_sections = \"\\n\\n\".join([s.content for s in sections])\n",
    "\n",
    "    if configurable.include_source_str:\n",
    "        return {\"final_report\": all_sections, \"source_str\": state[\"source_str\"]}\n",
    "    else:\n",
    "        return {\"final_report\": all_sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges\n",
    "\n",
    "We'll use a conditional edge to determine when to initiate the final compilation of all report sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_final_section_writing(state: ReportState):\n",
    "    \"\"\"Create parallel tasks for writing non-research sections.\n",
    "    \n",
    "    This edge function identifies sections that don't need research and\n",
    "    creates parallel writing tasks for each one.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with all sections and research context\n",
    "        \n",
    "    Returns:\n",
    "        List of Send commands for parallel section writing\n",
    "    \"\"\"\n",
    "\n",
    "    # Kick off section writing in parallel via Send() API for any sections that do not require research\n",
    "    return [\n",
    "        Send(\"write_final_sections\", {\"topic\": state[\"topic\"], \"section\": s, \"report_sections_from_research\": state[\"report_sections_from_research\"]}) \n",
    "        for s in state[\"sections\"] \n",
    "        if not s.research\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first put together the researcher submodule responsible for researching individual sections of our report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_90342/1617226580.py:2: LangGraphDeprecatedSinceV05: `output` is deprecated and will be removed. Please use `output_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  section_builder = StateGraph(SectionState, output=SectionOutputState)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10fa09d50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add nodes \n",
    "section_builder = StateGraph(SectionState, output=SectionOutputState)\n",
    "section_builder.add_node(\"generate_queries\", generate_queries)\n",
    "section_builder.add_node(\"search_web\", search_web)\n",
    "section_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# Add edges\n",
    "section_builder.add_edge(START, \"generate_queries\")\n",
    "section_builder.add_edge(\"generate_queries\", \"search_web\")\n",
    "section_builder.add_edge(\"search_web\", \"write_section\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then connect the researcher submodule to the planner submodule and summarize modules, creating a linear workflow to handle research tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_90342/956734853.py:4: LangGraphDeprecatedSinceV10: `config_schema` is deprecated and will be removed. Please use `context_schema` instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)\n",
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_90342/956734853.py:4: LangGraphDeprecatedSinceV05: `input` is deprecated and will be removed. Please use `input_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)\n",
      "/var/folders/jj/2fvdkyfj0856p6_6sdvv74rw0000gn/T/ipykernel_90342/956734853.py:4: LangGraphDeprecatedSinceV05: `output` is deprecated and will be removed. Please use `output_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "# Outer graph for initial report plan compiling results from each section -- \n",
    "# Add nodes\n",
    "builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)\n",
    "builder.add_node(\"generate_report_plan\", generate_report_plan)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"build_section_with_web_research\", section_builder.compile())\n",
    "builder.add_node(\"gather_completed_sections\", gather_completed_sections)\n",
    "builder.add_node(\"write_final_sections\", write_final_sections)\n",
    "builder.add_node(\"compile_final_report\", compile_final_report)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"generate_report_plan\")\n",
    "builder.add_edge(\"generate_report_plan\", \"human_feedback\")\n",
    "builder.add_edge(\"build_section_with_web_research\", \"gather_completed_sections\")\n",
    "builder.add_conditional_edges(\"gather_completed_sections\", initiate_final_section_writing, [\"write_final_sections\"])\n",
    "builder.add_edge(\"write_final_sections\", \"compile_final_report\")\n",
    "builder.add_edge(\"compile_final_report\", END)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display, Markdown\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running our Researcher\n",
    "\n",
    "We can run our agent using the code sections below. NOTE that it does take several minutes to run, and consumes a large amount of tokens. \n",
    "\n",
    "As such, we've also included a sample trace of a successful run.\n",
    "\n",
    "> Note: our agent has a human feedback step, so we've included traces for pre-feedback and post-feedback below\n",
    "\n",
    "**Pre-feedback Public Trace**: https://smith.langchain.com/public/c7046da2-d7ac-4ae1-8783-08dc00e62fb5/r\n",
    "\n",
    "**Post-feedback Public Trace**: https://smith.langchain.com/public/19b1afde-393b-4341-9e52-cfa1c2934b18/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide feedback on the following report plan. \n",
       "                        \n",
       "\n",
       "Section: Introduction\n",
       "Description: Briefly orient the reader to the Model Context Protocol (MCP) and why it matters for integrating external context and tools with large-language-model applications.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: MCP Architecture & Core Concepts\n",
       "Description: Explain the clientserver architecture, key primitives (tools, resources, prompts), transport options (stdio, HTTP/SSE), security model, and typical requestresponse flow so developers understand how MCP works under the hood.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Notable MCP Servers & Implementation Patterns\n",
       "Description: Survey interesting open-source or commercial MCP servers (e.g., Filesystem, Git, Apify, AWS, Smithery catalog) and show code/config snippets illustrating how developers build or connect to these servers in apps like Claude Desktop or Cursor IDE.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: MCP vs. Google Agent2Agent (A2A) Protocol\n",
       "Description: Compare goals, data models, transport layers, discovery mechanisms, state management, and ideal use cases; highlight how MCPs agent-to-tool focus complements A2As agent-to-agent collaboration.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Conclusion & Key Takeaways\n",
       "Description: Summarize the main insights and provide a concise table or bullet list distilling differences, architectural highlights, and practical next steps for developers.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "                        \n",
       "Does the report plan meet your needs?\n",
       "Pass 'true' to approve the report plan.\n",
       "Or, provide feedback to regenerate the report plan:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "# Define report structure template and configure the research workflow\n",
    "# This sets parameters for models, search tools, and report organization\n",
    "\n",
    "REPORT_STRUCTURE = \"\"\"Use this structure to create a report on the user-provided topic:\n",
    "\n",
    "1. Introduction (no research needed)\n",
    "   - Brief overview of the topic area\n",
    "\n",
    "2. Main Body Sections:\n",
    "   - Each section should focus on a sub-topic of the user-provided topic\n",
    "   \n",
    "3. Conclusion\n",
    "   - Aim for 1 structural element (either a list of table) that distills the main body sections \n",
    "   - Provide a concise summary of the report\"\"\"\n",
    "\n",
    "# Configuration: Use OpenAI o3 for both planning and writing (selected option)\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"openai\",\n",
    "                           \"planner_model\": \"o3\",\n",
    "                           \"writer_provider\": \"openai\",\n",
    "                           \"writer_model\": \"o3\",\n",
    "                           \"max_search_depth\": 2,\n",
    "                           \"report_structure\": REPORT_STRUCTURE,\n",
    "                           }}\n",
    "\n",
    "# Define research topic about Model Context Protocol\n",
    "topic = \"Overview of Model Context Protocol (MCP), an Anthropicbacked open standard for integrating external context and tools with LLMs. Give an architectural overview for developers, tell me about interesting MCP servers, and compare to google Agent2Agent (A2A) protocol.\"\n",
    "\n",
    "# Run the graph workflow until first interruption (waiting for user feedback)\n",
    "async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying User Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide feedback on the following report plan. \n",
       "                        \n",
       "\n",
       "Section: Introduction\n",
       "Description: Briefly introduces the Model Context Protocol (MCP), its purpose in integrating external context and tools with LLMs, and outlines what the report will cover.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: MCP Architecture & Core Concepts\n",
       "Description: Explains MCPs host-client-server model, key primitives (resources, tools, prompts), message types (requests, results, notifications, errors), supported transports (stdio, HTTP/SSE), and security considerations so developers grasp the protocols building blocks.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Implementing MCP: Developer Workflow & SDKs\n",
       "Description: Details how developers build or consume MCP servers/clients, including available SDKs (Python, TypeScript, Java, Kotlin), local vs. remote deployment patterns, configuration in apps like Claude Desktop, and illustrative code snippets.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Ecosystem Snapshot: Notable MCP Servers\n",
       "Description: Surveys interesting open-source and commercial MCP servers (e.g., GitHub PR review, Filesystem, Postgres, Slack, Apify, Web Search) and categorizes them by function to show practical utility and integration patterns.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: MCP vs. Google Agent-to-Agent (A2A) Protocol\n",
       "Description: Introduces Googles A2A protocol and provides a focused comparison with MCP across architecture, standardization, interoperability, and use-case fit, highlighting when developers might choose one over the other.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Conclusion\n",
       "Description: Summarizes key insights and presents a concise table distilling architectural differences, implementation tips, and ecosystem highlights discussed in the report.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "                        \n",
       "Does the report plan meet your needs?\n",
       "Pass 'true' to approve the report plan.\n",
       "Or, provide feedback to regenerate the report plan:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Submit feedback on the report plan\n",
    "# The system will continue execution with the updated requirements\n",
    "\n",
    "# Provide specific feedback to focus and refine the report structure\n",
    "async for event in graph.astream(Command(resume=\"Looks great! Just do one section related to Agent2Agent (A2A) protocol, introducing it and comparing to MCP.\"), thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_feedback': None}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Ecosystem Snapshot: Notable MCP Servers', description='Surveys interesting open-source and commercial MCP servers (e.g., GitHub PR review, Filesystem, Postgres, Slack, Apify, Web Search) and categorizes them by function to show practical utility and integration patterns.', research=True, content='## Ecosystem Snapshot: Notable MCP Servers  \\n\\nThe public registry already spans hundreds of servers, but a few work-horse groups dominate day-to-day agent workflows.  \\n\\n Version control: the official GitHub server exposes 70+ tools for pull-request review, workflow logs and issue triage, making code automation a popular first MCP use-case [1].  \\n\\n Databases: reference Postgres, BigQuery and Fireproof servers let assistants run safe SQL, inspect schema and even tune indexes, demonstrating a clear patternread-only by default with opt-in writes for production safety [1].  \\n\\n Communication: the Slack server turns channels, DMs and searches into callable tools, allowing an agent to summarise or reply inside team chat without custom bots [1].  \\n\\n Web search & scraping: Exas server provides real-time search APIs, while Apifys Actors server exposes 6 000+ web-automation micro-apps through a single MCP endpoint, giving agents broad reach with one integration [1][2].  \\n\\n Local context: the core Filesystem server delivers sandboxed read/write access to chosen folders, illustrating how hosts can supply private context without leaving the machine [3].  \\n\\nAcross categories, servers follow the same patterndeclare tools/prompts, speak JSON-RPC over stdio or SSE, and rely on the host to enforce consentmaking them easy to mix-and-match in production stacks.  \\n\\n### Sources  \\n[1] Awesome MCP Servers registry: https://www.codebolt.ai/registry/mcp-tools/385/  \\n[2] Apify blog  The state of MCP: https://blog.apify.com/what-is-model-context-protocol/  \\n[3] modelcontextprotocol/servers reference repo: https://github.com/modelcontextprotocol/servers')], 'source_str': 'Search results: \\n\\n\\n\\n--- SOURCE 1: Awesome MCP Servers | MCP Tool | CodeboltAI ---\\nURL: https://www.codebolt.ai/registry/mcp-tools/385/\\n\\nSUMMARY:\\nMCP is an open protocol that enables AI models to securely interact with local and remote resources through standardized server implementations. This list focuses on production-ready and experimental MCP servers that extend AI capabilities through file access, database connections, API integrations, and other contextual services. * @flux159/mcp-server-kubernetes -  / Typescript implementation of Kubernetes cluster operations for pods, deployments, services. * @fireproof-storage/mcp-database-server   * @reading-plus-ai/mcp-server-data-exploration   * exa-labs/exa-mcp-server    \\xa0A Model Context Protocol (MCP) server lets AI assistants like Claude use the Exa AI Search API for web searches. * Tomatio13/mcp-server-tavily   \\xa0Tavily AI search API * NS Travel Information MCP Server   * amidabuddha/unichat-mcp-server / \\n\\nFULL CONTENT:\\nAwesome MCP Servers | MCP Tool | CodeboltAI\\n\\n\\n\\n\\n# Registry\\n\\nDiscover and deploy MCP tools and AI agents to extend your development capabilities\\n\\n[AI Agents\\n\\nPre-built AI agents](/registry/agents/)\\n[MCP Tools\\n\\nModel Context Protocol servers](/registry/mcp-tools/)\\n\\n[Back to MCP Tools](/registry/mcp-tools/)\\n\\n# Awesome MCP Servers\\n\\nCreated by morisono\\n\\nNo description\\n\\n1 stars\\n\\nCategory:\\nResearch And Data\\n\\nUpdated 8 months ago\\n\\n[View on GitHub](https://github.com/morisono/awesome-mcp-servers)\\n\\n## Documentation\\n\\n# Awesome MCP Servers\\n\\nA curated list of awesome Model Context Protocol (MCP) servers.\\n\\n* [What is MCP?](#what-is-mcp)\\n* [Tutorials](#tutorials)\\n* [Server Implementations](#server-implementations)\\n* [Frameworks](#frameworks)\\n* [Tips & Tricks](#tips-and-tricks)\\n\\n## What is MCP?\\n\\n[MCP](https://modelcontextprotocol.io/) is an open protocol that enables AI models to securely interact with local and remote resources through standardized server implementations. This list focuses on production-ready and experimental MCP servers that extend AI capabilities through file access, database connections, API integrations, and other contextual services.\\n\\n## Tutorials\\n\\n* [Model Context Protocol (MCP)\\n\\nQuickstart](<https://glama.ai/blog/2024-11-25-model-context-protocol-quickstart>)\\n\\n* [Setup Claude Desktop App to Use a SQLite Database](https://youtu.be/wxCCzo9dGj0)\\n\\n## Community\\n\\n* [r/mcp Reddit](https://www.reddit.com/r/mcp)\\n* [Discord Server](https://glama.ai/mcp/discord)\\n\\n## Legend\\n\\n*  \\xa0official implementation\\n* programming language\\n\\n  +  \\xa0Python codebase\\n  +  \\xa0TypeScript codebase\\n  +  \\xa0Go codebase\\n  +  \\xa0Rust codebase\\n  + #\\n\\n* C# Codebase\\n\\n* scope\\n  + \\n\\n* Cloud Service\\n  + \\n* Local Service\\n\\n* operating system\\n  +   For macOS\\n  +   For Windows\\n\\n> [!NOTE]  \\n> Confused about Local  vs Cloud ?\\n\\n* Use local when MCP server is talking to a locally installed software, e.g. taking control over Chrome browser.\\n\\n\\n\\n* Use network when MCP server is talking to remote APIs, e.g. weather API.\\n\\n## Server Implementations\\n\\n> [!NOTE]  \\n> We now have a [web-based directory](https://glama.ai/mcp/servers) that is synced with the repository.\\n\\n*  - [Browser Automation](#browser-automation)\\n*  - [Art & Culture](#art-and-culture)\\n*  - [Cloud Platforms](#cloud-platforms)\\n*  - [Command Line](#command-line)\\n*  - [Communication](#communication)\\n*  - [Customer Data Platforms](#customer-data-platforms)\\n*  - [Databases](#databases)\\n*  - [Developer Tools](#developer-tools)\\n*  - [File Systems](#file-systems)\\n*  - [Finance & Fintech](#finance--fintech)\\n*  - [Knowledge & Memory](#knowledge--memory)\\n*  - [Location Services](#location-services)\\n*  - [Monitoring](#monitoring)\\n*  - [Search](#search)\\n*  - [Security](#security)\\n*  - [Travel & Transportation](#travel-and-transportation)\\n*  - [Version Control](#version-control)\\n*  - [Other Tools and Integrations](#other-tools-and-integrations)\\n\\n###  Browser Automation\\n\\nWeb content access and automation capabilities. Enables searching, scraping, and processing web content in AI-friendly formats.\\n\\n* [@blackwhite084/playwright-plus-python-mcp](https://github.com/blackwhite084/playwright-plus-python-mcp) \\n* An MCP python server using Playwright for browser automation,more suitable for llm\\n* [@executeautomation/playwright-mcp-server](https://github.com/executeautomation/mcp-playwright) \\n* An MCP server using Playwright for browser automation and webscrapping\\n* [@automatalabs/mcp-server-playwright](https://github.com/Automata-Labs-team/MCP-Server-Playwright)  \\n* An MCP server for browser automation using Playwright\\n* [@modelcontextprotocol/server-puppeteer](https://github.com/modelcontextprotocol/servers/tree/main/src/puppeteer)  \\n* Browser automation for web scraping and interaction\\n* [@kimtaeyoon83/mcp-server-youtube-transcript](https://github.com/kimtaeyoon83/mcp-server-youtube-transcript)  \\n* Fetch YouTube subtitles and transcripts for AI analysis\\n* [@recursechat/mcp-server-apple-shortcuts](https://github.com/recursechat/mcp-server-apple-shortcuts)   \\n* An MCP Server Integration with Apple Shortcuts\\n* [@kimtth/mcp-aoai-web-browsing](https://github.com/kimtth/mcp-aoai-web-browsing)  \\n* A `minimal` server/client MCP implementation using Azure OpenAI and Playwright.\\n* [@pskill9/web-search](https://github.com/pskill9/web-search)  \\n* An MCP server that enables free web searching using Google search results, with no API keys required.\\n\\n###  Art & Culture\\n\\nAccess and explore art collections, cultural heritage, and museum databases. Enables AI models to search and analyze artistic and cultural content.\\n\\n[burningion/video-editing-mcp](https://github.com/burningion/video-editing-mcp) \\n\\n* Add, Analyze, Search, and Generate Video Edits from your Video Jungle Collection\\n* [r-huijts/rijksmuseum-mcp](https://github.com/r-huijts/rijksmuseum-mcp)  \\n* Rijksmuseum API integration for artwork search, details, and collections\\n\\n###  Cloud Platforms\\n\\nCloud platform service integration. Enables management and interaction with cloud infrastructure and services.\\n\\n* [Cloudflare MCP Server](https://github.com/cloudflare/mcp-server-cloudflare)   \\n* Integration with Cloudflare services including Workers, KV, R2, and D1\\n* [Kubernetes MCP Server](https://github.com/strowk/mcp-k8s-go) -  / Kubernetes cluster operations through MCP\\n* [@flux159/mcp-server-kubernetes](https://github.com/Flux159/mcp-server-kubernetes) -  / Typescript implementation of Kubernetes cluster operations for pods, deployments, services.\\n\\n###  Command Line\\n\\nRun commands, capture output and otherwise interact with shells and command line tools.\\n\\n* [g0t4/mcp-server-commands](https://github.com/g0t4/mcp-server-commands)  \\n* Run any command with `run_command` and `run_script` tools.\\n* [MladenSU/cli-mcp-server](https://github.com/MladenSU/cli-mcp-server)  \\n* Command line interface with secure execution and customizable security policies\\n* [tumf/mcp-shell-server](https://github.com/tumf/mcp-shell-server)\\n\\nA secure shell command execution server implementing the Model Context Protocol (MCP)\\n\\n###  Communication\\n\\nIntegration with communication platforms for message management and channel operations. Enables AI models to interact with team communication tools.\\n\\n* [hannesrudolph/imessage-query-fastmcp-mcp-server](https://github.com/hannesrudolph/imessage-query-fastmcp-mcp-server)   \\n* An MCP server that provides safe access to your iMessage database through Model Context Protocol (MCP), enabling LLMs to query and analyze iMessage conversations with proper phone number validation and attachment handling\\n* [@modelcontextprotocol/server-slack](https://github.com/modelcontextprotocol/servers/tree/main/src/slack)  \\n* Slack workspace integration for channel management and messaging\\n* [@modelcontextprotocol/server-bluesky](https://github.com/keturiosakys/bluesky-context-server)  \\n* Bluesky instance integration for querying and interaction\\n* [MarkusPfundstein/mcp-gsuite](https://github.com/MarkusPfundstein/mcp-gsuite) -  \\n* Integration with gmail and Google Calendar.\\n* [adhikasp/mcp-twikit](https://github.com/adhikasp/mcp-twikit)  \\n* Interact with Twitter search and timeline\\n\\n###  Customer Data Platforms\\n\\nProvides access to customer profiles inside of customer data platforms\\n\\n* [sergehuber/inoyu-mcp-unomi-server](https://github.com/sergehuber/inoyu-mcp-unomi-server)  \\n* An MCP server to access and updates profiles on an Apache Unomi CDP server.\\n* [OpenDataMCP/OpenDataMCP](https://github.com/OpenDataMCP/OpenDataMCP)  \\n* Connect any Open Data to any LLM with Model Context Protocol.\\n* [tinybirdco/mcp-tinybird](https://github.com/tinybirdco/mcp-tinybird)  \\n* An MCP server to interact with a Tinybird Workspace from any MCP client.\\n\\n###  Databases\\n\\nSecure database access with schema inspection capabilities. Enables querying and analyzing data with configurable security controls including read-only access.\\n\\n* [domdomegg/airtable-mcp-server](https://github.com/domdomegg/airtable-mcp-server)  \\n* Airtable database integration with schema inspection, read and write capabilities\\n* [LucasHild/mcp-server-bigquery](https://github.com/LucasHild/mcp-server-bigquery)  \\n* BigQuery database integration with schema inspection and query capabilities\\n* [ergut/mcp-bigquery-server](https://github.com/ergut/mcp-bigquery-server)  \\n* Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\\n* [ClickHouse/mcp-clickhouse](https://github.com/ClickHouse/mcp-clickhouse)  \\n* ClickHouse database integration with schema inspection and query capabilities\\n* [@fireproof-storage/mcp-database-server](https://github.com/fireproof-storage/mcp-database-server)  \\n* Fireproof ledger database with multi-user sync\\n* [designcomputer/mysql\\\\_mcp\\\\_server](https://github.com/designcomputer/mysql_mcp_server)  \\n* MySQL database integration with configurable access controls, schema inspection, and comprehensive security guidelines\\n* [f4ww4z/mcp-mysql-server](https://github.com/f4ww4z/mcp-mysql-server)  \\n* Node.js-based MySQL database integration that provides secure MySQL database operations\\n* [@modelcontextprotocol/server-postgres](https://github.com/modelcontextprotocol/servers/tree/main/src/postgres)  \\n* PostgreSQL database integration with schema inspection and query capabilities\\n* [@modelcontextprotocol/server-sqlite](https://github.com/modelcontextprotocol/servers/tree/main/src/sqlite)  \\n* SQLite database operations with built-in analysis features\\n* [@joshuarileydev/supabase-mcp-server](https://github.com/joshuarileydev/supabase)\\n* Supabase MCP Server for managing and creating projects and organisations in Supabase\\n* [ktanaka101/mcp-server-duckdb](https://github.com/ktanaka101/mcp-server-duckdb)  \\n* DuckDB database integration with schema inspection and query capabilities\\n* [QuantGeekDev/mongo-mcp](https://github.com/QuantGeekDev/mongo-mcp)  \\n* MongoDB integration that enables LLMs to interact directly with databases.\\n* [tinybirdco/mcp-tinybird](https://github.com/tinybirdco/mcp-tinybird)  \\n* Tinybird integration with query and API capabilities\\n* [kiliczsh/mcp-mongo-server](https://github.com/kiliczsh/mcp-mongo-server)  \\n* A Model Context Protocol Server for MongoDB\\n* [KashiwaByte/vikingdb-mcp-server](https://github.com/KashiwaByte/vikingdb-mcp-server)  \\n* VikingDB integration with collection and index introduction, vector store and search capabilities.\\n* [neo4j-contrib/mcp-neo4j](https://github.com/neo4j-contrib/mcp-neo4j)  \\n* Model Context Protocol with Neo4j\\n* [isaacwasserman/mcp-snowflake-server](https://github.com/isaacwasserman/mcp-snowflake-server)  \\n* Snowflake integration implementing read and (optional) write operations as well as insight tracking\\n* [hannesrudolph/sqlite-explorer-fastmcp-mcp-server](https://github.com/hannesrudolph/sqlite-explorer-fastmcp-mcp-server)  \\n* An MCP server that provides safe, read-only access to SQLite databases through Model Context Protocol (MCP). This server is built with the FastMCP framework, which enables LLMs to explore and query SQLite databases with built-in safety features and query validation.\\n* [sirmews/mcp-pinecone](https://github.com/sirmews/mcp-pinecone)  \\n* Pinecone integration with vector search capabilities\\n\\n###  Developer Tools\\n\\nTools and integrations that enhance the development workflow and environment management.\\n\\n* [QuantGeekDev/docker-mcp](https://github.com/QuantGeekDev/docker-mcp)  \\n* Docker container management and operations through MCP\\n* [snaggle-ai/openapi-mcp-server](https://github.com/snaggle-ai/openapi-mcp-server)  \\n* Connect any HTTP/REST API server using an Open API spec (v3)\\n* [jetbrains/mcpProxy](https://github.com/JetBrains/mcpProxy)   \\n* Connect to JetBrains IDE\\n* [tumf/mcp-text-editor](https://github.com/tumf/mcp-text-editor)  \\n* A line-oriented text file editor. Optimized for LLM tools with efficient partial file access to minimize token usage.\\n* [@joshuarileydev/simulator-mcp-server](https://github.com/JoshuaRileyDev/simulator-mcp-server)  \\n* An MCP server to control iOS Simulators\\n* [@joshuarileydev/app-store-connect-mcp-server](https://github.com/JoshuaRileyDev/app-store-connect-mcp-server)  \\n* An MCP server to communicate with the App Store Connect API for iOS Developers\\n* [@sammcj/mcp-package-version](https://github.com/sammcj/mcp-package-version)  \\n* An MCP Server to help LLMs suggest the latest stable package versions when writing code.\\n* [@delano/postman-mcp-server](https://github.com/delano/postman-mcp-server)  \\n* Interact with [Postman API](https://www.postman.com/postman/postman-public-workspace/)\\n* [@vivekvells/mcp-pandoc](https://github.com/vivekVells/mcp-pandoc)  \\n* MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, PDF, DOCX (.docx), csv and more.\\n* [@pskill9/website-downloader](https://github.com/pskill9/website-downloader)  \\n* This MCP server provides a tool to download entire websites using wget. It preserves the website structure and converts links to work locally.\\n\\n###  Data Science Tools\\n\\nIntegrations and tools designed to simplify data exploration, analysis and enhance data science workflows.\\n\\n* [@reading-plus-ai/mcp-server-data-exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)  \\n* Enables autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort.\\n\\n###  File Systems\\n\\nProvides direct access to local file systems with configurable permissions. Enables AI models to read, write, and manage files within specified directories.\\n\\n* [@modelcontextprotocol/server-filesystem](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem)  \\n* Direct local file system access.\\n* [@modelcontextprotocol/server-google-drive](https://github.com/modelcontextprotocol/servers/tree/main/src/gdrive)  \\n* Google Drive integration for listing, reading, and searching files\\n* [hmk/box-mcp-server](https://github.com/hmk/box-mcp-server)  \\n* Box integration for listing, reading and searching files\\n* [mark3labs/mcp-filesystem-server](https://github.com/mark3labs/mcp-filesystem-server)  \\n* Golang implementation for local file system access.\\n* [mamertofabian/mcp-everything-search](https://github.com/mamertofabian/mcp-everything-search)   \\n* Fast Windows file search using Everything SDK\\n* [cyberchitta/llm-context.py](https://github.com/cyberchitta/llm-context.py)  \\n* Share code context with LLMs via MCP or clipboard\\n\\n###  Finance & Fintech\\n\\nFinancial data access and cryptocurrency market information. Enables querying real-time market data, crypto prices, and financial analytics.\\n\\n* [QuantGeekDev/coincap-mcp](https://github.com/QuantGeekDev/coincap-mcp)  \\n* Real-time cryptocurrency market data integration using CoinCap\\'s public API, providing access to crypto prices and market information without API keys\\n* [anjor/coinmarket-mcp-server](https://github.com/anjor/coinmarket-mcp-server)  \\n* Coinmarket API integration to fetch cryptocurrency listings and quotes\\n* [berlinbra/alpha-vantage-mcp](https://github.com/berlinbra/alpha-vantage-mcp)  \\n* Alpha Vantage API integration to fetch both stock and crypto information\\n\\n###  Knowledge & Memory\\n\\nPersistent memory storage using knowledge graph structures. Enables AI models to maintain and query structured information across sessions.\\n\\n* [@modelcontextprotocol/server-memory](https://github.com/modelcontextprotocol/servers/tree/main/src/memory)  \\n* Knowledge graph-based persistent memory system for maintaining context\\n* [/CheMiguel23/MemoryMesh](https://github.com/CheMiguel23/MemoryMesh)  \\n* Enhanced graph-based memory with a focus on AI role-play and story generation\\n* [/topoteretes/cognee](https://github.com/topoteretes/cognee/tree/dev/cognee-mcp)  \\n* Memory manager for AI apps and Agents using various graph and vector stores and allowing ingestion from 30+ data sources\\n* [@hannesrudolph/mcp-ragdocs](https://github.com/hannesrudolph/mcp-ragdocs)  \\n* An MCP server implementation that provides tools for retrieving and processing documentation through vector search, enabling AI assistants to augment their responses with relevant documentation context\\n* [@kaliaboi/mcp-zotero](https://github.com/kaliaboi/mcp-zotero)  \\n* A connector for LLMs to work with collections and sources on your Zotero Cloud\\n\\n###  Location Services\\n\\nGeographic and location-based services integration. Enables access to mapping data, directions, and place information.\\n\\n* [@modelcontextprotocol/server-google-maps](https://github.com/modelcontextprotocol/servers/tree/main/src/google-maps)  \\n* Google Maps integration for location services, routing, and place details\\n* [SecretiveShell/MCP-timeserver](https://github.com/SecretiveShell/MCP-timeserver)  \\n* Access the time in any timezone and get the current local time\\n* [webcoderz/MCP-Geo](https://github.com/webcoderz/MCP-Geo)  \\n* Geocoding MCP server for nominatim, ArcGIS, Bing\\n\\n###  Monitoring\\n\\nAccess and analyze application monitoring data. Enables AI models to review error reports and performance metrics.\\n\\n* [@modelcontextprotocol/server-sentry](https://github.com/modelcontextprotocol/servers/tree/main/src/sentry)  \\n* Sentry.io integration for error tracking and performance monitoring\\n* [@modelcontextprotocol/server-raygun](https://github.com/MindscapeHQ/mcp-server-raygun)  \\n* Raygun API V3 integration for crash reporting and real user monitoring\\n* [metoro-io/metoro-mcp-server](https://github.com/metoro-io/metoro-mcp-server)   \\n* Query and interact with kubernetes environments monitored by Metoro\\n\\n###  Search\\n\\n* [@modelcontextprotocol/server-brave-search](https://github.com/modelcontextprotocol/servers/tree/main/src/brave-search)  \\n* Web search capabilities using Brave\\'s Search API\\n* [@angheljf/nyt](https://github.com/angheljf/nyt)  \\n* Search articles using the NYTimes API\\n* [@modelcontextprotocol/server-fetch](https://github.com/modelcontextprotocol/servers/tree/main/src/fetch)   \\n* Efficient web content fetching and processing for AI consumption\\n* [ac3xx/mcp-servers-kagi](https://github.com/ac3xx/mcp-servers-kagi)  \\n* Kagi search API integration\\n* [exa-labs/exa-mcp-server](https://github.com/exa-labs/exa-mcp-server)    \\xa0A Model Context Protocol (MCP) server lets AI assistants like Claude use the Exa AI Search API for web searches. This setup allows AI models to get real-time web information in a safe and controlled way.\\n* [fatwang2/search1api-mcp](https://github.com/fatwang2/search1api-mcp)  \\n* Search via search1api (requires paid API key)\\n* [Tomatio13/mcp-server-tavily](https://github.com/Tomatio13/mcp-server-tavily)   \\xa0Tavily AI search API\\n* [blazickjp/arxiv-mcp-server](https://github.com/blazickjp/arxiv-mcp-server)  \\n* Search ArXiv research papers\\n* [mzxrai/mcp-webresearch](https://github.com/mzxrai/mcp-webresearch) \\n* Search Google and do deep web research on any topic\\n* [andybrandt/mcp-simple-arxiv](https://github.com/andybrandt/mcp-simple-arxiv) -   MCP for LLM to search and read papers from arXiv\\n* [andybrandt/mcp-simple-pubmed](https://github.com/andybrandt/mcp-simple-pubmed) -   MCP to search and read medical / life sciences papers from PubMed.\\n* [apify/mcp-server-rag-web-browser](https://github.com/apify/mcp-server-rag-web-browser)  \\n* An MCP server for Apify\\'s RAG Web Browser Actor to perform web searches, scrape URLs, and return content in Markdown.\\n* [SecretiveShell/MCP-searxng](https://github.com/SecretiveShell/MCP-searxng)  \\n* An MCP Server to connect to searXNG instances\\n* [Bigsy/Clojars-MCP-Server](https://github.com/Bigsy/Clojars-MCP-Server)  \\n* Clojars MCP Server for upto date dependency information of Clojure libraries\\n* [Ihor-Sokoliuk/MCP-SearXNG](https://github.com/ihor-sokoliuk/mcp-searxng)  /\\n* A Model Context Protocol Server for [SearXNG](https://docs.searxng.org)\\n* [erithwik/mcp-hn](https://github.com/erithwik/mcp-hn)  \\n* An MCP server to search Hacker News, get top stories, and more.\\n* [chanmeng/google-news-mcp-server](https://github.com/ChanMeng666/server-google-news)  \\n* Google News integration with automatic topic categorization, multi-language support, and comprehensive search capabilities including headlines, stories, and related topics through [SerpAPI](https://serpapi.com/).\\n* [devflowinc/trieve](https://github.com/devflowinc/trieve/tree/main/clients/mcp-server) \\n* Crawl, embed, chunk, search, and retrieve information from datasets through [Trieve](https://trieve.ai)\\n\\n###  Security\\n\\n* [dnstwist MCP Server](https://github.com/BurtTheCoder/mcp-dnstwist) \\n* MCP server for dnstwist, a powerful DNS fuzzing tool that helps detect typosquatting, phishing, and corporate espionage.\\n* [Maigret MCP Server](https://github.com/BurtTheCoder/mcp-maigret) \\n* MCP server for maigret, a powerful OSINT tool that collects user account information from various public sources. This server provides tools for searching usernames across social networks and analyzing URLs.\\n* [Shodan MCP Server](https://github.com/BurtTheCoder/mcp-shodan) \\n* MCP server for querying the Shodan API and Shodan CVEDB. This server provides tools for IP lookups, device searches, DNS lookups, vulnerability queries, CPE lookups, and more.\\n* [VirusTotal MCP Server](https://github.com/BurtTheCoder/mcp-virustotal) \\n* MCP server for querying the VirusTotal API. This server provides tools for scanning URLs, analyzing file hashes, and retrieving IP address reports.\\n\\n###  Travel & Transportation\\n\\nAccess to travel and transportation information. Enables querying schedules, routes, and real-time travel data.\\n\\n* [NS Travel Information MCP Server](https://github.com/r-huijts/ns-mcp-server)  \\n* Access Dutch Railways (NS) travel information, schedules, and real-time updates\\n\\n###  Version Control\\n\\nInteract with Git repositories and version control platforms. Enables repository management, code analysis, pull request handling, issue tracking, and other version control operations through standardized APIs.\\n\\n* [@modelcontextprotocol/server-github](https://github.com/modelcontextprotocol/servers/tree/main/src/github)  \\n* GitHub API integration for repository management, PRs, issues, and more\\n* [@modelcontextprotocol/server-gitlab](https://github.com/modelcontextprotocol/servers/tree/main/src/gitlab)   \\n* GitLab platform integration for project management and CI/CD operations\\n* [@modelcontextprotocol/server-git](https://github.com/modelcontextprotocol/servers/tree/main/src/git)  \\n* Direct Git repository operations including reading, searching, and analyzing local repositories\\n* [adhikasp/mcp-git-ingest](https://github.com/adhikasp/mcp-git-ingest)  \\n* Read and analyze GitHub repositories with your LLM\\n\\n###  Other Tools and Integrations\\n\\n* [ivo-toby/contentful-mcp](https://github.com/ivo-toby/contentful-mcp)  \\n* Update, create, delete content, content-models and assets in your Contentful Space\\n* [mzxrai/mcp-openai](https://github.com/mzxrai/mcp-openai)  \\n* Chat with OpenAI\\'s smartest models\\n* [mrjoshuak/godoc-mcp](https://github.com/mrjoshuak/godoc-mcp)  \\n* Token-efficient Go documentation server that provides AI assistants with smart access to package docs and types without reading entire source files\\n* [pierrebrunelle/mcp-server-openai](https://github.com/pierrebrunelle/mcp-server-openai)  \\n* Query OpenAI models directly from Claude using MCP protocol\\n* [@modelcontextprotocol/server-everything](https://github.com/modelcontextprotocol/servers/tree/main/src/everything)  \\n* MCP server that exercises all the features of the MCP protocol\\n* [baba786/phabricator-mcp-server](https://github.com/baba786/phabricator-mcp-server)  \\n* Interacting with Phabricator API\\n* [MarkusPfundstein/mcp-obsidian](https://github.com/MarkusPfundstein/mcp-obsidian)   \\n* Interacting with Obsidian via REST API\\n* [calclavia/mcp-obsidian](https://github.com/calclavia/mcp-obsidian)  \\n* This is a connector to allow Claude Desktop (or any MCP client) to read and search any directory containing Markdown notes (such as an Obsidian vault).\\n* [anaisbetts/mcp-youtube](https://github.com/anaisbetts/mcp-youtube)  \\n* Fetch YouTube subtitles\\n* [danhilse/notion\\\\_mcp](https://github.com/danhilse/notion_mcp)  \\n* Integrates with Notion\\'s API to manage personal todo lists\\n* [rusiaaman/wcgw](https://github.com/rusiaaman/wcgw/blob/main/src/wcgw/client/mcp_server/Readme.md)  \\n* Autonomous shell execution, computer control and coding agent. (Mac)\\n* [reeeeemo/ancestry-mcp](https://github.com/reeeeemo/ancestry-mcp)  \\n* Allows the AI to read .ged files and genetic data\\n* [sirmews/apple-notes-mcp](https://github.com/sirmews/apple-notes-mcp)  \\n* Allows the AI to read from your local Apple Notes database (macOS only)\\n* [anjor/coinmarket-mcp-server](https://github.com/anjor/coinmarket-mcp-server)  \\n* Coinmarket API integration to fetch cryptocurrency listings and quotes\\n* [suekou/mcp-notion-server](https://github.com/suekou/mcp-notion-server)  \\n* Interacting with Notion API\\n* [amidabuddha/unichat-mcp-server](https://github.com/amidabuddha/unichat-mcp-server) / \\n* Send requests to OpenAI, MistralAI, Anthropic, xAI, Google AI or DeepSeek using MCP protocol via tool or predefined prompts. Vendor API key required\\n* [evalstate/mcp-miro](https://github.com/evalstate/mcp-miro)  \\n* Access MIRO whiteboards, bulk create and read items. Requires OAUTH key for REST API.\\n* [sooperset/mcp-atlassian](https://github.com/sooperset/mcp-atlassian)  \\n* Natural language search and content access for Confluence workspaces\\n* [pyroprompts/any-chat-completions-mcp](https://github.com/pyroprompts/any-chat-completions-mcp)\\n* Chat with any other OpenAI SDK Compatible Chat Completions API, like Perplexity, Groq, xAI and more\\n* [anaisbetts/mcp-installer](https://github.com/anaisbetts/mcp-installer)  \\n* An MCP server that installs other MCP servers for you.\\n* [tanigami/mcp-server-perplexity](https://github.com/tanigami/mcp-server-perplexity)  \\n* Interacting with Perplexity API.\\n* [future-audiences/wikimedia-enterprise-model-context-protocol](https://gitlab.wikimedia.org/repos/future-audiences/wikimedia-enterprise-model-context-protocol)  \\n* Wikipedia Article lookup API\\n* [andybrandt/mcp-simple-timeserver](https://github.com/andybrandt/mcp-simple-timeserver)  \\n* An MCP server that allows checking local time on the client machine or current UTC time from an NTP server\\n* [andybrandt/mcp-simple-openai-assistant](https://github.com/andybrandt/mcp-simple-openai-assistant) -   MCP to talk to OpenAI assistants (Claude can use any GPT model as his assitant)\\n* [@llmindset/mcp-hfspace](https://github.com/evalstate/mcp-hfspace)  \\n* Use HuggingFace Spaces directly from Claude. Use Open Source Image Generation, Chat, Vision tasks and more. Supports Image, Audio and text uploads/downloads.\\n* [zueai/mcp-manager](https://github.com/zueai/mcp-manager)  \\n* Simple Web UI to install and manage MCP servers for Claude Desktop App.\\n* [wong2/mcp-cli](https://github.com/wong2/mcp-cli)  \\n* CLI tool for testing MCP servers\\n* [isaacwasserman/mcp-vegalite-server](https://github.com/isaacwasserman/mcp-vegalite-server)  \\n* Generate visualizations from fetched data using the VegaLite format and renderer.\\n* [tevonsb/homeassistant-mcp](https://github.com/tevonsb/homeassistant-mcp)  \\n* Access Home Assistant data and control devices (lights, switches, thermostats, etc).\\n* [allenporter/mcp-server-home-assistant](https://github.com/allenporter/mcp-server-home-assistant)  \\n* Expose all Home Assistant voice intents through a Model Context Protocol Server allowing home control.\\n* [nguyenvanduocit/all-in-one-model-context-protocol](https://github.com/nguyenvanduocit/all-in-one-model-context-protocol)  \\n* Some useful tools for developer, almost everything an engineer need: confluence, Jira, Youtube, run script, knowledge base RAG, fetch URL, Manage youtube channel, emails, calendar, gitlab\\n* [@joshuarileydev/mac-apps-launcher-mcp-server](https://github.com/JoshuaRileyDev/mac-apps-launcher)  \\n* An MCP server to list and launch applications on MacOS\\n* [ZeparHyfar/mcp-datetime](https://github.com/ZeparHyfar/mcp-datetime)\\n* MCP server providing date and time functions in various formats\\n* [SecretiveShell/MCP-wolfram-alpha](https://github.com/SecretiveShell/MCP-wolfram-alpha)  \\n* An MCP server for querying wolfram alpha API.\\n* [Amazon Bedrock Nova Canvas](https://github.com/zxkane/mcp-server-amazon-bedrock)  \\n* Use Amazon Nova Canvas model for image generation.\\n* [apinetwork/piapi-mcp-server](https://github.com/apinetwork/piapi-mcp-server)   PiAPI MCP server makes user able to generate media content with Midjourney/Flux/Kling/Hunyuan/Udio/Trellis directly from Claude or any other MCP-compatible apps.\\n* [gotoolkits/DifyWorkflow](https://github.com/gotoolkits/mcp-difyworkflow-server) -   Tools to the query and execute of Dify workflows\\n* [@pskill9/hn-server](https://github.com/pskill9/hn-server) -   Parses the HTML content from news.ycombinator.com (Hacker News) and provides structured data for different types of stories (top, new, ask, show, jobs).\\n* [@mediar-ai/screenpipe](https://github.com/mediar-ai/screenpipe) -     Local-first system capturing screen/audio with timestamped indexing, SQL/embedding storage, semantic search, LLM-powered history analysis, and event-triggered actions - enables building context-aware AI agents through a NextJS plugin ecosystem.\\n\\n## Frameworks\\n\\n* [FastMCP](https://github.com/jlowin/fastmcp) \\n* A high-level framework for building MCP servers in Python\\n* [FastMCP](https://github.com/punkpeye/fastmcp) \\n* A high-level framework for building MCP servers in TypeScript\\n* [Foxy Contexts](https://github.com/strowk/foxy-contexts) \\n* Golang libra\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 2: Anthropic\\'s Model Context Protocol (MCP): A Deep Dive ... - Medium ---\\nURL: https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc\\n\\nSUMMARY:\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&user=Amanatullah&userId=af4ccb03fab&source=---header_actions--1d3db39c9fdc---------------------clap_footer------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&source=---header_actions--1d3db39c9fdc---------------------bookmark_footer------------------) At its core, the Model Context Protocol (MCP) is an open standard designed to facilitate seamless integration between LLM applications and external data sources and tools . ![Image 3](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc) ![Image 4](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc) ![Image 5](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc) ![Image 6](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc) MCP provides a universal protocol for connecting AI systems with various data sources, allowing them to access real-time information and specialized tools to ground their responses in accurate and relevant context . ![Image 7](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc) Anthropics own **Claude Desktop** serves as a prime example of a **desktop AI application** that integrates MCP to allow the AI assistant to securely access local files, applications, and services, enhancing its ability to provide contextually relevant responses and perform tasks effectively . [Mcp Server](https://medium.com/tag/mcp-server?source=post_page-----1d3db39c9fdc---------------------------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&user=Amanatullah&userId=af4ccb03fab&source=---footer_actions--1d3db39c9fdc---------------------clap_footer------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&user=Amanatullah&userId=af4ccb03fab&source=---footer_actions--1d3db39c9fdc---------------------clap_footer------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&source=---footer_actions--1d3db39c9fdc---------------------bookmark_footer------------------)\\n\\nFULL CONTENT:\\nAnthropics Model Context Protocol (MCP): A Deep Dive for Developers | by Amanatullah | Medium\\n\\n===============\\n\\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1d3db39c9fdc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n\\n[Search](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n![Image 1](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\nAnthropics Model Context Protocol (MCP): A Deep Dive for Developers\\n====================================================================\\n\\n[![Image 2: Amanatullah](https://miro.medium.com/v2/resize:fill:64:64/1*Jg1DS1nkP3T6lY4rAMWeCA.jpeg)](https://medium.com/@amanatulla1606?source=post_page---byline--1d3db39c9fdc---------------------------------------)\\n\\n[Amanatullah](https://medium.com/@amanatulla1606?source=post_page---byline--1d3db39c9fdc---------------------------------------)\\n\\n15 min read\\n\\n\\n\\nMar 21, 2025\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&user=Amanatullah&userId=af4ccb03fab&source=---header_actions--1d3db39c9fdc---------------------clap_footer------------------)\\n\\n--\\n\\n2\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&source=---header_actions--1d3db39c9fdc---------------------bookmark_footer------------------)\\n\\nListen\\n\\nShare\\n\\nIntroduction: Bridging the Gap  Understanding Anthropics Model Context Protocol (MCP)\\n---------------------------------------------------------------------------------------\\n\\nThe landscape of artificial intelligence is rapidly evolving, with large language models (LLMs) at the forefront of this transformation. As these models become increasingly sophisticated in their ability to understand and generate human-like text, the demand for integrating them with external systems has grown significantly. This integration promises to unlock a new era of applications capable of leveraging real-world data and tools to enhance their functionality and provide more contextually relevant responses. However, traditional methods of connecting LLMs to external resources often involve complex and bespoke implementations for each data source, leading to fragmented and difficult-to-scale architectures.\\n\\nAnthropics Model Context Protocol (MCP) emerges as a pivotal solution to these challenges. This open protocol standardizes how applications provide context to LLMs, offering a unified and streamlined approach to connecting AI models with the vast ecosystem of data sources and tools . Think of MCP as a universal adapter, much like a USB-C port, that allows any compliant AI application to seamlessly interact with any compatible data source or service without the need for custom code for each connection . By providing this standardized framework, MCP aims to foster a collaborative ecosystem where developers can build and share connectors, ultimately accelerating the development of more intelligent and integrated AI applications .\\n\\nMCP: What It Is and Why It Matters\\n----------------------------------\\n\\nAt its core, the Model Context Protocol (MCP) is an open standard designed to facilitate seamless integration between LLM applications and external data sources and tools . It establishes a common language and set of rules for how AI models can access and interact with information and capabilities residing outside of their internal knowledge base . This standardized approach simplifies the often-complex process of connecting AI with the real world, enhancing interoperability and promoting scalability across various AI systems .\\n\\n![Image 3](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc)\\n\\nThe fundamental concept behind MCP is to act as a universal connector, enabling AI models to plug into different data sources and tools in a consistent manner . This eliminates the need for developers to create custom integrations for every new tool or dataset they want their AI application to interact with . The key objectives of MCP include simplifying these integrations, enhancing the ability of different AI systems and tools to work together, and making it easier to build and scale AI-powered applications .\\n\\nPress enter or click to view image in full size\\n\\n![Image 4](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc)\\n\\nMCP operates on a client-server architecture . This architecture involves three main components: the Host Process, MCP Clients, and MCP Servers . The **Host Process** is the AI-powered application or agent environment, such as the Claude desktop app or an IDE plugin, which the end-user interacts with. The host can connect to multiple MCP servers simultaneously . **MCP Clients** are intermediaries managed by the host, with each client handling the communication to one specific MCP server, ensuring security and sandboxing . The host spawns a client for each server it needs to use, maintaining a one-to-one link . **MCP Servers** are programs, typically external to the model, that implement the MCP standard and provide a specific set of capabilities. These capabilities usually include a collection of tools, access to data resources, and predefined prompts related to a particular domain . An MCP server might interface with a database, a cloud service, or any other data source . These servers expose their functionalities through standardized primitives, which include resources (data that can be read), tools (functions that can be executed), and prompts (pre-written templates to guide tasks) . This client-server architecture ensures a clear separation of concerns and allows for modular and scalable AI application development .\\n\\nMCP vs. OpenAI Function Calling: Key Differences and Use Cases\\n--------------------------------------------------------------\\n\\nAs developers explore ways to extend the capabilities of LLMs, OpenAIs function calling has emerged as a popular technique. Function calling allows LLMs to identify the need to call external functions or APIs based on user input and then structure the arguments for these calls . While both MCP and function calling aim to integrate LLMs with external systems, they differ significantly in their scope, standardization, and communication paradigms .\\n\\nPress enter or click to view image in full size\\n\\n![Image 5](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc)\\n\\nOpenAIs function calling is primarily focused on enabling LLMs to translate user prompts into structured API calls . It allows the model to determine which function to call and with what parameters, facilitating interactions with external services. In contrast, MCP is a broader protocol that standardizes the entire execution and interaction process between LLM applications and external systems . It not only handles the translation of user intent but also provides a structured framework for tool discovery, invocation, and response handling .\\n\\nA key distinction lies in standardization. OpenAIs function calling is largely vendor-specific, with each model potentially formatting function calls differently . While tools like LangChain can help manage these variations, there is no universal standard . MCP, on the other hand, is designed to be model-agnostic and an open standard . This means that any LLM that implements the MCP client can interact with any MCP server, promoting greater interoperability and reducing vendor lock-in .\\n\\nThe communication flow also differs. Function calling typically follows a request-response pattern where the AI asks for something and gets a predefined answer . MCP supports a more ongoing and interactive communication, allowing AI to not only request data but also receive updates from external tools dynamically . Furthermore, MCP operates on a client-side execution model, where the host application manages the clients and their connections to servers, whereas function calling logic often resides server-side .\\n\\nThe following table summarizes the key differences between MCP and OpenAI function calling:\\n\\n![Image 6](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc)\\n\\nMCP might be preferred over function calling in scenarios that require complex workflows involving multiple tools, the need for real-time updates, or when aiming for model and vendor independence . While function calling is sufficient for simple API interactions, MCP offers a more robust and standardized approach for building sophisticated AI agents and applications that need to interact with a diverse range of external systems .\\n\\nThe Problems MCP Solves: Breaking Down LLM Integration Barriers\\n---------------------------------------------------------------\\n\\nAnthropics Model Context Protocol is specifically designed to address several fundamental problems and limitations inherent in interacting with large language models and integrating them into real-world applications . One of the most significant challenges is the NM integration problem . As the number of AI applications (N) and the variety of tools and data sources (M) increase, the complexity of creating custom integrations for each combination becomes unmanageable. MCP tackles this by providing a standardized interface, effectively transforming the problem into a much simpler N+M setup where each AI model and each tool only needs to conform to the MCP standard once .\\n\\nAnother key issue MCP addresses is the isolation of LLMs from real-world, up-to-date information . Even the most advanced models are often constrained by their training data, which may be outdated or incomplete. MCP provides a universal protocol for connecting AI systems with various data sources, allowing them to access real-time information and specialized tools to ground their responses in accurate and relevant context . This capability is crucial for reducing LLM hallucinations, where models confidently generate incorrect or nonsensical information . By enabling access to external knowledge, MCP helps ensure that AI applications can provide more reliable and trustworthy outputs.\\n\\nFurthermore, MCP facilitates the development of more sophisticated and autonomous AI agents . By maintaining context across different tools and datasets, MCP supports the creation of AI systems capable of performing complex tasks on behalf of users. This is essential for building truly intelligent applications that can not only understand user requests but also proactively take actions to fulfill them .\\n\\nBeyond these core problems, MCP also aims to address broader challenges in AI development, such as integration complexity, the lack of common design patterns, scalability limitations, and the need for future-proofing . By establishing a standardized protocol, MCP frees up developer bandwidth and budget currently spent on creating and maintaining custom integrations . It also fosters a shared understanding of development best practices, which is increasingly important with the rise of more complex agentic AI . Moreover, a standard protocol simplifies the process of integrating more AI services and ensures that applications can adapt to new and emerging AI technologies without requiring major rewrites .\\n\\nUnlocking Potential: Benefits of MCP for Application Development\\n----------------------------------------------------------------\\n\\nThe Model Context Protocol offers a multitude of benefits for developers looking to build innovative AI-powered applications . One of the primary advantages is the **simplified development process** resulting from standardized integration . Instead of creating unique connections for each data source or tool, developers can leverage the MCP framework to establish consistent and reusable integrations .\\n\\nMCP also enhances **interoperability** between AI models and external tools . By providing a common language for communication, MCP allows different AI systems and tools to work together seamlessly, regardless of their underlying architecture or vendor . This promotes a more open and collaborative AI ecosystem.\\n\\nFurthermore, MCP significantly improves the **context awareness** of AI models . By enabling easy access to real-time data and specialized tools, MCP allows AI to ground their responses in accurate and relevant information, leading to more intelligent and useful applications . The protocol also supports **two-way communication**, allowing AI models not only to receive information but also to trigger actions in external systems, enabling more dynamic and interactive applications .\\n\\nThe underlying architecture of MCP is **modular and scalable** . The client-server design ensures a clear separation of concerns, allowing different components to be developed and scaled independently . This makes it easier to build complex AI applications that can handle increasing demands and integrate with a growing number of services.\\n\\nMCP opens up a wide range of potential use cases for application development. For instance, in **AI-powered coding assistants**, MCP can enable access to extensive codebases and documentation, providing developers with accurate code suggestions and insights . In enterprise settings, **enterprise data assistants** can leverage MCP to securely access company data, documents, and internal services, improving knowledge retrieval and task automation . **AI-driven data querying** applications can use MCP to connect AI models with databases, simplifying data analysis and reporting through natural language interfaces . **Desktop AI applications** like Anthropics Claude Desktop already integrate MCP to allow AI assistants to access local files and applications securely . Moreover, MCP facilitates the creation of **composable integrations and workflows**, allowing developers to build sophisticated AI agents that can orchestrate complex sequences of actions across different systems . The availability of **SDKs** in various programming languages like Python, TypeScript, Java, and Kotlin further simplifies the implementation of MCP servers and clients . Finally, MCP offers the potential for **vendor flexibility**, making it easier for developers to switch between LLM providers without significant code changes .\\n\\nUnder the Hood: MCP Architecture Explained\\n------------------------------------------\\n\\nThe Model Context Protocol (MCP) is built on a flexible and extensible architecture that facilitates seamless communication between LLM applications and various integrations . At its core, MCP follows a **client-server architecture** . This design involves several key components that work together to enable context-aware AI interactions.\\n\\nThe central component is the **Host Process** . This is the main AI application, such as Claude Desktop or an integrated development environment (IDE), that initiates connections to external resources. The host acts as a container and coordinator, managing multiple **MCP Clients** . Each client maintains a one-to-one connection with an **MCP Server** . The host is responsible for controlling client connection permissions and lifecycle, enforcing security policies and consent requirements, coordinating AI/LLM integration and sampling, and managing context aggregation across clients .\\n\\n**MCP Clients** reside within the host application and handle the communication with MCP servers . They are responsible for establishing and maintaining isolated server connections, handling protocol negotiation and capability exchange, routing protocol messages bidirectionally, managing subscriptions and notifications, and maintaining security boundaries between servers .\\n\\n**MCP Servers** provide the specialized context and capabilities to the host application . They expose resources, tools, and prompts via MCP primitives . Servers operate independently with focused responsibilities, request sampling through client interfaces, and must respect security constraints . They can be local processes or remote services .\\n\\nThe **communication flow** between clients and servers in MCP typically uses **JSON-RPC** . MCP supports multiple **transport mechanisms** for this communication, including **Stdio** (standard input/output) for local processes and **HTTP with Server-Sent Events (SSE)** for remote communication . The protocol defines several main **message types**: **Requests** which expect a response, **Results** which are successful responses, **Errors** indicating a failed request, and **Notifications** which are one-way messages that dont expect a response .\\n\\nA significant aspect of the MCP architecture is the emphasis on **security and controlled access** . The host instantiates clients and approves servers, allowing users and organizations to strictly manage what an AI assistant is allowed to connect to .\\n\\n**Diagram 1: Anthropic Model Context Protocol (MCP) Architecture**\\n\\n![Image 7](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc)\\n\\nThe modularity inherent in this architecture allows for the independent development and deployment of MCP servers, enabling the extension of AI application capabilities without modifying the core application . The support for multiple transport mechanisms provides flexibility for various deployment scenarios, accommodating both local and remote communication needs .\\n\\nReal-World Applications: Practical Implementation Examples of MCP\\n-----------------------------------------------------------------\\n\\nThe versatility of the Model Context Protocol is evident in its growing adoption across various applications and domains . Several **AI-powered coding assistants** have integrated MCP to enhance developer productivity. For example, **Sourcegraph Cody** utilizes MCP to access extensive codebases and documentation, providing developers with accurate code suggestions and insights . Similarly, **Zed Editor** has incorporated MCP to enable its AI features to interact seamlessly with various development tools and resources .\\n\\nIn the enterprise space, MCP is being used to facilitate **enterprise integrations**. Companies like **Block** have adopted MCP to securely connect their AI systems with internal data repositories, enabling more informed decision-making . **Apollo** utilizes MCP to link its AI tools with customer relationship management (CRM) systems, enhancing data accessibility and client interactions .\\n\\nMCP also powers **AI-driven data querying** applications. **AI2SQL**, for instance, leverages MCP to enable users to generate SQL queries through natural language prompts, simplifying data analysis and reporting . Anthropics own **Claude Desktop** serves as a prime example of a **desktop AI application** that integrates MCP to allow the AI assistant to securely access local files, applications, and services, enhancing its ability to provide contextually relevant responses and perform tasks effectively .\\n\\nBeyond these examples, MCP is being integrated with various **development tools**. Companies like **Replit**, **Codeium**, and **Sourcegraph** are working with MCP to enhance their platforms, enabling AI agents to better retrieve relevant information for coding tasks . **Apify** has developed an MCP server that allows AI agents to access all Apify Actors for automated data extraction and web searches . A practical example demonstrates building an MCP-powered server for **GitHub PR review**, which can fetch PR details, analyze code changes using Claude Desktop, and generate summaries and suggestions . The potential extends to creating **personal assistants** with deep integration into local data and applications , as well as facilitating complex **workflow orchestration** across disparate systems .\\n\\nHands-On with Claude Desktop: Integrating and Using MCP (with Code)\\n-------------------------------------------------------------------\\n\\nAnthropics Claude Desktop provides a user-friendly environment for developers to begin experimenting with the Model Context Protocol . Integrating MCP with Claude Desktop involves configuring local MCP servers through the `claude_desktop_config.json` file . This configuration file, located in the application support directory for Claude, tells the application which MCP servers to start up .\\n\\nTo add an MCP server, you need to edit this configuration file. The basic structure involves defining a server name and providing the command and any necessary arguments to run the server . For example, to enable Claude to access your local file system, you can add the Filesystem MCP Server . First, ensure you have Node.js installed. Then, locate or create the `claude_desktop_config.json` file. For macOS, it\\'s typically at `~/Library/Application Support/Claude/claude_desktop_config.json`, and for Windows, it\\'s at `%APPDATA%\\\\Claude\\\\claude_desktop_config.json` . Add the following configuration:\\n\\n{\\n\\n \"mcpServers\": {\\n\\n \"filesystem\": {\\n\\n \"command\": \"npx\",\\n\\n \"args\": [\\n\\n \"-y\",\\n\\n \"@modelcontextprotocol/server-filesystem\",\\n\\n \"/Users/your_username/Desktop\",\\n\\n \"/Users/your_username/Downloads\"\\n\\n ]\\n\\n }\\n\\n }\\n\\n}\\nReplace `/Users/your_username` with your actual username and specify the directories you want Claude to be able to access . After saving the file and restarting Claude Desktop, you should see a hammer icon in the bottom right corner of the input box, indicating that MCP servers are active . Clicking this icon will show the tools provided by the configured servers . You can then interact with the Filesystem Server through natural language prompts:\\n\\nSimilarly, you can integrate with Git repositories using the Git MCP Server. After installing the server using `uv tool install mcp-server-git`, you can configure it in `claude_desktop_config.json`:\\n\\n{\\n\\n \"mcpServers\": {\\n\\n \"git\": {\\n\\n \"command\": \"uvx\",\\n\\n \"args\": [\\n\\n \"mcp-server-git\",\\n\\n \"--repository\",\\n\\n \"/path/to/your/git/repo\"\\n\\n ]\\n\\n }\\n\\n }\\n\\n}\\nReplace `/path/to/your/git/repo` with the actual path to your repository . After restarting Claude, you can ask questions like:\\n\\n### Cursor and Smithery MCP\\n\\nSmithery is a platform designed to help developers discover and utilize extensions for language models that are compatible with the Model Context Protocol (MCP) . It acts as a central hub where you can find and potentially install MCP servers to enhance the capabilities of AI assistants and applications . Smitherys goal is to simplify the process of connecting language models with external tools and data sources, thereby accelerating the development of agentic AI .\\n\\nThe Smithery platform hosts a wide array of MCP servers that provide various functionalities . These servers act as intermediaries, allowing AI models to interact with external resources and perform specific tasks . Some examples of the types of MCP servers you might find on Smithery include those for:\\n\\n*   **Web Search:** To enable the AI to search the internet for up-to-date information .\\n*   **File System Access:** To allow the AI to read and write files on your local machine (with your permission) .\\n*   **Version Control (Git, GitHub, GitLab):** To interact with your code repositories, such as viewing recent commits or managing issues .\\n*   **Databases (PostgreSQL, SQLite, MySQL):** To enable the AI to query and interact with databases .\\n*   **Collaboration Tools (Slack):** To manage channels and send messages within Slack workspaces .\\n*   **Cloud Platforms (Cloudflare, Kubernetes, Docker):** To manage resources and services on various cloud platforms .\\n*   **Automation Tools (Puppeteer, Playwright):** To automate browser interactions and web scraping tasks .\\n*   **Note-Taking Apps (Obsidian, Notion):** To read, search, and update notes within these applications .\\n*   **Various APIs:** For accessing data and services from platforms like Google Maps, Stripe, AlphaVantage (stock data), and more .\\n\\nThe MCP servers on Smithery are built by a combination of the Smithery team and the wider community of developers . Smithery provides reference implementations and SDKs to help developers create their own MCP servers . The platform encourages contributions from the community, leading to a growing ecosystem of tools and integrations . While Smithery aims to be a reliable source, its worth noting that community-built servers might vary in quality and should be used with caution .\\n\\nTo use Smithery MCP servers inside the Cursor IDE, you need to configure Cursor to connect to these servers. Cursor acts as an MCP client, capable of communicating with MCP servers . Heres a general process based on the research:\\n\\n1.   **Find the desired MCP server on Smithery:** Navigate to the Smithery website ([https://smithery.ai/](https://smithery.ai/)) and browse or search for the MCP server that provides the functionality you need .\\n2.   **Get the installation command or configuration details:** On the servers page, Smithery often provides installation instructions, which might include a command-line instruction (often using `npx`) or specific configuration details . Smithery sometimes offers a \"Cursor button\" that provides a ready-to-copy snippet for Cursor .\\n3.   **Open Cursor Settings:** In the Cursor IDE, go to the settings or preferences section and find the MCP Servers option (it might be under Features) .\\n4.   **Add a new MCP server:** Click on the button to add a new MCP server (it might be labeled + Add New MCP Server or similar) .\\n5.   **Configure the server:** Youll typically need to provide the following information:\\n\\n*   **Name/Nickname:** Give the server a recognizable name (e.g., GitHub MCP, Web Search) .\\n*   **Type/Transport:** Select the transport type. This is usually either command (for local servers run via stdio) or URL (for remote servers using SSE) . The instructions on Smithery should indicate which type to use.\\n*   **Command/URL:** Paste the command or URL provided by Smithery. For command-type servers, you might need to prepend `node` to the command if it\\'s a Node.js server, or use the appropriate command for other languages like Python (`python` or `uvx`) . For URL types, paste the SSE endpoint URL .\\n*   **Environment Variables (if required):** Some MCP servers require API keys or other configuration parameters. You might need to add these as environment variables in the Cursor settings for the MCP server . Smitherys instructions should specify if any environment variables are needed.\\n\\n1.   **Enable the server:** After adding the server, make sure its enabled in the list of MCP servers in Cursors settings . You might see a green dot indicating that the server is active .\\n2.   **Refresh MCP tools (if necessary):** In some cases, you might need to click a refresh button in Cursors MCP settings to update the list of available tools from the newly added server .\\n3.   **Use the tools in Cursor:** Once the MCP server is configured and active, Cursors AI agent (Composer) can automatically use the tools provided by the server if it determines they are relevant to your prompt . You can also explicitly tell the agent to use a specific tool by referring to it by name or description in your prompt .\\n\\n[Mcp Server](https://medium.com/tag/mcp-server?source=post_page-----1d3db39c9fdc---------------------------------------)\\n\\n[Mcps](https://medium.com/tag/mcps?source=post_page-----1d3db39c9fdc---------------------------------------)\\n\\n[Anthropics](https://medium.com/tag/anthropics?source=post_page-----1d3db39c9fdc---------------------------------------)\\n\\n[AI](https://medium.com/tag/ai?source=post_page-----1d3db39c9fdc---------------------------------------)\\n\\n[Llm](https://medium.com/tag/llm?source=post_page-----1d3db39c9fdc---------------------------------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&user=Amanatullah&userId=af4ccb03fab&source=---footer_actions--1d3db39c9fdc---------------------clap_footer------------------)\\n\\n--\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1d3db39c9fdc&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amanatulla1606%2Fanthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc&user=Amanatullah&userId=af4ccb03fab&source=---footer_actions--1d3db39c9fdc---------------------clap_footer------------------)\\n\\n--\\n\\n2\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fm\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 3: Model Context Protocol Servers - Augment Code ---\\nURL: https://www.augmentcode.com/mcp\\n\\nSUMMARY:\\nModel-Context-Protocol (MCP) server that lets Claude Desktop run terminal commands, manage processes and edit/search local files via AI-driven tools. Model Context Protocol (MCP) server that lets AI assistants (e.g., Claude Desktop) access Exa AIs web-search API with optional tools for company research, crawling, LinkedIn search and deep research automation. Model-Context-Protocol (MCP) server that lets AI assistants search, download and analyse arXiv papers through a simple tool interface. Implementation of a Model Context Protocol (MCP) server that exposes VictoriaMetrics APIs, documentation search and troubleshooting tools to AI-assistants and other MCP clients. Go-based Model Context Protocol (MCP) server that lets AI agents manage and query Portainer (Docker/Kubernetes) environments via a standardised tool interface.\\n\\nFULL CONTENT:\\naugment-mcp-registry v1.0.0\\n\\n```\\n MCP Server Registry     Discover and integrate Model Context Protocol servers   to enhance your AI development workflow    \\n```\\n\\n$mcp-registry search\\n\\n navigate   select  / search  esc clear\\n\\nFound 286servers\\n\\n[```\\n  PR   OSS  \\n```\\n\\nprisma@prisma\\n\\n43.0k1.8kOpen Source\\n\\nNext-generation ORM for Node.js & TypeScript supporting PostgreSQL, MySQL, MariaDB, SQL Server, SQLite, MongoDB and CockroachDB.\\n\\ntools: prisma client, prisma migrate, prisma studio](/mcp/prisma)[```\\n  MI   OSS  \\n```\\n\\nmindsdb@mindsdb\\n\\n34.9k5.6kOpen Source\\n\\nAIs query-engine & MCP server for building agents that answer questions over large-scale, federated data sources.\\n\\ntools: views, knowledge bases, ml models, jobs +2 more](/mcp/mindsdb)[```\\n  GI   SRV  \\n```\\n\\ngithub-mcp-server@github\\n\\n17.4k1.3kEnterprise\\n\\nGitHubs official Model Context Protocol (MCP) server that exposes rich, tool-oriented access to GitHubs REST & GraphQL APIs. Supports remote (hosted) or local (Docker / native Go binary) deployment and fine-grained toolset configuration.\\n\\ntools: cancel\\\\_workflow\\\\_run, delete\\\\_workflow\\\\_run\\\\_logs, download\\\\_workflow\\\\_run\\\\_artifact, get\\\\_job\\\\_logs +70 more](/mcp/github-mcp-server)[```\\n  SC   OSS  \\n```\\n\\nscreenpipe@mediar-ai\\n\\n15.4k1.2kOpen Source\\n\\nAI app-store platform that continuously records a users desktop (screen + mic) locally, indexes it, and exposes an API so developers can build context-aware AI desktop apps (pipes) in Next.js, publish them and monetise through the built-in store.\\n\\ntools: screenpipe, pipe create, pipe register, pipe publish +1 more](/mcp/screenpipe)[```\\n  PL   OSS  \\n```\\n\\nplaywright-mcp@microsoft\\n\\n14.7k1.0kOpen Source\\n\\nPlaywright MCP server](/mcp/playwright-mcp)[```\\n  FI   OSS  \\n```\\n\\nFigma-Context-MCP@GLips\\n\\n9.5k774Open Source\\n\\nMCP server to provide Figma layout information to AI coding agents like Cursor](/mcp/figma-context-mcp)[```\\n  GE   OSS  \\n```\\n\\ngenai-toolbox@googleapis\\n\\n8.3k607Open Source\\n\\nMCP Toolbox for Databases  an open-source MCP server that sits between Gen-AI agents and relational data sources, providing connection pooling, auth, observability, and a YAML-driven tool definition system.\\n\\ntools: search-hotels-by-name](/mcp/genai-toolbox)[```\\n  GH   OSS  \\n```\\n\\nGhidraMCP@LaurieWired\\n\\n5.5k404Open Source\\n\\nModel-Context-Protocol (MCP) server and Ghidra plugin that lets LLM clients de-compile and analyse binaries through Ghidra autonomously.\\n\\ntools: decompile and analyze binaries in ghidra, automatically rename methods and data, list methods, classes, imports, and exports](/mcp/ghidramcp)[```\\n  AW   OSS  \\n```\\n\\nawslabs/mcp@awslabs\\n\\n4.7k585Open Source\\n\\nSuite of AWS-focused Model Context Protocol (MCP) servers  lightweight Python services that expose AWS tooling, documentation, pricing, IaC and other capabilities to MCP-compatible AI clients (Amazon Q, Cline, Cursor, Windsurf, etc.).\\n\\ntools: aws api mcp server, aws documentation mcp server, aws cdk mcp server, aws terraform mcp server +49 more](/mcp/awslabs-mcp)[```\\n  WH   SPL  \\n```\\n\\nwhatsapp-mcp@lharries\\n\\n4.6k658Specialized\\n\\nModel-Context-Protocol (MCP) server that lets Claude / Cursor read, search and send WhatsApp messages (text & media) through your personal account.\\n\\ntools: search\\\\_contacts, list\\\\_messages, list\\\\_chats, get\\\\_chat +8 more](/mcp/whatsapp-mcp)[```\\n  MC   OSS  \\n```\\n\\nmcp-playwright@executeautomation\\n\\n4.5k371Open Source\\n\\nPlaywright Model Context Protocol Server  expose Playwright-based browser automation, screenshotting, code-gen and JS execution as MCP tools.](/mcp/mcp-playwright)[```\\n  WO   OSS  \\n```\\n\\nwonderwhy-er/DesktopCommanderMCP@wonderwhy-er\\n\\n4.1k447Open Source\\n\\nModel-Context-Protocol (MCP) server that lets Claude Desktop run terminal commands, manage processes and edit/search local files via AI-driven tools.\\n\\ntools: get\\\\_config, set\\\\_config\\\\_value, start\\\\_process, interact\\\\_with\\\\_process +19 more](/mcp/wonderwhy-er-desktopcommandermcp)[```\\n  GI   OSS  \\n```\\n\\ngit-mcp@idosal\\n\\n3.7k259Open Source\\n\\nGitMCP is a free, open-source Model Context Protocol (MCP) server that turns any GitHub repository or GitHub-Pages site into an AI-readable documentation hub, eliminating code-hallucinations in tools such as Cursor, VSCode, Claude Desktop, etc.\\n\\ntools: fetch\\\\_\\\\_documentation, search\\\\_\\\\_documentation, fetch\\\\_url\\\\_content, search\\\\_\\\\_code +3 more](/mcp/git-mcp)[```\\n  MC   OSS  \\n```\\n\\nmcp@BrowserMCP\\n\\n3.4k228Open Source\\n\\nBrowser MCP  a Model Context Provider (MCP) server + Chrome extension enabling local, private AI-driven browser automation.](/mcp/mcp)[```\\n  ID   SPL  \\n```\\n\\nida-pro-mcp@mrexodia\\n\\n2.8k287Specialized\\n\\nMCP (Model Context Protocol) server and IDA Pro plugin that exposes IDA functionality (decompile, disassemble, xrefs, rename, debugging, ) through JSON-RPC so LLM-based clients (Cline, Cursor, Claude, VS Code agent mode, etc.) can automate reverse-engineering tasks.\\n\\ntools: check\\\\_connection, get\\\\_metadata, get\\\\_function\\\\_by\\\\_name, get\\\\_function\\\\_by\\\\_address +32 more](/mcp/ida-pro-mcp)[```\\n  MC   SRV  \\n```\\n\\nmcp-server-cloudflare@cloudflare\\n\\n2.8k232Enterprise\\n\\nMonorepo that hosts Cloudflare-maintained Model Context Protocol (MCP) servers. Each app exposes Cloudflare services (Workers bindings, observability, browser rendering, etc.) to any MCP-compatible client so developers can programmatically inspect or modify their Cloudflare account via natural-language tool calls.\\n\\ntools: documentation server, workers bindings server, workers builds server, observability server +11 more](/mcp/mcp-server-cloudflare)[```\\n  MC   OSS  \\n```\\n\\nmcp-atlassian@sooperset\\n\\n2.6k471Open Source\\n\\nModel Context Protocol (MCP) server that adds Confluence & Jira Cloud/Server support, exposing rich read/write tools for AI assistants.\\n\\ntools: confluence\\\\_add\\\\_comment, confluence\\\\_add\\\\_label, confluence\\\\_create\\\\_page, confluence\\\\_delete\\\\_page +37 more](/mcp/mcp-atlassian)[```\\n  MC   SPL  \\n```\\n\\nmcp-server-browserbase@browserbase\\n\\n2.3k241Specialized\\n\\nMCP server that lets LLMs control cloud browsers through Browserbase & Stagehand (web automation, screenshots, data-extraction, multi-session).](/mcp/mcp-server-browserbase)[```\\n  MC   OSS  \\n```\\n\\nmcp-server-chart@antvis\\n\\n2.2k201Open Source\\n\\nTypeScript-based Model Context Protocol (MCP) server that exposes 25+ chart-generation tools powered by AntV. Usable over stdio, SSE or streamable HTTP transport and easily integrable into Desktop AI clients or any MCP-compatible platform.\\n\\ntools: generate\\\\_area\\\\_chart, generate\\\\_bar\\\\_chart, generate\\\\_boxplot\\\\_chart, generate\\\\_column\\\\_chart +21 more](/mcp/mcp-server-chart)[```\\n  EX   SRV  \\n```\\n\\nexa-mcp-server@exa-labs\\n\\n2.0k174Enterprise\\n\\nModel Context Protocol (MCP) server that lets AI assistants (e.g., Claude Desktop) access Exa AIs web-search API with optional tools for company research, crawling, LinkedIn search and deep research automation.\\n\\ntools: web\\\\_search\\\\_exa, company\\\\_research, crawling, linkedin\\\\_search +2 more](/mcp/exa-mcp-server)[```\\n  EX   OSS  \\n```\\n\\nexcel-mcp-server@haris-musa\\n\\n1.8k206Open Source\\n\\nModel Context Protocol server that lets AI agents create, read and modify Excel workbooks without a local Excel install.](/mcp/excel-mcp-server)[```\\n  SU   OSS  \\n```\\n\\nsupabase-mcp@supabase-community\\n\\n1.8k167Open Source\\n\\nNode-based Model Context Protocol server that exposes Supabase projects (tables, docs, functions, etc.) to AI assistants such as Cursor, Claude and Windsurf.\\n\\ntools: list\\\\_projects, get\\\\_project, create\\\\_project, pause\\\\_project +27 more](/mcp/supabase-mcp)[```\\n  MC   SPL  \\n```\\n\\nmcp-obsidian@MarkusPfundstein\\n\\n1.6k197Specialized\\n\\nMCP server that interacts with Obsidian via the Local REST API community plugin, exposing tools for listing, reading, searching and modifying notes inside an Obsidian vault.\\n\\ntools: list\\\\_files\\\\_in\\\\_vault, list\\\\_files\\\\_in\\\\_dir, get\\\\_file\\\\_contents, search +3 more](/mcp/mcp-obsidian)[```\\n  MC   OSS  \\n```\\n\\nmcp-cli@chrishayuk\\n\\n1.6k270Open Source\\n\\nPython-based command-line interface for interacting with Model Context Protocol (MCP) servers; offers chat, interactive shell, and automation modes with built-in LLM provider & tool management.\\n\\ntools: list\\\\_tables, describe\\\\_table, read\\\\_query, write\\\\_file +1 more](/mcp/mcp-cli)[```\\n  MO   OSS  \\n```\\n\\nmobile-mcp@mobile-next\\n\\n1.6k146Open Source\\n\\nModel Context Protocol Server for Mobile Automation and Scraping (iOS, Android, Emulators, Simulators and Real Devices)](/mcp/mobile-mcp)[```\\n  AR   OSS  \\n```\\n\\narxiv-mcp-server@blazickjp\\n\\n1.5k93Open Source\\n\\nModel-Context-Protocol (MCP) server that lets AI assistants search, download and analyse arXiv papers through a simple tool interface.\\n\\ntools: search\\\\_papers, download\\\\_paper, list\\\\_papers, read\\\\_paper](/mcp/arxiv-mcp-server)[```\\n  MC   OSS  \\n```\\n\\nmcp-shrimp-task-manager@cjo4m06\\n\\n1.4k162Open Source\\n\\nShrimp Task Manager  an MCP server that turns natural-language requests into structured development tasks with dependency tracking, reflection and web/GUI support for AI agents.\\n\\ntools: plan\\\\_task, analyze\\\\_task, process\\\\_thought, reflect\\\\_task +9 more](/mcp/mcp-shrimp-task-manager)[```\\n  MC   OSS  \\n```\\n\\nmcp-installer@anaisbetts\\n\\n1.3k170Open Source\\n\\nMCP server that installs other MCP servers (via npm or PyPI) so Claude can use them.](/mcp/mcp-installer)[```\\n  GR   OSS  \\n```\\n\\ngrafana/mcp-grafana@grafana\\n\\n1.3k111Open Source\\n\\nGo implementation of a Model-Context-Protocol (MCP) server that exposes Grafana, Prometheus, Loki and related APIs as structured MCP tools.\\n\\ntools: list\\\\_teams, list\\\\_users\\\\_by\\\\_org, search\\\\_dashboards, get\\\\_dashboard\\\\_by\\\\_uid +37 more](/mcp/grafana-mcp-grafana)[```\\n  AN   OSS  \\n```\\n\\nanyquery@julien040\\n\\n1.1k63Open Source\\n\\nQuery anything (files, databases, +40 app integrations) with SQL, expose results to LLMs over the Model-Context-Protocol (MCP) and act as a MySQL-compatible server.\\n\\ntools: anyquery, anyquery mcp, anyquery gpt, anyquery server](/mcp/anyquery)[```\\n  DB   OSS  \\n```\\n\\ndbhub@bytebase\\n\\n1.0k98Open Source\\n\\nUniversal database gateway implementing the Model Context Protocol (MCP) server interface. Lets MCP-compatible clients (Cursor, Claude, etc.) explore and query MySQL, PostgreSQL, MariaDB, SQL Server and SQLite databases.\\n\\ntools: execute\\\\_sql, generate\\\\_sql, explain\\\\_db](/mcp/dbhub)[```\\n  BR   SRV  \\n```\\n\\nbrightdata-mcp@brightdata\\n\\n1.0k139Enterprise\\n\\nA powerful Model Context Protocol (MCP) server that provides an all-in-one solution for real-time web access, scraping and browser automation for LLM/agent integrations.\\n\\ntools: search\\\\_engine, scrape\\\\_as\\\\_markdown](/mcp/brightdata-mcp)[```\\n  ME   OSS  \\n```\\n\\nmetamcp@metatool-ai\\n\\n946130Open Source\\n\\nMetaMCP  an all-in-one MCP (Model Context Protocol) aggregator/orchestrator/middleware & gateway packaged for Docker. It groups multiple MCP servers into namespaces, exposes unified endpoints (SSE, Streamable HTTP, OpenAPI) and lets you plug in middlewares, auth (API-Key & OIDC) and inspection tools.\\n\\ntools: list\\\\_tools, call\\\\_tool](/mcp/metamcp)[```\\n  MC   OSS  \\n```\\n\\nmcp-server-kubernetes@Flux159\\n\\n933147Open Source\\n\\nMCP (Model Context Protocol) server that exposes high-level Kubernetes and Helm management tools through the MCP interface. It auto-detects kubeconfig, supports non-destructive mode, and bundles many kubectl/helm operations for chat-based automation.\\n\\ntools: kubectl\\\\_get, kubectl\\\\_describe, kubectl\\\\_create, kubectl\\\\_apply +17 more](/mcp/mcp-server-kubernetes)[```\\n  MC   OSS  \\n```\\n\\nmcp-jetbrains@JetBrains\\n\\n88163Open Source\\n\\nModel-Context-Protocol proxy server that forwards MCP requests from external clients (e.g., VS Code, Claude Desktop, Docker containers) to a running JetBrains IDE (IntelliJ IDEA, PyCharm, WebStorm, Android Studio, etc.).\\n\\ntools: list\\\\_tools](/mcp/mcp-jetbrains)[```\\n  MC   OSS  \\n```\\n\\nmcp-unity@CoderGamester\\n\\n824104Open Source\\n\\nModel Context Protocol (MCP) plugin that bridges Unity Editor with a Node.js-based MCP server, letting AI assistants (Claude, Windsurf, Cursor, Copilot, etc.) programmatically manipulate scenes, assets and tests inside Unity.\\n\\ntools: execute\\\\_menu\\\\_item, select\\\\_gameobject, update\\\\_gameobject, update\\\\_component +11 more](/mcp/mcp-unity)[```\\n  IO   SPL  \\n```\\n\\nios-simulator-mcp@joshuayoes\\n\\n81334Specialized\\n\\nMCP server for interacting with the iOS simulator (iOS Simulator MCP Server).\\n\\ntools: screenshot, record\\\\_video, stop\\\\_recording](/mcp/ios-simulator-mcp)[```\\n  PO   OSS  \\n```\\n\\npostgres-mcp@crystaldba\\n\\n81389Open Source\\n\\nPostgres MCP Pro  a Python-based Model Context Protocol (MCP) server that adds Postgres health checks, index tuning, explain-plan analysis and safe SQL execution for AI agents.\\n\\ntools: list\\\\_schemas, list\\\\_objects, get\\\\_object\\\\_details, execute\\\\_sql +5 more](/mcp/postgres-mcp)[```\\n  MC   OSS  \\n```\\n\\nmcp-server-qdrant@qdrant\\n\\n808114Open Source\\n\\nOfficial Model Context Protocol (MCP) server that uses Qdrant as a semantic-memory backend (vector store). It exposes two MCP tools  qdrant-store and qdrant-find  for persisting and retrieving embeddings.\\n\\ntools: qdrant-store, qdrant-find](/mcp/mcp-server-qdrant)[```\\n  MC   OSS  \\n```\\n\\nmcp-notion-server@suekou\\n\\n799133Open Source\\n\\nMCP Server that lets LLMs interact with Notion workspaces. Includes optional Markdown-conversion to minimise token usage.\\n\\ntools: notion\\\\_append\\\\_block\\\\_children, notion\\\\_retrieve\\\\_block, notion\\\\_retrieve\\\\_block\\\\_children, notion\\\\_delete\\\\_block +13 more](/mcp/mcp-notion-server)[```\\n  FE   OSS  \\n```\\n\\nfetcher-mcp@jae-jae\\n\\n79057Open Source\\n\\nMCP server that fetches web-page content via a Playwright headless browser, with Readability extraction and HTTP/SSE transports.\\n\\ntools: fetch\\\\_url, fetch\\\\_urls](/mcp/fetcher-mcp)[```\\n  SU   OSS  \\n```\\n\\nsuekou/mcp-notion-server@suekou\\n\\n787134Open Source\\n\\nNode-based MCP server that lets LLMs read/write Notion workspaces via the Notion API; supports optional Markdown conversion to shrink token usage.\\n\\ntools: notion\\\\_append\\\\_block\\\\_children, notion\\\\_retrieve\\\\_block, notion\\\\_retrieve\\\\_block\\\\_children, notion\\\\_delete\\\\_block +13 more](/mcp/suekou-mcp-notion-server)[```\\n  SU   OSS  \\n```\\n\\nsupabase-mcp-server@alexander-zuev\\n\\n77493Open Source\\n\\nQuery MCP enables end-to-end management of Supabase via chat interface (SQL execution, Management API, Auth Admin SDK, automatic migrations, safety layer, etc.).\\n\\ntools: get\\\\_schemas, get\\\\_tables, get\\\\_table\\\\_schema, execute\\\\_postgresql +9 more](/mcp/supabase-mcp-server)[```\\n  OP   OSS  \\n```\\n\\nopenapi-mcp-server@janwilmake\\n\\n75281Open Source\\n\\nModel-Context-Protocol (MCP) server that lets Claude/Cursor search & explore any OpenAPI spec via openapisearch.com, summarising APIs in plain language.](/mcp/openapi-mcp-server)[```\\n  MC   OSS  \\n```\\n\\nmcp-language-server@isaacphi\\n\\n74855Open Source\\n\\nMCP server that proxies any stdio-based Language Server (LSP) and exposes semantic code-navigation tools (definition, references, hover, rename, diagnostics, edit) to MCP-capable LLM clients.\\n\\ntools: definition, references, diagnostics, hover +2 more](/mcp/mcp-language-server)[```\\n  MY   OSS  \\n```\\n\\nmysql\\\\_mcp\\\\_server@designcomputer\\n\\n698162Open Source\\n\\nPython implementation of a Model Context Protocol (MCP) server that safely exposes MySQL databases to AI clients.\\n\\ntools: list available mysql tables as resources, read table contents, execute sql queries with proper error handling, secure database access through environment variables +1 more](/mcp/mysql-mcp-server)[```\\n  MC   OSS  \\n```\\n\\nmcp-server-mysql@benborla\\n\\n67991Open Source\\n\\nA Model Context Protocol (MCP) server that lets LLMs inspect MySQL schemas and execute SQL queries (read-only by default, writable when enabled). Built with Node.js.\\n\\ntools: mysql\\\\_query](/mcp/mcp-server-mysql)[```\\n  GO   SPL  \\n```\\n\\ngodot-mcp@Coding-Solo\\n\\n66975Specialized\\n\\nMCP server for interfacing with Godot  lets AI assistants launch/run Godot projects, capture debug output, manipulate scenes, etc.\\n\\ntools: launch\\\\_editor, run\\\\_project, get\\\\_debug\\\\_output, stop\\\\_project +10 more](/mcp/godot-mcp)[```\\n  KU   OSS  \\n```\\n\\nkubectl-mcp-server@rohitg00\\n\\n667118Open Source\\n\\nA Model Context Protocol server that lets AI assistants (Claude, Cursor, Windsurf, etc.) issue natural-language Kubernetes commands through kubectl/Helm.\\n\\ntools: connect to a kubernetes cluster, list and manage pods, services, deployments, and nodes, create, delete, and describe pods and other resources, get pod logs and kubernetes events +60 more](/mcp/kubectl-mcp-server)[```\\n  BR   OSS  \\n```\\n\\nbrowser-use-mcp-server@co-browser\\n\\n66387Open Source\\n\\nMCP server that lets AI agents control a Chromium-based browser through the browser-use Playwright wrapper. Offers SSE and stdio transports, optional VNC streaming, and Docker support.](/mcp/browser-use-mcp-server)[```\\n  K8   OSS  \\n```\\n\\nk8m@weibaohui\\n\\n59097Open Source\\n\\nAI-driven mini Kubernetes dashboard (MCP-enabled). Single-binary server with built-in LLMs, multi-cluster management, Kom-based k8s client, AMIS front-end and 49+ MCP tools.](/mcp/k8m)[```\\n  MC   OSS  \\n```\\n\\nmcp-neo4j@neo4j-contrib\\n\\n580144Open Source\\n\\nModel Context Protocol (MCP) servers and clients for Neo4j  natural-language Cypher, knowledge-graph memory, Aura Cloud management, and graph data-modeling.\\n\\ntools: mcp-neo4j-cypher, mcp-neo4j-memory, mcp-neo4j-cloud-aura-api, mcp-neo4j-data-modeling](/mcp/mcp-neo4j)[```\\n  QG   SPL  \\n```\\n\\nqgis\\\\_mcp@jjsantos01\\n\\n57372Specialized\\n\\nModel Context Protocol (MCP) server + QGIS plugin that lets LLMs (e.g. Claude) control a local QGIS Desktop session\\n\\ntools: ping, get\\\\_qgis\\\\_info, load\\\\_project, create\\\\_new\\\\_project +11 more](/mcp/qgis_mcp)[```\\n  JU   OSS  \\n```\\n\\njupyter-mcp-server@datalayer\\n\\n54493Open Source\\n\\n  Model Context Protocol (MCP) Server for real-time interaction with Jupyter notebooks (edit, execute, document) over the MCP standard.\\n\\ntools: insert\\\\_execute\\\\_code\\\\_cell, append\\\\_markdown\\\\_cell, get\\\\_notebook\\\\_info, read\\\\_cell](/mcp/jupyter-mcp-server)[```\\n  MC   OSS  \\n```\\n\\nmcp-server-docker@ckreiling\\n\\n53262Open Source\\n\\nMCP server that lets you manage Docker containers, images, networks and volumes through natural-language prompts. Ships CLI + Docker image, supports local or remote (SSH) Docker daemons, and exposes a rich tool set for compose/inspect/debug workflows.\\n\\ntools: list\\\\_containers, create\\\\_container, run\\\\_container, recreate\\\\_container +15 more](/mcp/mcp-server-docker)[```\\n  FE   OSS  \\n```\\n\\nfetch-mcp@zcaceres\\n\\n51787Open Source\\n\\nA flexible HTTP fetching Model Context Protocol (MCP) server that retrieves web content and returns it as HTML, JSON, plain-text or Markdown.\\n\\ntools: fetch\\\\_html, fetch\\\\_json, fetch\\\\_txt, fetch\\\\_markdown](/mcp/fetch-mcp)[```\\n  MC   OSS  \\n```\\n\\nmcp-link@automation-ai-labs\\n\\n50356Open Source\\n\\nConvert Any OpenAPI V3 API to MCP Server\\n\\ntools: serve, sse](/mcp/mcp-link)[```\\n  WE   SPL  \\n```\\n\\nwenyan-mcp@caol64\\n\\n49059Specialized\\n\\nMCP server that formats Markdown with Wenyan themes and publishes the result to WeChat Official Account drafts.](/mcp/wenyan-mcp)[```\\n  MC   OSS  \\n```\\n\\nmcp-filesystem-server@mark3labs\\n\\n47169Open Source\\n\\nGo server implementing the Model Context Protocol (MCP) to expose secure filesystem operations (read, write, copy, move, delete, search, etc.) as resources/tools.\\n\\ntools: read\\\\_file, read\\\\_multiple\\\\_files, write\\\\_file, copy\\\\_file +10 more](/mcp/mcp-filesystem-server)[```\\n  MC   OSS  \\n```\\n\\nmcp-clickhouse@ClickHouse\\n\\n46590Open Source\\n\\nConnect ClickHouse to your AI assistants via an MCP (Model Context Protocol) server that exposes ClickHouse and chDB query tools plus a built-in health-check endpoint.\\n\\ntools: run\\\\_select\\\\_query, list\\\\_databases, list\\\\_tables, run\\\\_chdb\\\\_select\\\\_query](/mcp/mcp-clickhouse)[```\\n  MC   OSS  \\n```\\n\\nmcp-server-data-exploration@reading-plus-ai\\n\\n44847Open Source\\n\\nMCP Server that equips Claude Desktop with an explore-data prompt template plus two tools (load-csv and run-script) for fully-automated, conversational data exploration.\\n\\ntools: load-csv, run-script](/mcp/mcp-server-data-exploration)[```\\n  MA   SPL  \\n```\\n\\nmanim-mcp-server@abhiemj\\n\\n43841Specialized\\n\\nMCP server that executes Manim animation scripts and returns rendered videos.](/mcp/manim-mcp-server)[```\\n  CE   OSS  \\n```\\n\\ncentralmind/gateway@centralmind\\n\\n43747Open Source\\n\\nUniversal MCP-Server that automatically generates LLM-optimised REST & MCP APIs for relational databases (Postgres, MySQL, ClickHouse, Snowflake, etc.).](/mcp/centralmind-gateway)[```\\n  DE   SRV  \\n```\\n\\ndev-mcp@Shopify\\n\\n43646Enterprise\\n\\nShopify.dev Model Context Protocol (MCP) server and CLI that exposes tools for Shopify Admin GraphQL, Functions and optional Polaris docs.\\n\\ntools: learn\\\\_shopify\\\\_api, search\\\\_docs\\\\_chunks, fetch\\\\_full\\\\_docs, introspect\\\\_graphql\\\\_schema +1 more](/mcp/dev-mcp)[```\\n  LI   SPL  \\n```\\n\\nline-bot-mcp-server@line\\n\\n43565Specialized\\n\\nMCP server that integrates the LINE Messaging API to connect an AI Agent to the LINE Official Account.\\n\\ntools: push\\\\_text\\\\_message, push\\\\_flex\\\\_message, broadcast\\\\_text\\\\_message, broadcast\\\\_flex\\\\_message +6 more](/mcp/line-bot-mcp-server)[```\\n  SH   SRV  \\n```\\n\\nShopify/dev-mcp@Shopify\\n\\n41441Enterprise\\n\\nModel Context Protocol (MCP) server for interacting with Shopify APIs (Admin GraphQL, Functions, optional Polaris).\\n\\ntools: learn\\\\_shopify\\\\_api, search\\\\_docs\\\\_chunks, fetch\\\\_full\\\\_docs, introspect\\\\_admin\\\\_schema](/mcp/shopify-dev-mcp)[```\\n  MC   OSS  \\n```\\n\\nmcp-gsuite@MarkusPfundstein\\n\\n41383Open Source\\n\\nMCP (Model-Context-Protocol) server that exposes Gmail and Google Calendar tooling  query mail, draft/reply messages, manage events, and handle multiple Google accounts via OAuth2.\\n\\ntools: multiple google accounts, get your gmail user information, query emails with flexible search (e.g., unread, from specific senders, date ranges, with attachments), retrieve complete email content by id +9 more](/mcp/mcp-gsuite)[```\\n  ME   SPL  \\n```\\n\\nmem0-mcp@mem0ai\\n\\n40685Specialized\\n\\nMCP Server that integrates with mem0.ai to store, retrieve and semantically-search coding preferences via an SSE endpoint.\\n\\ntools: add\\\\_coding\\\\_preference, get\\\\_all\\\\_coding\\\\_preferences, search\\\\_coding\\\\_preferences](/mcp/mem0-mcp)[```\\n  IT   OSS  \\n```\\n\\niterm-mcp@ferrislucas\\n\\n40243Open Source\\n\\nModel Context Protocol (MCP) server that lets an AI model read from and write to the active iTerm2 terminal tab, enabling natural-language REPL/CLI interactions.\\n\\ntools: write\\\\_to\\\\_terminal, read\\\\_terminal\\\\_output, send\\\\_control\\\\_character](/mcp/iterm-mcp)[```\\n  MC   SPL  \\n```\\n\\nmcp-youtube@anaisbetts\\n\\n40248Specialized\\n\\nA Model-Context Protocol server that uses yt-dlp to fetch YouTube subtitles and expose them to Claude/other MCP-compatible LLMs.](/mcp/mcp-youtube)[```\\n  JA   OSS  \\n```\\n\\njadx-ai-mcp@zinja-coder\\n\\n39842Open Source\\n\\nJADX-AI-MCP is a Java plugin for the JADX decompiler plus a companion Python MCP server that lets LLMs (e.g. Claude) inspect and analyse Android APKs in real-time. It exposes rich reverse-engineering tools (fetch\\\\_current\\\\_class, get\\\\_android\\\\_manifest, etc.) over Model Context Protocol so an LLM can locate vulnerabilities, review code and decompile resources on-demand.\\n\\ntools: fetch\\\\_current\\\\_class(), get\\\\_selected\\\\_text(), get\\\\_all\\\\_classes(), get\\\\_class\\\\_source() +12 more](/mcp/jadx-ai-mcp)[```\\n  SL   OSS  \\n```\\n\\nslack-mcp-server@korotovsky\\n\\n39847Open Source\\n\\nFeature-rich Model Context Protocol (MCP) server that lets LLM agents read/search/post Slack messages in both OAuth and totally permission-less stealth modes. Supports Stdio & SSE transports, DM/Group-DM, smart history pagination, proxy routing, built-in caching and a rich tool set.\\n\\ntools: conversations\\\\_history, conversations\\\\_replies, conversations\\\\_add\\\\_message, conversations\\\\_search\\\\_messages +1 more](/mcp/slack-mcp-server)[```\\n  WR   SRV  \\n```\\n\\nwren-engine@Canner\\n\\n392106Enterprise\\n\\nThe Semantic Engine for Model Context Protocol (MCP) clients and AI agents. Provides a semantic layer that lets LLM-powered agents query enterprise data sources with context, governance and security.\\n\\ntools: bigqueryconnectioninfo, gcsfileconnectioninfo, localfileconnectioninfo, mssqlconnectioninfo +7 more](/mcp/wren-engine)[```\\n  CL   OSS  \\n```\\n\\nclaude-debugs-for-you@jasonjmcghee\\n\\n38932Open Source\\n\\nVS Code extension + MCP server that lets Claude (or any LLM) drive the VS Code debugger through the Model Context Protocol, enabling interactive, language-agnostic debugging sessions.\\n\\ntools: debug](/mcp/claude-debugs-for-you)[```\\n  MC   OSS  \\n```\\n\\nmcp-server-neon@neondatabase-labs\\n\\n38956Open Source\\n\\nModel-Context-Protocol (MCP) server that lets developers interact with Neon Postgres projects & databases via natural-language requests.\\n\\ntools: list\\\\_projects, describe\\\\_project, create\\\\_project, delete\\\\_project +17 more](/mcp/mcp-server-neon)[```\\n  HO   OSS  \\n```\\n\\nhomeassistant-mcp@tevonsb\\n\\n38329Open Source\\n\\nModel Context Protocol server that exposes your Home Assistant instance to LLM-based applications through a secure, real-time HTTP/SSE/WebSocket API.\\n\\ntools: control, addon, package, automation\\\\_config](/mcp/homeassistant-mcp)[```\\n  KU   OSS  \\n```\\n\\nkubernetes-mcp-server@manusa\\n\\n37761Open Source\\n\\nModel Context Protocol (MCP) server for Kubernetes and OpenShift. Native Go binary that offers CRUD, pod-level, namespace, event, Helm and generic resource management operations with no kubectl/helm dependency.\\n\\ntools: configuration\\\\_view, events\\\\_list, helm\\\\_install, helm\\\\_list +15 more](/mcp/kubernetes-mcp-server)[```\\n  DO   OSS  \\n```\\n\\ndocker-mcp@QuantGeekDev\\n\\n35447Open Source\\n\\nMCP (Model Context Protocol) server that lets Claude interact with Docker  create single containers, deploy compose stacks, inspect logs and list containers.\\n\\ntools: create-container, deploy-compose, get-logs, list-containers](/mcp/docker-mcp)[```\\n  GR   SRV  \\n```\\n\\ngraphlit-mcp-server@graphlit\\n\\n34242Enterprise\\n\\nModel Context Protocol (MCP) Server that connects MCP-compatible IDE/agent clients with the Graphlit knowledge-graph platform for ingestion, search, RAG and publishing workflows.\\n\\ntools: query contents, query collections, query feeds, query conversations +63 more](/mcp/graphlit-mcp-server)[```\\n  MC   OSS  \\n```\\n\\nmcp-pandoc@vivekVells\\n\\n33844Open Source\\n\\nModel-Context-Protocol (MCP) server that wraps Pandoc to convert documents between Markdown, HTML, PDF, DOCX, LaTeX, reStructuredText, EPUB, ODT, IPYNB and TXT formats.\\n\\ntools: convert-contents](/mcp/mcp-pandoc)[```\\n  DU   OSS  \\n```\\n\\nduckduckgo-mcp-server@nickclyde\\n\\n33767Open Source\\n\\nA Model Context Protocol (MCP) server that adds DuckDuckGo web-search and content-fetching tools with rate-limiting and LLM-ready formatting.\\n\\ntools: search, fetch\\\\_content](/mcp/duckduckgo-mcp-server)[```\\n  MC   OSS  \\n```\\n\\nmcp-hfspace@evalstate\\n\\n33048Open Source\\n\\nNode-based MCP Server that lets you expose one or more Hugging Face Spaces as Model Context Protocol (MCP) endpoints, with special integration for Claude Desktop (file handling, desktop-mode, tool discovery, etc.).\\n\\ntools: black-forest-labs/flux.1-schnell, shuttleai/shuttle-3.1-aesthetic, shuttleai/shuttle-jaguar, yanze/pulid-flux +16 more](/mcp/mcp-hfspace)[```\\n  MC   OSS  \\n```\\n\\nmcp-k8s-go@strowk\\n\\n33041Open Source\\n\\nGolang-based Model-Context-Protocol (MCP) server that exposes Kubernetes clusters as a set of chat-accessible resources and tools (list/get/create/modify resources, fetch logs, exec, etc.).\\n\\ntools: list kubernetes contexts, list kubernetes namespaces, list, get, create and modify any kubernetes resources, list kubernetes nodes +4 more](/mcp/mcp-k8s-go)[```\\n  TF   OSS  \\n```\\n\\ntfmcp@nwiizo\\n\\n32820Open Source\\n\\nTerraform Model Context Protocol (MCP) CLI/server that lets AI assistants analyse, plan and apply Terraform with enterprise-grade security.\\n\\ntools: mcp, analyze, help, resources/list +2 more](/mcp/tfmcp)[```\\n  DB   OSS  \\n```\\n\\ndbt-mcp@dbt-labs\\n\\n32538Open Source\\n\\nAn MCP (Model Context Protocol) server that exposes dbt Core/Cloud functionality  CLI commands, Semantic Layer, model discovery and SQL execution  to any MCP-capable client.\\n\\ntools: build, compile, docs, ls +15 more](/mcp/dbt-mcp)[```\\n  UN   SPL  \\n```\\n\\nUnity-MCP@IvanMurzak\\n\\n30329Specialized\\n\\nBridge between Large-Language-Model (LLM) clients (Claude, Cursor, custom) and the Unity Editor. Ships as a Unity-package that spins up an MCP server inside the editor and exposes a catalogue of AI-driven tools (GameObject, Scene, Assets, Prefab, etc.) so an external client can query or manipulate the open Unity project.\\n\\ntools: create, destroy, find, modify (tag, layer, name, static) +56 more](/mcp/unity-mcp)[```\\n  EV  \\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 4: The state of MCP: Insights from the Developers Summit ---\\nURL: https://blog.apify.com/what-is-model-context-protocol/\\n\\nSUMMARY:\\nOver the past year,\\xa0**Model Context Protocol (MCP)**\\xa0has gone from a curiosity on GitHub to the de facto way serious teams wire LLM agents into real-world data and tools. + Apify has built an\\xa0MCP server\\xa0that allows\\xa0AI agents\\xa0or frameworks that implement Model Context Protocol to access 6,000+\\xa0Apify Actors\\xa0(microapps for web automation) as tools for data extraction, web searching, and other tasks. ## Read more about MCP and AI agents * How to use MCP with Apify Actors - Learn how to expose over 5,000 Apify Actors to AI agents like Claude and LangGraph, and configure MCP clients and servers.\\n\\nFULL CONTENT:\\n[Back to all posts](https://blog.apify.com)\\n\\n[AI](/tag/ai/)\\n\\n[AI agents](/tag/ai-agents/)\\n\\n# The state of MCP: Insights from the Developers Summit\\n\\nLearn about the latest developments in Model Context Protocol, based on key updates from the MCP Developers Summit - San Francisco, May 2025\\n\\nby\\n\\n[Ji Spilka](/author/jiri/)\\n\\n[Theo Vasilis](/author/theo/)\\n\\nShare this article:\\n\\n## Why everyone in AI is talking about MCP\\n\\nOver the past year,\\xa0**Model Context Protocol (MCP)**\\xa0has gone from a curiosity on GitHub to the de facto way serious teams wire LLM agents into real-world data and tools. At the\\xa0[2025 MCP Developers Summit in San Francisco](https://mcpdevsummit.ai/), speakers from Anthropic, OpenAI, Bloomberg, GitHub, AWS, PayPal, Elastic, and others all echoed the same refrain:\\n\\n> We\\'re shifting away from early experimentation and simple tool calling to building trustworthy, scalable and modular AI systems using MCP as the foundation.\\n\\nThat claim matters because integration, not model quality, is now the bottleneck. Organizations already\\xa0*have*\\xa0valuable data in GitHub, Snowflake, Elasticsearch, or Salesforce; what they lack is a safe, repeatable way for an agent to\\xa0**see**,\\xa0**search**,\\xa0and\\xa0**act**\\xa0on that data. MCPs answer is a single, open, bidirectional interface - much like USB-C replaced drawers full of proprietary cables.\\n\\n## What exactly is MCP (Model Context Protocol)?\\n\\nModel Context Protocol (MCP) is an open standard designed by Anthropic to bridge the gap between AI assistants and external data sources and make AI applications more relevant and context-aware.\\n\\nTraditionally, AI models have struggled with integrating external data efficiently. The result has been fragmented implementations for each new data source.\\n\\nMCP addresses this problem by providing a standardized framework for secure and scalable connections between AI tools and various systems. It supports secure two-way connections through MCP servers and clients:\\n\\n* **MCP servers**\\xa0expose data from external sources such as Google Drive, Slack, GitHub, Postgres, and Puppeteer.\\n* **MCP clients**\\xa0(AI applications) connect to these servers to access structured information and enhance responses with relevant context.\\n\\nBecause the protocol is\\xa0**model-agnostic**\\xa0and\\xa0**server-agnostic**, any Claude, GPT, Llama, or Mistral-based agent can talk to any compliant server. The result: the first real chance at plug-and-play interoperability across the AI stack.\\n\\n## A short history - and why MCP rose above competing specs\\n\\n1. **The pain point.**\\xa0Early agent builders hard-coded REST calls for each data source, then rewrote everything when they switched clouds - or worse, when security asked for audit trails.\\n2. **The breakthrough.**\\xa0Anthropics early MCP prototype (late 2023) added\\xa0*typed messages*\\xa0and a lightweight stream transport so agents could pull just the context they needed.\\n3. **Network effects.**\\xa0By mid-2025, the spec had thousands of GitHub stars, dozens of SDKs, and backing from enterprise vendors who saw it as a neutral standard (unlike vendor-locked agent frameworks).\\n\\nCompeting proposals fall into two buckets:\\n\\n* **Inter-agent protocols**\\xa0(Google A2A, Cisco/IBM ACP, Agora) focus on agents negotiating with\\xa0*each other*.\\n* **Context-oriented protocols**\\xa0(MCP, to some extent LangGraph) focus on agents acquiring\\xa0*structured context -* a more immediate production need.\\n\\nMCPs decision to own context first, coordination later gave it a pragmatic edge and the community momentum that React enjoyed over more academically pure rivals.\\n\\n## How MCP works today\\n\\nMCPs appeal is that it feels simple for the\\xa0**agent creator**, yet hides a surprising amount of protocol engineering under the hood. Below is a plain-language tour of four features that were demoed at the San Francisco MCP Developers Summit, and why they matter when you move from hello world to production.\\n\\n### 1. Streamable HTTP\\n\\nEarly MCP servers spoke over\\xa0*Server-Sent Events*\\xa0(SSE). That was fine on a laptop, but in production, SSE created headaches:\\n\\n* **Enterprise firewalls**\\xa0often block or time out long-lived SSE connections.\\n* **Cloud functions**\\xa0such as AWS Lambda cant keep an open socket alive for minutes.\\n* **Back-pressure**\\xa0was clunky: you either waited for the whole tool result or you polled.\\n\\nThe\\xa0**Streamable HTTP**\\xa0upgrade (released March 26, 2025) fixes all three issues by tunnelling a bidirectional byte-stream through a single, ordinary HTTP request that supports\\xa0*chunked transfer encoding*. In practice, it means:\\n\\n* You can deploy an MCP server\\xa0**as a stateless Lambda/Fargate task**; it spins up, emits streamed chunks, then shuts down.\\n* Corporate proxies treat it as just another HTTPS call, so network teams stop saying no.\\n* Agents start receiving partial results - say, the first 100 database rows - *while*\\xa0the rest of the tool call is still running, which cuts perceived latency and lets the LLM answer sooner.\\n\\nIf you build on serverless or behind locked-down enterprise networks, this one feature may cut weeks from your rollout schedule.\\n\\n\\n\\nWith MCP being open source, changes like Streamable HTTP are already available for developers to implement.\\n\\n### 2. Typed schemas\\n\\n* **Elicitation schema**\\n  + A server can describe - in JSON - *exactly*\\xa0what information it needs from the client (e.g.\\xa0`{ \"query\": \"string\", \"date_range\": \"YYYY-MM-DD\" }`). Your UI can auto-render the right form controls. Your agent no longer has to guess the prompt that will satisfy the server, reducing error-handling glue code.\\n* **Tool output schema**\\n  + A server declares the JSON shape it will return. Instead of pasting raw unstructured text into the LLMs context window (token-hungry and brittle), the client can inject a concise, structured object - often 1020 smaller. That leaves more budget for the\\xa0*actual*\\xa0reasoning tokens.\\n\\n\\n\\nThese schemas are currently unreleased; they\\'re in the draft stage and may evolve.\\n\\n### 3. Sampling and Roots\\n\\nSampling and Roots are two primitives that are currently overlooked and underexplored. The keynote speech at the summit highlighted these. They\\'re not new, but they can improve the security between agent interactions.\\n\\n* **Sampling**\\n  + Think of *sampling* as the servers right to call back into\\xa0*your*\\xa0LLM for a small completion. Its handy when the server wants, say, a short summary in the style the user already sees. Centralizing those completions in the client keeps API keys and model choice under your control.\\n\\n\\n\\n****Caveat:****\\xa0Disable or gate **sampling** on third-party servers; the same mechanism could be abused for prompt-injection.\\n\\n* **Roots**\\n  + Before an agent starts browsing your Git repository, you can hand the server a\\xa0*roots*\\xa0object like\\xa0`[\"/repos/acme-payments\", \"/repos/acme-docs\"]`. Its an\\xa0**advisory scope marker** -not a hard permission check - but servers that respect *roots* avoid needless crawling and keep responses focused. Pair it with normal ACLs (Access Control Lists) for real enforcement.\\n\\nTogether, these primitives facilitate richer, cooperative workflows without inventing extra protocol layers.\\n\\n### 4. OAuth 2.1\\n\\nTraditional OAuth flows assume the\\xa0*server*\\xa0redirects a human user to an auth page - a poor fit when the user is now an autonomous agent. Oktas Aaron Parecki proposed (and the community adopted) an\\xa0**agent-first OAuth 2.1 pattern**:\\n\\n1. **The MCP client**\\xa0initiates the flow, directs the human user (or a service account) to sign in via SSO, and receives the access token.\\n2. **The MCP server**\\xa0only verifies the token and reads a tiny\\xa0`server.json`\\xa0that lists scopes and endpoints.\\n\\n* **Why it matters**\\n  + **For enterprise IT:**\\xa0You preserve existing SSO, MFA**,** and audit logs; nothing new to approve.\\n  + **For server authors:**\\xa0You skip building an OAuth UI, reduce your liability surface, and still accept any standards-compliant identity provider out of the box.\\n\\nPut differently, OAuth 2.1 done right lets you keep security teams happy\\xa0*and*\\xa0ship features faster - a rare win-win in compliance-heavy environments.\\n\\n## Bottom line for agent builders\\n\\n1. Streamable HTTP gets your packets through corporate walls\\n2. Typed schemas shrink token usage and UI glue code\\n3. Sampling and Roots add power when you need it\\n4. The revamped OAuth flow turns a traditional security blocker into a check-box exercise.\\n\\nWhen you combine these four concepts, youll have crossed 80 percent of the gap between a weekend MCP demo and a production-ready, enterprise-approved deployment.\\n\\n## How to experiment with MCP right now\\n\\n* **Try a turnkey client**.\\xa0Claude Desktop bundles a local MCP server; LibreChat and LangGraph have first-class clients.\\n* **Create your own server**.\\xa0Official SDKs exist in Python, TypeScript, and Go. Deploy with Streamable HTTP on\\xa0Fly.io, Lambda, or a bare VM.\\n* **Try Apify\\'s MCP Server**.\\n  + Apify has built an\\xa0[MCP server](https://docs.apify.com/platform/integrations/mcp)\\xa0that allows\\xa0[AI agents](https://blog.apify.com/what-are-ai-agents/)\\xa0or frameworks that implement Model Context Protocol to access 6,000+\\xa0[Apify Actors](https://apify.com/actors)\\xa0(microapps for web automation) as tools for data extraction, web searching, and other tasks.\\n  + This implementation lets agents collect data from websites (e.g. Facebook posts, Google search results pages, URLs), summarize web trends, and execute automated workflows without requiring user intervention.\\n  + The [Actors MCP Server](https://docs.apify.com/platform/integrations/mcp) offers a streamable HTTP endpoint at\\xa0`https://mcp.apify.com`, a legacy SSE endpoint at\\xa0`https://mcp.apify.com/sse`, and local stdin/stdout connections started with\\xa0`npx -y @apify/actors-mcp-server`.\\n  + Users can interact with the server through clients like Claude Desktop, LibreChat, the\\xa0VS Code MCP extension, and Apify\\'s\\xa0[Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client/api).\\n  + For more details, [check out the docs](https://docs.apify.com/platform/integrations/mcp).\\n\\n## Why Model Context Protocol is worth the hype\\n\\nMCP is still evolving, but its trajectory is clear. Just as HTTP unified the early web, Model Context Protocol is rapidly becoming the connective tissue of agentic AI. Getting familiar with it today is the surest way to future-proof your stack for whatever models and business demands arrive next.\\n\\n## Read more about MCP and AI agents\\n\\n* [How to use MCP with Apify Actors](https://blog.apify.com/how-to-use-mcp/) - Learn how to expose over 5,000 Apify Actors to AI agents like Claude and LangGraph, and configure MCP clients and servers.\\n* [How to build an AI agent](https://blog.apify.com/how-to-build-an-ai-agent/) - A complete step-by-step guide to creating, publishing, and monetizing AI agents on the Apify platform.\\n* [What are AI agents?](https://blog.apify.com/what-are-ai-agents/) - The Apify platform is turning the potential of AI agents into practical solutions.\\n* [LLM agents: all you need to know in 2025](https://blog.apify.com/llm-agents/) - LLM agents are changing how we approach AI by enabling interaction with external sources and reasoning through complex tasks.\\n* [10 best AI agent frameworks](https://blog.apify.com/10-best-ai-agent-frameworks/) - 5 paid platforms and 5 open-source options for building AI agents.\\n* [Best low-code and no-code AI agent builders in 2025](https://blog.apify.com/ai-agent-builders/) - If frameworks like LangGraph or Haystack are too challenging for you, these AI agent builders might be what you\\'re looking for.\\n* [AI agent workflow - building an agent to query Apify datasets](https://blog.apify.com/ai-agent-workflow/) - Learn how to extract insights from datasets using simple natural language queries without deep SQL knowledge or external data exports.\\n* [AI agent vs. chatbot](https://blog.apify.com/ai-agent-vs-chatbot/) - We break down the differences between agents and chatbots to help you decide which one to use for your business goals.\\n* [AI agent orchestration with OpenAI Agents SDK](https://blog.apify.com/ai-agent-orchestration/) - Learn to build an effective multiagent system with AI agent orchestration.\\n* [5 open-source AI agents on Apify that save you time](https://blog.apify.com/open-source-ai-agents/) - These AI agents are practical tools you can test and use today, or build on if you\\'re creating your own automation.\\n* [6 AI agent tools that keep your agents grounded in current data](https://blog.apify.com/ai-agent-tools/) - Apify Actors give agentic systems the ability to query the live web at production scale. Here are 6 you should try.\\n* [AI agent architecture in 1,000 words](https://blog.apify.com/ai-agent-architecture/) - A comprehensive overview of AI agents\\' core components and architectural types.\\n* [11 AI agent use cases (on Apify)](https://blog.apify.com/ai-agent-use-cases/) - 10 practical applications for AI agents, plus one meta-use case that hints at the future of agentic systems.\\n* [7 real-world AI agent examples in 2025 you need to know](https://blog.apify.com/ai-agent-examples/) - From\\xa0goal-based assistants\\xa0to\\xa0learning-driven systems, these agents are powering everything from self-driving cars to advanced web automation.\\n* [7 types of AI agents you should know about](https://blog.apify.com/types-of-ai-agents/) - What defines an AI agent? We go through the agent spectrum, from simple reflexive systems to adaptive multi-agent networks.\\n\\n[Ji Spilka\\n\\nAI Engineer (AI plumber), passionate about solving practical problems with data (and AI)](/author/jiri/) [Theo Vasilis\\n\\nSenior Content Manager at Apify. I\\'ve been crafting content since before SEO existed. I\\'m keeping my career AI-proof with writing that educates, converts, and tickles the parts that LLMs can\\'t reach.](/author/theo/)\\n\\nOn this page\\n\\nShare this article:\\n\\nBuild the scraper you want\\n\\nNo credit card required\\n\\n[Start building](https://apify.com/templates)\\n\\n### Related articles\\n\\n[AI](/tag/ai/)\\n\\n[Developer community](/tag/developer-community/)\\n\\n[Presenting the winners of the Apify MCP server configurator competition](/presenting-the-winners-of-the-apify-mcp-server-configurator-competition/)\\n\\n[Fergus O\\'Sullivan](/author/fergus/)\\n\\n[Case studies](/tag/case-studies/)\\n\\n[Finance and Fintech](/tag/finance-and-fintech/)\\n\\n[AI](/tag/ai/)\\n\\n[How Diligent AI cut costs 30% with 40k monthly runs with Apify](/diligent-ai-cut-costs-with-apify/)\\n\\n[Daniel Lee](/author/daniel/)\\n\\n[Life at Apify](/tag/life-at-apify/)\\n\\n[AI](/tag/ai/)\\n\\n[Web automation and RPA](/tag/web-automation-and-rpa/)\\n\\n[How Apify automates its own processes](/how-apify-automates-its-own-processes/)\\n\\n[Fergus O\\'Sullivan](/author/fergus/)\\n\\n \\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 5: modelcontextprotocol/servers: Model Context Protocol ... ---\\nURL: https://github.com/modelcontextprotocol/servers\\n\\nSUMMARY:\\n[MIT license](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE) *   [Code](https://github.com/modelcontextprotocol/servers) *   [Issues 194](https://github.com/modelcontextprotocol/servers/issues) *   [Actions](https://github.com/modelcontextprotocol/servers/actions) *   [Insights](https://github.com/modelcontextprotocol/servers/pulse) *   [Code](https://github.com/modelcontextprotocol/servers) *   [Issues](https://github.com/modelcontextprotocol/servers/issues) *   [Actions](https://github.com/modelcontextprotocol/servers/actions) *   [Security](https://github.com/modelcontextprotocol/servers/security) *   [Insights](https://github.com/modelcontextprotocol/servers/pulse) *   [README](https://github.com/modelcontextprotocol/servers#) *   [Code of conduct](https://github.com/modelcontextprotocol/servers#) *   [Contributing](https://github.com/modelcontextprotocol/servers#) *   [MIT license](https://github.com/modelcontextprotocol/servers#) *   [Security](https://github.com/modelcontextprotocol/servers#) [](https://github.com/modelcontextprotocol/servers#-reference-servers) *   **[Filesystem](https://github.com/modelcontextprotocol/servers/blob/main/src/filesystem)** - Secure file operations with configurable access controls. *   **[Git](https://github.com/modelcontextprotocol/servers/blob/main/src/git)** - Tools to read, search, and manipulate Git repositories. [](https://github.com/modelcontextprotocol/servers#-getting-started) [](https://github.com/modelcontextprotocol/servers#using-mcp-servers-in-this-repository) For example, this will start the [Memory](https://github.com/modelcontextprotocol/servers/blob/main/src/memory) server: [](https://github.com/modelcontextprotocol/servers#using-an-mcp-client) [](https://github.com/modelcontextprotocol/servers#-contributing) See [CONTRIBUTING.md](https://github.com/modelcontextprotocol/servers/blob/main/CONTRIBUTING.md) for information about contributing to this repository. [](https://github.com/modelcontextprotocol/servers#-security) [](https://github.com/modelcontextprotocol/servers#-license) [](https://github.com/modelcontextprotocol/servers#-community) [](https://github.com/modelcontextprotocol/servers#-support) [Readme](https://github.com/modelcontextprotocol/servers#readme-ov-file) [MIT license](https://github.com/modelcontextprotocol/servers#MIT-1-ov-file) [Code of conduct](https://github.com/modelcontextprotocol/servers#coc-ov-file) [Contributing](https://github.com/modelcontextprotocol/servers#contributing-ov-file) [Security policy](https://github.com/modelcontextprotocol/servers#security-ov-file) [Please reload this page](https://github.com/modelcontextprotocol/servers). [Activity](https://github.com/modelcontextprotocol/servers/activity) [**71k** stars](https://github.com/modelcontextprotocol/servers/stargazers) [**519** watching](https://github.com/modelcontextprotocol/servers/watchers) [**8.5k** forks](https://github.com/modelcontextprotocol/servers/forks) [Releases 20](https://github.com/modelcontextprotocol/servers/releases) [+ 19 releases](https://github.com/modelcontextprotocol/servers/releases) [Please reload this page](https://github.com/modelcontextprotocol/servers). *   [TypeScript 58.0%](https://github.com/modelcontextprotocol/servers/search?l=typescript) *   [Python 21.7%](https://github.com/modelcontextprotocol/servers/search?l=python) *   [JavaScript 18.2%](https://github.com/modelcontextprotocol/servers/search?l=javascript) *   [Dockerfile 2.1%](https://github.com/modelcontextprotocol/servers/search?l=dockerfile)\\n\\nFULL CONTENT:\\nGitHub - modelcontextprotocol/servers: Model Context Protocol Servers\\n\\n===============\\n\\n[Skip to content](https://github.com/modelcontextprotocol/servers#start-of-content)\\nNavigation Menu\\n---------------\\n\\nToggle navigation\\n\\n[](https://github.com/)\\n\\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers)\\n\\nAppearance settings\\n\\n*    Platform \\n\\n    *   [GitHub Copilot Write better code with AI](https://github.com/features/copilot)\\n    *   [GitHub Spark New Build and deploy intelligent apps](https://github.com/features/spark)\\n    *   [GitHub Models New Manage and compare prompts](https://github.com/features/models)\\n    *   [GitHub Advanced Security Find and fix vulnerabilities](https://github.com/security/advanced-security)\\n    *   [Actions Automate any workflow](https://github.com/features/actions)\\n\\n    *   [Codespaces Instant dev environments](https://github.com/features/codespaces)\\n    *   [Issues Plan and track work](https://github.com/features/issues)\\n    *   [Code Review Manage code changes](https://github.com/features/code-review)\\n    *   [Discussions Collaborate outside of code](https://github.com/features/discussions)\\n    *   [Code Search Find more, search less](https://github.com/features/code-search)\\n\\nExplore\\n    *   [Why GitHub](https://github.com/why-github)\\n    *   [Documentation](https://docs.github.com/)\\n    *   [GitHub Skills](https://skills.github.com/)\\n    *   [Blog](https://github.blog/)\\n\\nIntegrations\\n    *   [GitHub Marketplace](https://github.com/marketplace)\\n    *   [MCP Registry](https://github.com/mcp)\\n\\n[View all features](https://github.com/features)\\n\\n*    Solutions \\n\\nBy company size\\n    *   [Enterprises](https://github.com/enterprise)\\n    *   [Small and medium teams](https://github.com/team)\\n    *   [Startups](https://github.com/enterprise/startups)\\n    *   [Nonprofits](https://github.com/solutions/industry/nonprofits)\\n\\nBy use case\\n    *   [App Modernization](https://github.com/solutions/use-case/app-modernization)\\n    *   [DevSecOps](https://github.com/solutions/use-case/devsecops)\\n    *   [DevOps](https://github.com/solutions/use-case/devops)\\n    *   [CI/CD](https://github.com/solutions/use-case/ci-cd)\\n    *   [View all use cases](https://github.com/solutions/use-case)\\n\\nBy industry\\n    *   [Healthcare](https://github.com/solutions/industry/healthcare)\\n    *   [Financial services](https://github.com/solutions/industry/financial-services)\\n    *   [Manufacturing](https://github.com/solutions/industry/manufacturing)\\n    *   [Government](https://github.com/solutions/industry/government)\\n    *   [View all industries](https://github.com/solutions/industry)\\n\\n[View all solutions](https://github.com/solutions)\\n\\n*    Resources \\n\\nTopics\\n    *   [AI](https://github.com/resources/articles?topic=ai)\\n    *   [DevOps](https://github.com/resources/articles?topic=devops)\\n    *   [Security](https://github.com/resources/articles?topic=security)\\n    *   [Software Development](https://github.com/resources/articles?topic=software-development)\\n    *   [View all](https://github.com/resources/articles)\\n\\nExplore\\n    *   [Learning Pathways](https://resources.github.com/learn/pathways)\\n    *   [Events & Webinars](https://github.com/resources/events)\\n    *   [Ebooks & Whitepapers](https://github.com/resources/whitepapers)\\n    *   [Customer Stories](https://github.com/customer-stories)\\n    *   [Partners](https://github.com/partners)\\n    *   [Executive Insights](https://github.com/solutions/executive-insights)\\n\\n*    Open Source \\n\\n    *   [GitHub Sponsors Fund open source developers](https://github.com/sponsors)\\n\\n    *   [The ReadME Project GitHub community articles](https://github.com/readme)\\n\\nRepositories\\n    *   [Topics](https://github.com/topics)\\n    *   [Trending](https://github.com/trending)\\n    *   [Collections](https://github.com/collections)\\n\\n*    Enterprise \\n\\n    *   [Enterprise platform AI-powered developer platform](https://github.com/enterprise)\\n\\nAvailable add-ons\\n    *   [GitHub Advanced Security Enterprise-grade security features](https://github.com/security/advanced-security)\\n    *   [Copilot for business Enterprise-grade AI features](https://github.com/features/copilot/copilot-business)\\n    *   [Premium Support Enterprise-grade 24/7 support](https://github.com/premium-support)\\n\\n*   [Pricing](https://github.com/pricing)\\n\\nSearch or jump to...\\n\\nSearch code, repositories, users, issues, pull requests...\\n==========================================================\\n\\n Search  \\n\\nClear\\n\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n\\nProvide feedback\\n================\\n\\nWe read every piece of feedback, and take your input very seriously.\\n\\n- [x] Include my email address so I can be contacted \\n\\n Cancel  Submit feedback \\n\\nSaved searches\\n==============\\n\\nUse saved searches to filter your results more quickly\\n------------------------------------------------------\\n\\nName \\n\\nQuery \\n\\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\n\\n Cancel  Create saved search \\n\\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers)\\n\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=modelcontextprotocol%2Fservers)\\n\\nAppearance settings\\n\\nResetting focus\\n\\nYou signed in with another tab or window. [Reload](https://github.com/modelcontextprotocol/servers) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/modelcontextprotocol/servers) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/modelcontextprotocol/servers) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[modelcontextprotocol](https://github.com/modelcontextprotocol)/**[servers](https://github.com/modelcontextprotocol/servers)**Public\\n\\n*   [Notifications](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)You must be signed in to change notification settings\\n*   [Fork 8.5k](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)\\n*   [Star 71k](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers) \\n\\nModel Context Protocol Servers\\n\\n[modelcontextprotocol.io](https://modelcontextprotocol.io/ \"https://modelcontextprotocol.io\")\\n\\n### License\\n\\n[MIT license](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE)\\n\\n[71k stars](https://github.com/modelcontextprotocol/servers/stargazers)[8.5k forks](https://github.com/modelcontextprotocol/servers/forks)[Branches](https://github.com/modelcontextprotocol/servers/branches)[Tags](https://github.com/modelcontextprotocol/servers/tags)[Activity](https://github.com/modelcontextprotocol/servers/activity)\\n\\n[Star](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)\\n\\n[Notifications](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)You must be signed in to change notification settings\\n\\n*   [Code](https://github.com/modelcontextprotocol/servers)\\n*   [Issues 194](https://github.com/modelcontextprotocol/servers/issues)\\n*   [Pull requests 80](https://github.com/modelcontextprotocol/servers/pulls)\\n*   [Actions](https://github.com/modelcontextprotocol/servers/actions)\\n*   [Security### Uh oh! There was an error while loading. [Please reload this page](https://github.com/modelcontextprotocol/servers).](https://github.com/modelcontextprotocol/servers/security)\\n*   [Insights](https://github.com/modelcontextprotocol/servers/pulse)\\n\\nAdditional navigation options\\n\\n*   [Code](https://github.com/modelcontextprotocol/servers)\\n*   [Issues](https://github.com/modelcontextprotocol/servers/issues)\\n*   [Pull requests](https://github.com/modelcontextprotocol/servers/pulls)\\n*   [Actions](https://github.com/modelcontextprotocol/servers/actions)\\n*   [Security](https://github.com/modelcontextprotocol/servers/security)\\n*   [Insights](https://github.com/modelcontextprotocol/servers/pulse)\\n\\nmodelcontextprotocol/servers\\n============================\\n\\nmain\\n\\n[Branches](https://github.com/modelcontextprotocol/servers/branches)[Tags](https://github.com/modelcontextprotocol/servers/tags)\\n\\n[](https://github.com/modelcontextprotocol/servers/branches)[](https://github.com/modelcontextprotocol/servers/tags)\\n\\nGo to file\\n\\nCode\\n\\nOpen more actions menu\\n\\nFolders and files\\n-----------------\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| Latest commit ------------- History ------- [3,688 Commits](https://github.com/modelcontextprotocol/servers/commits/main/) [](https://github.com/modelcontextprotocol/servers/commits/main/) |\\n| [.github](https://github.com/modelcontextprotocol/servers/tree/main/.github \".github\") | [.github](https://github.com/modelcontextprotocol/servers/tree/main/.github \".github\") |  |  |\\n| [.vscode](https://github.com/modelcontextprotocol/servers/tree/main/.vscode \".vscode\") | [.vscode](https://github.com/modelcontextprotocol/servers/tree/main/.vscode \".vscode\") |  |  |\\n| [scripts](https://github.com/modelcontextprotocol/servers/tree/main/scripts \"scripts\") | [scripts](https://github.com/modelcontextprotocol/servers/tree/main/scripts \"scripts\") |  |  |\\n| [src](https://github.com/modelcontextprotocol/servers/tree/main/src \"src\") | [src](https://github.com/modelcontextprotocol/servers/tree/main/src \"src\") |  |  |\\n| [.gitattributes](https://github.com/modelcontextprotocol/servers/blob/main/.gitattributes \".gitattributes\") | [.gitattributes](https://github.com/modelcontextprotocol/servers/blob/main/.gitattributes \".gitattributes\") |  |  |\\n| [.gitignore](https://github.com/modelcontextprotocol/servers/blob/main/.gitignore \".gitignore\") | [.gitignore](https://github.com/modelcontextprotocol/servers/blob/main/.gitignore \".gitignore\") |  |  |\\n| [.npmrc](https://github.com/modelcontextprotocol/servers/blob/main/.npmrc \".npmrc\") | [.npmrc](https://github.com/modelcontextprotocol/servers/blob/main/.npmrc \".npmrc\") |  |  |\\n| [CODE_OF_CONDUCT.md](https://github.com/modelcontextprotocol/servers/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\") | [CODE_OF_CONDUCT.md](https://github.com/modelcontextprotocol/servers/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\") |  |  |\\n| [CONTRIBUTING.md](https://github.com/modelcontextprotocol/servers/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") | [CONTRIBUTING.md](https://github.com/modelcontextprotocol/servers/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") |  |  |\\n| [LICENSE](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE \"LICENSE\") | [LICENSE](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE \"LICENSE\") |  |  |\\n| [README.md](https://github.com/modelcontextprotocol/servers/blob/main/README.md \"README.md\") | [README.md](https://github.com/modelcontextprotocol/servers/blob/main/README.md \"README.md\") |  |  |\\n| [SECURITY.md](https://github.com/modelcontextprotocol/servers/blob/main/SECURITY.md \"SECURITY.md\") | [SECURITY.md](https://github.com/modelcontextprotocol/servers/blob/main/SECURITY.md \"SECURITY.md\") |  |  |\\n| [package-lock.json](https://github.com/modelcontextprotocol/servers/blob/main/package-lock.json \"package-lock.json\") | [package-lock.json](https://github.com/modelcontextprotocol/servers/blob/main/package-lock.json \"package-lock.json\") |  |  |\\n| [package.json](https://github.com/modelcontextprotocol/servers/blob/main/package.json \"package.json\") | [package.json](https://github.com/modelcontextprotocol/servers/blob/main/package.json \"package.json\") |  |  |\\n| [tsconfig.json](https://github.com/modelcontextprotocol/servers/blob/main/tsconfig.json \"tsconfig.json\") | [tsconfig.json](https://github.com/modelcontextprotocol/servers/blob/main/tsconfig.json \"tsconfig.json\") |  |  |\\n| View all files |\\n\\nRepository files navigation\\n---------------------------\\n\\n*   [README](https://github.com/modelcontextprotocol/servers#)\\n*   [Code of conduct](https://github.com/modelcontextprotocol/servers#)\\n*   [Contributing](https://github.com/modelcontextprotocol/servers#)\\n*   [MIT license](https://github.com/modelcontextprotocol/servers#)\\n*   [Security](https://github.com/modelcontextprotocol/servers#)\\n\\nModel Context Protocol servers\\n==============================\\n\\n[](https://github.com/modelcontextprotocol/servers#model-context-protocol-servers)\\n\\nThis repository is a collection of _reference implementations_ for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references to community-built servers and additional resources.\\n\\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources. Typically, each MCP server is implemented with an MCP SDK:\\n\\n*   [C# MCP SDK](https://github.com/modelcontextprotocol/csharp-sdk)\\n*   [Go MCP SDK](https://github.com/modelcontextprotocol/go-sdk)\\n*   [Java MCP SDK](https://github.com/modelcontextprotocol/java-sdk)\\n*   [Kotlin MCP SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\\n*   [PHP MCP SDK](https://github.com/modelcontextprotocol/php-sdk)\\n*   [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\\n*   [Ruby MCP SDK](https://github.com/modelcontextprotocol/ruby-sdk)\\n*   [Rust MCP SDK](https://github.com/modelcontextprotocol/rust-sdk)\\n*   [Swift MCP SDK](https://github.com/modelcontextprotocol/swift-sdk)\\n*   [TypeScript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk)\\n\\nNote\\n\\nLists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\\n\\n Reference Servers\\n--------------------\\n\\n[](https://github.com/modelcontextprotocol/servers#-reference-servers)\\n\\nThese servers aim to demonstrate MCP features and the official SDKs.\\n\\n*   **[Everything](https://github.com/modelcontextprotocol/servers/blob/main/src/everything)** - Reference / test server with prompts, resources, and tools.\\n*   **[Fetch](https://github.com/modelcontextprotocol/servers/blob/main/src/fetch)** - Web content fetching and conversion for efficient LLM usage.\\n*   **[Filesystem](https://github.com/modelcontextprotocol/servers/blob/main/src/filesystem)** - Secure file operations with configurable access controls.\\n*   **[Git](https://github.com/modelcontextprotocol/servers/blob/main/src/git)** - Tools to read, search, and manipulate Git repositories.\\n*   **[Memory](https://github.com/modelcontextprotocol/servers/blob/main/src/memory)** - Knowledge graph-based persistent memory system.\\n*   **[Sequential Thinking](https://github.com/modelcontextprotocol/servers/blob/main/src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences.\\n*   **[Time](https://github.com/modelcontextprotocol/servers/blob/main/src/time)** - Time and timezone conversion capabilities.\\n\\n### Archived\\n\\n[](https://github.com/modelcontextprotocol/servers#archived)\\n\\nThe following reference servers are now archived and can be found at [servers-archived](https://github.com/modelcontextprotocol/servers-archived).\\n\\n*   **[AWS KB Retrieval](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime.\\n*   **[Brave Search](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search)** - Web and local search using Brave\\'s Search API. Has been replaced by the [official server](https://github.com/brave/brave-search-mcp-server).\\n*   **[EverArt](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/everart)** - AI image generation using various models.\\n*   **[GitHub](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/github)** - Repository management, file operations, and GitHub API integration.\\n*   **[GitLab](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gitlab)** - GitLab API, enabling project management.\\n*   **[Google Drive](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gdrive)** - File access and search capabilities for Google Drive.\\n*   **[Google Maps](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/google-maps)** - Location services, directions, and place details.\\n*   **[PostgreSQL](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres)** - Read-only database access with schema inspection.\\n*   **[Puppeteer](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer)** - Browser automation and web scraping.\\n*   **[Redis](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/redis)** - Interact with Redis key-value stores.\\n*   **[Sentry](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sentry)** - Retrieving and analyzing issues from Sentry.io.\\n*   **[Slack](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)** - Channel management and messaging capabilities. Now maintained by [Zencoder](https://github.com/zencoderai/slack-mcp-server)\\n*   **[SQLite](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sqlite)** - Database interaction and business intelligence capabilities.\\n\\n Third-Party Servers\\n----------------------\\n\\n[](https://github.com/modelcontextprotocol/servers#-third-party-servers)\\n\\n###  Official Integrations\\n\\n[](https://github.com/modelcontextprotocol/servers#%EF%B8%8F-official-integrations)\\n\\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\\n\\n*   [![Image 1: 21st.dev Logo](https://camo.githubusercontent.com/ef5a9519983d6587ccd70a7bee6285138d209055be84391a3dc3fa6f41d7d747/68747470733a2f2f7777772e323173742e6465762f66617669636f6e2e69636f)](https://camo.githubusercontent.com/ef5a9519983d6587ccd70a7bee6285138d209055be84391a3dc3fa6f41d7d747/68747470733a2f2f7777772e323173742e6465762f66617669636f6e2e69636f)**[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.\\n*   [![Image 2: 2slides Logo](https://camo.githubusercontent.com/9924f54cbd55fc75b3eda001a6a5e090093919812255deac17f3e52eb190c938/68747470733a2f2f7777772e32736c696465732e636f6d2f696d616765732f32736c696465732d7265642e737667)](https://camo.githubusercontent.com/9924f54cbd55fc75b3eda001a6a5e090093919812255deac17f3e52eb190c938/68747470733a2f2f7777772e32736c696465732e636f6d2f696d616765732f32736c696465732d7265642e737667)**[2slides](https://github.com/2slides/2slides-mcp)** - An MCP server that provides tools to convert content into slides/PPT/presentation or generate slides/PPT/presentation with user intention.\\n*   [![Image 3: Paragon Logo](https://camo.githubusercontent.com/5d19f99fb4a7a1b10a0265ff5d0dd956baf8cd2d5e24c19151d640d5440f3726/68747470733a2f2f6672616d657275736572636f6e74656e742e636f6d2f696d616765732f4c70534b3174535a77656f6d7241484f4d416a3947656139366c412e737667)](https://camo.githubusercontent.com/5d19f99fb4a7a1b10a0265ff5d0dd956baf8cd2d5e24c19151d640d5440f3726/68747470733a2f2f6672616d657275736572636f6e74656e742e636f6d2f696d616765732f4c70534b3174535a77656f6d7241484f4d416a3947656139366c412e737667)**[ActionKit by Paragon](https://github.com/useparagon/paragon-mcp)** - Connect to 130+ SaaS integrations (e.g. Slack, Salesforce, Gmail) with Paragons [ActionKit](https://www.useparagon.com/actionkit) API.\\n*   [![Image 4: Adfin Logo](https://camo.githubusercontent.com/978f3390d19c95bde1012aac19eeb95da45d543255a90e2c98c648beb361a1c9/68747470733a2f2f696e766f78782d7075626c69632d6275636b65742e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f66726f6e74656e642d7265736f75726365732f616466696e2d6c6f676f2d736d616c6c2e737667)](https://camo.githubusercontent.com/978f3390d19c95bde1012aac19eeb95da45d543255a90e2c98c648beb361a1c9/68747470733a2f2f696e766f78782d7075626c69632d6275636b65742e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f66726f6e74656e642d7265736f75726365732f616466696e2d6c6f676f2d736d616c6c2e737667)**[Adfin](https://github.com/Adfin-Engineering/mcp-server-adfin)** - The only platform you need to get paid - all payments in one place, invoicing and accounting reconciliations with [Adfin](https://www.adfin.com/).\\n*   [![Image 5: AgentOps Logo](https://github.com/AgentOps-AI/agentops/raw/main/docs/favicon.png)](https://github.com/AgentOps-AI/agentops/blob/main/docs/favicon.png)**[AgentOps](https://github.com/AgentOps-AI/agentops-mcp)** - Provide observability and tracing for debugging AI agents with [AgentOps](https://www.agentops.ai/) API.\\n*   [![Image 6: AgentQL Logo](https://camo.githubusercontent.com/baeb7ec1139c8feb93a05f587971757c3f128bf8f02c12cc5b56a2049b133f45/68747470733a2f2f7777772e6167656e74716c2e636f6d2f66617669636f6e2f66617669636f6e2e706e67)](https://camo.githubusercontent.com/baeb7ec1139c8feb93a05f587971757c3f128bf8f02c12cc5b56a2049b133f45/68747470733a2f2f7777772e6167656e74716c2e636f6d2f66617669636f6e2f66617669636f6e2e706e67)**[AgentQL](https://github.com/tinyfish-io/agentql-mcp)** - Enable AI agents to get structured data from unstructured web with [AgentQL](https://www.agentql.com/).\\n*   [![Image 7: AgentRPC Logo](https://camo.githubusercontent.com/75fe1b227f93614c9cf9dc684227b7f7ea8e9f84967f29dba14fe2618cf02833/68747470733a2f2f6167656e747270632e636f6d2f66617669636f6e2e69636f)](https://camo.githubusercontent.com/75fe1b227f93614c9cf9dc684227b7f7ea8e9f84967f29dba14fe2618cf02833/68747470733a2f2f6167656e747270632e636f6d2f66617669636f6e2e69636f)**[AgentRPC](https://github.com/agentrpc/agentrpc)** - Connect to any function, any language, across network boundaries using [AgentRPC](https://www.agentrpc.com/).\\n*   **[Agentset](https://github.com/agentset-ai/mcp-server)** - RAG for your knowledge base connected to [Agentset](https://agentset.ai/).\\n*   [![Image 8: Aiven Logo](https://camo.githubusercontent.com/b9e8399c9193817a478aa3db8b3910a49922e622191ebf2c69562775a60d5c2a/68747470733a2f2f616976656e2e696f2f66617669636f6e2e69636f)](https://camo.githubusercontent.com/b9e8399c9193817a478aa3db8b3910a49922e622191ebf2c69562775a60d5c2a/68747470733a2f2f616976656e2e696f2f66617669636f6e2e69636f)**[Aiven](https://github.com/Aiven-Open/mcp-aiven)** - Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL, Apache Kafka, ClickHouse and OpenSearch services\\n*   [![Image 9: Alation Logo](https://camo.githubusercontent.com/9276a04adea6e587b34015ffa566eba997517f66aa9a7f329c7382ad5736be88/68747470733a2f2f7777772e616c6174696f6e2e636f6d2f7265736f757263652d63656e7465722f646f776e6c6f61642f377033766e62627a6e6669772f3334464d7442546578357070767332684e59613946632f63383737633337653838653533333938373836353836393763343664326435382f416c6174696f6e2d4c6f676f2d4275672d5072696d6172792e737667)](https://camo.githubusercontent.com/9276a04adea6e587b34015ffa566eba997517f66aa9a7f329c7382ad5736be88/68747470733a2f2f7777772e616c6174696f6e2e636f6d2f7265736f757263652d63656e7465722f646f776e6c6f61642f377033766e62627a6e6669772f3334464d7442546578357070767332684e59613946632f63383737633337653838653533333938373836353836393763343664326435382f416c6174696f6e2d4c6f676f2d4275672d5072696d6172792e737667)**[Alation](https://github.com/Alation/alation-ai-agent-sdk)** - Unlock the power of the enterprise Data Catalog by harnessing tools provided by the Alation MCP server.\\n*   [![Image 10: Alby Logo](https://camo.githubusercontent.com/517f3cfab19a84df59740752b29438273cf295fd7e26f95bee4faa76b873739f/68747470733a2f2f692e706f7374696d672e63632f354e597739716a532f616c62792d69636f6e2d686561642d79656c6c6f772d353030783530302e706e67)](https://camo.githubusercontent.com/517f3cfab19a84df59740752b29438273cf295fd7e26f95bee4faa76b873739f/68747470733a2f2f692e706f7374696d672e63632f354e597739716a532f616c62792d69636f6e2d686561642d79656c6c6f772d353030783530302e706e67)**[Alby Bitcoin Payments](https://github.com/getAlby/mcp)** - Connect any bitcoin lightning wallet to your agent to send and receive instant payments globally with your agent.\\n*   **[Algolia](https://github.com/algolia/mcp)** - Use AI agents to provision, configure, and query your [Algolia](https://algolia.com/) search indices.\\n*   [![Image 11: Alibaba Cloud AnalyticDB for MySQL Logo](https://camo.githubusercontent.com/7cb82e1b6c37954f3435a9079ed7ea0d143776e473632d5f0a8e7f76174a315b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69342f4f31434e303165706b58774831574c41586b5a6656364e5f2121363030303030303030323737312d322d7470732d3230302d3230302e706e67)](https://camo.githubusercontent.com/7cb82e1b6c37954f3435a9079ed7ea0d143776e473632d5f0a8e7f76174a315b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69342f4f31434e303165706b58774831574c41586b5a6656364e5f2121363030303030303030323737312d322d7470732d3230302d3230302e706e67)**[Alibaba Cloud AnalyticDB for MySQL](https://github.com/aliyun/alibabacloud-adb-mysql-mcp-server)** - Connect to an [AnalyticDB for MySQL](https://www.alibabacloud.com/en/product/analyticdb-for-mysql) cluster for getting database or table metadata, querying and analyzing data. It will be supported to add the OpenAPI for cluster operation in the future.\\n*   [![Image 12: Alibaba Cloud AnalyticDB for PostgreSQL Logo](https://github.com/aliyun/alibabacloud-adbpg-mcp-server/raw/master/images/AnalyticDB.png)](https://github.com/aliyun/alibabacloud-adbpg-mcp-server/blob/master/images/AnalyticDB.png)**[Alibaba Cloud AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server)** - An MCP server to connect to [AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server) instances, query and analyze data.\\n*   [![Image 13: DataWorks Logo](https://camo.githubusercontent.com/1547d08512702fe5794db8b93dfd6e25c8fb388c64b85a9dd28b0972c5b5a65b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69332f4f31434e30313031555757463155596e337241653348555f2121363030303030303030323533302d322d7470732d33322d33322e706e67)](https://camo.githubusercontent.com/1547d08512702fe5794db8b93dfd6e25c8fb388c64b85a9dd28b0972c5b5a65b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69332f4f31434e30313031555757463155596e337241653348555f2121363030303030303030323533302d322d7470732d33322d33322e706e67)**[Alibaba Cloud DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\\n*   [![Image 14: Alibaba Cloud OpenSearch Logo](https://camo.githubusercontent.com/3b9b10166cde86742b0cec5f648610d446f0d9c5addc1a00429cec0306c364a0/68747470733a2f2f6f70656e7365617263682d7368616e676861692e6f73732d636e2d7368616e676861692e616c6979756e63732e636f6d2f6f756875616e672f616c6979756e2d69636f6e2e706e67)](https://camo.githubusercontent.com/3b9b10166cde86742b0cec5f648610d446f0d9c5addc1a00429cec0306c364a0/68747470733a2f2f6f70656e7365617263682d7368616e676861692e6f73732d636e2d7368616e676861692e616c6979756e63732e636f6d2f6f756875616e672f616c6979756e2d69636f6e2e706e67)**[Alibaba Cloud OpenSearch](https://github.com/aliyun/alibabacloud-opensearch-mcp-server)** - This MCP server equips AI Agents with tools to interact with [OpenSearch](https://help.aliyun.com/zh/open-search/?spm=5176.7946605.J_5253785160.6.28098651AaYZXC) through a standardized and extensible interface.\\n*   [![Image 15: Alibaba Cloud OPS Logo](https://github.com/aliyun/alibaba-cloud-ops-mcp-server/raw/master/image/alibaba-cloud.png)](https://github.com/aliyun/alibaba-cloud-ops-mcp-server/blob/master/image/alibaba-cloud.png)**[Alibaba Cloud OPS](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)** - Manage the lifecycle of your Alibaba Cloud resources with [CloudOps Orchestration Service](https://www.alibabacloud.com/en/product/oos) and Alibaba Cloud OpenAPI.\\n*   [![Image 16: Alibaba Cloud RDS MySQL Logo](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/raw/main/assets/alibabacloudrds.png)](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/blob/main/assets/alibabacloudrds.png)**[Alibaba Cloud RDS](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server)** - An MCP server designed to interact with the Alibaba Cloud RDS OpenAPI, enabling programmatic management of RDS resources via an LLM.\\n*   [![Image 17: AlipayPlus Logo](https://camo.githubusercontent.com/00b2ae041a2431b6cc89568cb84b35ceedf06cfcbeb7888fbdf3542a64047f7a/68747470733a2f2f7777772e616c69706179706c75732e636f6d2f66617669636f6e2e69636f)](https://camo.githubusercontent.com/00b2ae041a2431b6cc89568cb84b35ceedf06cfcbeb7888fbdf3542a64047f7a/68747470733a2f2f7777772e616c69706179706c75732e636f6d2f66617669636f6e2e69636f)**[AlipayPlus](https://github.com/alipay/global-alipayplus-mcp)** - Connect your AI Agents to AlipayPlus Checkout Payment.\\n*   [![Image 18: AllVoiceLab Logo](https://camo.githubusercontent.com/4de224e2a3bdd36ed2e67c284236a061734be55dc4d5042e528ddfdd127b3c1e/68747470733a2f2f63646e2e616c6c766f6963656c61622e636f6d2f7265736f75726365732f776f726b62656e63682f646973742f69636f6e2d6461726b2e69636f)](https://camo.githubusercontent.com/4de224e2a3bdd36ed2e67c284236a061734be55dc4d5042e528ddfdd127b3c1e/68747470733a2f2f63646e2e616c6c766f6963656c61622e636f6d2f7265736f75726365732f776f726b62656e63682f646973742f69636f6e2d6461726b2e69636f)**[AllVoiceLab](https://www.allvoicelab.com/mcp)** - An AI voice toolkit with TTS, voice cloning, and video translation, now available as an MCP server for smarter agent integration.\\n*   [![Image 19: Alpaca Logo](https://camo.githubusercontent.com/8a36ba1473c15f7eff5b1de1156bd339f9ac116b647d67b1bd43d7263d20799c/68747470733a2f2f66696c65732e616c706163612e6d61726b6\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 6: What is Anthropic\\'s Model Context Protocol (MCP)? ---\\nURL: https://blog.promptlayer.com/mcp/\\n\\nSUMMARY:\\nIn short, MCP is an open, standardized client-server architecture designed to seamlessly connect LLMs to external tools and data sources, streamlining integration through structured, two-way communication. The Model Context Protocol (MCP) is an open standard designed to provide a universal method for AI models, primarily LLMs, to interact with external data sources and tools. * **Integration with Development Tools:**\\xa0Companies like Zed, Replit, Codeium, and Sourcegraph are integrating MCP into their platforms, enabling AI agents to better retrieve relevant information for coding tasks. Anthropic\\'s Model Context Protocol (MCP) represents a significant step towards a more open, interoperable, and capable AI ecosystem. By providing a standardized way for AI models to connect with external data sources and tools, MCP has the potential to unlock new levels of productivity and innovation.\\n\\nFULL CONTENT:\\n* [Platform](#t)\\n* [-- Prompt Management](https://www.promptlayer.com/platform/prompt-management)\\n* [-- Evaluations](https://www.promptlayer.com/platform/evaluations)\\n* [-- Observability](https://www.promptlayer.com/platform/observability)\\n* [-- Dataset Management](https://www.promptlayer.com/platform/dataset-management)\\n* [-- Prompt Chaining](https://www.promptlayer.com/platform/prompt-chaining)\\n* [Docs](https://docs.promptlayer.com/)\\n* [Blog](/)\\n* [Case Studies](https://www.promptlayer.com/case-studies)\\n* [Careers](https://www.promptlayer.com/careers)\\n* [Log in](https://dashboard.promptlayer.com/login?_gl=1*16zc5v3*_ga*MTczNTE5MTk0OC4xNzUzNTMyOTU0*_ga_XXMML34VE3*czE3NTQzMTU3NzkkbzI5JGcxJHQxNzU0MzE1OTMwJGozNiRsMCRoMA..*_gcl_au*MTgwNjYyNzYxLjE3NTM1MzI5NTQ.)\\n* [Contact Us](https://www.promptlayer.com/contact-us)\\n\\n[Contact Us](https://www.promptlayer.com/contact-us)   [Log In](https://dashboard.promptlayer.com/login?_gl=1*fi04t4*_ga*MTczNTE5MTk0OC4xNzUzNTMyOTU0*_ga_XXMML34VE3*czE3NTQzMTU3NzkkbzI5JGcxJHQxNzU0MzE1Nzc5JGo2MCRsMCRoMA..*_gcl_au*MTgwNjYyNzYxLjE3NTM1MzI5NTQ.)\\n\\n[Back](https://blog.promptlayer.com) \\n\\n# What is Anthropic\\'s Model Context Protocol (MCP)?\\n\\nBy [Erich H.](/author/erich_h/)   Mar 13, 2025\\n\\nwhat is mcp?\\n\\nOne persistent challenge in AI has been connecting powerful LLMs to the vast array of external data sources and tools necessary for real-world applications. Anthropic\\'s Model Context Protocol (MCP), introduced in late November 2024, offers a promising solution. In short, MCP is an open, standardized client-server architecture designed to seamlessly connect LLMs to external tools and data sources, streamlining integration through structured, two-way communication.  \\n  \\nThis article dives into MCP, exploring its purpose, key features, use cases, underlying technology, and reception within the AI community.\\n\\n**Table of Contents**\\n\\n1. [What is Anthropic\\'s Model Context Protocol (MCP)?](#what-is-anthropics-model-context-protocol-mcp)\\n2. [Key Features and Functionalities of MCP](#key-features-and-functionalities-of-mcp)\\n3. [Use Cases and Examples of MCP](#use-cases-and-examples-of-mcp)\\n4. [Insights into the Technology and Algorithms Behind MCP](#insights-into-the-technology-and-algorithms-behind-mcp)\\n5. [Notable Reactions and Reviews from Experts in the AI Community](#notable-reactions-and-reviews-from-experts-in-the-ai-community )\\n6. [Final thoughts](#final-thoughts)\\n\\n## **What is Anthropic\\'s Model Context Protocol (MCP)?**\\n\\nThe Model Context Protocol (MCP) is an open standard designed to provide a universal method for AI models, primarily LLMs, to interact with external data sources and tools. Think of it as a \"USB port\" for AI: a standardized way for any AI assistant to connect to any data source or service without requiring custom-built integrations for each connection.\\n\\nBefore MCP, integrating LLMs with different data sources was a significant hurdle. Each connection required bespoke code, leading to a fragmented and difficult-to-scale architecture. MCP aims to replace these ad-hoc integrations with a single, open protocol, streamlining the process and fostering a more interoperable AI ecosystem.\\n\\nIn essence, MCP is a protocol for AI\\xa0capabilities. It sets a standard for how AI applications are built and how they exchange data, addressing the \"MxN\" problem  the challenge of connecting\\xa0M\\xa0different LLMs with\\xa0N\\xa0different tools. By providing a common language, MCP allows LLM vendors and tool builders to work together seamlessly.\\n\\n> **Want to compare model performance yourself?**  \\n>   \\n> [PromptLayer](https://promptlayer.com/?ref=blog.promptlayer.com)\\xa0is specifically designed for capturing and analyzing LLM interactions. Providing insights into prompt effectiveness, model performance, and overall system behavior.  \\n>   \\n> With\\xa0[PromptLayer](https://promptlayer.com/?ref=blog.promptlayer.com), your team can:  \\n> - Use Prompt Versioning and Tracking  \\n> - Get In-Depth Performance Monitoring and Cost Analysis  \\n> - Detect and Debug errors fast  \\n> - Compare Claude and other models side-by-side  \\n>   \\n> Manage and monitor prompts with your whole team.\\xa0[Get started here.](https://www.promptlayer.com/?ref=blog.promptlayer.com)\\n\\n## **Key Features and Functionalities of MCP**\\n\\nMCP\\'s design centers around a client-server architecture and a set of well-defined communication primitives. Here\\'s a breakdown of its key features:\\n\\n* **Client-Server Architecture:**\\xa0MCP operates on a client-server model using JSON-RPC. AI applications (e.g., the Claude Desktop app or an IDE) act as\\xa0clients, connecting to\\xa0servers\\xa0that represent data sources or tools.\\n* **Communication Primitives:**\\xa0MCP defines core message types, called \"primitives,\" that govern interactions. These include:\\n  + **Server-side Primitives:**\\n    - **Prompts:**\\xa0Prepared instructions or templates that guide the AI model.\\n    - **Resources:**\\xa0Structured data (e.g., document snippets, code fragments) that enrich the model\\'s context.\\n    - **Tools:**\\xa0Executable functions or actions the model can invoke through the server (e.g., querying a database, performing a web search, sending a message).\\n  + **Client-side Primitives:**\\n    - **Roots:**\\xa0Entry points into the host\\'s file system or environment, accessible by the server with permission.\\n    - **Sampling:**\\xa0A mechanism for the server to request the host AI to generate a completion based on a prompt, facilitating multi-step reasoning. Anthropic recommends human approval for sampling requests to maintain control.\\n* **Two-Way Communication:**\\xa0MCP supports bidirectional communication. This means AI models can not only receive information but also trigger actions in external systems, enabling more dynamic and interactive applications.\\n* **Secure Connectivity:**\\xa0Security is a core design principle. The host (where the AI model resides) controls client connection permissions, allowing users and organizations to strictly manage what an AI assistant can access.\\n* **Standardized Ecosystem:**\\xa0MCP aims to create an interoperable ecosystem. Once tools and models adhere to the MCP standard, any compliant model can work with any compliant tool, fostering collaboration and innovation.\\n* **Layered Context Management:**\\xa0MCP allows for breaking down data into manageable sections, potentially improving the efficiency of AI processing.\\n* **Protocol Version Compatibility:**\\xa0The protocol includes mechanisms for negotiating version compatibility, ensuring smooth interoperability between clients and servers even as the standard evolves.\\n\\n## **Use Cases and Examples of MCP**\\n\\nThe potential applications of MCP are vast and span various industries. Here are some notable examples:\\n\\n* **Enterprise Data Assistants:**\\xa0MCP enables AI assistants to securely access company data, documents, and internal services. Imagine a corporate chatbot that can seamlessly query multiple systems (HR databases, project management tools, Slack channels) within a single conversation, all through standardized MCP connectors.\\n* **AI-Powered Coding Assistants:**\\xa0IDE integrations can use MCP to access extensive codebases and documentation. Sourcegraph\\'s AI assistant, Cody, exemplifies this, providing developers with accurate code suggestions and insights.\\n* **AI-Driven Data Querying:**\\xa0MCP simplifies connecting AI models to databases, streamlining data analysis and reporting. AI2SQL, which uses MCP to generate SQL queries from natural language prompts, demonstrates this capability.\\n* **Desktop AI Applications:**\\xa0Anthropic\\'s Claude Desktop utilizes MCP to allow AI assistants to securely access local files, applications, and services, enhancing their ability to provide contextually relevant responses and perform tasks.\\n* **Integration with Development Tools:**\\xa0Companies like Zed, Replit, Codeium, and Sourcegraph are integrating MCP into their platforms, enabling AI agents to better retrieve relevant information for coding tasks.\\n* **Automated Data Extraction and Web Searches:**\\xa0Apify has developed an MCP server that allows AI agents to access all Apify Actors, streamlining tasks like automated data extraction and web searches without requiring direct user involvement.\\n* **Real-time Data Processing:**\\xa0MCP can be used in applications requiring real-time data interactions, such as processing live data streams or interfacing with sensors.\\n* **Multi-Tool Coordination:**\\xa0MCP facilitates complex workflows by integrating multiple tools (e.g., file systems and GitHub) into a cohesive operational framework.\\n* **Integration with Various Platforms:**\\xa0Pre-built MCP servers are available or under development for popular enterprise systems like Google Drive, Slack, GitHub, Git, Postgres, and Puppeteer.\\n\\n## **Insights into the Technology and Algorithms Behind MCP**\\n\\nMCP\\'s technical foundation is built on several key components:\\n\\n* **Client-Server Architecture:**\\xa0A flexible and extensible architecture that allows for modularity and scalability.\\n* **JSON-RPC:**\\xa0A lightweight remote procedure call protocol used for communication between clients and servers.\\n* **Primitives:**\\xa0A well-defined set of core message types that standardize interactions between clients and servers.\\n* **Claude 3.5 Sonnet\\'s role:**\\xa0Anthropic\\'s Claude 3.5 Sonnet is good at quickly creating the implementations of the MCP servers.\\n* **SDKs:**\\xa0Software Development Kits (SDKs) are available for developers to build MCP clients and servers in various programming languages, including Python, TypeScript, Kotlin, and Java.\\n* **Spring AI Project:**\\xa0This project extends the MCP Java SDK, adding developer productivity enhancements for integration with Spring Boot applications.\\n* **Controlled Access:**\\xa0MCP emphasizes controlled access, with the host managing client connections and permissions to ensure security.\\n\\n## **Notable Reactions and Reviews from Experts in the AI Community**\\n\\nThe release of MCP has generated considerable discussion within the AI community. Here\\'s a summary of key reactions:\\n\\n* **Potential for Transformation:**\\xa0Experts suggest MCP could revolutionize business AI integrations, similar to how service-oriented architecture (SOA) and other protocols transformed application interoperability.\\n* **Comparison to Established Standards:**\\xa0Gideon Mendels (Comet) likened MCP to REST and SQL, highlighting its potential to accelerate GenAI application development and improve reliability. He also emphasized the potential for increased interoperability and experimentation.\\n* **\"Microservices with Intelligence\":**\\xa0Mahesh Murag (Anthropic) described MCP as \"very much like microservices, but we are bringing in intelligence.\"\\n* **Game-Changer Potential:**\\xa0Some view MCP as a potential \"game-changer\" that could simplify integrations, enhance performance, and support the development of more autonomous AI systems.\\n* **Concerns and Challenges:**\\n  + Concerns have been raised about potential over-reliance on AI and the risks of AI influencing decisions in extreme ways.\\n  + The need for widespread adoption to realize MCP\\'s full potential has been emphasized, along with the challenge of convincing developers already invested in established ecosystems to adopt it.\\n  + JD Raimondi (Making Sense) noted that while Anthropic is a leader in large context experiments, model accuracy can sometimes suffer, though it\\'s expected to improve over time.\\n  + The importance of supporting remote servers and lowering the usage threshold for MCP to gain wider adoption has been highlighted. The current requirement for some development background is seen as a barrier to entry.\\n* **Active Community Development:**\\xa0The community is actively working on enhancing MCP, with proposals for identity authentication using OAuth 2.0 and efforts to improve usability through package management, installation tools, sandboxing, and server registration.\\n\\n## **Final thoughts**\\n\\nAnthropic\\'s Model Context Protocol (MCP) represents a significant step towards a more open, interoperable, and capable AI ecosystem. By providing a standardized way for AI models to connect with external data sources and tools, MCP has the potential to unlock new levels of productivity and innovation. While challenges remain, particularly in achieving widespread adoption and addressing potential risks, MCP\\'s early reception suggests it could be a transformative technology in the evolution of AI. As the AI community continues to develop and refine MCP, it will be crucial to prioritize security, usability, and responsible development to ensure its long-term success.\\n\\n---\\n\\n## **About PromptLayer**\\n\\nPromptLayer is a prompt management system that helps you iterate on prompts faster\\u200a\\u200afurther speeding up the development cycle! Use their prompt CMS to update a prompt, run evaluations, and deploy it to production in minutes. Check them out\\xa0[here](http://www.promptlayer.com/?ref=blog.promptlayer.com). \\n\\n[LLM Agents vs. Function Calling: An Analysis of Techniques](/llm-agents-vs-function-calling/)\\n\\n [Previous](/llm-agents-vs-function-calling/)\\n\\n[Braintrust vs. PromptLayer: Choose the Right LLM Management Platform](/braintrust-vs-promptlayer/)\\n\\n [Next](/braintrust-vs-promptlayer/)\\n\\n## RECENT ARTICLES\\n\\n## [GPT-5 API Features](/gpt-5-api-features/)\\n\\n## [Opus 4.5: What We Expect](/opus-4-5-what-we-expect/)\\n\\n## [Browser Agent Security Risk](/browser-agent-security-risk/)\\n\\n## The first platform built for prompt engineering\\n\\n[Start for free](https://dashboard.promptlayer.com/create-account?_gl=1*1o0jmu7*_ga*MTczNTE5MTk0OC4xNzUzNTMyOTU0*_ga_XXMML34VE3*czE3NTQzMTU3NzkkbzI5JGcxJHQxNzU0MzE1OTk1JGo2MCRsMCRoMA..*_gcl_au*MTgwNjYyNzYxLjE3NTM1MzI5NTQ.)\\n\\nMade in NYC \\n\\n[hello@promptlayer.com](mailto:hello@promptlayer.com)\\n\\n###### Usage\\n\\n* [Docs](https://docs.promptlayer.com/introduction)\\n* [Blog](/)\\n* [Case Studies](https://www.promptlayer.com/case-studies)\\n* [Glossary](https://www.promptlayer.com/glossary)\\n* [Models](https://www.promptlayer.com/models)\\n* [Research Papers](https://www.promptlayer.com/research-papers)\\n* [Log in](https://dashboard.promptlayer.com/login?_gl=1*16zc5v3*_ga*MTczNTE5MTk0OC4xNzUzNTMyOTU0*_ga_XXMML34VE3*czE3NTQzMTU3NzkkbzI5JGcxJHQxNzU0MzE1OTMwJGozNiRsMCRoMA..*_gcl_au*MTgwNjYyNzYxLjE3NTM1MzI5NTQ.)\\n* [Contact Us](https://www.promptlayer.com/contact-us)\\n\\n###### Company\\n\\n* [Email Us](mailto:hello@promptlayer.com)\\n* [Discord](https://discord.com/invite/DBAhQbW39S)\\n* [Prompt Engineering Audit](https://www.promptlayer.com/prompt-engineering-audit)\\n* [Referral](https://www.promptlayer.com/referral)\\n\\n###### Follow Us\\n\\n Copyright 2025 Magniv, Inc. All rights reserved.\\n\\n \\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 7: punkpeye/awesome-mcp-servers ---\\nURL: https://github.com/punkpeye/awesome-mcp-servers\\n\\nSUMMARY:\\n* 1mcp/agent       - A unified Model Context Protocol server implementation that aggregates multiple MCP servers into one. * TheLunarCompany/lunar#mcpx       - MCPX is a production-ready, open-source gateway to manage MCP servers at scalecentralize tool discovery, access controls, call prioritization, and usage tracking to simplify agent workflows. * wso2/fhir-mcp-server    - Model Context Protocol server for Fast Healthcare Interoperability Resources (FHIR) APIs. Provides seamless integration with FHIR servers, enabling AI assistants to search, retrieve, create, update, and analyze clinical healthcare data with SMART-on-FHIR authentication support. * HenryHaoson/Yuque-MCP-Server -   A Model-Context-Protocol (MCP) server for integrating with Yuque API, allowing AI models to manage documents, interact with knowledge bases, search content, and access analytics data from the Yuque platform.\\n\\nFULL CONTENT:\\n[Skip to content](#start-of-content)   \\n\\n\\n\\n## Navigation Menu\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fpunkpeye%2Fawesome-mcp-servers) \\n\\nAppearance settings\\n\\n# Search code, repositories, users, issues, pull requests...\\n\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fpunkpeye%2Fawesome-mcp-servers)\\n\\n [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=punkpeye%2Fawesome-mcp-servers) \\n\\nAppearance settings\\n\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n\\n{{ message }}\\n\\n[punkpeye](/punkpeye)   /  **[awesome-mcp-servers](/punkpeye/awesome-mcp-servers)**  Public\\n\\n* Couldn\\'t load subscription status.\\xa0\\n\\n  ### Uh oh!\\n\\n  There was an error while loading. Please reload this page.\\n* [Fork 6.2k](/login?return_to=%2Fpunkpeye%2Fawesome-mcp-servers)\\n* [Star  73.8k](/login?return_to=%2Fpunkpeye%2Fawesome-mcp-servers)\\n\\nA collection of MCP servers.\\n\\n[glama.ai/mcp/servers](https://glama.ai/mcp/servers \"https://glama.ai/mcp/servers\")\\n\\n### License\\n\\n[MIT license](/punkpeye/awesome-mcp-servers/blob/main/LICENSE)\\n\\n[73.8k stars](/punkpeye/awesome-mcp-servers/stargazers)   [6.2k forks](/punkpeye/awesome-mcp-servers/forks)   [Branches](/punkpeye/awesome-mcp-servers/branches)   [Tags](/punkpeye/awesome-mcp-servers/tags)   [Activity](/punkpeye/awesome-mcp-servers/activity)\\n\\n[Star](/login?return_to=%2Fpunkpeye%2Fawesome-mcp-servers)\\n\\nCouldn\\'t load subscription status.\\n\\n### Uh oh!\\n\\nThere was an error while loading. Please reload this page.\\n\\n# punkpeye/awesome-mcp-servers\\n\\n[Branches](/punkpeye/awesome-mcp-servers/branches)[Tags](/punkpeye/awesome-mcp-servers/tags)\\n\\nOpen more actions menu\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| Latest commit   History[2,817 Commits](/punkpeye/awesome-mcp-servers/commits/main/) |\\n| [CONTRIBUTING.md](/punkpeye/awesome-mcp-servers/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") | [CONTRIBUTING.md](/punkpeye/awesome-mcp-servers/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") |  |  |\\n| [LICENSE](/punkpeye/awesome-mcp-servers/blob/main/LICENSE \"LICENSE\") | [LICENSE](/punkpeye/awesome-mcp-servers/blob/main/LICENSE \"LICENSE\") |  |  |\\n| [README-ja.md](/punkpeye/awesome-mcp-servers/blob/main/README-ja.md \"README-ja.md\") | [README-ja.md](/punkpeye/awesome-mcp-servers/blob/main/README-ja.md \"README-ja.md\") |  |  |\\n| [README-ko.md](/punkpeye/awesome-mcp-servers/blob/main/README-ko.md \"README-ko.md\") | [README-ko.md](/punkpeye/awesome-mcp-servers/blob/main/README-ko.md \"README-ko.md\") |  |  |\\n| [README-pt\\\\_BR.md](/punkpeye/awesome-mcp-servers/blob/main/README-pt_BR.md \"README-pt_BR.md\") | [README-pt\\\\_BR.md](/punkpeye/awesome-mcp-servers/blob/main/README-pt_BR.md \"README-pt_BR.md\") |  |  |\\n| [README-th.md](/punkpeye/awesome-mcp-servers/blob/main/README-th.md \"README-th.md\") | [README-th.md](/punkpeye/awesome-mcp-servers/blob/main/README-th.md \"README-th.md\") |  |  |\\n| [README-zh.md](/punkpeye/awesome-mcp-servers/blob/main/README-zh.md \"README-zh.md\") | [README-zh.md](/punkpeye/awesome-mcp-servers/blob/main/README-zh.md \"README-zh.md\") |  |  |\\n| [README-zh\\\\_TW.md](/punkpeye/awesome-mcp-servers/blob/main/README-zh_TW.md \"README-zh_TW.md\") | [README-zh\\\\_TW.md](/punkpeye/awesome-mcp-servers/blob/main/README-zh_TW.md \"README-zh_TW.md\") |  |  |\\n| [README.md](/punkpeye/awesome-mcp-servers/blob/main/README.md \"README.md\") | [README.md](/punkpeye/awesome-mcp-servers/blob/main/README.md \"README.md\") |  |  |\\n|  |\\n\\n## Repository files navigation\\n\\n# Awesome MCP Servers\\n\\nA curated list of awesome Model Context Protocol (MCP) servers.\\n\\n* [What is MCP?](#what-is-mcp)\\n* [Clients](#clients)\\n* [Tutorials](#tutorials)\\n* [Community](#community)\\n* [Legend](#legend)\\n* [Server Implementations](#server-implementations)\\n* [Frameworks](#frameworks)\\n* [Tips & Tricks](#tips-and-tricks)\\n\\n## What is MCP?\\n\\n[MCP](https://modelcontextprotocol.io/) is an open protocol that enables AI models to securely interact with local and remote resources through standardized server implementations. This list focuses on production-ready and experimental MCP servers that extend AI capabilities through file access, database connections, API integrations, and other contextual services.\\n\\n## Clients\\n\\nCheckout [awesome-mcp-clients](https://github.com/punkpeye/awesome-mcp-clients/) and [glama.ai/mcp/clients](https://glama.ai/mcp/clients).\\n\\nTip\\n\\n[Glama Chat](https://glama.ai/chat) is a multi-modal AI client with MCP support & [AI gateway](https://glama.ai/gateway).\\n\\n## Tutorials\\n\\n* [Model Context Protocol (MCP) Quickstart](https://glama.ai/blog/2024-11-25-model-context-protocol-quickstart)\\n* [Setup Claude Desktop App to Use a SQLite Database](https://youtu.be/wxCCzo9dGj0)\\n\\n## Community\\n\\n* [r/mcp Reddit](https://www.reddit.com/r/mcp)\\n* [Discord Server](https://glama.ai/mcp/discord)\\n\\n## Legend\\n\\n*   official implementation\\n* programming language\\n\\n  +   Python codebase\\n  +   TypeScript (or JavaScript) codebase\\n  +   Go codebase\\n  +   Rust codebase\\n  + # - C# Codebase\\n  +  - Java codebase\\n  +   C/C++ codebase\\n  +  - Ruby codebase\\n* scope\\n\\n  +  - Cloud Service\\n  +  - Local Service\\n  +  - Embedded Systems\\n* operating system\\n\\n  +   For macOS\\n  +   For Windows\\n  +  - For Linux\\n\\nNote\\n\\nConfused about Local  vs Cloud ?\\n\\n* Use local when MCP server is talking to a locally installed software, e.g. taking control over Chrome browser.\\n* Use cloud when MCP server is talking to remote APIs, e.g. weather API.\\n\\n## Server Implementations\\n\\nNote\\n\\nWe now have a [web-based directory](https://glama.ai/mcp/servers) that is synced with the repository.\\n\\n*  - [Aggregators](#aggregators)\\n*  - [Art & Culture](#art-and-culture)\\n*  - [Browser Automation](#browser-automation)\\n*  - [Biology Medicine and Bioinformatics](#bio)\\n*  - [Cloud Platforms](#cloud-platforms)\\n* \\u200d - [Code Execution](#code-execution)\\n*  - [Coding Agents](#coding-agents)\\n*  - [Command Line](#command-line)\\n*  - [Communication](#communication)\\n*  - [Customer Data Platforms](#customer-data-platforms)\\n*  - [Databases](#databases)\\n*  - [Data Platforms](#data-platforms)\\n*  - [Delivery](#delivery)\\n*  - [Developer Tools](#developer-tools)\\n*  - [Data Science Tools](#data-science-tools)\\n*  - [Embedded system](#embedded-system)\\n*  - [File Systems](#file-systems)\\n*  - [Finance & Fintech](#finance--fintech)\\n*  - [Gaming](#gaming)\\n*  - [Knowledge & Memory](#knowledge--memory)\\n*  - [Location Services](#location-services)\\n*  - [Marketing](#marketing)\\n*  - [Monitoring](#monitoring)\\n*  - [Multimedia Process](#multimedia-process)\\n*  - [Search & Data Extraction](#search)\\n*  - [Security](#security)\\n*  - [Social Media](#social-media)\\n*  - [Sports](#sports)\\n*  - [Support & Service Management](#support-and-service-management)\\n*  - [Translation Services](#translation-services)\\n*  - [Text-to-Speech](#text-to-speech)\\n*  - [Travel & Transportation](#travel-and-transportation)\\n*  - [Version Control](#version-control)\\n*  - [Workplace & Productivity](#workplace-and-productivity)\\n*  - [Other Tools and Integrations](#other-tools-and-integrations)\\n\\n###  Aggregators\\n\\nServers for accessing many apps and tools through a single MCP server.\\n\\n* [1mcp/agent](https://github.com/1mcp-app/agent)       - A unified Model Context Protocol server implementation that aggregates multiple MCP servers into one.\\n* [duaraghav8/MCPJungle](https://github.com/duaraghav8/MCPJungle)   - Self-hosted MCP Server registry for enterprise AI Agents\\n* [glenngillen/mcpmcp-server](https://github.com/glenngillen/mcpmcp-server)      - A list of MCP servers so you can ask your client which servers you can use to improve your daily workflow.\\n* [hamflx/imagen3-mcp](https://github.com/hamflx/imagen3-mcp)      - A powerful image generation tool using Google\\'s Imagen 3.0 API through MCP. Generate high-quality images from text prompts with advanced photography, artistic, and photorealistic controls.\\n* [julien040/anyquery](https://github.com/julien040/anyquery)    - Query more than 40 apps with one binary using SQL. It can also connect to your PostgreSQL, MySQL, or SQLite compatible database. Local-first and private by design.\\n* [metatool-ai/metatool-app](https://github.com/metatool-ai/metatool-app)       - MetaMCP is the one unified middleware MCP server that manages your MCP connections with GUI.\\n* [mindsdb/mindsdb](https://github.com/mindsdb/mindsdb) - Connect and unify data across various platforms and databases with [MindsDB as a single MCP server](https://docs.mindsdb.com/mcp/overview).\\n* [particlefuture/MCPDiscovery](https://github.com/particlefuture/MCPDiscovery) - MCP of MCPs. A central hub for MCP servers. Helps you discover available MCP servers and learn how to install and use them.\\n* [PipedreamHQ/pipedream](https://github.com/PipedreamHQ/pipedream/tree/master/modelcontextprotocol)   - Connect with 2,500 APIs with 8,000+ prebuilt tools, and manage servers for your users, in your own app.\\n* [sitbon/magg](https://github.com/sitbon/magg)       - Magg: A meta-MCP server that acts as a universal hub, allowing LLMs to autonomously discover, install, and orchestrate multiple MCP servers - essentially giving AI assistants the power to extend their own capabilities on-demand.\\n* [SureScaleAI/openai-gpt-image-mcp](https://github.com/SureScaleAI/openai-gpt-image-mcp)   - OpenAI GPT image generation/editing MCP server.\\n* [sxhxliang/mcp-access-point](https://github.com/sxhxliang/mcp-access-point)       - Turn a web service into an MCP server in one click without making any code changes.\\n* [TheLunarCompany/lunar#mcpx](https://github.com/TheLunarCompany/lunar/tree/main/mcpx)       - MCPX is a production-ready, open-source gateway to manage MCP servers at scalecentralize tool discovery, access controls, call prioritization, and usage tracking to simplify agent workflows.\\n* [tigranbs/mcgravity](https://github.com/tigranbs/mcgravity)   - A proxy tool for composing multiple MCP servers into one unified endpoint. Scale your AI tools by load balancing requests across multiple MCP servers, similar to how Nginx works for web servers.\\n* [VeriTeknik/pluggedin-mcp-proxy](https://github.com/VeriTeknik/pluggedin-mcp-proxy)   - A comprehensive proxy server that combines multiple MCP servers into a single interface with extensive visibility features. It provides discovery and management of tools, prompts, resources, and templates across servers, plus a playground for debugging when building MCP servers.\\n* [WayStation-ai/mcp](https://github.com/waystation-ai/mcp)    - Seamlessly and securely connect Claude Desktop and other MCP hosts to your favorite apps (Notion, Slack, Monday, Airtable, etc.). Takes less than 90 secs.\\n* [wegotdocs/open-mcp](https://github.com/wegotdocs/open-mcp)      - Turn a web API into an MCP server in 10 seconds and add it to the open source registry: <https://open-mcp.org>\\n* [Data-Everything/mcp-server-templates](https://github.com/Data-Everything/mcp-server-templates)      - One server. All tools. A unified MCP platform that connects many apps, tools, and services behind one powerful interfaceideal for local devs or production agents.\\n* [YangLiangwei/PersonalizationMCP](https://github.com/YangLiangwei/PersonalizationMCP)       - Comprehensive personal data aggregation MCP server with Steam, YouTube, Bilibili, Spotify, Reddit and other platforms integrations. Features OAuth2 authentication, automatic token management, and 90+ tools for gaming, music, video, and social platform data access.\\n\\n###  Aerospace & Astrodynamics\\n\\n* [IO-Aerospace-software-community/mcp-server](https://github.com/IO-Aerospace-software-engineering/mcp-server) # /  - IO Aerospace MCP Server: a .NET-based MCP server for aerospace & astrodynamics  ephemeris, orbital conversions, DSS tools, time conversions, and unit/math utilities. Supports STDIO and SSE transports; Docker and native .NET deployment documented.\\n\\n###  Art & Culture\\n\\nAccess and explore art collections, cultural heritage, and museum databases. Enables AI models to search and analyze artistic and cultural content.\\n\\n* [drakonkat/wizzy-mcp-tmdb](https://github.com/drakonkat/wizzy-mcp-tmdb)   - A MCP server for The Movie Database API that enables AI assistants to search and retrieve movie, TV show, and person information.\\n* [8enSmith/mcp-open-library](https://github.com/8enSmith/mcp-open-library)   - A MCP server for the Open Library API that enables AI assistants to search for book information.\\n* [abhiemj/manim-mcp-server](https://github.com/abhiemj/manim-mcp-server)     - A local MCP server that generates animations using Manim.\\n* [ahujasid/blender-mcp](https://github.com/ahujasid/blender-mcp)  - MCP server for working with Blender\\n* [burningion/video-editing-mcp](https://github.com/burningion/video-editing-mcp)  - Add, Analyze, Search, and Generate Video Edits from your Video Jungle Collection\\n* [cantian-ai/bazi-mcp](https://github.com/cantian-ai/bazi-mcp)      - Provides comprehensive and accurate Bazi (Chinese Astrology) charting and analysis\\n* [cswkim/discogs-mcp-server](https://github.com/cswkim/discogs-mcp-server)   - MCP server to interact with the Discogs API\\n* [diivi/aseprite-mcp](https://github.com/diivi/aseprite-mcp)   - MCP server using the Aseprite API to create pixel art\\n* [djalal/quran-mcp-server](https://github.com/djalal/quran-mcp-server)   MCP server to interact with Quran.com corpus via the official REST API v4.\\n* [raveenb/fal-mcp-server](https://github.com/raveenb/fal-mcp-server)   - Generate AI images, videos, and music using Fal.ai models (FLUX, Stable Diffusion, MusicGen) directly in Claude Desktop\\n* [mikechao/metmuseum-mcp](https://github.com/mikechao/metmuseum-mcp)   - Metropolitan Museum of Art Collection API integration to search and display artworks in the collection.\\n* [OctoEverywhere/mcp](https://github.com/OctoEverywhere/mcp) #  - A 3D printer MCP server that allows for getting live printer state, webcam snapshots, and printer control.\\n* [omni-mcp/isaac-sim-mcp](https://github.com/omni-mcp/isaac-sim-mcp)   - A MCP Server and an extension enables natural language control of NVIDIA Isaac Sim, Lab, OpenUSD and etc.\\n* [PatrickPalmer/MayaMCP](https://github.com/PatrickPalmer/MayaMCP)   - MCP server for Autodesk Maya\\n* [peek-travel/mcp-intro](https://github.com/peek-travel/mcp-intro)     - Remote MCP Server for discovering and planning experiences, at home and on vacation\\n* [r-huijts/oorlogsbronnen-mcp](https://github.com/r-huijts/oorlogsbronnen-mcp)   - Oorlogsbronnen (War Sources) API integration for accessing historical WWII records, photographs, and documents from the Netherlands (1940-1945)\\n* [r-huijts/rijksmuseum-mcp](https://github.com/r-huijts/rijksmuseum-mcp)   - Rijksmuseum API integration for artwork search, details, and collections\\n* [samuelgursky/davinci-resolve-mcp](https://github.com/samuelgursky/davinci-resolve-mcp)  - MCP server integration for DaVinci Resolve providing powerful tools for video editing, color grading, media management, and project control\\n* [yuna0x0/anilist-mcp](https://github.com/yuna0x0/anilist-mcp)   - A MCP server integrating AniList API for anime and manga information\\n\\n### Biology, Medicine and Bioinformatics\\n\\n* [genomoncology/biomcp](https://github.com/genomoncology/biomcp)   - Biomedical research MCP server providing access to PubMed, ClinicalTrials.gov, and MyVariant.info.\\n* [longevity-genie/biothings-mcp](https://github.com/longevity-genie/biothings-mcp)    - MCP server to interact with the BioThings API, including genes, genetic variants, drugs, and taxonomic information.\\n* [longevity-genie/gget-mcp](https://github.com/longevity-genie/gget-mcp)    - MCP server providing a powerful bioinformatics toolkit for genomics queries and analysis, wrapping the popular `gget` library.\\n* [longevity-genie/opengenes-mcp](https://github.com/longevity-genie/opengenes-mcp)     - MCP server for a queryable database for aging and longevity research from the OpenGenes project.\\n* [longevity-genie/synergy-age-mcp](https://github.com/longevity-genie/synergy-age-mcp)     - MCP server for the SynergyAge database of synergistic and antagonistic genetic interactions in longevity.\\n* [the-momentum/fhir-mcp-server](https://github.com/the-momentum/fhir-mcp-server)    - MCP Server that connects AI agents to FHIR servers. One example use case is querying patient history in natural language.\\n* [wso2/fhir-mcp-server](https://github.com/wso2/fhir-mcp-server)    - Model Context Protocol server for Fast Healthcare Interoperability Resources (FHIR) APIs. Provides seamless integration with FHIR servers, enabling AI assistants to search, retrieve, create, update, and analyze clinical healthcare data with SMART-on-FHIR authentication support.\\n* [JamesANZ/medical-mcp](https://github.com/JamesANZ/medical-mcp)   - An MCP server that provides access to medical information, drug databases, and healthcare resources. Enables AI assistants to query medical data, drug interactions, and clinical guidelines.\\n* [the-momentum/apple-health-mcp-server](https://github.com/the-momentum/apple-health-mcp-server)      - An MCP server that provides access to exported data from Apple Health. Data analytics included.\\n* [OHNLP/omop\\\\_mcp](https://github.com/OHNLP/omop_mcp)    - Map clinical terminology to OMOP concepts using LLMs for healthcare data standardization and interoperability.\\n\\n###  Browser Automation\\n\\nWeb content access and automation capabilities. Enables searching, scraping, and processing web content in AI-friendly formats.\\n\\n* [34892002/bilibili-mcp-js](https://github.com/34892002/bilibili-mcp-js)   - A MCP server that supports searching for Bilibili content. Provides LangChain integration examples and test scripts.\\n* [agent-infra/mcp-server-browser](https://github.com/bytedance/UI-TARS-desktop/tree/main/packages/agent-infra/mcp-servers/browser)   - Browser automation capabilities using Puppeteer, both support local and remote browser connection.\\n* [automatalabs/mcp-server-playwright](https://github.com/Automata-Labs-team/MCP-Server-Playwright)  - An MCP server for browser automation using Playwright\\n* [blackwhite084/playwright-plus-python-mcp](https://github.com/blackwhite084/playwright-plus-python-mcp)  - An MCP python server using Playwright for browser automation,more suitable for llm\\n* [browserbase/mcp-server-browserbase](https://github.com/browserbase/mcp-server-browserbase)   - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\\n* [browsermcp/mcp](https://github.com/browsermcp/mcp)   - Automate your local Chrome browser\\n* [co-browser/browser-use-mcp-server](https://github.com/co-browser/browser-use-mcp-server)  - browser-use packaged as an MCP server with SSE transport. includes a dockerfile to run chromium in docker + a vnc server.\\n* [eat-pray-ai/yutu](https://github.com/eat-pray-ai/yutu)      - A fully functional MCP server and CLI for YouTube to automate YouTube operation\\n* [executeautomation/playwright-mcp-server](https://github.com/executeautomation/mcp-playwright)  - An MCP server using Playwright for browser automation and webscrapping\\n* [eyalzh/browser-control-mcp](https://github.com/eyalzh/browser-control-mcp)   - An MCP server paired with a browser extension that enables LLM clients to control the user\\'s browser (Firefox).\\n* [freema/firefox-devtools-mcp](https://github.com/freema/firefox-devtools-mcp)   - Firefox browser automation via WebDriver BiDi for testing, scraping, and browser control. Supports snapshot/UID-based interactions, network monitoring, console capture, and screenshots.\\n* [fradser/mcp-server-apple-reminders](https://github.com/FradSer/mcp-server-apple-reminders)    - An MCP server for interacting with Apple Reminders on macOS\\n* [getrupt/ashra-mcp](https://github.com/getrupt/ashra-mcp)   - Extract structured data from any website. Just prompt and get JSON.\\n* [kimtaeyoon83/mcp-server-youtube-transcript](https://github.com/kimtaeyoon83/mcp-server-youtube-transcript)   - Fetch YouTube subtitles and transcripts for AI analysis\\n* [kimtth/mcp-aoai-web-browsing](https://github.com/kimtth/mcp-aoai-web-browsing)   - A `minimal` server/client MCP implementation using Azure OpenAI and Playwright.\\n* [lightpanda-io/gomcp](https://github.com/lightpanda-io/gomcp)  / / - An MCP server in Go for Lightpanda, the ultra fast headless browser designed for web automation\\n* [microsoft/playwright-mcp](https://github.com/microsoft/playwright-mcp) - Official Microsoft Playwright MCP server, enabling LLMs to interact with web pages through structured accessibility snapshots\\n* [modelcontextprotocol/server-puppeteer](https://github.com/modelcontextprotocol/servers/tree/main/src/puppeteer)   - Browser automation for web scraping and interaction\\n* [ndthanhdev/mcp-browser-kit](https://github.com/ndthanhdev/mcp-browser-kit)   - An MCP Server that enables AI assistants to interact with your local browsers.\\n* [operative\\\\_sh/web-eval-agent](https://github.com/Operative-Sh/web-eval-agent)    - An MCP Server that autonomously debugs web applications with browser-use browser agents\\n* [pskill9/web-search](https://github.com/pskill9/web-search)   - An MCP server that enables free web searching using Google search results, with no API keys required.\\n* [PhungXuanAnh/selenium-mcp-server](https://github.com/PhungXuanAnh/selenium-mcp-server)      - A Model Context Protocol server providing web automation capabilities through Selenium WebDriver\\n* [recursechat/mcp-server-apple-shortcuts](https://github.com/recursechat/mcp-server-apple-shortcuts)    - An MCP Server Integration with Apple Shortcuts\\n* [xspadex/bilibili-mcp](https://github.com/xspadex/bilibili-mcp.git)   - A FastMCP-based tool that fetches Bilibili\\'s trending videos and exposes them via a standard MCP interface.\\n* [imprvhub/mcp-browser-agent](https://github.com/imprvhub/mcp-browser-agent)   - A Model Context Protocol (MCP) integration that provides Claude Desktop with autonomous browser automation capabilities.\\n\\n###  Cloud Platforms\\n\\nCloud platform service integration. Enables management and interaction with cloud infrastructure and services.\\n\\n* [4everland/4everland-hosting-mcp](https://github.com/4everland/4everland-hosting-mcp)      - An MCP server implementation for 4EVERLAND Hosting enabling instant deployment of AI-generated code to decentralized storage networks like Greenfield, IPFS, and Arweave.\\n* [aashari/mcp-server-aws-sso](https://github.com/aashari/mcp-server-aws-sso)    - AWS Single Sign-On (SSO) integration enabling AI systems to securely interact with AWS resources by initiating SSO login, listing accounts/roles, and executing AWS CLI commands using temporary credentials.\\n* [alexbakers/mcp-ipfs](https://github.com/alexbakers/mcp-ipfs)   - upload and manipulation of IPFS storage\\n* [alexei-led/aws-mcp-server](https://github.com/alexei-led/aws-mcp-server)   - A lightweight but powerful server that enables AI assistants to execute AWS CLI commands, use Unix pipes, and apply prompt templates for common AWS tasks in a safe Docker environment with multi-architecture support\\n* [alexei-led/k8s-mcp-server](https://github.com/alexei-led/k8s-mcp-server)  - A lightweight yet robust server that empowers AI assistants to securely execute Kubernetes CLI commands (`kubectl`, `helm`, `istioctl`, and `argocd`) using Unix pipes in a safe Docker environment with multi-architecture support.\\n* [aliyun/alibaba-cloud-ops-mcp-server](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)    - A MCP server that enables AI assistants to operation resources on Alibaba Cloud, supporting ECS, Cloud Monitor, OOS and widely used cloud products.\\n* [awslabs/mcp](https://github.com/awslabs/mcp)   - AWS MCP servers for seamless integration with AWS services and resources.\\n* [bright8192/esxi-mcp-server](https://github.com/bright8192/esxi-mcp-server)   - A VMware ESXi/vCenter management server based on MCP (Model Control Protocol), providing simple REST API interfaces for virtual machine management.\\n* [cloudflare/mcp-server-cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)    - Integration with Cloudflare services including Workers, KV, R2, and D1\\n* [cyclops-ui/mcp-cyclops](https://github.com/cyclops-ui/mcp-cyclops)    - An MCP server that allows AI agents to manage Kubernetes resources through Cyclops abstraction\\n* [elementfm/mcp](https://gitlab.com/elementfm/mcp)      - Open source podcast hosting platform\\n* [erikhoward/adls-mcp-server](https://github.com/erikhoward/adls-mcp-server)  / - MCP Server for Azure Data Lake Storage. It can perform manage containers, read/write/upload/download operations on container files and manage file metadata.\\n* [espressif/esp-rainmaker-mcp](https://github.com/espressif/esp-rainmaker-mcp)      - Official Espressif MCP Server to manage and control ESP RainMaker Devices.\\n* [flux159/mcp-server-kubernetes](https://github.com/Flux159/mcp-server-kubernetes)  / - Typescript implementation of Kubernetes cluster operations for pods, deployments, services.\\n* [hardik-id/azure-resource-graph-mcp-server](https://github.com/hardik-id/azure-resource-graph-mcp-server)  / - A Model Context Protocol server for querying and analyzing Azure resources at scale using Azure Resource Graph, enabling AI assistants to explore and monitor Azure infrastructure.\\n* [jdubois/azure-cli-mcp](https://github.com/jdubois/azure-cli-mcp) - A wrapper around the Azure CLI command line that allows you to talk directly to Azure\\n* [johnneerdael/netskope-mcp](https://github.com/johnneerdael/netskope-mcp)   - An MCP to give access to all Netskope Private Access components within a Netskope Private Access environments including detailed setup information and LLM examples on usage.\\n* [kestra-io/mcp-server-python](https://github.com/kestra-io/mcp-server-python)   - Implementation of MCP server for [Kestra](https://kestra.io) workflow orchestration platform.\\n* [liveblocks/liveblocks-mcp-server](https://github.com/liveblocks/liveblocks-mcp-server)    - Create, modify, and delete different aspects of [Liveblocks](https://liveblocks.io) such as rooms, threads, comments, notifications, and more. Additionally, it has read access to Storage and Yjs.\\n* [manusa/Kubernetes MCP Server](https://github.com/manusa/kubernetes-mcp-server)   A - powerful Kubernetes MCP server with additional support for OpenShift. Besides providing CRUD operations for **any** Kubernetes resource, this server provides specialized tools to interact with your cluster.\\n* [Nebula-Block-Data/nebulablock-mcp-server](https://github.com/Nebula-Block-Data/nebulablock-mcp-server)   - integrates with the fastmcp library to expose the full range of NebulaBlock API functionalities as accessible tools\\n* [nwiizo/tfmcp](https://github.com/nwiizo/tfmcp) -   - A Terraform MCP server allowing AI assistants to manage and operate Terraform environments, enabling reading configurations, analyzing plans, applying configurations, and managing Terraform state.\\n* [openstack-kr/python-openstackmcp-server](https://github.com/openstack-kr/python-openstackmcp-server)   - OpenStack MCP server for cloud infrastructure management based on openstacksdk.\\n* [pibblokto/cert-manager-mcp-server](https://github.com/pibblokto/cert-manager-mcp-server)  /  - mcp server for [cert-manager](https://github.com/cert-manager/cert-manager) management and troubleshooting\\n* [portainer/portainer-mcp](https://github.com/portainer/portainer-mcp)  / - A powerful MCP server that enables AI assistants to seamlessly interact with Portainer instances, providing natural language access to container management, deployment operations, and infrastructure monitoring capabilities.\\n* [pulumi/mcp-server](https://github.com/pulumi/mcp-server)    - MCP server for interacting with Pulumi using the Pulumi Automation API and Pulumi Cloud API. Enables MCP clients to perform Pulumi operations like retrieving package information, previewing changes, deploying updates, and retrieving stack outputs programmatically.\\n* [pythonanywhere/pythonanywhere-mcp-server](https://github.com/pythonanywhere/pythonanywhere-mcp-server)   - MCP server implementation for PythonAnywhere cloud platform.\\n* [qiniu/qiniu-mcp-server](https://github.com/qiniu/qiniu-mcp-server)   - A MCP built on Qiniu Cloud products, supporting access to Qiniu Cloud Storage, media processing services, etc.\\n* [redis/mcp-redis-cloud](https://github.com/redis/mcp-redis-cloud)   - Manage your Redis Cloud resources effortlessly using natural language. Create databases, monitor subscriptions, and configure cloud deployments with simple commands.\\n* [reza-gholizade/k8s-mcp-server](https://github.com/reza-gholizade/k8s-mcp-server)  / - A Kubernetes Model Context Protocol (MCP) server that provides tools for interacting with Kubernetes clusters through a standardized interface, including API resource discovery, resource management, pod logs, metrics, and events.\\n* [rohitg00/kubectl-mcp-server](https://github.com/rohitg00/kubectl-mcp-server)  / - A Model Context Protocol (MCP) server for Kubernetes that enables AI assistants like Claude, Cursor, and others to interact with Kubernetes clusters through natural language.\\n* [rrmistry/tilt-mcp](https://github.com/rrmistry/tilt-mcp)      - A Model Context Protocol server that integrates with Tilt to\\n\\n--------------------------------------------------------------------------------\\n'}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='MCP vs. Google Agent-to-Agent (A2A) Protocol', description='Introduces Googles A2A protocol and provides a focused comparison with MCP across architecture, standardization, interoperability, and use-case fit, highlighting when developers might choose one over the other.', research=True, content='## MCP vs. Google Agent-to-Agent (A2A) Protocol  \\n\\nGoogles A2A protocol lets autonomous agents talk as peers. It rides on familiar web techHTTP(S) plus JSON-RPC or gRPC, optional Server-Sent Eventsand adds Agent Cards for capability discovery and a task lifecycle that supports streaming updates and long-running work [1]. The design assumes each agent hides its internals yet must negotiate formats, share artifacts, and update status securely across company boundaries.  \\n\\nMCP tackles a different layer. It standardizes how one model or agent invokes **tools**APIs, databases, file systemsthrough typed schemas that feel like function calls, giving the model a single, structured port to external resources [2]. Think of MCP as tool wiring, not peer dialogue.  \\n\\nComparison:  \\n ArchitectureA2A = agent-to-agent, stateful conversation; MCP = agent-to-tool, stateless calls.  \\n StandardizationA2A defines discovery, security, and task states; MCP defines JSON schemas for tool inputs/outputs.  \\n InteroperabilityA2A bridges agents from any vendor; MCP solves the N  M problem of models versus APIs.  \\n\\nChoose MCP when one LLM needs safe, repeatable access to internal systems. Choose A2A when several specialized agents must divide work, stream progress, and present a unified answeroften using MCP internally for their own tool calls [3].  \\n\\n### Sources  \\n[1] Agent2Agent Protocol Official Specification: https://a2a-protocol.org/latest/specification/  \\n[2] A2A  MCP: Complementary Protocols for Agentic Systems: https://a2a-protocol.org/latest/topics/a2a-and-mcp/  \\n[3] MCP vs. A2A  Descope Blog: https://www.descope.com/blog/post/mcp-vs-a2a')], 'source_str': 'Search results: \\n\\n\\n\\n--- SOURCE 1: Specification - A2A Protocol ---\\nURL: https://a2a-protocol.org/latest/specification/\\n\\nSUMMARY:\\nThe Agent2Agent (A2A) Protocol is an open standard designed to facilitate communication and interoperability between independent, potentially opaque AI agent\\n\\nFULL CONTENT:\\n[Skip to content](https://a2a-protocol.org/latest/specification/#agent2agent-a2a-protocol-official-specification)\\n\\n\\n\\n# Agent2Agent (A2A) Protocol Official Specification[](https://a2a-protocol.org/latest/specification/#agent2agent-a2a-protocol-official-specification \"Permanent link\")\\n\\n**Version:** [`0.3.0`](https://github.com/a2aproject/A2A/releases/tag/v0.3.0)\\n\\nSee [Release Notes](https://github.com/a2aproject/A2A/releases) for changes made between versions.\\n\\n## 1. Introduction[](https://a2a-protocol.org/latest/specification/#1-introduction \"Permanent link\")\\n\\nThe Agent2Agent (A2A) Protocol is an open standard designed to facilitate communication and interoperability between independent, potentially opaque AI agent systems. In an ecosystem where agents might be built using different frameworks, languages, or by different vendors, A2A provides a common language and interaction model.\\n\\nThis document provides the detailed technical specification for the A2A protocol. Its primary goal is to enable agents to:\\n\\n* Discover each other\\'s capabilities.\\n* Negotiate interaction modalities (text, files, structured data).\\n* Manage collaborative tasks.\\n* Securely exchange information to achieve user goals **without needing access to each other\\'s internal state, memory, or tools.**\\n\\n### 1.1. Key Goals of A2A[](https://a2a-protocol.org/latest/specification/#11-key-goals-of-a2a \"Permanent link\")\\n\\n* **Interoperability:** Bridge the communication gap between disparate agentic systems.\\n* **Collaboration:** Enable agents to delegate tasks, exchange context, and work together on complex user requests.\\n* **Discovery:** Allow agents to dynamically find and understand the capabilities of other agents.\\n* **Flexibility:** Support various interaction modes including synchronous request/response, streaming for real-time updates, and asynchronous push notifications for long-running tasks.\\n* **Security:** Facilitate secure communication patterns suitable for enterprise environments, relying on standard web security practices.\\n* **Asynchronicity:** Natively support long-running tasks and interactions that may involve human-in-the-loop scenarios.\\n\\n### 1.2. Guiding Principles[](https://a2a-protocol.org/latest/specification/#12-guiding-principles \"Permanent link\")\\n\\n* **Simple:** Reuse existing, well-understood standards (HTTP, JSON-RPC 2.0, Server-Sent Events).\\n* **Enterprise Ready:** Address authentication, authorization, security, privacy, tracing, and monitoring by aligning with established enterprise practices.\\n* **Async First:** Designed for (potentially very) long-running tasks and human-in-the-loop interactions.\\n* **Modality Agnostic:** Support exchange of diverse content types including text, audio/video (via file references), structured data/forms, and potentially embedded UI components (e.g., iframes referenced in parts).\\n* **Opaque Execution:** Agents collaborate based on declared capabilities and exchanged information, without needing to share their internal thoughts, plans, or tool implementations.\\n\\nFor a broader understanding of A2A\\'s purpose and benefits, see [What is A2A?](https://a2a-protocol.org/latest/topics/what-is-a2a/).\\n\\n## 2. Core Concepts Summary[](https://a2a-protocol.org/latest/specification/#2-core-concepts-summary \"Permanent link\")\\n\\nA2A revolves around several key concepts. For detailed explanations, please refer to the [Key Concepts guide](https://a2a-protocol.org/latest/topics/key-concepts/).\\n\\n* **A2A Client:** An application or agent that initiates requests to an A2A Server on behalf of a user or another system.\\n* **A2A Server (Remote Agent):** An agent or agentic system that exposes an A2A-compliant HTTP endpoint, processing tasks and providing responses.\\n* **Agent Card:** A JSON metadata document published by an A2A Server, describing its identity, capabilities, skills, service endpoint, and authentication requirements.\\n* **Message:** A communication turn between a client and a remote agent, having a `role` (\"user\" or \"agent\") and containing one or more `Parts`.\\n* **Task:** The fundamental unit of work managed by A2A, identified by a unique ID. Tasks are stateful and progress through a defined lifecycle.\\n* **Part:** The smallest unit of content within a Message or Artifact (e.g., `TextPart`, `FilePart`, `DataPart`).\\n* **Artifact:** An output (e.g., a document, image, structured data) generated by the agent as a result of a task, composed of `Parts`.\\n* **Streaming (SSE):** Real-time, incremental updates for tasks (status changes, artifact chunks) delivered via Server-Sent Events.\\n* **Push Notifications:** Asynchronous task updates delivered via server-initiated HTTP POST requests to a client-provided webhook URL, for long-running or disconnected scenarios.\\n* **Context:** An optional, server-generated identifier to logically group related tasks.\\n* **Extension:** A mechanism for agents to provide additional functionality or data beyond the core A2A specification.\\n\\n## 3. Transport and Format[](https://a2a-protocol.org/latest/specification/#3-transport-and-format \"Permanent link\")\\n\\n### 3.1. Transport Layer Requirements[](https://a2a-protocol.org/latest/specification/#31-transport-layer-requirements \"Permanent link\")\\n\\nA2A supports multiple transport protocols, all operating over **HTTP(S)**. Agents have flexibility in choosing which transport protocols to implement based on their specific requirements and use cases:\\n\\n* A2A communication **MUST** occur over **HTTP(S)**.\\n* The A2A Server exposes its service at one or more URLs defined in its `AgentCard`.\\n* Agents **MUST** implement at least one of the three core transport protocols defined in this specification.\\n* All supported transport protocols are considered equal in status and capability.\\n\\n### 3.2. Supported Transport Protocols[](https://a2a-protocol.org/latest/specification/#32-supported-transport-protocols \"Permanent link\")\\n\\nA2A defines three core transport protocols. **A2A-compliant agents SHOULD implement at least one of these transport protocols. They MAY be compliant implementing a transport extension as defined in [3.2.4](https://a2a-protocol.org/latest/specification/#324-transport-extensions)** All three protocols are considered equal in status, and agents may choose to implement any combination of them based on their requirements.\\n\\n#### 3.2.1. JSON-RPC 2.0 Transport[](https://a2a-protocol.org/latest/specification/#321-json-rpc-20-transport \"Permanent link\")\\n\\nAgents **MAY** support JSON-RPC 2.0 transport. If implemented, it **MUST** conform to these requirements:\\n\\n* The primary data format is **[JSON-RPC 2.0](https://www.jsonrpc.org/specification)** for all requests and responses (excluding SSE stream wrapper).\\n* Client requests and server responses **MUST** adhere to the JSON-RPC 2.0 specification.\\n* The `Content-Type` header for HTTP requests and responses containing JSON-RPC payloads **MUST** be `application/json`.\\n* Method names follow the pattern `{category}/{action}` (e.g., `\"message/send\"`, `\"tasks/get\"`).\\n\\n#### 3.2.2. gRPC Transport[](https://a2a-protocol.org/latest/specification/#322-grpc-transport \"Permanent link\")\\n\\nAgents **MAY** support gRPC transport. If implemented, it **MUST** conform to these requirements:\\n\\n* **Protocol Definition**: **MUST** use the normative Protocol Buffers definition in [`specification/grpc/a2a.proto`](https://github.com/a2aproject/A2A/blob/main/specification/grpc/a2a.proto).\\n* **Message Serialization**: **MUST** use Protocol Buffers version 3 for message serialization.\\n* **Service Definition**: **MUST** implement the `A2AService` gRPC service as defined in the proto file.\\n* **Method Coverage**: **MUST** provide all methods with functionally equivalent behavior to other supported transports.\\n* **Field Mapping**: **MUST** use the `json_name` annotations for HTTP/JSON transcoding compatibility.\\n* **Error Handling**: **MUST** map A2A error codes to appropriate gRPC status codes as defined in the proto annotations.\\n* **Transport Security**: **MUST** support TLS encryption (gRPC over HTTP/2 with TLS).\\n\\n#### 3.2.3. HTTP+JSON/REST Transport[](https://a2a-protocol.org/latest/specification/#323-httpjsonrest-transport \"Permanent link\")\\n\\nAgents **MAY** support REST-style HTTP+JSON transport. If implemented, it **MUST** conform to these requirements:\\n\\n* **HTTP Methods**: **MUST** use appropriate HTTP verbs (GET for queries, POST for actions, PUT for updates, DELETE for removal).\\n* **URL Patterns**: **MUST** follow the URL patterns documented in each method section (e.g., `/v1/message:send`, `/v1/tasks/{id}`).\\n* **Content-Type**: **MUST** use `application/json` for request and response bodies.\\n* **HTTP Status Codes**: **MUST** use appropriate HTTP status codes (200, 400, 401, 403, 404, 500, etc.) that correspond to A2A error types.\\n* **Request/Response Format**: **MUST** use JSON objects that are structurally equivalent to the core A2A data structures.\\n* **Method Coverage**: **MUST** provide all methods with functionally equivalent behavior to other supported transports.\\n* **Error Format**: **MUST** return error responses in a consistent JSON format that maps to A2A error types.\\n\\n#### 3.2.4. Transport Extensions[](https://a2a-protocol.org/latest/specification/#324-transport-extensions \"Permanent link\")\\n\\nAdditional transport protocols **MAY** be defined as extensions to the core A2A specification. Such extensions:\\n\\n* **MUST** maintain functional equivalence with the core transports\\n* **MUST** use clear namespace identifiers to avoid conflicts\\n* **MUST** be clearly documented and specified\\n* **SHOULD** provide migration paths from core transports\\n\\n### 3.3. Streaming Transport (Server-Sent Events)[](https://a2a-protocol.org/latest/specification/#33-streaming-transport-server-sent-events \"Permanent link\")\\n\\nStreaming capabilities are **transport-specific**:\\n\\n#### 3.3.1. JSON-RPC 2.0 Streaming[](https://a2a-protocol.org/latest/specification/#331-json-rpc-20-streaming \"Permanent link\")\\n\\nWhen streaming is used for methods like `message/stream` or `tasks/resubscribe`:\\n\\n* The server responds with an HTTP `200 OK` status and a `Content-Type` header of `text/event-stream`.\\n* The body of this HTTP response contains a stream of **[Server-Sent Events (SSE)](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events)** as defined by the W3C.\\n* Each SSE `data` field contains a complete JSON-RPC 2.0 Response object (specifically, a [`SendStreamingMessageResponse`](https://a2a-protocol.org/latest/specification/#721-sendstreamingmessageresponse-object)).\\n\\n#### 3.3.2. gRPC Streaming[](https://a2a-protocol.org/latest/specification/#332-grpc-streaming \"Permanent link\")\\n\\ngRPC transport uses **server streaming RPCs** for streaming operations as defined in the Protocol Buffers specification.\\n\\n#### 3.3.3. HTTP+JSON/REST Streaming[](https://a2a-protocol.org/latest/specification/#333-httpjsonrest-streaming \"Permanent link\")\\n\\nIf REST transport is supported it **MUST** implement streaming using Server-Sent Events similar to JSON-RPC.\\n\\n### 3.4. Transport Compliance and Interoperability[](https://a2a-protocol.org/latest/specification/#34-transport-compliance-and-interoperability \"Permanent link\")\\n\\n#### 3.4.1. Functional Equivalence Requirements[](https://a2a-protocol.org/latest/specification/#341-functional-equivalence-requirements \"Permanent link\")\\n\\nWhen an agent supports multiple transports, all supported transports **MUST**:\\n\\n* **Identical Functionality**: Provide the same set of operations and capabilities.\\n* **Consistent Behavior**: Return semantically equivalent results for the same requests.\\n* **Same Error Handling**: Map errors consistently across transports using the error codes defined in [Section 8](https://a2a-protocol.org/latest/specification/#8-error-handling).\\n* **Equivalent Authentication**: Support the same authentication schemes declared in the `AgentCard`.\\n\\n#### 3.4.2. Transport Selection and Negotiation[](https://a2a-protocol.org/latest/specification/#342-transport-selection-and-negotiation \"Permanent link\")\\n\\n* **Agent Declaration**: Agents **MUST** declare all supported transports in their `AgentCard` using the `preferredTransport` and `additionalInterfaces` fields.\\n* **Client Choice**: Clients **MAY** choose any transport declared by the agent.\\n* **No Transport Negotiation**: A2A does not define a dynamic transport negotiation protocol. Clients select a transport based on the static `AgentCard` information.\\n* **Fallback Behavior**: Clients **SHOULD** implement fallback logic to try alternative transports if their preferred transport fails. The specific fallback strategy is implementation-dependent.\\n\\n#### 3.4.3. Transport-Specific Extensions[](https://a2a-protocol.org/latest/specification/#343-transport-specific-extensions \"Permanent link\")\\n\\nTransports **MAY** provide transport-specific optimizations or extensions that do not compromise functional equivalence:\\n\\n* **gRPC**: May leverage gRPC-specific features like bidirectional streaming, metadata, or custom status codes.\\n* **REST**: May provide additional HTTP caching headers or support HTTP conditional requests.\\n* **JSON-RPC**: May include additional fields in the JSON-RPC request/response objects that do not conflict with the core specification.\\n\\nSuch extensions **MUST** be backward-compatible and **MUST NOT** break interoperability with clients that do not support the extensions.\\n\\n### 3.5. Method Mapping and Naming Conventions[](https://a2a-protocol.org/latest/specification/#35-method-mapping-and-naming-conventions \"Permanent link\")\\n\\nTo ensure consistency and predictability across different transports, A2A defines normative method mapping rules.\\n\\n#### 3.5.1. JSON-RPC Method Naming[](https://a2a-protocol.org/latest/specification/#351-json-rpc-method-naming \"Permanent link\")\\n\\nJSON-RPC methods **MUST** follow the pattern: `{category}/{action}` where:\\n\\n* `category` represents the resource type (e.g., \"message\", \"tasks\", \"agent\")\\n* `action` represents the operation (e.g., \"send\", \"get\", \"cancel\")\\n* Nested actions use forward slashes (e.g., \"tasks/pushNotificationConfig/set\")\\n\\n#### 3.5.2. gRPC Method Naming[](https://a2a-protocol.org/latest/specification/#352-grpc-method-naming \"Permanent link\")\\n\\ngRPC methods **MUST** follow Protocol Buffers service conventions using PascalCase:\\n\\n* Convert JSON-RPC category/action to PascalCase compound words\\n* Use standard gRPC method prefixes (Get, Set, List, Create, Delete, Cancel)\\n\\n#### 3.5.3. HTTP+JSON/REST Method Naming[](https://a2a-protocol.org/latest/specification/#353-httpjsonrest-method-naming \"Permanent link\")\\n\\nREST endpoints **MUST** follow RESTful URL patterns with appropriate HTTP verbs:\\n\\n* Use resource-based URLs: `/v1/{resource}[/{id}][:{action}]`\\n* Use standard HTTP methods aligned with REST semantics\\n* Use colon notation for non-CRUD actions\\n\\n#### 3.5.4. Method Mapping Compliance[](https://a2a-protocol.org/latest/specification/#354-method-mapping-compliance \"Permanent link\")\\n\\nWhen implementing multiple transports, agents **MUST**:\\n\\n* **Use standard mappings**: Follow the method mappings defined in sections 3.5.2 and 3.5.3.\\n* **Maintain functional equivalence**: Each transport-specific method **MUST** provide identical functionality across all supported transports.\\n* **Consistent parameters**: Use equivalent parameter structures across transports (accounting for transport-specific serialization differences).\\n* **Equivalent responses**: Return semantically equivalent responses across all transports for the same operation.\\n\\n#### 3.5.5. Extension Method Naming[](https://a2a-protocol.org/latest/specification/#355-extension-method-naming \"Permanent link\")\\n\\nFor custom or extension methods not defined in the core A2A specification:\\n\\n* **JSON-RPC**: Follow the `{category}/{action}` pattern with a clear namespace (e.g., `myorg.extension/action`)\\n* **gRPC**: Use appropriate service and method names following Protocol Buffers conventions\\n* **REST**: Use clear resource-based URLs with appropriate HTTP methods\\n\\nExtension methods **MUST** be clearly documented and **MUST NOT** conflict with core A2A method names or semantics.\\n\\n#### 3.5.6. Method Mapping Reference Table[](https://a2a-protocol.org/latest/specification/#356-method-mapping-reference-table \"Permanent link\")\\n\\nFor quick reference, the following table summarizes the method mappings across all transports:\\n\\n| JSON-RPC Method | gRPC Method | REST Endpoint | Description |\\n| --- | --- | --- | --- |\\n| `message/send` | `SendMessage` | `POST /v1/message:send` | Send message to agent |\\n| `message/stream` | `SendStreamingMessage` | `POST /v1/message:stream` | Send message with streaming |\\n| `tasks/get` | `GetTask` | `GET /v1/tasks/{id}` | Get task status |\\n| `tasks/list` | `ListTask` | `GET /v1/tasks` | List tasks (gRPC/REST only) |\\n| `tasks/cancel` | `CancelTask` | `POST /v1/tasks/{id}:cancel` | Cancel task |\\n| `tasks/resubscribe` | `TaskSubscription` | `POST /v1/tasks/{id}:subscribe` | Resume task streaming |\\n| `tasks/pushNotificationConfig/set` | `CreateTaskPushNotification` | `POST /v1/tasks/{id}/pushNotificationConfigs` | Set push notification config |\\n| `tasks/pushNotificationConfig/get` | `GetTaskPushNotification` | `GET /v1/tasks/{id}/pushNotificationConfigs/{configId}` | Get push notification config |\\n| `tasks/pushNotificationConfig/list` | `ListTaskPushNotification` | `GET /v1/tasks/{id}/pushNotificationConfigs` | List push notification configs |\\n| `tasks/pushNotificationConfig/delete` | `DeleteTaskPushNotification` | `DELETE /v1/tasks/{id}/pushNotificationConfigs/{configId}` | Delete push notification config |\\n| `agent/getAuthenticatedExtendedCard` | `GetAgentCard` | `GET /v1/card` | Get authenticated agent card |\\n\\n## 4. Authentication and Authorization[](https://a2a-protocol.org/latest/specification/#4-authentication-and-authorization \"Permanent link\")\\n\\nA2A treats agents as standard enterprise applications, relying on established web security practices. Identity information is **not** transmitted within A2A JSON-RPC payloads; it is handled at the HTTP transport layer.\\n\\nFor a comprehensive guide on enterprise security aspects, see [Enterprise-Ready Features](https://a2a-protocol.org/latest/topics/enterprise-ready/).\\n\\n### 4.1. Transport Security[](https://a2a-protocol.org/latest/specification/#41-transport-security \"Permanent link\")\\n\\nAs stated in section 3.1, production deployments **MUST** use HTTPS. Implementations **SHOULD** use modern [TLS](https://datatracker.ietf.org/doc/html/rfc8446) configurations (TLS 1.3+ recommended) with strong cipher suites.\\n\\n### 4.2. Server Identity Verification[](https://a2a-protocol.org/latest/specification/#42-server-identity-verification \"Permanent link\")\\n\\nA2A Clients **SHOULD** verify the A2A Server\\'s identity by validating its TLS certificate against trusted certificate authorities (CAs) during the TLS handshake.\\n\\n### 4.3. Client/User Identity & Authentication Process[](https://a2a-protocol.org/latest/specification/#43-clientuser-identity-authentication-process \"Permanent link\")\\n\\n1. **Discovery of Requirements:** The client discovers the server\\'s required authentication schemes via the `authentication` field in the [`AgentCard`](https://a2a-protocol.org/latest/specification/#55-agentcard-object-structure). Scheme names often align with [OpenAPI Authentication methods](https://swagger.io/docs/specification/authentication/) (e.g., \"Bearer\" for OAuth 2.0 tokens, \"Basic\" for Basic Auth, \"ApiKey\" for API keys).\\n2. **Credential Acquisition (Out-of-Band):** The client obtains the necessary credentials (e.g., API keys, OAuth tokens, JWTs) through an **out-of-band process** specific to the required authentication scheme and the identity provider. This process is outside the scope of the A2A protocol itself.\\n3. **Credential Transmission:** The client includes these credentials in the appropriate [HTTP headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers) (e.g., `Authorization: Bearer <token>`, `X-API-Key: <value>`) of every A2A request sent to the server.\\n\\n### 4.4. Server Responsibilities for Authentication[](https://a2a-protocol.org/latest/specification/#44-server-responsibilities-for-authentication \"Permanent link\")\\n\\nThe A2A Server:\\n\\n* **MUST** authenticate every incoming request based on the provided HTTP credentials and its declared authentication requirements from its Agent Card.\\n* **SHOULD** use standard HTTP status codes like [`401 Unauthorized`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401) or [`403 Forbidden`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403) for authentication challenges or rejections.\\n* **SHOULD** include relevant HTTP headers (e.g., [`WWW-Authenticate`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/WWW-Authenticate)) with `401 Unauthorized` responses to indicate the required authentication scheme(s), guiding the client.\\n* **SHOULD** verify the Client\\'s webhook server identity by validating its TLS certificate against trusted certificate authorities (CAs) during the TLS handshake.\\n\\n### 4.5. In-Task Authentication (Secondary Credentials)[](https://a2a-protocol.org/latest/specification/#45-in-task-authentication-secondary-credentials \"Permanent link\")\\n\\nIf an agent, during the execution of a task, requires *additional* credentials for a *different* system or resource (e.g., to access a specific tool on behalf of the user that requires its own auth):\\n\\n1. It **SHOULD** transition the A2A task to the `auth-required` state (see [`TaskState`](https://a2a-protocol.org/latest/specification/#63-taskstate-enum)).\\n2. The accompanying `TaskStatus.message` (often a [`DataPart`](https://a2a-protocol.org/latest/specification/#653-datapart-object)) **SHOULD** provide details about the required secondary authentication, potentially using an [`PushNotificationAuthenticationInfo`](https://a2a-protocol.org/latest/specification/#69-pushnotificationauthenticationinfo-object)-like structure to describe the need.\\n3. The A2A Client then obtains these new credentials out-of-band and provides them in a subsequent [`message/send`](https://a2a-protocol.org/latest/specification/#71-messagesend) or [`message/stream`](https://a2a-protocol.org/latest/specification/#72-messagestream) request. How these credentials are used (e.g., passed as data within the A2A message if the agent is proxying, or used by the client to interact directly with the secondary system) depends on the specific scenario.\\n\\n### 4.6. Authorization[](https://a2a-protocol.org/latest/specification/#46-authorization \"Permanent link\")\\n\\nOnce a client is authenticated, the A2A Server is responsible for authorizing the request based on the authenticated client/user identity and its own policies. Authorization logic is implementation-specific and MAY be enforced based on:\\n\\n* The specific skills requested (e.g., as identified by `AgentSkill.id` from the Agent Card).\\n* The actions attempted within the task.\\n* Data access policies relevant to the resources the agent manages.\\n* OAuth scopes associated with the presented token, if applicable.\\n\\nServers should implement the principle of least privilege.\\n\\n## 5. Agent Discovery: The Agent Card[](https://a2a-protocol.org/latest/specification/#5-agent-discovery-the-agent-card \"Permanent link\")\\n\\n### 5.1. Purpose[](https://a2a-protocol.org/latest/specification/#51-purpose \"Permanent link\")\\n\\nA2A Servers **MUST** make an Agent Card available. The Agent Card is a JSON document that describes the server\\'s identity, capabilities, skills, service endpoint URL, and how clients should authenticate and interact with it. Clients use this information for discovering suitable agents and for configuring their interactions.\\n\\nFor more on discovery strategies, see the [Agent Discovery guide](https://a2a-protocol.org/latest/topics/agent-discovery/).\\n\\n### 5.2. Discovery Mechanisms[](https://a2a-protocol.org/latest/specification/#52-discovery-mechanisms \"Permanent link\")\\n\\nClients can find Agent Cards through various methods, including but not limited to:\\n\\n* **Well-Known URI:** Accessing a predefined path on the agent\\'s domain (see [Section 5.3](https://a2a-protocol.org/latest/specification/#53-recommended-location)).\\n* **Registries/Catalogs:** Querying curated catalogs or registries of agents (which might be enterprise-specific, public, or domain-specific).\\n* **Direct Configuration:** Clients may be pre-configured with the Agent Card URL or the card content itself.\\n\\n### 5.3. Recommended Location[](https://a2a-protocol.org/latest/specification/#53-recommended-location \"Permanent link\")\\n\\nIf using the well-known URI strategy, the recommended location for an agent\\'s Agent Card is:\\n`https://{server_domain}/.well-known/agent-card.json`\\nThis follows the principles of [RFC 8615](https://datatracker.ietf.org/doc/html/rfc8615) for well-known URIs.\\n\\n### 5.4. Security of Agent Cards[](https://a2a-protocol.org/latest/specification/#54-security-of-agent-cards \"Permanent link\")\\n\\nAgent Cards themselves might contain information that is considered sensitive.\\n\\n* If an Agent Card contains sensitive information, the endpoint serving the card **MUST** be protected by appropriate access controls (e.g., mTLS, network restrictions, authentication required to fetch the card).\\n* It is generally **NOT RECOMMENDED** to include plaintext secrets (like static API keys) directly in an Agent Card. Prefer authentication schemes where clients obtain dynamic credentials out-of-band.\\n\\n### 5.5. `AgentCard` Object Structure[](https://a2a-protocol.org/latest/specification/#55-agentcard-object-structure \"Permanent link\")\\n\\n```\\n/**\\n * The AgentCard is a self-describing manifest for an agent. It provides essential\\n * metadata including the agent\\'s identity, capabilities, skills, supported\\n * communication methods, and security requirements.\\n */\\nexport interface AgentCard {\\n  /**\\n   * The version of the A2A protocol this agent supports.\\n   * @default \"0.3.0\"\\n   */\\n  protocolVersion: string;\\n  /**\\n   * A human-readable name for the agent.\\n   *\\n   * @TJS-examples [\"Recipe Agent\"]\\n   */\\n  name: string;\\n  /**\\n   * A human-readable description of the agent, assisting users and other agents\\n   * in understanding its purpose.\\n   *\\n   * @TJS-examples [\"Agent that helps users with recipes and cooking.\"]\\n   */\\n  description: string;\\n  /**\\n   * The preferred endpoint URL for interacting with the agent.\\n   * This URL MUST support the transport specified by \\'preferredTransport\\'.\\n   *\\n   * @TJS-examples [\"https://api.example.com/a2a/v1\"]\\n   */\\n  url: string;\\n  /**\\n   * The transport protocol for the preferred endpoint (the main \\'url\\' field).\\n   * If not specified, defaults to \\'JSONRPC\\'.\\n   *\\n   * IMPORTANT: The transport specified here MUST be available at the main \\'url\\'.\\n   * This creates a binding between the main URL and its supported transport protocol.\\n   * Clients should prefer this transport and URL combination when both are supported.\\n   *\\n   * @default \"JSONRPC\"\\n   * @TJS-examples [\"JSONRPC\", \"GRPC\", \"HTTP+JSON\"]\\n   */\\n  preferredTransport?: TransportProtocol | string;\\n  /**\\n   * A list of additional supported interfaces (transport and URL combinations).\\n   * This allows agents to expose multiple transports, potentially at different URLs.\\n   *\\n   * Best practices:\\n   * - SHOULD include all supported transports for completeness\\n   * - SHOULD include an entry matching the main \\'url\\' and \\'preferredTransport\\'\\n   * - MAY reuse URLs if multiple transports are available at the same endpoint\\n   * - MUST accurately declare the transport available at each URL\\n   *\\n   * Clients can select any interface from this list based on their transport capabilities\\n   * and preferences. This enables transport negotiation and fallback scenarios.\\n   */\\n  additionalInterfaces?: AgentInterface[];\\n  /** An optional URL to an icon for the agent. */\\n  iconUrl?: string;\\n  /** Information about the agent\\'s service provider. */\\n  provider?: AgentProvider;\\n  /**\\n   * The agent\\'s own version number. The format is defined by the provider.\\n   *\\n   * @TJS-examples [\"1.0.0\"]\\n   */\\n  version: string;\\n  /** An optional URL to the agent\\'s documentation. */\\n  documentationUrl?: string;\\n  /** A declaration of optional capabilities supported by the agent. */\\n  capabilities: AgentCapabilities;\\n  /**\\n   * A declaration of the security schemes available to authorize requests. The key is the\\n   * scheme name. Follows the OpenAPI 3.0 Security Scheme Object.\\n   */\\n  securitySchemes?: { [scheme: string]: SecurityScheme };\\n  /**\\n   * A list of security requirement objects that apply to all agent interactions. Each object\\n   * lists security schemes that can be used. Follows the OpenAPI 3.0 Security Requirement Object.\\n   * This list can be seen as an OR of ANDs. Each object in the list describes one possible\\n   * set of security requirements that must be present on a request. This allows specifying,\\n   * for example, \"callers must either use OAuth OR an API Key AND mTLS.\"\\n   *\\n   * @TJS-examples [[{\"oauth\": [\"read\"]}, {\"api-key\": [], \"mtls\": []}]]\\n   */\\n  security?: { [scheme: string]: string[] }[];\\n  /**\\n   * Default set of supported input MIME types for all skills, which can be\\n   * overridden on a per-skill basis.\\n   */\\n  defaultInputModes: string[];\\n  /**\\n   * Default set of supported output MIME types for all skills, which can be\\n   * overridden on a per-skill basis.\\n   */\\n  defaultOutputModes: string[];\\n  /** The set of skills, or distinct capabilities, that the agent can perform. */\\n  skills: AgentSkill[];\\n  /**\\n   * If true, the agent can provide an extended agent card with additional details\\n   * to authenticated users. Defaults to false.\\n   */\\n  supportsAuthenticatedExtendedCard?: boolean;\\n  /** JSON Web Signatures computed for this AgentCard. */\\n  signatures?: AgentCardSignature[];\\n}\\n\\n```\\n\\n```\\n// AgentCard conveys key information:\\n// - Overall details (version, name, description, uses)\\n// - Skills; a set of actions/solutions the agent can perform\\n// - Default modalities/content types s\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 2: Agentic MCP and A2A Architecture: A Comprehensive Guide ---\\nURL: https://medium.com/@anil.jain.baba/agentic-mcp-and-a2a-architecture-a-comprehensive-guide-0ddf4359e152\\n\\nSUMMARY:\\nThe Agent-to-Agent (A2A) protocol, introduced by Google, is an open standard designed to enable AI agents to communicate, share information, and\\n\\nFULL CONTENT:\\nSign up\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40anil.jain.baba%2Fagentic-mcp-and-a2a-architecture-a-comprehensive-guide-0ddf4359e152&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\nSign up\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40anil.jain.baba%2Fagentic-mcp-and-a2a-architecture-a-comprehensive-guide-0ddf4359e152&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n# Agentic MCP and A2A Architecture: A Comprehensive Guide\\n\\n![Anil Jain | AI / ML Architect | Data Architect](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*bNwOMHiokqgpnrUm)\\n\\n--\\n\\n3\\n\\nListen\\n\\nShare\\n\\n## 1. Introduction\\n\\n![]()\\n\\nModern AI systems are increasingly built as agents that can interact with tools, data sources, and other agents to accomplish complex tasks. Two important architectural standards have emerged to facilitate these interactions: the Model Context Protocol (MCP) and the Agent-to-Agent (A2A) protocol. This guide explores both architectures, highlighting their differences, suitable scenarios, and providing sample projects to get started.\\n\\n## 2. Key Points\\n\\n## 3. Agentic MCP and A2A Overview\\n\\n![]()\\n\\n**Agentic MCP (Model Context Protocol)** is a protocol that helps AI models, like chatbots, connect to external systems such as databases or business tools. Its like giving the AI a set of tools to fetch information or perform tasks during a conversation, making it smarter and more helpful.\\n\\n**A2A (Agent-to-Agent) Architecture** is about letting different AI agents talk to each other. Imagine a team where each agent has a job, like one handles customer queries and another manages tickets  they can work together smoothly using A2A.\\n\\nBoth are part of the growing field of AI agents, which are software entities that reason and act on behalf of users, and theyre shaping how we build intelligent systems.\\n\\n## 4. Agentic MCP Architecture\\n\\n### 4.1 What is MCP?\\n\\nThe Model Context Protocol (MCP) is an open standard introduced by Anthropic that standardizes how AI models connect with external tools, data sources, and services. It acts as a USB-C port for AI applications, providing a universal interface between models and the outside world.\\n\\n### 4.2 Core Components\\n\\nMCP follows a client-server architecture with the following key components:\\n\\n### 4.3 MCP Architecture Diagram\\n\\n![]()\\n\\n*The diagram illustrates how an MCP client connects to multiple MCP servers, each providing different capabilities such as search functionality, custom prompts, email operations, and web search.*\\n\\n### 4.4 How MCP Works\\n\\n![]()\\n\\nMCP standardizes three main types of capabilities:\\n\\nThe protocol operates through a defined connection lifecycle:\\n\\n`initialize`\\n`initialized`\\n\\nMCP uses JSON-RPC 2.0 as its message format, transported via either standard I/O (for local processes) or HTTP with Server-Sent Events (for remote communication).\\n\\n## 5. A2A Architecture\\n\\n### 5.1 What is A2A?\\n\\nThe Agent-to-Agent (A2A) protocol, introduced by Google, is an open standard designed to enable AI agents to communicate, share information, and collaborate effectively, regardless of the underlying framework or vendor.\\n\\n### 5.2 Core Components\\n\\nA2A architecture centers around facilitating communication between agents with these key components:\\n\\n### 5.3 A2A Architecture Diagram\\n\\n![]()\\n\\n### 5.4 How A2A Works\\n\\nA2A facilitates agent-to-agent communication through:\\n\\nThe protocol is built on established web standards (HTTP, SSE, JSON-RPC) and is secure by default with enterprise-grade authentication.\\n\\n## 6. MCP vs A2A: Key Differences\\n\\n### 6.1 Focus and Purpose\\n\\n### 6.2 Interaction Mode\\n\\n### 6.3 Abstraction Level\\n\\n### 6.4 Comparison Table\\n\\n![]()\\n\\n## 7. Suitable Scenarios for MCP\\n\\nMCP is better suited for scenarios where:\\n\\n**Real-world examples** where MCP excels:\\n\\n## 8. Suitable Scenarios for A2A\\n\\nA2A is more suitable for scenarios requiring:\\n\\n**Real-world examples** where A2A excels:\\n\\n## 9. Complementary Nature of MCP and A2A\\n\\nRather than competing alternatives, MCP and A2A are complementary technologies that can be used together:\\n\\nIn a well-designed system, agents can use MCP to connect with their tools and data, while using A2A to collaborate with other agents on complex tasks.\\n\\n## 10. MCP Sample Project\\n\\nTo get started with MCP, you can implement a simple MCP server that exposes tools and resources:\\n\\n### 10. 1 **Project Setup**:\\n\\n### 10.2 **Create a basic MCP server** (e.g., `main.py`):\\n\\n`main.py`\\n\\n### **10.3 Run the server**:\\n\\n### **10.4 Connect with Claude Desktop**:\\n\\n## 11. A2A Sample Project\\n\\nFor A2A, you can implement a simple currency conversion agent based on Googles example:\\n\\n### 11.1 **Setup the Environment**:\\n\\n### 11.2 **Run the A2A Agent**:\\n\\n### 11.3 **Test with Client**:\\n\\n### 11.4 **Example Interaction**:\\n\\nYou can test the agent with queries like Convert 100 USD to EUR and see how it handles the conversation and performs the currency conversion task.\\n\\n### 12. Conclusion\\n\\nAs of April 14, 2025, MCP and A2A represent two dimensions of AI agent development  MCP for tool integration and A2A for agent collaboration  signaling a shift from deterministic programming to autonomous, collaborative systems. Their complementary nature suggests a future where AI applications can think, adapt, and collaborate, revolutionizing software development. Teneo.ai and other platforms are monitoring these protocols for enterprise integration, with ongoing discussions on challenges like security, scalability, and legacy system adaptation ([MCP and A2A Protocols Explained The Future of Agentic AI  | Teneo.ai](https://www.teneo.ai/blog/mcp-and-a2a-protocols-explained-the-future-of-agentic-ai-is-here), [A2A and MCP: Start of the AI Agent Protocol Wars? | Koyeb](https://www.koyeb.com/blog/a2a-and-mcp-start-of-the-ai-agent-protocol-wars)).\\n\\nThis analysis, based on recent articles and blog posts, provides a foundation for developers, designers, and AI product builders to navigate this evolving landscape, with resources like [Logto Blog: A2A vs MCP](https://blog.logto.io/a2a-mcp) and [Introducing the Model Context Protocol | Anthropic](https://www.anthropic.com/news/model-context-protocol) offering further insights.\\n\\n## 13. References\\n\\n--\\n\\n--\\n\\n3\\n\\n![Anil Jain | AI / ML Architect | Data Architect](https://miro.medium.com/v2/resize:fill:96:96/0*bNwOMHiokqgpnrUm)\\n![Anil Jain | AI / ML Architect | Data Architect](https://miro.medium.com/v2/resize:fill:128:128/0*bNwOMHiokqgpnrUm)\\n\\n## Written by Anil Jain | AI / ML Architect | Data Architect\\n\\nWorking as ML and Data Architect and Engineer for analytical applications using Machine learning and Big Data stack.\\n\\n## Responses (3)\\n\\nHelp\\n\\nStatus\\n\\nAbout\\n\\nCareers\\n\\nPress\\n\\nBlog\\n\\nPrivacy\\n\\nRules\\n\\nTerms\\n\\nText to speech\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 3: What is the Agent-to-Agent Protocol (A2A) | by Arvind Kumar ---\\nURL: https://codefarm0.medium.com/what-is-the-agent-to-agent-protocol-a2a-c80dabc6d82b\\n\\nSUMMARY:\\nA2A Protocol is a communication standard proposed by Google DeepMind ... Message schemas include task type, context, urgency, etc.\\n\\nFULL CONTENT:\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fcodefarm0.medium.com%2Fwhat-is-the-agent-to-agent-protocol-a2a-c80dabc6d82b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fcodefarm0.medium.com%2Fwhat-is-the-agent-to-agent-protocol-a2a-c80dabc6d82b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n# What is the Agent-to-Agent Protocol (A2A)\\n\\n## Explain it to me like I am an absolute beginner and compare it with MCP protocol\\n\\n![Arvind Kumar](https://miro.medium.com/v2/resize:fill:64:64/1*qLgT62h04Vn1WA1vdYL9lg.png)\\n\\n--\\n\\nListen\\n\\nShare\\n\\nLets dive into **Agent-to-Agent (A2A) Protocol** by **Google DeepMind**, and compare it with **MCP (Model Context Protocol)** by **Anthropic**.AI agents offer a unique opportunity to help people be more productive by autonomously handling many daily recurring or complex tasks.\\n\\n![]()\\n\\n##  What is the Agent-to-Agent Protocol (A2A)?\\n\\n**A2A Protocol** is a **communication standard** proposed by Google DeepMind in 2024 that enables **language model-based agents to interact with each other autonomously**, like theyre texting each other, but with structured rules.\\n\\nThink of it as:\\n\\n*What if ChatGPT, Claude, and Gemini could* ***talk to each other****, collaborate on tasks, and exchange information, using a common protocol?*\\n\\n##  At its core, A2A protocol defines:\\n\\nSo its like **HTTP + OAuth + JSON-RPC**, but for LLM-powered agents talking to each other.\\n\\n##  Is A2A Different from MCP?\\n\\n**Yes  completely different in purpose and scope.**\\n\\n![]()\\n\\n##  Real-World Analogy:\\n\\nImagine building a **travel booking app**:\\n\\n##  Key Features of A2A Protocol\\n\\n**2. Structured Messaging**\\n\\n**3. Task Delegation**\\n\\n**3. Security and Trust**\\n\\n##  Why This Matters\\n\\nThe future of LLM applications is **multi-agent**:\\n\\nA2A defines the language of **LLM agents as microservices**, allowing distributed, cooperative AI.\\n\\n##  So What Should You Watch For?\\n\\n## TL;DR\\n\\n## A diagrammatic representation for booking travel\\n\\n![]()\\n\\ndiagram code  [link](https://www.planttext.com/?text=VP8_JyCm4CNt-nH75gQAWOq1OQUgo1O4YFcQN1ghhXtPJak-FNR-b4P2354K-_tUlNVAYm_aGd_IS1TQFZ7wlcFNihC0G5Mm3ZyzEu0kobIbEZ81irAJCUnG73X-YWp9erXBTbeTse3IsgCoXrafHwLSAtFIR6fQtF9HaqDDWVRa-Meboc8QL1OtbrTwEvbl9K1AZ9jd5FY4MO6ND2PORFIGNfBCWRHrZ8Q_0rwOZrcggiuKEDO0aTWyiNdBrH7xQ7VlaSwaDEsLLc709YxcBpo7FD5R6V6tdjs0rHmGujbcCHQJbsQq1h-uVlXe-ooXI-gnGkDuBQZvPj2KCmtATihKiLvQarzNlAMlh0GvhgSi8lpEvAfseI4TRcRVtUpOsDxK87_JFSvoj5rGrlXLCZacYzAnGrI_SWn2yHbixt3FFlo72tY9-qf_9Fm0)\\n\\n===========\\n\\n***Get more stories about Gen AI***\\n\\n![Arvind Kumar](https://miro.medium.com/v2/resize:fill:40:40/1*qLgT62h04Vn1WA1vdYL9lg.png)\\n\\n[Arvind Kumar](/?source=post_page-----c80dabc6d82b---------------------------------------)\\n\\n## Java and Generative AI | Generative AI Project | Spring AI\\n\\n![](https://miro.medium.com/v2/da:true/resize:fill:388:388/0*CyhhlqaFhmq4xE4R)\\n![](https://miro.medium.com/v2/da:true/resize:fill:388:388/0*cznxjxhwiipfexHp)\\n![](https://miro.medium.com/v2/da:true/resize:fill:388:388/0*DMlO6nLe8Y3FX2z7)\\n\\n***Please clap the story and follow me for more stories like this***\\n\\n--\\n\\n--\\n\\n![Arvind Kumar](https://miro.medium.com/v2/resize:fill:96:96/1*qLgT62h04Vn1WA1vdYL9lg.png)\\n![Arvind Kumar](https://miro.medium.com/v2/resize:fill:128:128/1*qLgT62h04Vn1WA1vdYL9lg.png)\\n\\n## Written by Arvind Kumar\\n\\nStaff Engineer | System Design, Microservices, Java, SpringBoot, Kafka, DBs, AWS, GenAI | Teaching concepts via stories & characters | [linkedin.com/in/codefarm0](http://linkedin.com/in/codefarm0)\\n\\n## No responses yet\\n\\nHelp\\n\\nStatus\\n\\nAbout\\n\\nCareers\\n\\nPress\\n\\nBlog\\n\\nPrivacy\\n\\nRules\\n\\nTerms\\n\\nText to speech\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 4: Google Agent-to-Agent (A2A) Protocol Explained ---\\nURL: https://medium.com/@shamim_ru/google-agent-to-agent-a2a-protocol-explained-with-real-working-examples-99e362b61ba8\\n\\nSUMMARY:\\nthe A2A protocol just defines a clear way for two smart AI Agents to collaborate over HTTP  one asks for something, the other does it, and they\\n\\nFULL CONTENT:\\nSign up\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40shamim_ru%2Fgoogle-agent-to-agent-a2a-protocol-explained-with-real-working-examples-99e362b61ba8&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\nSign up\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40shamim_ru%2Fgoogle-agent-to-agent-a2a-protocol-explained-with-real-working-examples-99e362b61ba8&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n# Google Agent-to-Agent (A2A) Protocol Explained  with Real Working Examples\\n\\n![Shamim Bhuiyan](https://miro.medium.com/v2/resize:fill:64:64/0*gDbbhT13ylqASHVy.jpg)\\n\\n--\\n\\n2\\n\\nListen\\n\\nShare\\n\\nThere are already tons of blog posts and vlogs floating around about agent-based systems, protocols, and AI orchestration. Most of them go deep into the theory or stick to flashy diagrams  but leave developers wondering:*Okay, but how do I actually use this?*\\n\\nIn this post, Ill take a different approach.\\n\\nInstead of just talking about what the [**Google A2A Protocol**](https://github.com/google/A2A) is, Ill walk you through how to build a real system with it  **step by step**  using working Python examples. Youll see how agents can talk to each other, how they collaborate to solve a task like travel planning, and how you can plug this into a local LLM like **Ollama**.\\n\\n## What Is A2A?\\n\\nGoogles **Agent-to-Agent (A2A)** protocol is an open specification that allows AI agents to:\\n\\nThink of it like giving each agent its own little resume, email address, and inbox  so that other agents can contact it and ask for help.\\n\\nIf youre curious how the protocol works under the hood, please refer to the official protocol [specification](https://google.github.io/A2A/#/) and the excellent hands-on tutorial from the Google Cloud community: [Getting Started with Google A2A  A Hands-On Tutorial](/google-cloud/getting-started-with-google-a2a-a-hands-on-tutorial-for-the-agent2agent-protocol-3d3b5e055127)\\n\\nHowever, the official GitHub repository provides good examples to get started, **but for Python beginners, its not so straightforward to dive into right away**. Thats why this blog post focuses on a **human-friendly, practical approach**  showing you exactly what to write and how it works, one line at a time.\\n\\nWhile Google provides a solid GitHub repository with protocol definitions and usage examples, the experience can be overwhelming for beginners, especially if youre not comfortable setting up everything from scratch.\\n\\n**Therefore, I explored several third-party community implementations** that help reduce boilerplate code and offer a much smoother entry point into working with A2A agents. These tools allow you to focus more on logic and behavior rather than wiring up the protocol manually.\\n\\nOn GitHub, I found **two popular high-level Python libraries** that stand out:\\n\\n`python-a2a`\\n`a2a-server`\\n\\nThese libraries are great for getting your hands dirty quickly, especially if youre building practical use cases like agent orchestration or work-flow. And thats exactly what well use in the upcoming examples.\\n\\nFrom these, `python-a2a` **appears to be the more advanced option**. It requires **minimal external dependencies**, making it easier to use in lightweight setups or small projects. With `python-a2a`, you can spin up agents and connect them with just a few lines of code  perfect for quick experimentation or educational use cases.\\n\\n`python-a2a`\\n`python-a2a`\\n\\n## A Simple Overview of How A2A Works\\n\\nBefore we jump into coding, lets first understand in plain language what the Google Agent-to-Agent (A2A) protocol is all about. Think of it as a set of rules that let AI agents talk to each other smoothly over the web.\\n\\nHere are the main building blocks you need to know:\\n\\n## Agent Card\\n\\nEvery agent has a public business card  a small file (usually found at `/.well-known/agent.json`) that tells the world:\\n\\n`/.well-known/agent.json`\\n\\nClients read this card to discover and connect to agents.\\n\\n## A2A Server\\n\\nThis is the agent that *listens* for requests. It exposes an HTTP API following the A2A protocol. You can think of it like a smart bot thats ready to accept tasks and do something useful  like fetching weather, searching the web, or generating text.\\n\\n## A2A Client\\n\\nThis is any app (or another agent) that *sends* tasks to the A2A server. It knows how to talk to the agent using the protocol, and its the one that says: Hey agent, I need you to do this for me.\\n\\n## Task\\n\\nA task is the actual job or command you want the agent to perform. It could be anything  Whats the weather in Paris? or Summarize this article. Each task has a unique ID and goes through stages like:\\n\\n`submitted`\\n`working`\\n`input-required`\\n`completed`\\n`failed`\\n`canceled`\\n\\n## Message\\n\\nMessages are the back-and-forth communication between the client and the agent during a task. Each message has a role:\\n\\n`\"user\"`\\n`\"agent\"`\\n\\nMessages carry actual content (called Parts)  like text, images, or structured data  that help the agent understand what to do.\\n\\nIn summary, the A2A protocol just defines a clear way for two smart AI Agents to collaborate over HTTP  one asks for something, the other does it, and they keep track of their conversation along the way.\\n\\n## Good and Bad parts of the A2A Protocol\\n\\nWhile the A2A Protocol provides several strengths that make it well-suited for building agent-based systems, it also comes with certain drawbacks.\\n\\n### Good Parts of the A2A Protocol\\n\\n### Bad Parts of the A2A Protocol\\n\\n## A2A vs. MCP  Not a Battle, but a Partnership\\n\\nOne more thing to clarify: **theres no competition between A2A and the MCP (Model Context Protocol)**. They serve different but complementary purposes:\\n\\nIn real-world AI applications, **you often need both**:\\n\\nIn the next section, well walk through building a real-world example: a Travel Planner AI that uses multiple A2A agents to provide a personalized itinerary.\\n\\n## Lets Build: A Travel Planner AI Agent Using A2A Protocol\\n\\nTo put everything weve learned into action, lets walk through a hands-on example of how to build a **Travel Planner AI** using the A2A protocol.\\n\\n## Use Case\\n\\nWere planning a short holiday trip. We want an AI assistant (an A2A agent server) that can help us decide **where to go and what to do** based on the weather.\\n\\nHeres the idea:\\n\\nBy combining these two sources, the travel planner can give smart, personalized suggestions for your trip.\\n\\n![]()\\n\\n## Communication Flow\\n\\nAfter the Travel Planner Agent gathers weather information and activity suggestions from the other agents, the final step is to **turn all that data into a friendly and helpful summary**. This is where a **local LLM (Large Language Model)** comes in.\\n\\nInstead of sending your private travel data to a third-party API, well run a **local LLM**, such as one powered by Ollama, to generate the final travel itinerary.\\n\\n### If youre interested in AI using local LLMs, dont miss our book [Generative AI with local LLM](https://leanpub.com/quickstartwithai) for more in-depth information.\\n\\n## What Well Build\\n\\nIn the next section, well walk through step-by-step how to:\\n\\n`python-a2a`\\n\\nThis approach shows how real AI agents can collaborate using A2A, each doing its job well  and together building something smarter.\\n\\n## Prerequisites\\n\\n## Step 1. Clone the repositories\\n\\n## Step 2. Create an Agent: WeatherAgent\\n\\nCreate a new Python file named **WeatherAgent.py** and add the following code:\\n\\nThis above Python script implements a simple **Weather Agent** using the `python-a2a` library. The agent follows the **Google A2A protocol** and exposes a skill to provide real-time weather forecasts using the **OpenWeatherMap API**.\\n\\n`python-a2a`\\n\\n### What it does:\\n\\n`get_weather(location)`\\n`\"What\\'s the weather in Paris?\"`\\n\\n### Key Features:\\n\\n`OPENWEATHER_API_KEY`\\n`8001`\\n`run_server()`\\n\\n### Note that, All the Python code used in this tutorial is available in the GitHub repository at <https://github.com/srecon/python-a2a/tree/main/examples/tutorials>, so you can easily copy, run, and modify the examples.\\n\\n## Step 3. Create an Agent: BraveSearchAgent\\n\\nCreate a new Python file named **BraveSearchAgent.py** and add the following code:\\n\\nThis Python script sets up a web search agent that uses the **Brave Search API** and follows the **Google A2A protocol**, built with the `python-a2a` library.\\n\\n`python-a2a`\\n\\n### What it does:\\n\\n`search(query)`\\n\\n### Key Features:\\n\\n`BRAVE_API_KEY`\\n`8002`\\n\\n## Step 4. Create an Agent: Local\\\\_LLM\\n\\nCreate a new Python file named **local\\\\_llm.py** and add the following code:\\n\\nThis script wraps a **local LLM (LLaMA 3.2)** as an **A2A-compatible agent server** using the `python-a2a` and `langchain` libraries.\\n\\n`python-a2a`\\n`langchain`\\n\\n### What it does:\\n\\n`to_a2a_server()`\\n\\n### Key Points:\\n\\nNote that, to run the above code, you have install langchain-ollama which can be installed by the following command:\\n\\n## Step 5. Create the Agent Server: Travel planner\\n\\nCreate a new Python file named **Travel\\\\_Planner\\\\_Agent.py** and add the following code:\\n\\nThis async Python script demonstrates how to **orchestrate multiple A2A agents** to build a smart **travel planning assistant** using weather data, search results, and a local LLM for summarization.\\n\\n### Workflow Overview:\\n\\n`python-a2a`\\n`AgentNetwork`\\n`weather`\\n`search`\\n`A2AClient`\\n\\n### Key Highlights:\\n\\n## Step 6: Lets Execute the Agents\\n\\nNow that weve built all the components of our A2A-based travel planner, its time to run the agents and see them work together in action.\\n\\nHeres the step-by-step execution order:\\n\\n### 1. Start the Ollama Server with LLaMA 3.2\\n\\nIf you havent already, pull and run the LLaMA 3.2 model with the following command:\\n\\n* Leave this running  it serves the model for local inference via the* `langchain_ollama` *integration.*\\n\\n`langchain_ollama`\\n\\n### 2. Start the Weather Agent\\n\\nMake sure your `OPENWEATHER_API_KEY` is available in your environment. The Agent will be avilaable at the port 8001.\\n\\n`OPENWEATHER_API_KEY`\\n\\nHere is a console output:\\n\\n### 3. Start the Brave Search Agent\\n\\nEnsure `BRAVE_API_KEY` is set correctly through *export BRAVE\\\\_API\\\\_KEY=YOUR\\\\_API\\\\_KEY*. The agent will be available at 8002 port\\n\\n`BRAVE_API_KEY`\\n\\n### 4. Run the Local LLM Agent Server\\n\\nThis wraps the Ollama LLM in an A2A-compatible agent server running at `http://localhost:5001`.\\n\\n`http://localhost:5001`\\n\\n### 5. Run the Travel Planner (Coordinator)\\n\\nThis will:\\n\\nIf everything goes fine, you should get a simillar output as shown below:\\n\\nSo, we walked through the process of building a simple yet powerful **AI agent network using the A2A (Agent-to-Agent) protocol**. Our goal was to design a **travel assistant** that can dynamically:\\n\\nAlong the way, we learned:\\n\\n`python-a2a`\\n`@skill`\\n`AgentNetwork`\\n`A2AClient`\\n\\nThis example lays the groundwork for scalable, modular AI applications where agents collaborate to perform complex tasks  a key principle in the future of agent-based software systems.\\n\\n**Special thanks and full credit go to the author and contributors of the** `python-a2a` **library**, whose work made this seamless agent communication framework possible.\\n\\n`python-a2a`\\n\\nThe article was first published on [https://www.shamimbhuiyan.ru](https://www.shamimbhuiyan.ru/)\\n\\n--\\n\\n--\\n\\n2\\n\\n![Shamim Bhuiyan](https://miro.medium.com/v2/resize:fill:96:96/0*gDbbhT13ylqASHVy.jpg)\\n![Shamim Bhuiyan](https://miro.medium.com/v2/resize:fill:128:128/0*gDbbhT13ylqASHVy.jpg)\\n\\n## Written by Shamim Bhuiyan\\n\\nEnterprise architect, speaker, Big data and AI evangelist. Co-author of several books about in-memory computing and Generative AI\\n\\n## Responses (2)\\n\\nHelp\\n\\nStatus\\n\\nAbout\\n\\nCareers\\n\\nPress\\n\\nBlog\\n\\nPrivacy\\n\\nRules\\n\\nTerms\\n\\nText to speech\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 5: a2aproject/A2A: An open protocol enabling communication ... ---\\nURL: https://github.com/a2aproject/A2A\\n\\nSUMMARY:\\na2a-protocol.org/ # Agent2Agent (A2A) Protocol # Agent2Agent (A2A) Protocol The Agent2Agent (A2A) protocol addresses a critical challenge in the AI landscape: enabling gen AI agents, built on diverse frameworks by different companies running on separate servers, to communicate and collaborate effectively - as agents, not just as tools. A2A aims to provide a common language for agents, fostering a more interconnected, powerful, and innovative AI ecosystem. With A2A, agents can: ## Why A2A? We welcome community contributions to enhance and evolve the A2A protocol! The A2A Protocol is an open-source project by Google LLC, under the Apache License 2.0, and is open to contributions from the community. a2a-protocol.org/ agents   linux-foundation   a2a   generative-ai   a2a-protocol   a2a-mcp   a2a-server\\n\\nFULL CONTENT:\\n[Skip to content](#start-of-content)   \\n\\n\\n\\n## Navigation Menu\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fa2aproject%2FA2A) \\n\\nAppearance settings\\n\\n# Search code, repositories, users, issues, pull requests...\\n\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fa2aproject%2FA2A)\\n\\n [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=a2aproject%2FA2A) \\n\\nAppearance settings\\n\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n\\n{{ message }}\\n\\n[a2aproject](/a2aproject)   /  **[A2A](/a2aproject/A2A)**  Public\\n\\n* [Notifications](/login?return_to=%2Fa2aproject%2FA2A)  You must be signed in to change notification settings\\n* [Fork 2.1k](/login?return_to=%2Fa2aproject%2FA2A)\\n* [Star  20.5k](/login?return_to=%2Fa2aproject%2FA2A)\\n\\nAn open protocol enabling communication and interoperability between opaque agentic applications.\\n\\n[a2a-protocol.org/](https://a2a-protocol.org/ \"https://a2a-protocol.org/\")\\n\\n### License\\n\\n[Apache-2.0 license](/a2aproject/A2A/blob/main/LICENSE)\\n\\n[20.5k stars](/a2aproject/A2A/stargazers)   [2.1k forks](/a2aproject/A2A/forks)   [Branches](/a2aproject/A2A/branches)   [Tags](/a2aproject/A2A/tags)   [Activity](/a2aproject/A2A/activity)\\n\\n[Star](/login?return_to=%2Fa2aproject%2FA2A)\\n\\n[Notifications](/login?return_to=%2Fa2aproject%2FA2A)  You must be signed in to change notification settings\\n\\n# a2aproject/A2A\\n\\n[Branches](/a2aproject/A2A/branches)[Tags](/a2aproject/A2A/tags)\\n\\nOpen more actions menu\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| Latest commit   History[423 Commits](/a2aproject/A2A/commits/main/) |\\n| [.gemini](/a2aproject/A2A/tree/main/.gemini \".gemini\") | [.gemini](/a2aproject/A2A/tree/main/.gemini \".gemini\") |  |  |\\n| [.github](/a2aproject/A2A/tree/main/.github \".github\") | [.github](/a2aproject/A2A/tree/main/.github \".github\") |  |  |\\n| [.mkdocs/overrides](/a2aproject/A2A/tree/main/.mkdocs/overrides \"This path skips through empty directories\") | [.mkdocs/overrides](/a2aproject/A2A/tree/main/.mkdocs/overrides \"This path skips through empty directories\") |  |  |\\n| [.vscode](/a2aproject/A2A/tree/main/.vscode \".vscode\") | [.vscode](/a2aproject/A2A/tree/main/.vscode \".vscode\") |  |  |\\n| [docs](/a2aproject/A2A/tree/main/docs \"docs\") | [docs](/a2aproject/A2A/tree/main/docs \"docs\") |  |  |\\n| [scripts](/a2aproject/A2A/tree/main/scripts \"scripts\") | [scripts](/a2aproject/A2A/tree/main/scripts \"scripts\") |  |  |\\n| [specification](/a2aproject/A2A/tree/main/specification \"specification\") | [specification](/a2aproject/A2A/tree/main/specification \"specification\") |  |  |\\n| [types](/a2aproject/A2A/tree/main/types \"types\") | [types](/a2aproject/A2A/tree/main/types \"types\") |  |  |\\n| [.editorconfig](/a2aproject/A2A/blob/main/.editorconfig \".editorconfig\") | [.editorconfig](/a2aproject/A2A/blob/main/.editorconfig \".editorconfig\") |  |  |\\n| [.git-blame-ignore-revs](/a2aproject/A2A/blob/main/.git-blame-ignore-revs \".git-blame-ignore-revs\") | [.git-blame-ignore-revs](/a2aproject/A2A/blob/main/.git-blame-ignore-revs \".git-blame-ignore-revs\") |  |  |\\n| [.gitattributes](/a2aproject/A2A/blob/main/.gitattributes \".gitattributes\") | [.gitattributes](/a2aproject/A2A/blob/main/.gitattributes \".gitattributes\") |  |  |\\n| [.gitignore](/a2aproject/A2A/blob/main/.gitignore \".gitignore\") | [.gitignore](/a2aproject/A2A/blob/main/.gitignore \".gitignore\") |  |  |\\n| [.gitvote.yml](/a2aproject/A2A/blob/main/.gitvote.yml \".gitvote.yml\") | [.gitvote.yml](/a2aproject/A2A/blob/main/.gitvote.yml \".gitvote.yml\") |  |  |\\n| [.prettierrc](/a2aproject/A2A/blob/main/.prettierrc \".prettierrc\") | [.prettierrc](/a2aproject/A2A/blob/main/.prettierrc \".prettierrc\") |  |  |\\n| [.ruff.toml](/a2aproject/A2A/blob/main/.ruff.toml \".ruff.toml\") | [.ruff.toml](/a2aproject/A2A/blob/main/.ruff.toml \".ruff.toml\") |  |  |\\n| [CHANGELOG.md](/a2aproject/A2A/blob/main/CHANGELOG.md \"CHANGELOG.md\") | [CHANGELOG.md](/a2aproject/A2A/blob/main/CHANGELOG.md \"CHANGELOG.md\") |  |  |\\n| [CODE\\\\_OF\\\\_CONDUCT.md](/a2aproject/A2A/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\") | [CODE\\\\_OF\\\\_CONDUCT.md](/a2aproject/A2A/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\") |  |  |\\n| [CONTRIBUTING.md](/a2aproject/A2A/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") | [CONTRIBUTING.md](/a2aproject/A2A/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") |  |  |\\n| [GOVERNANCE.md](/a2aproject/A2A/blob/main/GOVERNANCE.md \"GOVERNANCE.md\") | [GOVERNANCE.md](/a2aproject/A2A/blob/main/GOVERNANCE.md \"GOVERNANCE.md\") |  |  |\\n| [LICENSE](/a2aproject/A2A/blob/main/LICENSE \"LICENSE\") | [LICENSE](/a2aproject/A2A/blob/main/LICENSE \"LICENSE\") |  |  |\\n| [MAINTAINERS.md](/a2aproject/A2A/blob/main/MAINTAINERS.md \"MAINTAINERS.md\") | [MAINTAINERS.md](/a2aproject/A2A/blob/main/MAINTAINERS.md \"MAINTAINERS.md\") |  |  |\\n| [README.md](/a2aproject/A2A/blob/main/README.md \"README.md\") | [README.md](/a2aproject/A2A/blob/main/README.md \"README.md\") |  |  |\\n| [SECURITY.md](/a2aproject/A2A/blob/main/SECURITY.md \"SECURITY.md\") | [SECURITY.md](/a2aproject/A2A/blob/main/SECURITY.md \"SECURITY.md\") |  |  |\\n| [lychee.toml](/a2aproject/A2A/blob/main/lychee.toml \"lychee.toml\") | [lychee.toml](/a2aproject/A2A/blob/main/lychee.toml \"lychee.toml\") |  |  |\\n| [mkdocs.yml](/a2aproject/A2A/blob/main/mkdocs.yml \"mkdocs.yml\") | [mkdocs.yml](/a2aproject/A2A/blob/main/mkdocs.yml \"mkdocs.yml\") |  |  |\\n| [requirements-docs.txt](/a2aproject/A2A/blob/main/requirements-docs.txt \"requirements-docs.txt\") | [requirements-docs.txt](/a2aproject/A2A/blob/main/requirements-docs.txt \"requirements-docs.txt\") |  |  |\\n|  |\\n\\n## Repository files navigation\\n\\n# Agent2Agent (A2A) Protocol\\n\\n# Agent2Agent (A2A) Protocol\\n\\n**An open protocol enabling communication and interoperability between opaque agentic applications.**\\n\\nThe Agent2Agent (A2A) protocol addresses a critical challenge in the AI landscape: enabling gen AI agents, built on diverse frameworks by different companies running on separate servers, to communicate and collaborate effectively - as agents, not just as tools. A2A aims to provide a common language for agents, fostering a more interconnected, powerful, and innovative AI ecosystem.\\n\\nWith A2A, agents can:\\n\\n* Discover each other\\'s capabilities.\\n* Negotiate interaction modalities (text, forms, media).\\n* Securely collaborate on long running tasks.\\n* Operate without exposing their internal state, memory, or tools.\\n\\n## Intro to A2A Video\\n\\n## Why A2A?\\n\\nAs AI agents become more prevalent, their ability to interoperate is crucial for building complex, multi-functional applications. A2A aims to:\\n\\n* **Break Down Silos:** Connect agents across different ecosystems.\\n* **Enable Complex Collaboration:** Allow specialized agents to work together on tasks that a single agent cannot handle alone.\\n* **Promote Open Standards:** Foster a community-driven approach to agent communication, encouraging innovation and broad adoption.\\n* **Preserve Opacity:** Allow agents to collaborate without needing to share internal memory, proprietary logic, or specific tool implementations, enhancing security and protecting intellectual property.\\n\\n### Key Features\\n\\n* **Standardized Communication:** JSON-RPC 2.0 over HTTP(S).\\n* **Agent Discovery:** Via \"Agent Cards\" detailing capabilities and connection info.\\n* **Flexible Interaction:** Supports synchronous request/response, streaming (SSE), and asynchronous push notifications.\\n* **Rich Data Exchange:** Handles text, files, and structured JSON data.\\n* **Enterprise-Ready:** Designed with security, authentication, and observability in mind.\\n\\n## Getting Started\\n\\n*  **Explore the Documentation:** Visit the [Agent2Agent Protocol Documentation Site](https://a2a-protocol.org) for a complete overview, the full protocol specification, tutorials, and guides.\\n*  **View the Specification:** [A2A Protocol Specification](https://a2a-protocol.org/latest/specification/)\\n* Use the SDKs:\\n  + [ A2A Python SDK](https://github.com/a2aproject/a2a-python) `pip install a2a-sdk`\\n  + [\\u200d A2A JS SDK](https://github.com/a2aproject/a2a-js) `npm install @a2a-js/sdk`\\n  + [ A2A Java SDK](https://github.com/a2aproject/a2a-java) using maven\\n  + [ A2A .NET SDK](https://github.com/a2aproject/a2a-dotnet) using [NuGet](https://www.nuget.org/packages/A2A) `dotnet add package A2A`\\n*  Use our [samples](https://github.com/a2aproject/a2a-samples) to see A2A in action\\n\\n## Contributing\\n\\nWe welcome community contributions to enhance and evolve the A2A protocol!\\n\\n* **Questions & Discussions:** Join our [GitHub Discussions](https://github.com/a2aproject/A2A/discussions).\\n* **Issues & Feedback:** Report issues or suggest improvements via [GitHub Issues](https://github.com/a2aproject/A2A/issues).\\n* **Contribution Guide:** See our [CONTRIBUTING.md](/a2aproject/A2A/blob/main/CONTRIBUTING.md) for details on how to contribute.\\n* **Private Feedback:** Use this [Google Form](https://goo.gle/a2a-feedback).\\n* **Partner Program:** Google Cloud customers can join our partner program via this [form](https://goo.gle/a2a-partner).\\n\\n## What\\'s next\\n\\n### Protocol Enhancements\\n\\n* **Agent Discovery:**\\n  + Formalize inclusion of authorization schemes and optional credentials directly within the `AgentCard`.\\n* **Agent Collaboration:**\\n  + Investigate a `QuerySkill()` method for dynamically checking unsupported or unanticipated skills.\\n* **Task Lifecycle & UX:**\\n  + Support for dynamic UX negotiation *within* a task (e.g., agent adding audio/video mid-conversation).\\n* **Client Methods & Transport:**\\n  + Explore extending support to client-initiated methods (beyond task management).\\n  + Improvements to streaming reliability and push notification mechanisms.\\n\\nThe A2A Protocol is an open-source project by Google LLC, under the [Apache License 2.0](/a2aproject/A2A/blob/main/LICENSE), and is open to contributions from the community.\\n\\n## About\\n\\nAn open protocol enabling communication and interoperability between opaque agentic applications.\\n\\n[a2a-protocol.org/](https://a2a-protocol.org/ \"https://a2a-protocol.org/\")\\n\\n### Topics\\n\\n[agents](/topics/agents \"Topic: agents\")   [linux-foundation](/topics/linux-foundation \"Topic: linux-foundation\")   [a2a](/topics/a2a \"Topic: a2a\")   [generative-ai](/topics/generative-ai \"Topic: generative-ai\")   [a2a-protocol](/topics/a2a-protocol \"Topic: a2a-protocol\")   [a2a-mcp](/topics/a2a-mcp \"Topic: a2a-mcp\")   [a2a-server](/topics/a2a-server \"Topic: a2a-server\")\\n\\n### Resources\\n\\n### License\\n\\n[Apache-2.0 license](#Apache-2.0-1-ov-file)\\n\\n### Code of conduct\\n\\n[Code of conduct](#coc-ov-file)\\n\\n### Contributing\\n\\n[Contributing](#contributing-ov-file)\\n\\n### Security policy\\n\\n[Security policy](#security-ov-file)\\n\\n### Uh oh!\\n\\nThere was an error while loading. Please reload this page.\\n\\n[Custom properties](/a2aproject/A2A/custom-properties)\\n\\n### Stars\\n\\n[**20.5k** stars](/a2aproject/A2A/stargazers)\\n\\n### Watchers\\n\\n[**224** watching](/a2aproject/A2A/watchers)\\n\\n### Forks\\n\\n[**2.1k** forks](/a2aproject/A2A/forks)\\n\\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fa2aproject%2FA2A&report=a2aproject+%28user%29)\\n\\n## [Releases 9](/a2aproject/A2A/releases)\\n\\n[v0.3.0  Latest\\n\\nJul 30, 2025](/a2aproject/A2A/releases/tag/v0.3.0)\\n\\n[+ 8 releases](/a2aproject/A2A/releases)\\n\\n### Uh oh!\\n\\nThere was an error while loading. Please reload this page.\\n\\n## [Contributors 120](/a2aproject/A2A/graphs/contributors)\\n\\n\\n\\n[+ 106 contributors](/a2aproject/A2A/graphs/contributors)\\n\\n## Languages\\n\\n* [TypeScript 88.8%](/a2aproject/A2A/search?l=typescript)\\n* [Shell 11.2%](/a2aproject/A2A/search?l=shell)\\n\\nYou cant perform that action at this time.\\n\\n \\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 6: Model Context Protocol (MCP) vs Agent2Agent Protocol (A2A) | by ... ---\\nURL: https://medium.com/@narasimhulu.yeggoli/model-context-protocol-mcp-vs-agent2agent-protocol-a2a-896125e818c3\\n\\nSUMMARY:\\nModel Context Protocol (MCP) provides a standardized way for AI to access external resources, enabling them to generate more accurate, relevant, and context-aware responses. Without a protocol like MCP, integrating AI with external systems requires custom code and bespoke solutions for each data source or tool. Agent2Agent Protocol (A2A) help agents across different ecosystems communicate with each other. In conclusion, while both Model Context Protocol (MCP) and Agent2Agent Protocol (A2A) are crucial for advancing AI capabilities, they tackle different challenges. The transition from MCPs tool communication to A2As agent communication marks a significant evolution in AI architecture, paving the way for more. ### The Model Context Protocol (MCP) is rapidly emerging as a universal USBC for AI agents, providing a standardized bridge between language\\n\\nFULL CONTENT:\\n[Sitemap](/sitemap/sitemap.xml)\\n\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F896125e818c3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40narasimhulu.yeggoli%2Fmodel-context-protocol-mcp-vs-agent2agent-protocol-a2a-896125e818c3&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40narasimhulu.yeggoli%2Fmodel-context-protocol-mcp-vs-agent2agent-protocol-a2a-896125e818c3&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n# Model Context Protocol (MCP) vs Agent2Agent Protocol (A2A)\\n\\n[Narasimhulu Yeggoli](/@narasimhulu.yeggoli?source=post_page---byline--896125e818c3---------------------------------------)\\n\\n5 min readApr 21, 2025\\n\\nA Transition Story From Tool Communication To Agent Communication\\n\\nAI models, particularly Large Language Models (LLMs), are often limited by their training data and lack access to real-time information or specific data sources. Model Context Protocol (MCP) provides a standardized way for AI to access external resources, enabling them to generate more accurate, relevant, and context-aware responses.\\n\\nWithout a protocol like MCP, integrating AI with external systems requires custom code and bespoke solutions for each data source or tool. Traditionally, connecting an AI system to external tools involves integrating multiple APIs. Each API integration means separate code, documentation, authentication methods, error handling, and maintenance.\\n\\nMCP offers a universal and open standard, simplifying the integration process and reducing the need for custom integrations. MCP allows developers to easily switch between different AI models and providers without rewriting integrations. It supports multiple communication methods, ensuring flexibility in tool integration. By providing a common framework for AI integration, MCP promotes collaboration across teams and organizations. It enables developers to focus on model logic rather than writing boilerplate code for every integration, fostering innovation and accelerating the development of AI-powered solutions.\\n\\nMCP follows a client-server architecture where a host application can connect to multiple servers\\n\\n**Components of MCP:**\\n\\n* **MCP Hosts:** Programs like Claude Desktop, IDEs, or AI tools that want to access data through MCP.\\n* **MCP Clients:** Protocol clients that maintain 1:1 connections with servers.\\n* **MCP Servers:** Lightweight programs that each expose specific capabilities through the standardized Model Context Protocol.\\n* **Local Data Sources:** Your computers files, databases, and services that MCP servers can securely access.\\n* **Remote Services:** External systems available over the internet (e.g., through APIs) that MCP servers can connect to.\\n\\nAgentic AI tools help autonomous agents to complete a complex task. MCP addresses about a specification that enables agent and tool communication. Where as is lacks addressing the agent interoperability.\\n\\n## Get Narasimhulu Yeggolis stories in\\xa0your\\xa0inbox\\n\\nJoin Medium for free to get updates from\\xa0this\\xa0writer.\\n\\nToday, enterprises are increasingly building and deploying autonomous agents to help scale, automate and enhance processes throughout the workplacefrom ordering new laptops, to aiding customer service representatives, to assisting in supply chain planning. **Enabling agents to interoperate with each other, even if they were** **built by different vendors is a challenge.**\\n\\nAgent2Agent Protocol (A2A) help agents across different ecosystems communicate with each other. Google is driving this open protocol initiative and A2A work is still in progress. A2A protocol will be critical to support multi-agent communication by giving agents a common language  irrespective of the framework or vendor they are built on. This protocol is used for enabling interaction and coordination between multiple artificial intelligence agents. These agents can be software programs, robots, or even virtual assistants. A2A protocols define the rules, formats, and mechanisms for these agents to exchange information, negotiate, cooperate, or compete with each other to achieve individual or collective goals.\\n\\n**Core Principles and Objectives:**\\n\\n**Interoperability:** The primary goal is to allow agents, potentially built by different developers or organizations, to work together effectively. This requires a standardized way to understand each others messages and capabilities.  \\n**Communication:** A2A protocols define the language and format agents use to communicate. This includes specifying message structures, content encoding, and addressing schemes.  \\n**Coordination:** Beyond simple message passing, A2A protocols often include mechanisms for agents to coordinate their actions. This can involve negotiation, task delegation, resource sharing, and conflict resolution.  \\n**Autonomy:** Agents should retain a degree of autonomy while participating in the A2A network. They should be able to make independent decisions based on their own goals and knowledge, while still adhering to the protocols rules.  \\n**Scalability:** The protocol should be designed to handle a large number of agents and complex interactions without significant performance degradation.  \\n**Robustness:** The protocol should be resilient to errors, failures, and malicious behavior from other agents.   \\n**Message Format:** Defines the structure and content of messages exchanged between agents.  \\n**Security Mechanisms:** Ensures secure communication between agents.\\n\\n**Difference between MCP and A2A:**\\n\\nAgent2Agent (A2A) Protocol and Model Context Protocol (MCP) serve fundamentally different purposes and operate at different levels within a system. While both involve protocols for communication and data exchange, their focus and applications are distinct.\\n\\n**A2A Protocol:** Defines how the project managers communicate with each other: What language they use for reporting, how they request updates, how they negotiate deadlines, and how they coordinate tasks.  \\n**MCP:** Describes how the project document is structured, versioned, and accessed. It ensures that everyone is working with the correct version of the document, that changes are tracked, and that relevant project data is available.\\n\\nIn conclusion, while both Model Context Protocol (MCP) and Agent2Agent Protocol (A2A) are crucial for advancing AI capabilities, they tackle different challenges. MCP standardizes the way AI models access external tools and data sources, promoting efficiency and interoperability within a tool-centric ecosystem. However, as the industry shifts towards more complex multi-agent systems, A2A emerges as the necessary next step. By providing a common language and framework for agents to communicate, coordinate, and cooperate, A2A unlocks the potential for truly autonomous and collaborative AI solutions. The transition from MCPs tool communication to A2As agent communication marks a significant evolution in AI architecture, paving the way for more.\\n\\nThis is a high level overview on Agent2Agent Protocol. For more information refer the below links:\\n\\n[## GitHub - google/A2A: An open protocol enabling communication and interoperability between opaque\\n\\n### An open protocol enabling communication and interoperability between opaque agentic applications. - google/A2A\\n\\ngithub.com](https://github.com/google/A2A?source=post_page-----896125e818c3---------------------------------------)\\n\\n[## Agent2Agent Protocol\\n\\n### An open protocol enabling communication and interoperability between opaque agentic applications.\\n\\ngoogle.github.io](https://google.github.io/A2A/?source=post_page-----896125e818c3---------------------------------------#/documentation)\\n\\nThe images used in the post are referenced from the above links.\\n\\nThis is my first blog post, I hope you enjoyed reading it.\\n\\nThank you,\\n\\nDr. Narasimhulu Yeggoli, NextGen R&D, Technology Software and Services, Tata Consultancy Services.\\n\\n#A2AProtocol #MCP #A2AvsMCP #AgenticAI #LLM #AIAgents\\n\\n[## Written by Narasimhulu Yeggoli](/@narasimhulu.yeggoli?source=post_page---post_author_info--896125e818c3---------------------------------------)\\n\\n0 followers\\n\\n[1 following](/@narasimhulu.yeggoli/following?source=post_page---post_author_info--896125e818c3---------------------------------------)\\n\\n## No responses yet\\n\\nWrite a response\\n\\n[What are your thoughts?](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40narasimhulu.yeggoli%2Fmodel-context-protocol-mcp-vs-agent2agent-protocol-a2a-896125e818c3&source=---post_responses--896125e818c3---------------------respond_sidebar------------------)\\n\\n## Recommended from Medium\\n\\n[Yash Bhaskar](/@yash9439?source=post_page---read_next_recirc--896125e818c3----0---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[## MCPs Three Core Capabilities: Tools, Resources, and Prompts\\n\\n### Connecting an AI to external software is the key to building powerful applications. But how do you do it in a way that is both flexible and](/@yash9439/mcps-three-core-capabilities-tools-resources-and-prompts-43c3214ff43e?source=post_page---read_next_recirc--896125e818c3----0---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nJun 30\\n\\n[7](/@yash9439/mcps-three-core-capabilities-tools-resources-and-prompts-43c3214ff43e?source=post_page---read_next_recirc--896125e818c3----0---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[Dharmendra Pratap Singh](/@dharamai2024?source=post_page---read_next_recirc--896125e818c3----1---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[## Model Context Protocol -PART-4: Connecting Multiple MCP Servers With Host and MCP Client\\n\\n### Introduction:](/@dharamai2024/model-context-protocol-part-4-connecting-multiple-mcp-servers-with-host-and-mcp-client-cc53c67a3f89?source=post_page---read_next_recirc--896125e818c3----1---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nJul 27\\n\\n[8](/@dharamai2024/model-context-protocol-part-4-connecting-multiple-mcp-servers-with-host-and-mcp-client-cc53c67a3f89?source=post_page---read_next_recirc--896125e818c3----1---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nIn\\n\\n[AlgoMart](https://medium.com/algomart?source=post_page---read_next_recirc--896125e818c3----0---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nby\\n\\n[Yash Jain](/@yash0307jain?source=post_page---read_next_recirc--896125e818c3----0---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[## Best Practices for Observability in Agentic GenAI Systems\\n\\n### When youre working with conventional software, bad logging can ruin a weekend. With LLM-based agents? It can destroy the week. Or worse](/algomart/best-practices-for-observability-in-agentic-genai-systems-577f851f9bd6?source=post_page---read_next_recirc--896125e818c3----0---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nAug 12\\n\\n[31](/algomart/best-practices-for-observability-in-agentic-genai-systems-577f851f9bd6?source=post_page---read_next_recirc--896125e818c3----0---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[Chamuditha Kekulawala](/@ckekula?source=post_page---read_next_recirc--896125e818c3----1---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[## Model Context Protocol (MCP) and its limitations\\n\\n### In part 1 we got a high level understanding of what MCP is. Now lets go into more technical details: MCP provides a standardized way for](/@ckekula/model-context-protocol-mcp-and-its-limitations-4d3c2561b206?source=post_page---read_next_recirc--896125e818c3----1---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nMay 28\\n\\n[5](/@ckekula/model-context-protocol-mcp-and-its-limitations-4d3c2561b206?source=post_page---read_next_recirc--896125e818c3----1---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[Afrid Mondal](/@afrid.mndl?source=post_page---read_next_recirc--896125e818c3----2---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[## Mastering MCP: Scalable Client-Server Communication for AI Agents\\n\\n### The Model Context Protocol (MCP) is rapidly emerging as a universal USBC for AI agents, providing a standardized bridge between language](/@afrid.mndl/mastering-mcp-scalable-client-server-communication-for-ai-agents-640c8fa733a4?source=post_page---read_next_recirc--896125e818c3----2---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nOct 16\\n\\n[Elizabeth Thuo](/@elizabeththuo15?source=post_page---read_next_recirc--896125e818c3----3---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[## Why Guardrails Are Non-Negotiable When Building AI Agents (And What Happens When You Skip Them)\\n\\n### Look, I get it. Youre excited about building AI agents. Everyones talking about autonomous systems that can handle customer support](/@elizabeththuo15/why-guardrails-are-non-negotiable-when-building-ai-agents-and-what-happens-when-you-skip-them-0e348a86ea8e?source=post_page---read_next_recirc--896125e818c3----3---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\nOct 21\\n\\n[16\\n\\n1](/@elizabeththuo15/why-guardrails-are-non-negotiable-when-building-ai-agents-and-what-happens-when-you-skip-them-0e348a86ea8e?source=post_page---read_next_recirc--896125e818c3----3---------------------c266762b_93ea_4480_9f19_5751f291a973--------------)\\n\\n[See more recommendations](/?source=post_page---read_next_recirc--896125e818c3---------------------------------------)\\n\\n[Text to speech](https://speechify.com/medium?source=post_page-----896125e818c3---------------------------------------)\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 7: MCP vs A2A: Everything you need to know - Composio ---\\nURL: https://composio.dev/blog/mcp-vs-a2a-everything-you-need-to-know\\n\\nSUMMARY:\\nEach backend agent connects to its respective services (Google Calendar, Google Doc etc.) using MCP, pulls the required data, and then responds through A2A. MCP provides the tools each agent uses, while A2A facilitates the collaboration between agents. One way to use MCP servers in A2A agents is via Google Agent Development Kit. So, first install the ADK. \"\"\"Creates an ADK Agent equipped with tools from the MCP Server.\"\"\" MCP, or Model Context Protocol, is an open standard that lets AI agents interact with external tools and data sources through a consistent interface. In short, MCP is about *tool use*, while A2A is about *agent collaboration*. MCP gives agents the ability to use external tools, while A2A enables them to work together.\\n\\nFULL CONTENT:\\n[Sign in](https://app.composio.dev/)\\n\\n# MCP vs A2A: Everything you need to know\\n\\n[Sunil Kumar Dash](../authors/sunil-kumar-dash)\\n\\nApr 23, 2025\\n\\n\\n\\n14 mins\\n\\n[Understanding MCPs  The Role of the Model Context Protocol](#header-2)[Agent2Agent Protocol by Google](#header-4)[1. Communication](#header-16)[2. Task Management](#header-19)[3. Capability Specification](#header-22)[How to use MCP with A2A](#header-25)[Conclusion](#header-26)[Frequently Asked Questions (FAQ)](#header-27)[Recommended Blogs](#header-32)\\n\\nGet started with Rube\\n\\n#### Power your AI Assistant with 500+ Apps\\n\\n[Try for free](https://getrube.link/SD6bQNF)\\n\\nAm I a bit late to talk about MCP and [A2A protocols](https://composio.dev/blog/agent2agent-a-practical-guide-to-build-agents)? I hope not! Both have been all over the internet, and they are mind-blowing!! A race is underway, and nobody wants to be left behind in introducing new models and tools.\\n\\nA few months ago, Anthropic released MCP (Model Context Protocol) for agents, and it received strong community traction. Recently, we saw OpenAIs integration with MCP. MCP tells you how the agent will communicate with the APIs, making tool calling standardised.\\n\\nNow, Google has released an A2A (Agent2Agent) protocol to streamline agent communication. So, in short, A2A standardises agent-to-agent communication, while MCP standardises agent-to-tool communication.\\n\\nSo, yes, they are not competing but complementing each other. Google has extended support for MCP in the [Agents Development Kit (ADK)](https://google.github.io/adk-docs/tools/mcp-tools/).\\n\\nThis blog post explains how they work together to standardise building production-ready AI agents.\\n\\nLets first discuss the MCP and then proceed with the A2A protocol to see how both work.\\n\\n## Understanding MCPs  The Role of the Model Context Protocol\\n\\nMCP stands for Model Context Protocol, an open standard developed by Anthropic. It defines a structured, efficient way for applications to provide external context to large language models (LLMs), such as Claude and GPT. Think of it like USB for AI  it lets AI models connect to external tools and data sources in a standardised way.\\n\\n### Whats the Core Problem MCP Solves?\\n\\nMCP has three critical components.\\n\\n* Client: The client maintains a 1:1 connection with the servers, handles all the LLM routing and orchestration, and negotiates capabilities with the servers.\\n* Server: These are API services, databases, and logs that the LLMs can access to complete tasks. Servers expose tools that the LLMs use to accomplish tasks.\\n* Protocol: The core protocol standardises communication between clients and servers.\\n\\nFor an in-depth guide on MCP, the architecture, and internal workings, check out this article: [Model Context Protocol (MCP): Explained](https://composio.dev/blog/what-is-model-context-protocol-mcp-explained/).\\n\\nIn short, MCP allows app developers to build clients (Cursor, Windsurf, etc) and server developers to create API servers without worrying about each others implementation. A client app or MCP host can connect to any MCP server and vice versa.\\n\\nEach tool implementation is different in its own way. Theyre structured differently:\\n\\n* Different field names (start\\\\_time vs event\\\\_time)\\n* Different auth schemes (OAuth, API key, JWT, etc.)\\n* Different error messages and formats\\n\\nMCP standardizes how the servers are built. While you still have to write the integration logic for each app you need(or you can use [Composio](https://composio.dev/)). MCP allows any server built by anyone to be integrated with any MCP client. This standardisation makes it easy for millions of developers.  \\nMCP abstracts away the differences, making it far easier for the LLM to send commands without needing custom logic for every specific tool.\\n\\nYou can think of it like this:\\n\\n* User: Adds [Google Calendar](https://mcp.composio.dev/googlecalendar/tinkling-faint-car-f6g1zk) MCP server to the client app, like Cursor IDE.\\n* The client app fetches all the server-exposed tools. And add it to the LLM context.\\n* User: Schedule a team sync on Thursday at 3 PM.\\n* MCP client: The LLM receives the message, understands it needs to call a tool, and then calls it with required parameters. (You need to finish authentication first.)\\n* Calendar MCP Server: Executes the tool with the required parameters\\n* Result: The meeting is created without you manually configuring anything.\\n\\nSo instead of spending hours wiring up six services with brittle code, you now have a modular **interface** that speaks one clean language, regardless of the tool behind it.\\n\\nBy the way, MCP, despite all its merits, is not great for production use cases. From security issues to reliability issues, it can be very tough to manage multiple Server integrations. Hence, why we at Composio are building the safest and most robust MCP infra for your AI workflows.\\n\\n## Agent2Agent Protocol by Google\\n\\nGoogle introduced the Agent-to-Agent Protocol (A2A), which is inspired by Anthropics Model Context Protocol (MCP). While MCP focused on agent-to-server communication, A2A is about agent-to-agent interoperability.\\n\\nLets say Im using a travel assistant agent to plan a train trip from Delhi to Mumbai.\\n\\nThat travel agent would have its own LLM, but it could also connect to other specialised agents, like a train booking agent, a hotel booking agent, and maybe even a cab service agent.\\n\\nSo I could say:  \\nPlan a full trip from Delhi to Mumbai, book my train, find a hotel near the station, and arrange local transport.\\n\\nAnd this travel agent would figure out:\\n\\n* Which train to take?\\n* Which hotel to book?\\n* And what cab or ride service should I schedule for pickup?\\n\\nBehind the scenes, it uses the A2A protocol to link itself with the other agents, like forming a mini-team, each handling their part of the job. Its all coordinated and handled automatically.\\n\\nThats the power of agent-to-agent communication: modular, connected, and way more intelligent than manually doing it all.\\n\\n### **A2A Design Principles**\\n\\nAt its core, A2A (Agent-to-Agent) enables flexible and intelligent communication between autonomous agents, regardless of who built them or what ecosystem they belong to. The protocol is shaped around five foundational design principles that make it adaptable, extensible, and future-proof.\\n\\n**A2A in a nutshell**\\n\\n**Key advantages**\\n\\n* **True agentic behaviour**  Agents run independently and cooperate without shared state or central control.\\n* **Familiar tech stack**  Pure HTTP\\xa0+\\xa0ServerSent\\xa0Events\\xa0+\\xa0JSONRPC: fits straight into existing backend workflows.\\n* **Enterprisegrade security**  Builtin auth\\xa0/\\xa0authz on par with OpenAPI.\\n* **Short or longrunning tasks**  Realtime progress, state tracking, and humanintheloop support.\\n* **Modalityagnostic**  Handles text, audio, video, and other rich media.\\n\\n### How A2A Works?\\n\\n| Stage | What happens |\\n| --- | --- |\\n| **Capability discovery** | Agents publish *Agent Cards* (JSON) that list skills, modalities, and constraints. |\\n| **Task lifecycle** | A client agent delegates a *task*; the remote agent updates status until it delivers an *artefact* (result). |\\n| **Collaboration** | Agents exchange messages, artefacts, and contextmore than simple command/response. |\\n| **UX negotiation** | Every message is broken into typed *parts* (text, chart, image, video, form, etc.), letting the sender tailor output to the clients UI abilities. |\\n\\n### **Key Concepts of A2A Protocol**\\n\\n### **1. Multi-Agent Collaboration**\\n\\n* Agents can now share tasks, communicate results, and work collaboratively across ecosystems.\\n* Think of a recruiting agent talking to a companys internal hiring agent, or a delivery app agent coordinating between McDonalds agents and Subway agents\\n\\n### **2. Open & Extensible**\\n\\n* A2A is an **open protocol** with contributions from over 50 tech companies (like Atlassian, Box, Langchain, PayPal, HCL, Infosys, etc.).\\n* Built on existing standards like:\\n* **JSON-RPC**\\n* **Service & Event Descriptions**\\n\\n### **3. Secure by Default**\\n\\n* Supports authentication and authorisation based on widely used identity frameworks (e.g., OpenID Connect).\\n* Uses well-known endpoint conventions for agent discovery (e.g., .well-known/agent.json).\\n\\n### **Working of A2A With Examples**\\n\\n#### **Architecture Example:**\\n\\nLets imagine a system involving three agents within a productivity suite:\\n\\n**Calendar Agent:**\\n\\n* Hosted on its own server.\\n* Pulls availability data from [Google Calendar](https://mcp.composio.dev/googlecalendar/tinkling-faint-car-f6g1zk) via its MCP interface.\\n\\n**Document Agent:**\\n\\n* It also uses its own MCP server to retrieve documents and meeting notes from Notion or Google Docs.\\n\\n**Assistant Agent:**\\n\\n* A user-facing LLM-based agent that delegates tasks to respective agents.\\n\\n#### **Flow:**\\n\\nA user says to the Assistant Agent:  \\nSchedule a meeting with Alice and summarize the key points from our last document.\\n\\nThe Assistant Agent, using the A2A protocol, does the following:\\n\\n1. Contacts the Calendar Agent to check Alices and the users mutual availability.\\n2. Contact the Document Agent to pull the relevant document and summarize its content.\\n\\nEach backend agent connects to its respective services (Google Calendar, Google Doc etc.) using MCP, pulls the required data, and then responds through A2A.\\n\\nSo in this setup:\\n\\n* A2A is responsible for smooth agent-to-agent communication.\\n* MCP bridges the gap between agents and Calendar app.\\n\\n### **Agent Discovery (Inspired by OpenID Connect)**\\n\\nNow, how do these agents know about each other?\\n\\nEvery organisation that hosts an agent exposes a discovery URL like:\\n\\n`yourdomain.com/.well-known/agent.json`\\n\\nThis JSON file acts like a profile, and typically includes:\\n\\n* Agent name and description\\n* Declared capabilities\\n* Example queries it can handle\\n* Supported modalities and protocols\\n\\nThis approach is inspired by OpenID Connects discovery mechanism (.well-known/openid-configuration), making agents discoverable and interoperable without needing tight coupling or manual configuration.\\n\\nAll these agents register themselves using .well-known/agent.json, enabling any new agent in the ecosystem to dynamically discover, assess, and interact with them, thanks to A2As standard messaging and coordination format.\\n\\n#### **A2A vs MCP**\\n\\n|  |  |  |\\n| --- | --- | --- |\\n| **Feature** | **MCP (Model Context Protocol)** | **A2A (Agent-to-Agent Protocol)** |\\n| Communication | Agent  External Systems/APIs | Agent  Agent |\\n| Goal | API Integration | Collaboration & Interoperability |\\n| Layer | Backend (Data/API access) | Mid-layer (Agent Network) |\\n| Tech Standard | REST, JSON, DB Drivers | JSON-RPC, Services, Events |\\n| Inspired By | Language Server Protocol (LSP) | OpenID Connect, Service Discovery |\\n\\nMCP provides the tools each agent uses, while A2A facilitates the collaboration between agents. They complement each other, ensuring both the execution of individual tasks and the coordination of complex, multi-step processes.\\u200b\\n\\nWhile MCP equips agents with the necessary tools to perform specific tasks, A2A enables these agents to collaborate, ensuring a cohesive and efficient experience.\\n\\nBoth Anthropics MCP and Googles A2A protocols facilitate interaction between AI systems and external components, but they cater to different scenarios and architectures.\\n\\n|  |  |  |\\n| --- | --- | --- |\\n| **Category** | **Anthropic MCP** | **Google A2A** |\\n| **Main Objective** | Tailored for linking a single AI model with external tools and data pipelines. | Designed to support interaction between autonomous AI agents across environments. |\\n| **Best Fit Scenario** | Ideal for enterprise systems needing controlled and secure data access. | Suited for distributed B2B use cases where multiple AI agents need to coordinate. |\\n| **Communication Protocol** | Local: STDIO; Remote: HTTP with Server-Sent Events (SSE) for real-time responses. | HTTP/HTTPS enhanced with webhooks and SSE to support async, scalable messaging. |\\n| **Service Discovery** | Based on fixed server settings; connections are manually defined. | Uses Agent Cards to find and connect with compatible capabilities dynamically. |\\n| **Interaction Pattern** | Top-down approachLLM accesses external resources directly. | Peer-to-peer collaborationagents interact with each other as equals. |\\n| **Security Approach** | Emphasises secure interactions across trust boundaries in multi-agent setups. | Tailored to link a single AI model with external tools and data pipelines. |\\n| **Workflow Handling** | Optimized for simple, direct request-and-response flows. | Built for managing ongoing tasks with state tracking and lifecycle awareness. |\\n\\n## 1. Communication\\n\\n#### **MCP: Structured Schemas**\\n\\n* In MCP (Multi-Call Protocol), the interaction is explicit and schema-driven.\\n* The assistant knows exactly what tool to call, what arguments to pass, and in what format.\\n* **Flow**: AI Assistant  Tool with structured input  Tool returns raw result.\\n\\n**MCP Flow:**\\n\\n* AI sends: get\\\\_weather\\\\_forecast(Tokyo, 2025-04-22)\\n* Tool returns: Sunny, 22C\\n* AI just displays the result.\\n\\n#### **A2A: Natural Language**\\n\\n* A2A (Agent-to-Agent) is much more conversation-style, using natural language tasks.\\n* Tasks are expressed like real user queries, and agents internally decide how to interpret them.\\n* **Flow**: User Agent  Task in plain English  Target Agent processes  Responds naturally.\\n\\n**A2A Flow:**\\n\\n* User says: Can you tell me the weather in Tokyo on April 22nd and current $NVDA price?\\n* Agent routes to the appropriate Finance/Weather Agent\\n* Response might be: Sure! The forecast for Tokyo on April 22nd is sunny with a high of 22C. or $NVDA price currently is $101.42 down by 0.064%\\n\\n## 2. Task Management\\n\\n#### **MCP: Single-Stage Execution**\\n\\n* MCP handles tasks like a classic function call.\\n* You call the function (or tool) and immediately get a response: either a success with the result or a failure (error/exception).\\n* The whole process is immediate and atomic, one shot, one answer.\\n\\n#### **A2A: Multi-Stage Lifecycle**\\n\\n* A2A treats tasks like long-running jobs.\\n* Tasks have multiple possible states:\\n\\n  + pending  waiting to start\\n  + running  work in progress (can even provide partial results!)\\n  + completed  final result ready\\n  + failed  something went wrong\\n\\nYou can check back anytime to see progress, grab partial data, or wait for the full result.\\n\\n## 3. Capability Specification\\n\\n#### **MCP: Low-Level, Instruction-Based**\\n\\nMCP capabilities are described with very strict schemas, usually in JSON Schema format. They are about precision and control, like telling a machine exactly what to do and how to do it.\\n\\n```\\n{\\n\\n\\xa0\\xa0\"name\": \"book_table\",\\n\\n\\xa0\\xa0\"description\": \"Books a table at a restaurant\",\\n\\n\\xa0\\xa0\"inputSchema\": {\\n\\n\\xa0\\xa0\\xa0\\xa0\"type\": \"object\",\\n\\n\\xa0\\xa0\\xa0\\xa0\"properties\": {\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"restaurant\": { \"type\": \"string\" },\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"date\": { \"type\": \"string\", \"format\": \"date\" },\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"time\": { \"type\": \"string\", \"pattern\": \"^\\\\\\\\d{2}:\\\\\\\\d{2}$\" },\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"party_size\": { \"type\": \"integer\", \"minimum\": 1 }\\n\\n\\xa0\\xa0\\xa0\\xa0},\\n\\n\\xa0\\xa0\\xa0\\xa0\"required\": [\"restaurant\", \"date\", \"time\", \"party_size\"]\\n\\n\\xa0\\xa0}\\n\\n}\\n```\\n\\n#### A2A: High-Level, Goal-Oriented\\n\\nIn contrast, A2A uses an Agent Card to describe capabilities regarding goals, roles, and expertise. Its like explaining what someone is good at and trusting them to handle it.\\n\\n```\\nagent_card = AgentCard(\\n\\n\\xa0\\xa0\\xa0\\xa0id=\"restaurant-agent\",\\n\\n\\xa0\\xa0\\xa0\\xa0name=\"Dining Assistant\",\\n\\n\\xa0\\xa0\\xa0\\xa0description=\"Helps users find and book tables at restaurants.\",\\n\\n\\xa0\\xa0\\xa0\\xa0agent_skills=[\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0AgentSkill(\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0id=\"table_booking\",\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0name=\"Table Booking\",\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0description=\"Can search restaurants and book tables as per user preferences.\",\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0examples=[\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"Book a table for 4 at an Italian place this Friday night.\",\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"Find a quiet restaurant near downtown and reserve for two people.\"\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0]\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0)\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0]\\n\\n)\\n```\\n\\n* **MCP** allows you add skills (API services, Databases, records, etc) to your agents.\\n* **A2A** gives you **flexibility**, **judgment**, and **delegation power. Think of** a team of thoughtful *coworkers*.\\n* Theyre like pairing an engineer (MCP) with a project manager (A2A). One does exact work; the other handles the chaos.\\n\\n## How to use MCP with A2A\\n\\nOne way to use MCP servers in A2A agents is via Google Agent Development Kit. So, first install the ADK.\\n\\nPython example\\n\\n```\\npip install google adk\\n```\\n\\nImport necessary modules\\n\\n```\\n# ./adk_agent_samples/mcp_agent/agent.py\\nimport asyncio\\nfrom dotenv import load_dotenv\\nfrom google.genai import types\\nfrom google.adk.agents.llm_agent import LlmAgent\\nfrom google.adk.runners import Runner\\nfrom google.adk.sessions import InMemorySessionService\\nfrom google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService # Optional\\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, SseServerParams, StdioServerParameters\\n\\n# Load environment variables from .env file in the parent directory\\nload_dotenv(\\'.env\\')\\n```\\n\\nConfigure the MCP server and fetch tools\\n\\n```\\n# --- Step 1: Import Tools from MCP Server ---\\nasync def get_tools_async():\\n  \"\"\"Gets tools from the File System MCP Server.\"\"\"\\n  print(\"Attempting to connect to MCP Filesystem server...\")\\n  tools, exit_stack = await MCPToolset.from_server(\\n      connection_params=SseServerParams(url=\"https://mcp.composio.dev/gmail/tinkling-faint-car-f6g1zk\")\\n  )\\n  print(\"MCP Toolset created successfully.\")\\n  \\n  return tools, exit_stack\\n```\\n\\nHere, we have used the HTTP SSE URL for Gmail server from the [mcp.composio.dev](https://mcp.composio.dev/).\\n\\nFor a STDIO based tool\\n\\n```\\nasync def get_tools_async():\\n  \"\"\"Gets tools from the File System MCP Server.\"\"\"\\n  print(\"Attempting to connect to MCP Filesystem server...\")\\n  tools, exit_stack = await MCPToolset.from_server(\\n      connection_params=StdioServerParameters(\\n          command=\\'npx\\',\\n          args=[\"-y\",    \\n                \"@modelcontextprotocol/server-filesystem\",\\n                \"/path/to/your/folder\"],\\n      )\\n  )\\n  print(\"MCP Toolset created successfully.\")\\n  return tools, exit_stack\\n```\\n\\nCreate the agent\\n\\n```\\nasync def get_agent_async():\\n  \"\"\"Creates an ADK Agent equipped with tools from the MCP Server.\"\"\"\\n  tools, exit_stack = await get_tools_async()\\n  print(f\"Fetched {len(tools)} tools from MCP server.\")\\n  root_agent = LlmAgent(\\n      model=\\'gemini-2.0-flash\\', # Adjust if needed\\n      name=\\'maps_assistant\\',\\n      instruction=\\'Help user with mapping and directions using available tools.\\',\\n      tools=tools,\\n  )\\n  return root_agent, exit_stack\\n```\\n\\nDefine the `main` function.\\n\\n```\\nasync def async_main():\\n  session_service = InMemorySessionService()\\n  artifacts_service = InMemoryArtifactService() # Optional\\n\\n  session = session_service.create_session(\\n      state={}, app_name=\\'mcp_maps_app\\', user_id=\\'user_maps\\'\\n  )\\n\\n  # TODO: Use specific addresses for reliable results with this server\\n  query = \"What is the route from 1600 Amphitheatre Pkwy to 1165 Borregas Ave\"\\n  print(f\"User Query: \\'{query}\\'\")\\n  content = types.Content(role=\\'user\\', parts=[types.Part(text=query)])\\n\\n  root_agent, exit_stack = await get_agent_async()\\n\\n  runner = Runner(\\n      app_name=\\'mcp_maps_app\\',\\n      agent=root_agent,\\n      artifact_service=artifacts_service, # Optional\\n      session_service=session_service,\\n  )\\n\\n  print(\"Running agent...\")\\n  events_async = runner.run_async(\\n      session_id=session.id, user_id=session.user_id, new_message=content\\n  )\\n\\n  async for event in events_async:\\n    print(f\"Event received: {event}\")\\n\\n  print(\"Closing MCP server connection...\")\\n  await exit_stack.aclose()\\n  print(\"Cleanup complete.\")\\n\\nif __name__ == \\'__main__\\':\\n  try:\\n    asyncio.run(async_main())\\n  except Exception as e:\\n      print(f\"An error occurred: {e}\")\\n```\\n\\nNow, run the application and see the agents in action.\\n\\n## Conclusion\\n\\nMCP makes it easier for agents to communicate with the tools that wrap external application services, and Agent2Agent makes it easier for multiple agents to communicate and collaborate. Both MCP and Agent2Agent are steps in the direction of standardising agent development. It would be interesting to see how they transform the agentic ecosystem.\\n\\n## Frequently Asked Questions (FAQ)\\n\\n### What exactly is MCP?\\n\\nMCP, or Model Context Protocol, is an open standard that lets AI agents interact with external tools and data sources through a consistent interface. It focuses on providing agents with reliable, structured access to resources such as APIs or databases.\\n\\n### What exactly is A2A?\\n\\nA2A, or Agent-to-Agent Protocol, defines how different AI agents communicate and collaborate. Its built for coordination and task delegation between agents rather than between an agent and a tool.\\n\\n### How do MCP and A2A differ in purpose?\\n\\nMCP focuses on vertical integration  connecting an agent with external tools and systems. A2A focuses on horizontal integration  allowing multiple agents to coordinate and share tasks. In short, MCP is about *tool use*, while A2A is about *agent collaboration*.\\n\\n### Can MCP and A2A be used together?\\n\\nYes. MCP and A2A are complementary. MCP gives agents the ability to use external tools, while A2A enables them to work together. Using both can help build richer and more capable AI systems.\\n\\n## Recommended Blogs\\n\\n[MCP\\n\\nOpen AI\\n\\n10/24/25\\n\\n### How to integrate Jira MCP with OpenAI Agent Builder?\\n\\nin\\n\\nShrijal](./jira-mcp-with-openai-agent-builder)\\n\\n[MCP\\n\\nOpen AI\\n\\n10/23/25\\n\\n### How to connect Salesforce MCP with OpenAI Agent Builder\\n\\nin\\n\\nRohit](./salesforce-mcp-with-openai-agent-builder)\\n\\n[Open AI\\n\\nMCP\\n\\n10/23/25\\n\\n### How to integrate Supabase with OpenAI Agent Builder\\n\\nin](./supabase-mcp-with-openai-agent-builder)\\n\\n[AI Agents\\n\\n10/23/25\\n\\n### 11 problems I have noticed building Agents (and fixes nobody talks about)\\n\\nin](./11-problems-i-have-noticed-building-agents-(and-fixes-nobody-talks-about))\\n\\nStay updated.\\n\\n[Join discord](https://dub.composio.dev/discord)\\n\\n[mcp](../mcp-gateway) gateway\\n\\n[pricing](../pricing)\\n\\n[agent auth](../agentauth)\\n\\n[docs](https://docs.composio.dev/getting-started/welcome)\\n\\n[blog](../blog)\\n\\n[OAuth2 guides](../auth)\\n\\n[Case Studies](../case-study)\\n\\n[Privacy Policy](../privacy)\\n\\n \\xa0Composio 2025\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 8: A Survey of Agent Interoperability Protocols: Model Context ... - arXiv ---\\nURL: https://arxiv.org/html/2505.02279v1\\n\\nSUMMARY:\\n*K*eywords\\u2002Large Language Models (LLMs), Agent Communication, Interoperability Protocols, Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), Agent Network Protocol (ANP), Autonomous Agents, Multimodal Messaging, Decentralized Identity (DID) In response to this gap, recent proposals such as the Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent2Agent Protocol (A2A) and Agent Network Protocol (ANP) aim to define lightweight, formal interfaces for context ingestion, performative messaging, and peer discovery using JSON-RPC schemas\\xa0[6, 10, 9, 11, 12]. Table\\xa03, Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)\") summarizes the most critical security threats identified across each lifecycle phase of MCP deployments, alongside their corresponding mitigation strategies and authoritative references.\\n\\nFULL CONTENT:\\n# A Survey of Agent Interoperability Protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)\\n\\nAbul Ehtesham   \\nKent State University   \\nKent, OH, USA   \\naehtesha@kent.edu   \\n  \\u2003\\u2003 Aditi Singh   \\nCleveland State University   \\nCleveland, OH, USA   \\na.singh22@csuohio.edu   \\n  \\u2003\\u2003 Gaurav Kumar Gupta   \\nYoungstown State University   \\nYoungstown, OH, USA   \\ngkgupta@student.ysu.edu   \\n  \\u2003\\u2003 Saket Kumar   \\nNortheastern University   \\nBoston, MA, USA   \\nkumar.sak@northeastern.edu\\n\\n###### Abstract\\n\\nLarge language model (LLM)-powered autonomous agents demand robust, standardized protocols to integrate tools, share contextual data, and coordinate tasks across heterogeneous systems. Ad-hoc integrations are difficult to scale, secure, and generalize across domains. This survey examines four emerging agent communication protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP), each addressing interoperability in distinct deployment contexts. MCP provides a JSON-RPC client-server interface for secure tool invocation and typed data exchange. ACP introduces REST-native messaging via multi-part messages and asynchronous streaming to support multimodal agent responses. A2A enables peer-to-peer task outsourcing through capability-based Agent Cards, facilitating enterprise-scale workflows. ANP supports open-network agent discovery and secure collaboration using decentralized identifiers (DIDs) and JSON-LD graphs. The protocols are compared across multiple dimensions, including interaction modes, discovery mechanisms, communication patterns, and security models. Based on the comparative analysis, a phased adoption roadmap is proposed: beginning with MCP for tool access, followed by ACP for multimodal messaging, A2A for collaborative task execution, and extending to ANP for decentralized agent marketplaces. This work provides a comprehensive foundation for designing secure, interoperable, and scalable ecosystems of LLM-powered agents.\\n\\n*K*eywords\\u2002Large Language Models (LLMs), Agent Communication, Interoperability Protocols, Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), Agent Network Protocol (ANP), Autonomous Agents, Multimodal Messaging, Decentralized Identity (DID)\\n\\n## 1 Introduction\\n\\nLarge Language Models (LLMs) have become central to modern artificial intelligence, powering autonomous agents that operate across cloud, edge, and desktop environments\\xa0[[1](https://arxiv.org/html/2505.02279v1#bib.bib1), [2](https://arxiv.org/html/2505.02279v1#bib.bib2)]. These agents\\xa0[[3](https://arxiv.org/html/2505.02279v1#bib.bib3)] ingest contextual information, execute tasks, and interact with external services or tools. However, inconsistent and fragmented interoperability practices make it difficult to integrate, secure, and scale communication among LLM-driven agents\\xa0[[4](https://arxiv.org/html/2505.02279v1#bib.bib4)].\\n\\nInteroperability (the ability of distinct agents and systems to discover capabilities, exchange context, and coordinate actions seamlessly) is essential for modular, reusable, and resilient multi-agent\\xa0[[5](https://arxiv.org/html/2505.02279v1#bib.bib5)] workflows. Standardized protocols reduce development overhead, improve security, and enable cross-platform collaboration. Clear, universally adopted standards remain nascent.\\n\\nThis survey examines four emerging agent communication protocols, each targeting a different interoperability tier:\\n\\n* \\n\\n  Model Context Protocol (MCP): a JSON-RPC clientserver interface for secure context ingestion and structured tool invocation\\xa0[[6](https://arxiv.org/html/2505.02279v1#bib.bib6), [7](https://arxiv.org/html/2505.02279v1#bib.bib7), [8](https://arxiv.org/html/2505.02279v1#bib.bib8)].\\n* \\n\\n  Agent-to-Agent Protocol (A2A): a peer-to-peer framework using capability-based Agent Cards over HTTP and Server-Sent Events for enterprise-scale task orchestration\\xa0[[9](https://arxiv.org/html/2505.02279v1#bib.bib9)].\\n* \\n\\n  Agent Communication Protocol (ACP): a REST-native performative messaging layer with multi-part messages, asynchronous streaming, and observability features for local multi-agent systems\\xa0[[10](https://arxiv.org/html/2505.02279v1#bib.bib10)].\\n* \\n\\n  Agent Network Protocol (ANP): a decentralized discovery and collaboration protocol built on decentralized identifiers (DIDs) and JSON-LD graphs for open-internet agent marketplaces \\xa0[[11](https://arxiv.org/html/2505.02279v1#bib.bib11), [12](https://arxiv.org/html/2505.02279v1#bib.bib12)].\\n\\nArchitectural details, integration approaches, communication patterns, and security considerations are reviewed for each protocol. A comparison highlights trade-offs in interaction modes, discovery mechanisms, communication models, and security frameworks. A phased adoption roadmap sequences MCP, A2A, ACP, and ANP to guide progressive deployment in real-world agent ecosystems.\\n\\nThe remainder of the paper is organized as follows. Section 2 discusses challenges in agent interoperability. Section 3 reviews background and related work. Sections 47 describe the architectures of MCP, A2A, ACP, and ANP, respectively. Section 8 presents the comparative evaluation. Section 9 outlines the phased adoption roadmap. Section 10 concludes and suggests future research directions.\\n\\n## 2 Challenges and Solutions in Agent Protocol Interoperability\\n\\nDespite the emergence of multiple open protocols like MCP, ACP, A2A, and ANP, achieving seamless agent interoperability in real-world AI systems remains a non-trivial task. This section identifies key challenges encountered in agent-based architectures and highlights how each protocol addresses them with purpose-built design principles.\\n\\nLack of Context Standardization for LLMs: Large Language Models (LLMs) require contextual grounding to produce accurate outputs. However, existing application architectures provide no unified mechanism to deliver structured context to LLMs, leading to ad hoc tool integrations and unreliable behavior. Solution: The Model Context Protocol (MCP) addresses this by standardizing how applications deliver tools, datasets, and sampling instructions to LLMs, akin to a USB-C for AI. It supports flexible plug-and-play tools, safe infrastructure integration, and compatibility across LLM vendors.\\n\\nCommunication Barriers Between Heterogeneous Agents: Enterprise systems often consist of agents built using different stacks and frameworks, resulting in isolated behavior and poor collaboration. Solution: The Agent Communication Protocol (ACP) offers a RESTful, SDK-optional interface with open governance under the Linux Foundation. It enables asynchronous-first interactions, offline discovery, and vendor-neutral execution, bridging interoperability gaps at scale.\\n\\nAbsence of Unified Agent Collaboration Standards: Even when agents communicate, theres no shared framework for dynamic negotiation, capability sharing, and coordination. Solution: The Agent2Agent (A2A) protocol introduces a multimodal communication standard to unlock dynamic interaction between opaque, autonomous agentsregardless of framework. It simplifies enterprise integration and supports shared task management and user experience negotiation.\\n\\nInternet-Agnostic Agent Communication: The modern internet is optimized for human interaction but suboptimal for autonomous agents, which require low-latency, API-native communication and decentralized identity validation. Solution: The Agent Network Protocol (ANP) provides a layered protocol architecture incorporating decentralized identity (W3C DID), semantic web principles, and encrypted communication to facilitate cross-platform agent collaboration over the open internet.\\n\\nTogether, these protocols aim to transform fragmented AI ecosystems into robust, secure, and interoperable agent networksscalable across organizational and vendor boundaries. See Table\\xa0[7](https://arxiv.org/html/2505.02279v1#S7.T7 \"Table 7  7.4 Security Considerations Across the ANP Lifecycle  7 ANP Architecture  A Survey of Agent Interoperability Protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)\") for a detailed comparative overview.\\n\\n## 3 Background and Related Work\\n\\nAutonomous agents powered by large language models (LLMs) are rapidly being adopted across industries to automate complex tasks, yet disparate frameworks and ad-hoc integrations hinder robust interoperability, security, and scalability\\xa0[[2](https://arxiv.org/html/2505.02279v1#bib.bib2), [4](https://arxiv.org/html/2505.02279v1#bib.bib4)]. Recent surveys have begun to characterize the landscape of LLM-based multi-agent systems, categorizing collaboration patterns, memory architectures, and orchestration strategies\\xa0[[13](https://arxiv.org/html/2505.02279v1#bib.bib13), [14](https://arxiv.org/html/2505.02279v1#bib.bib14), [15](https://arxiv.org/html/2505.02279v1#bib.bib15)]. However, these works largely focus on high-level workflows and neglect the underlying protocols necessary for dynamic peer discovery, capability negotiation, and secure tool invocation.\\n\\nEffective interoperabilityenabling agents to discover capabilities, share context, and coordinate actionsis critical for building modular, reusable, and resilient multi-agent systems. Early efforts in dynamic discovery have introduced metadata manifests and capability descriptors to allow runtime agent registration and lookup\\xa0[[16](https://arxiv.org/html/2505.02279v1#bib.bib16)], while recent work on automated tool testing frameworks (e.g., TOOLFUZZ) highlights the challenges of ensuring compatibility across evolving API surfaces\\xa0[[17](https://arxiv.org/html/2505.02279v1#bib.bib17)]. Yet, no unified protocol has emerged that specifies how agents should announce their interfaces, authenticate peers, or negotiate context sharing across heterogeneous LLM frameworks.\\n\\nIn response to this gap, recent proposals such as the Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent2Agent Protocol (A2A) and Agent Network Protocol (ANP) aim to define lightweight, formal interfaces for context ingestion, performative messaging, and peer discovery using JSON-RPC schemas\\xa0[[6](https://arxiv.org/html/2505.02279v1#bib.bib6), [10](https://arxiv.org/html/2505.02279v1#bib.bib10), [9](https://arxiv.org/html/2505.02279v1#bib.bib9), [11](https://arxiv.org/html/2505.02279v1#bib.bib11), [12](https://arxiv.org/html/2505.02279v1#bib.bib12)]. Each protocol is examined in detail, followed by a comparative analysis and a roadmap for their integration within emerging multi-agent ecosystems.\\n\\n### 3.1 AI Agents: Definition and Scope\\n\\nAn *AI agent* is defined as any autonomous software entity that perceives its environment through inputs (e.g., user queries, sensor data) and acts upon it via outputs (e.g., API calls, messages) to achieve designated goals\\xa0[[18](https://arxiv.org/html/2505.02279v1#bib.bib18)]. Agents operate within environments characterized along dimensions such as observability, determinism, episodicity, and dynamicity, and may employ sensors and actuators to interact with physical or virtual world models\\xa0[[18](https://arxiv.org/html/2505.02279v1#bib.bib18), [19](https://arxiv.org/html/2505.02279v1#bib.bib19)].\\n\\nAccording to Franklin and Graessers taxonomy, agents can be categorized based on attributes like autonomy, sociability, reactivity, and adaptability, reflecting their ability to function in open, multi-agent settings\\xa0[[20](https://arxiv.org/html/2505.02279v1#bib.bib20)]. Jennings emphasizes proactive goal generation, complex planning, and robust recovery capabilities under uncertainty as key distinguishing features from simple reactive programs\\xa0[[21](https://arxiv.org/html/2505.02279v1#bib.bib21)]. Wooldridge further identifies four core properties*autonomy*, *social ability*, *reactivity*, and *proactiveness*, that enables agents to operate without direct human intervention, collaborate with peers, and pursue longterm objectives\\xa0[[19](https://arxiv.org/html/2505.02279v1#bib.bib19)].\\n\\nAgent architectures span from simple rulebased reactive models, where actions are direct responses to percepts, to rich deliberative frameworks such as BeliefDesireIntention (BDI) systems that support symbolic reasoning, dynamic plan execution, and intention reconsideration. In multi-agent systems, coordination is achieved through communication protocols, negotiation strategies, and organizational structures, laying the groundwork for LLMpowered ecosystems that require robust interoperability, security, and scalability. This broad yet precise definition underpins our subsequent review of communication standards, orchestration frameworks, and protocol designs.\\n\\n### 3.2 Early Symbolic Agent LanguagesEvolution of Agent Communication Standards\\n\\nThe first formal agent messaging languages emerged in the early 1990s with the goal of providing a standardized envelope and performative vocabulary for knowledgebased systems. The Knowledge Query and Manipulation Language (KQML) introduced by Genesereth and Ketchpel defined a set of speechact performatives (e.g., askif, tell, reply) along with a flexible message envelope supporting parameters such as :content, :language, :ontology, :receiver, and :replywith. KQML also specified contentlanguage bindings (commonly KIF) to express propositions in a machineinterpretable form\\xa0[[22](https://arxiv.org/html/2505.02279v1#bib.bib22), [23](https://arxiv.org/html/2505.02279v1#bib.bib23)]. Although widely used in DARPAs Open Knowledge Base and Agent projects, KQMLs lack of formal semantics for performatives and heavyweight XMLstyle encodings hindered largescale deployments.\\n\\nBuilding on KQML, the FIPA Agent Communication Language (FIPAACL)ratified by the Foundation for Intelligent Physical Agents in 2000refined the notion of communicative acts by prescribing precise pre and postcondition semantics grounded in agents mental states (beliefs, desires, intentions). FIPAACL defined a richer set of performatives (e.g., agree, refuse, request), standardized content languages (e.g., SL0, SL1), and outlined interaction protocols for common patterns such as *contract net*, *iterated contract net*, and *subscribe/notify*\\xa0[[24](https://arxiv.org/html/2505.02279v1#bib.bib24)]. Reference implementations in platforms like JADE and JACK offered Javabased agent containers and messagehandling APIs, yet the complexity of FIPAs ontology management, coupled with verbose XML encodings, limited its uptake to academic and defense use cases rather than lightweight, industrygrade systems.\\n\\n### 3.3 Service-Oriented Integrations and Retrieval-Augmented Generation\\n\\nThe early 2000s witnessed the rise of service-oriented architectures (SOA), in which enterprise systems exposed functionality as web services (SOAP, WSDL, WS-\\\\* standards) and registered endpoints in UDDI repositories\\xa0[[25](https://arxiv.org/html/2505.02279v1#bib.bib25)]. Message-oriented middleware and enterprise service buses (ESBs) such as Apache Camel and Mule ESB facilitated protocol bridging, message routing, and payload transformation, leveraging patterns like content-based routing, message splitting, and aggregation\\xa0[[26](https://arxiv.org/html/2505.02279v1#bib.bib26)]. While SOA and ESBs decoupled service producers from consumers, they often incurred high operational complexity, brittle adapters, and configuration sprawl as APIs evolved and security requirements tightened.\\n\\nWith the advent of large language models, Retrieval-Augmented Generation (RAG) emerged in 2020 to integrate external knowledge into generation pipelines by coupling dense vector retrieval with autoregressive decoding\\xa0[[27](https://arxiv.org/html/2505.02279v1#bib.bib27)]. RAG systems encode queries and documents in a shared embedding space (e.g., DPR) to fetch top- relevant passages, then condition LLM outputs on retrieved context to reduce hallucinations and enable dynamic knowledge updates\\xa0[[28](https://arxiv.org/html/2505.02279v1#bib.bib28)]. Despite improving factuality and flexibility, RAG frameworks treat retrieval and generation as separate batch processes and do not prescribe how LLMs should translate grounded content into executable actions or orchestrate multi-step workflowshighlighting a need for protocol-level standards that unify knowledge grounding with action invocation.\\n\\n### 3.4 LLM Agents and Function Calling\\n\\nThe rapid evolution of large language models (LLMs) such as GPT-3.5, GPT-4, Claude, and Gemini has fundamentally transformed agent design by enabling zero- and few-shot understanding of complex natural language instructions without bespoke rule engines\\xa0[[2](https://arxiv.org/html/2505.02279v1#bib.bib2)]. These foundation models can parse user intent, plan multi-step workflows, and maintain dialogue coherence across diverse domains, opening the door to LLM agents that combine linguistic reasoning with external tool execution.\\n\\nTo operationalize tool use, OpenAI introduced function calling in 2023, a lightweight protocol whereby an LLM can output a JSON-formatted signature corresponding to a predefined API endpoint\\xa0[[29](https://arxiv.org/html/2505.02279v1#bib.bib29)]. Under this paradigm, developers supply the model with a catalog of function definitionseach described by a name, JSON schema for arguments, and descriptive help textand the model decides at generation time whether to invoke a function, emitting well-formed JSON that can be parsed and executed by downstream systems. This approach unifies natural language understanding and action invocation, enabling real-time data fetches, database queries, and transactional operations from within a single LLM response.\\n\\nBuilding on this core capability, several frameworks have emerged to simplify agent development:\\n\\n* \\n\\n  LangChain provides abstractions for chaining LLM calls, memory buffers, and function invocation in modular workflows, with built-in support for retrievers, vector stores, and agent loops\\xa0[[30](https://arxiv.org/html/2505.02279v1#bib.bib30)].\\n* \\n\\n  LlamaIndex (formerly GPT Index) focuses on integrating LLMs with custom knowledge bases, offering document loaders, index wrappers, and a tool registry that maps user queries to API calls\\xa0[[31](https://arxiv.org/html/2505.02279v1#bib.bib31)].\\n* \\n\\n  The OpenAI Plugin Store enables third-party tool providers to register plugins that expose RESTful interfaces, metadata, and authentication flows, which can be discovered and invoked by any model with plugin access\\xa0[[32](https://arxiv.org/html/2505.02279v1#bib.bib32)].\\n\\nDespite these advances, current function-calling ecosystems suffer from several limitations. Tool definitions are typically static: agents must be re-initialized whenever new APIs are added or schemas change, preventing truly dynamic discovery. Security boundariessuch as authentication tokens, rate limits, and access controlare ad-hoc and framework-specific, increasing the risk of unauthorized calls. Moreover, each framework employs its own metadata conventions, hindering cross-framework reuse of tools and requiring bespoke adapters for interoperability\\xa0[[33](https://arxiv.org/html/2505.02279v1#bib.bib33)]. Addressing these challenges requires protocol-level standards that prescribe a common schema for function metadata, dynamic capability negotiation, and end-to-end security guarantees across heterogeneous LLM agent platforms.\\n\\n### 3.5 Orchestration and Lightweight Agent Frameworks\\n\\nRecent advances have extended the capabilities of LLMs beyond reasoning to include orchestration of external tool invocation. Toolformer employs a self-supervised masking strategy that exposes potential API calls during pretraining, enabling the model to learn when and how to invoke functions as part of its text generation\\xa0[[34](https://arxiv.org/html/2505.02279v1#bib.bib34)]. ReAct interleaves chain-of-thought reasoning with explicit action calls, allowing models to alternate between thinking steps and tool invocations based on intermediate observations\\xa0[[35](https://arxiv.org/html/2505.02279v1#bib.bib35)]. These approaches unify reasoning and action at the single-agent level but do not address peer discovery or multi-agent coordination.\\n\\nComplementing these algorithmic techniques, several lightweight frameworks have emerged to suppprt multi-agent orchestration with minimal boilerplate (Table\\xa0[1](https://arxiv.org/html/2505.02279v1#S3.T1 \"Table 1  3.5 Orchestration and Lightweight Agent Frameworks  3 Background and Related Work  A Survey of Agent Interoperability Protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)\")). Additional orchestration systems, such as AutoGPTs autonomous loops\\xa0[[36](https://arxiv.org/html/2505.02279v1#bib.bib36)] and Reflexions iterative self-improvement mechanism\\xa0[[37](https://arxiv.org/html/2505.02279v1#bib.bib37)], highlight the value of feedback and adaptation in agent workflows, However, these frameworks continue to rely on static tool registries and bespoke communication layers. Across these approaches, the lack of a standardized protocol for capability advertisement, peer authentication, and cross-framework composition contributes to fragmentation-hindering the emergence of a cohesive, interoperable agent ecosystem.\\n\\nTable 1: Lightweight LLM Agent Frameworks\\n\\n| Framework | Core Feature | Reference |\\n| --- | --- | --- |\\n| CrewAI | High-level crew abstractions for role assignment, subtask delegation, and message routing among agents | [[38](https://arxiv.org/html/2505.02279v1#bib.bib38)] |\\n| SmolAgents | Single-file Python library combining retrieval, vision, and agent loop primitives for rapid prototyping | [[39](https://arxiv.org/html/2505.02279v1#bib.bib39)] |\\n| AG2 (AutoGen) | Open-source AgentOS with human-in-the-loop checkpoints, policy enforcement hooks, and lifecycle management | [[40](https://arxiv.org/html/2505.02279v1#bib.bib40)] |\\n| Semantic Kernel | Enterprise-grade SDK unifying memory stores, planning modules, and plugin orchestration across sessions | [[41](https://arxiv.org/html/2505.02279v1#bib.bib41)] |\\n| Swarm | Stateless multi-agent coordination via JSON-RPC routines, spawning and aggregating parallel agent tasks | [[42](https://arxiv.org/html/2505.02279v1#bib.bib42)] |\\n\\n### 3.6 Protocol Evolution Timeline\\n\\nThe evolution of agent interoperability is illustrated through a visual timeline (Figure\\xa0[2](https://arxiv.org/html/2505.02279v1#S3.F2 \"Figure 2  3.6 Protocol Evolution Timeline  3 Background and Related Work  A Survey of Agent Interoperability Protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)\")) and a detailed table (Table\\xa0[2](https://arxiv.org/html/2505.02279v1#S3.T2 \"Table 2  3.6 Protocol Evolution Timeline  3 Background and Related Work  A Survey of Agent Interoperability Protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)\")). The timeline captures high-level milestones, while the table offers technical detail, describing each development alongside key contributions. Together, these representations outline the trajectory of interoperability standards and protocols over time.\\n\\nTable 2: Timeline of Key Agent Interoperability Milestones\\n\\n| Year | Milestone | Key Contribution |\\n| --- | --- | --- |\\n| 1993 | KQML | Introduced speech-act primitives and a flexible message envelope for knowledge-based agents\\xa0[[22](https://arxiv.org/html/2505.02279v1#bib.bib22)]. |\\n| 1998 | MASIF | Defined basic service registration and discovery mechanisms for agent environments\\xa0[[43](https://arxiv.org/html/2505.02279v1#bib.bib43)]. |\\n| 2000 | FIPA-ACL | Standardized performative semantics, content languages, and interaction protocols with formal pre-/post-conditions\\xa0[[24](https://arxiv.org/html/2505.02279v1#bib.bib24)]. |\\n| 2002 | Web Services (SOAP/WSDL) | Enabled service-oriented agent integration via UDDI, XML messaging, and contract definitions\\xa0[[25](https://arxiv.org/html/2505.02279v1#bib.bib25)]. |\\n| 2006 | ESB Patterns | Codified enterprise integration patterns (routing, transformation) in ESBs like Apache Camel and Mule\\xa0[[26](https://arxiv.org/html/2505.02279v1#bib.bib26)]. |\\n| 2020 | RAG | Coupled dense vector retrieval with LLM decoding to ground outputs in external corpora\\xa0[[27](https://arxiv.org/html/2505.02279v1#bib.bib27)]. |\\n| 2023 | Function Calling | Allowed LLMs to emit JSON-formatted API calls against a catalog of function schemas\\xa0[[29](https://arxiv.org/html/2505.02279v1#bib.bib29)]. |\\n| 2023 | Toolformer | Trained LLMs via self-supervised masking to predict API call placement in text\\xa0[[34](https://arxiv.org/html/2505.02279v1#bib.bib34)]. |\\n| 2023 | ReAct | Interleaved chain-of-thought reasoning and explicit action calls for dynamic workflows\\xa0[[35](https://arxiv.org/html/2505.02279v1#bib.bib35)]. |\\n| 2024 | MCP | Proposed a JSON-RPC protocol for standardized context ingestion and tool invocation\\xa0[[6](https://arxiv.org/html/2505.02279v1#bib.bib6)]. |\\n| 2024 | ANP | Peer-to-peer protocol enabling cross-platform and cross-organization agent communication over the open internet.\\xa0[[11](https://arxiv.org/html/2505.02279v1#bib.bib11)]. |\\n| 2024 | ACP | Defined performative messaging primitives with formal types and security layers\\xa0[[10](https://arxiv.org/html/2505.02279v1#bib.bib10)]. |\\n| 2025 | A2A | Introduced peer discovery, capability exchange, and decentralized agent dialogues\\xa0[[9](https://arxiv.org/html/2505.02279v1#bib.bib9)]. |\\n\\nThree distinct evolutionary phases emerge:\\n\\n1. 1.\\n\\n   Symbolic and SOA Foundations (19932006): Early interoperability standards such as KQML and FIPA-ACL set formal semantic foundations. Subsequent developments in Web Services and Enterprise Service Bus (ESB) frameworks streamlined enterprise integration but introduced complexity and limited flexibility.\\n2. 2.\\n\\n   Retrieval and In-Model Action (20202023): Marked by the introduction of Retrieval-Augmented Generation (RAG), this phase leveraged vector-based retrieval to enhance the grounding of language model outputs. Innovations like Function Calling, Toolformer, and ReAct enabled LLMs to directly translate reasoning into executable API calls, significantly advancing agent autonomy and flexibility.\\n3. 3.\\n\\n   Protocol-Oriented Interoperability (20242025): The current phase emphasizes lightweight, standardized protocols such as MCP, ACP, ANP, and A2A. These protocols address previous limitations by enabling dynamic discovery, secure communication, and decentralized collaboration across heterogeneous agent systems, promoting scalability and robust interoperability.\\n\\n## 4 MCP\\n\\n### 4.1 Client Application (Host)\\n\\nThe Client Application (Host) serves as the initiator of interactions in the MCP ecosystem. It is responsible for managing connections to one or more MCP Servers and orchestrating communication workflows in accordance with protocol specifications. In practice, the client initializes sessions, requests and processes the four core primitives Resources, Tools, Prompts, and Sampling, and handles asynchronous notifications related to server-side events. The client must also implement robust error-handling routines to gracefully manage communication failures or timeout conditions, ensuring reliable coordination with remote MCP Servers.\\n\\n### 4.2 MCP Server (Providing Context & Capabilities)\\n\\nThe MCP Server functions as the provider of data, services, and interaction templates that the client can utilize to enrich LLM-based workflows. It exposes and manages contextual Resources, executes external operations via Tools, defines reusable Prompts for consistent interaction patterns, and optionally delegates text-generation tasks through Sampling. Beyond serving requests, the server is responsible for enforcing access control policies, maintaining operational security, and emitting notifications that reflect changes in its available capabilities. This provider-side architecture complements the clients orchestration logic by modularizing access to complex or dynamic resources.\\n\\n### 4.3 Core Components\\n\\nThe Model Context Protocol is composed of several layered abstractions that govern the structure and semantics of communication. At the foundation lies the Protocol Layer, which defines the semantics of message exchange using the JSON-RPC 2.0 specification. It ensures that each request is linked to a corresponding response and that all interactions conform to predictable patterns. Above this, the Transport Layer handles the physical transmission of messages between the client and server, supporting both local communication via Stdio and network-based channels such as HTTP with optional Server-Sent Events (SSE). At the highest abstraction, MCP organizes messages into four types: Requests, which are calls expecting replies; Results, which are successful responses to earlier requests; and Errors, which indicate failures or invalid invocations. A fourth type, Notifications, is used for asynchronous updates that do not require a client acknowledgment.\\n\\n### 4.4 MCP Server Core Capabilities\\n\\nThe MCP Server offers four core capabilities Tools, Resources, Prompts, and Sampling each mapped to a distinct control model that governs the interaction between the client, the server, and the LLM.\\n\\nTools are model-controlled capabilities that allow the LLM to invoke external APIs or services, often automatically and sometimes with user approval. This facilitates seamless integration with third-party systems and streamlines access to real-world data and operations.\\n\\nResources are application-controlled elements, such as structured documents or contextual dataset\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 9: A2A and MCP ---\\nURL: https://a2a-protocol.org/latest/topics/a2a-and-mcp/\\n\\nSUMMARY:\\n* A2A  MCP: Complementary Protocols for Agentic Systems * **Model Context Protocol (MCP)**: This protocol focuses on how an agent interacts with individual tools and resources, enabling an agent to utilize a specific tool, such as a database or an API. Each individual agent internally uses MCP to interact with its specific tools *An agentic application might use A2A to communicate with other agents, while each agent internally uses MCP to interact with its specific tools and resources.* Mechanic agent uses MCP to interact with its specialized tools. * MCP enables the mechanic agent to use its specific, structured tools to By leveraging both A2A for inter-agent collaboration and MCP for tool integration, developers can build more powerful, flexible, and interoperable AI systems.\\n\\nFULL CONTENT:\\n[Skip to content](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#a2a-and-mcp-detailed-comparison)\\n\\n\\n\\n* [Why Different Protocols?](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#why-different-protocols)\\n* [Model Context Protocol (MCP)](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#model-context-protocol-mcp)\\n* [Agent2Agent Protocol (A2A)](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#agent2agent-protocol-a2a)\\n* [A2A  MCP: Complementary Protocols for Agentic Systems](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#a2a-mcp-complementary-protocols-for-agentic-systems)\\n\\n  + [Example Scenario: The Auto Repair Shop](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#example-scenario-the-auto-repair-shop)\\n* [Representing A2A Agents as MCP Resources](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#representing-a2a-agents-as-mcp-resources)\\n\\n# A2A and MCP: Detailed Comparison[](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#a2a-and-mcp-detailed-comparison \"Permanent link\")\\n\\nIn AI agent development, two key protocol types emerge to facilitate\\ninteroperability. One connects agents to tools and resources. The other enables\\nagent-to-agent collaboration. The Agent2Agent (A2A) Protocol and the Model\\nContext Protocol (MCP) address these distinct but highly complementary needs.\\n\\n* **[Model Context Protocol (MCP)](https://modelcontextprotocol.io/)**: This protocol focuses on how an agent interacts with individual tools and resources, enabling an agent to utilize a specific tool, such as a database or an API.\\n* **Agent2Agent (A2A) Protocol**: This protocol focuses on how different agents collaborate with each other, enabling agents to work together to achieve a common goal.\\n\\nBoth protocols are crucial for building complex AI systems, and they address\\ndistinct but highly complementary needs.\\n\\n## Why Different Protocols?[](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#why-different-protocols \"Permanent link\")\\n\\nThe distinction between A2A and MCP arises from the nature of what an agent\\ninteracts with.\\n\\n* **Tools and Resources (MCP Domain)**:\\n  + **Characteristics:** These are typically primitives with well-defined,\\n    structured inputs and outputs. They perform specific, often stateless,\\n    functions. Examples include a calculator, a database query API, or a\\n    weather lookup service.\\n  + **Purpose:** Agents use tools to gather information and perform discrete\\n    functions.\\n* **Agents (A2A domain)**:\\n  + **Characteristics:** These are more autonomous systems. They reason,\\n    plan, use multiple tools, maintain state over longer interactions, and\\n    engage in complex, often multi-turn dialogues to achieve novel or\\n    evolving tasks.\\n  + **Purpose:** Agents collaborate with other agents to tackle broader, more\\n    complex goals.\\n\\n## Model Context Protocol (MCP)[](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#model-context-protocol-mcp \"Permanent link\")\\n\\n* Standardizes how AI models and agents connect to and interact with tools,\\n  APIs, data sources, and other external resources.\\n* Defines a structured way to describe tool capabilities, similar to\\n  function calling in Large Language Models.\\n* Passes inputs to tools and receives structured outputs.\\n* Use cases include enabling an LLM to call an external API, allowing an\\n  agent to query a database, or connecting an agent to a set of predefined\\n  functions.\\n\\n## Agent2Agent Protocol (A2A)[](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#agent2agent-protocol-a2a \"Permanent link\")\\n\\n* Standardizes how independent, often opaque, AI agents communicate and\\n  collaborate with each other as peers.\\n* Provides an application-level protocol for agents to discover each other,\\n  negotiate interaction modalities, manage shared Tasks, and exchange\\n  conversational context and complex Artifacts.\\n* Use cases include a customer service agent delegating an inquiry to a\\n  billing agent, or a travel agent coordinating with flight, hotel, and\\n  activity agents.\\n\\n## A2A  MCP: Complementary Protocols for Agentic Systems[](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#a2a-mcp-complementary-protocols-for-agentic-systems \"Permanent link\")\\n\\nAn agentic application might primarily use A2A to communicate with other agents.\\nEach individual agent internally uses MCP to interact with its specific tools\\nand resources.\\n\\n*An agentic application might use A2A to communicate with other agents, while each agent internally uses MCP to interact with its specific tools and resources.*\\n\\n### Example Scenario: The Auto Repair Shop[](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#example-scenario-the-auto-repair-shop \"Permanent link\")\\n\\nConsider an auto repair shop staffed by autonomous AI agent \"mechanics\".\\nThese mechanics use special-purpose tools, such as vehicle diagnostic scanners,\\nrepair manuals, and platform lifts, to diagnose and repair problems. The repair\\nprocess can involve extensive conversations, research, and interaction with part\\nsuppliers.\\n\\n* **Customer Interaction (User-to-Agent using A2A)**: A customer (or their\\n  primary assistant agent) uses A2A to communicate with the \"Shop Manager\"\\n  agent.\\n\\n  For example, the customer might say, \"My car is making a rattling noise\".\\n  - **Multi-turn Diagnostic Conversation (Agent-to-Agent using A2A)**: The Shop\\n  Manager agent uses A2A for a multi-turn diagnostic conversation.\\n\\n  For example,\\n  the Manager might ask, \"Can you send a video of the noise?\" or \"I see\\n  some fluid leaking. How long has this been happening?\".\\n  - **Internal Tool Usage (Agent-to-Tool using MCP)**: The Mechanic agent,\\n  assigned the task by the Shop Manager, needs to diagnose the issue. The\\n  Mechanic agent uses MCP to interact with its specialized tools.\\n\\n  For example:\\n  - MCP call to a \"Vehicle Diagnostic Scanner\" tool:\\n  `scan_vehicle_for_error_codes(vehicle_id=\\'XYZ123\\')`\\n  - MCP call to a \"Repair Manual Database\" tool:\\n  `get_repair_procedure(error_code=\\'P0300\\', vehicle_make=\\'Toyota\\',\\n  vehicle_model=\\'Camry\\')`\\n  - MCP call to a \"Platform Lift\" tool: `raise_platform(height_meters=2)`\\n  - **Supplier Interaction (Agent-to-Agent using A2A)**: The Mechanic agent\\n  determines that a specific part is needed. The Mechanic agent uses A2A to\\n  communicate with a \"Parts Supplier\" agent to order a part.\\n  For example, the\\n  Mechanic agent might ask, \"Do you have part #12345 in stock for a Toyota Camry 2018?\"\\n  - **Order processing (Agent-to-Agent using A2A)**: The Parts Supplier agent,\\n  which is also an A2A-compliant system, responds, potentially leading to an\\n  order.\\n\\nIn this example:\\n\\n* A2A facilitates the higher-level, conversational, and task-oriented\\n  interactions between the customer and the shop, and between the shop\\'s\\n  agents and external supplier agents.\\n* MCP enables the mechanic agent to use its specific, structured tools to\\n  perform its diagnostic and repair functions.\\n\\nAn A2A server could expose some of its skills as MCP-compatible resources.\\nHowever, A2A\\'s primary strength lies in its support for more flexible, stateful,\\nand collaborative interactions. These interactions go beyond a typical tool\\ninvocation. A2A focuses on agents partnering on tasks, whereas MCP focuses on\\nagents using capabilities.\\n\\n## Representing A2A Agents as MCP Resources[](https://a2a-protocol.org/latest/topics/a2a-and-mcp/#representing-a2a-agents-as-mcp-resources \"Permanent link\")\\n\\nAn A2A Server (a remote agent) could expose some of its skills as MCP-compatible resources, especially if those skills are well-defined and can be invoked in a more tool-like, stateless manner. In such a case, another agent might \"discover\" this A2A agent\\'s specific skill through an MCP-style tool description (perhaps derived from its Agent Card).\\n\\nHowever, the primary strength of A2A lies in its support for more flexible, stateful, and collaborative interactions that go beyond typical tool invocation. A2A is about agents *partnering* on tasks, while MCP is more about agents *using* capabilities.\\n\\nBy leveraging both A2A for inter-agent collaboration and MCP for tool integration, developers can build more powerful, flexible, and interoperable AI systems.\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 10: MCP vs. A2A - Descope ---\\nURL: https://www.descope.com/blog/post/mcp-vs-a2a\\n\\nSUMMARY:\\nWhile MCP focuses on helping LLMs interact with external data sources and tools, Googles A2A protocol enables autonomous agents to communicate and collaborate with one another. * **MCP** focuses on helping a single LLM or agent interact with external tools and data sources. * **Use MCP** when your primary need is for a single LLM to **draw from internal data or tools** to complete user tasks. Together, MCP and A2A represent a shift toward a more modular, cooperative future for AI systemsone where agents can access the right data, coordinate effectively, and adapt to complex workflows with less overhead. Moreover, Descope Inbound Apps and MCP Auth SDKs help developers add OAuth to their APIs and remote MCP servers for secure, scoped, and consented access.\\n\\nFULL CONTENT:\\nWe\\'ve extended and closed our seed funding round with $88M in total funding! [Read more >](https://www.descope.com/press-release/seed-funding-advisory-board)\\n\\n[Log In](https://app.descope.com)\\n\\n[Blog](/blog)\\n\\n# MCP vs. A2A\\n\\n[Auth Thoughts](/blog/auth-thoughts)\\n\\n[Alex Brown](/blog/author/alex-brown)\\n\\nContent Marketing Manager\\n\\nShare on:\\n\\n[Share on Blusky](https://bsky.app/intent/compose?text=)\\n\\nTable of Contents\\n\\nWhat is MCP?\\n\\nAs large language models (LLMs) move deeper into enterprise workflows, the need for seamless, scalable integration has become clear. Two emerging protocolsModel Context Protocol (MCP) and Agent-to-Agent (A2A)address this challenge from different angles. Both are designed to reduce complexity, streamline operations, and support smarter automation.\\n\\nBelow, we break down what each protocol does, how they work, and why theyre better together than apart.\\n\\n## What is MCP?\\n\\n[MCP](https://www.descope.com/learn/post/mcp) is an [open-source protocol](https://www.descope.com/learn/post/authentication-protocols) that standardizes how LLMs such as ChatGPT or Claude connect with data sources and tools. Without MCP, connecting an LLM with Google, GitHub, and other external sources often requires several unique application programming interfaces (APIs). With MCP, you can leverage one protocol across most use cases.\\n\\n[Anthropic developed MCP](https://www.anthropic.com/news/model-context-protocol) to address issues faced by developers and end users related to this complexity. For developers, the core issue is the NM problem, where N is the number of LLMs and M is the number of systems they need to integrate with. Each combination requires custom logic or infrastructure, leading to unsustainable complexity. For users, the main pain point is the friction caused by manually copying and pasting content between applications and interfaces.\\n\\nMCP introduces several innovations to address these challenges, including:\\n\\n* **Standardized contextualization**, enabling models to receive structured context across tools.\\n* **State synchronization**, allowing tools and agents to share memory or history with the model.\\n* **System interoperability,** ensuring consistent behavior across tools, apps, and services.\\n\\nThe benefits of MCP include faster and more scalable integration of LLMs into existing tech stacks, reduced development overhead, and smoother user workflows. However, as with any system that facilitates access to third-party tools, security considerationsparticularly around [authorization](https://www.descope.com/learn/post/authorization) mechanisms such as [OAuth](https://www.descope.com/learn/post/oauth)remain critical and must be carefully managed at the implementation level.\\n\\n### How MCP works\\n\\nThe underlying mechanisms that make MCP work are connections and trust between an LLM application and the bodies of data its authorized to access and process. This starts with a protocol handshake in which the client connects to MCP servers, determines what each dataset can do, and registers capabilities for future use in answering user demands.\\n\\nThen, when users make a request that requires external data, the following steps typically occur:\\n\\n* **Request analysis**: The LLM analyzes the users prompt and determines that it needs information beyond its current context.\\n* **User consent**: The LLM prompts the user to authorize access to the relevant external system or dataset, if needed.\\n* **Access request**: The LLM sends a structured request to the MCP server using a standardized schema.\\n* **Data provisioning**: The MCP server evaluates the request, checks permissions, and returns the appropriate data or tool output.\\n* **Context integration**: The LLM incorporates the new information into its session context.\\n* **Response generation**: The LLM uses the enriched context to generate a more accurate, informed response.\\n\\nThough this may seem like a multi-step workflow, the exchange typically happens in milliseconds, allowing users to receive responses without the hassle of repeatedly feeding information into the LLM to answer similar questions.\\n\\n## What is A2A?\\n\\nWhile MCP focuses on helping LLMs interact with external data sources and tools, Googles [A2A protocol](https://www.descope.com/learn/post/a2a) enables autonomous agents to communicate and collaborate with one another. [Google announced A2A](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/) in April of 2025, touting the massive collaborative effort that went into its development. The result of 50+ partners coming together was a solution that allows agents to work in concert in their raw states, even without sharing direct access to the same resources that agent-to-agent synchronicity typically needed.\\n\\nLike MCP, this protocol was born out of a necessity to simplify and scale LLM and agent utility. Additionally, Google lists **security**, **support for legacy processes**, and **modality agnosticism** (i.e., not tied to specific input/output formats like text, images, or speech) among the core design principles that make A2A what it is today.\\n\\nThrough this structure, A2A enables four foundational capabilities:\\n\\n* **Capability discovery**: Agents can query one another to identify which tools, actions, or processes are best suited to fulfilling a user\\'s request.\\n* **Task management**: Agents can determine and report on status dynamically as a task is being completed, communicating with each other to ensure synchronization throughout.\\n* **Collaboration**: Agents can ask each other questions, answer them semi-independently, and generate useful outputs such as artifacts or instructions for optimal user visibility.\\n* **UX negotiation**: Agents talk with each other to determine the best ways to present information to users, taking into account format, accessibility, and user background.\\n\\nTogether, these features allow agents to function more cooperatively across ecosystems, offering a more seamless experience for users and less custom integration work for developers. However, A2A is still in its early days. It doesnt yet support fully autonomous agent networks, and organizations must actively manage the evolving risks associated with early-stage interoperability protocols.\\n\\n### How A2A works\\n\\nA2A enables AI agentspowered by LLMs or similar modelsto communicate and collaborate via standardized protocols like HTTP, using structured JSON messages sent over an A2A server.\\n\\nBefore agents begin working together, they establish mutual trust through the exchange of Agent Cards. These cards describe an agents capabilities and supported actions without exposing proprietary implementation details, allowing interoperability without sacrificing privacy or security.\\n\\nThe typical A2A interaction unfolds as follows:\\n\\n* **User request:** A user prompts an AI agent to perform a complex task.\\n* **Agent coordination:** The initiating agent determines that it needs help from other agents to fulfill the request.\\n* **Agent card discovery:** The initiating agent reviews available Agent Cards to assess which other agents are best suited for specific subtasks.\\n* **Delegation:** The initiating agent delegates parts of the task to selected external agents.\\n* **Dynamic communication**: The agents communicate in real time, coordinating efforts and sharing intermediate results.\\n* **Progress updates:** The initiating agent provides the user with task status updates throughout the process.\\n* **Artifact generation:** Once the task is complete, the initiating agent compiles final outputs (e.g., reports, recommendations, or structured data artifacts).\\n\\nThis approach effectively helps a single AI tool to punch above its weight and marshal the expertise and functionality of multiple external agents. Thus delivering better results with less manual input from the user.\\n\\n**Read more:** [Outbound Apps: Connect AI Agents With External Tools](https://www.descope.com/blog/post/outbound-apps)\\n\\n## MCP vs. A2A or MCP + A2A?\\n\\nFor development teams considering how to streamline authentication, authorization, and system interoperability, understanding the difference between MCP and A2A is essential, but not always straightforward. Both protocols are designed to improve communication between systems and agents, and both can play a role in modernizing enterprise workflows.\\n\\nThe truth is: **MCP and A2A are more complementary than competitive**, and theyre designed to work together.\\n\\n* **MCP** focuses on helping a single LLM or agent interact with external tools and data sources.\\n* **A2A**, on the other hand, facilitates communication and collaboration between multiple agents, regardless of whether they share direct access to those same resources.\\n\\n### Security considerations\\n\\nBoth protocols can expand the \"surface area\" of interaction, introducing new layers of logic and communication. But neither MCP nor A2A inherently introduces more risk. Their security posture depends heavily on the configuration and vulnerabilities of the systems they connect to. In both cases, standard best practicessuch as robust authentication, least privilege access, and monitoringare essential.\\n\\n### Choosing (or combining) the right protocol\\n\\nThe best fit depends on your specific use case:\\n\\n* **Use MCP** when your primary need is for a single LLM to **draw from internal data or tools** to complete user tasks.\\n* **Use A2A** when youre focused on **coordinating multiple AI agents** to carry out more distributed or collaborative workflows.\\n\\nBut in most cases, the ideal approach is not either/orits both. When used in combination, they provide a foundation for LLMs to both access the tools they need **and** collaborate with other agents across systems.\\n\\nFor optimal results, both protocols should be implemented alongside a secure authorization stack, including features like multi-factor authentication (MFA) and fine-grained access controls, to ensure safety without sacrificing flexibility. All of this can often be achieved with minimal code overhead.\\n\\n## MCP and A2A: The beginning of a new era\\n\\nTogether, MCP and A2A represent a shift toward a more modular, cooperative future for AI systemsone where agents can access the right data, coordinate effectively, and adapt to complex workflows with less overhead. Whether you\\'re building smarter interfaces, streamlining internal tools, or experimenting with agent-based automation, these protocols offer a solid foundation.\\n\\nIf you\\'re looking to [secure AI apps, agents, or chatbots](https://www.descope.com/use-cases/ai), Descope can help. Using our drag & drop editor, you can add frictionless, secure authentication and access controls with built-in support for OAuth, SSO, SCIM, and fine-grained access control. Moreover, Descope [Inbound Apps](https://www.descope.com/blog/post/inbound-apps) and [MCP Auth SDKs](https://www.descope.com/blog/post/mcp-auth-sdk) help developers add OAuth to their APIs and remote MCP servers for secure, scoped, and consented access.\\n\\n[Sign up](https://www.descope.com/sign-up) for a free Descope account to get started or [book a demo](https://www.descope.com/demo) with our team to learn more.\\n\\nIdentity and auth news.\\n\\n  \\n\\nStraight to your inbox.\\n\\n## Liked what you saw?\\n\\nCheck out these posts next\\n\\n[### Diving Into the MCP Authorization Specification\\n\\nRead more](/blog/post/mcp-auth-spec)[### Securing Your APIs With Progressive Scoping\\n\\nRead more](/blog/post/progressive-scoping)[### MCP Auth SDKs & APIs: Secure Your Remote MCP Servers\\n\\nRead more](/blog/post/mcp-auth-sdk)\\n\\n[### Diving Into the MCP Authorization Specification\\n\\nRead more](/blog/post/mcp-auth-spec)[### Securing Your APIs With Progressive Scoping\\n\\nRead more](/blog/post/progressive-scoping)[### MCP Auth SDKs & APIs: Secure Your Remote MCP Servers\\n\\nRead more](/blog/post/mcp-auth-sdk)\\n\\n[Descope - Go to homepage](/)\\n\\n[Chat with Sales](https://start-chat.com/slack/descope/V5mA8i)\\n\\nAnonymously - no Slack account required\\n\\n\\n\\n---\\n\\n[Leave a Descope review](https://www.g2.com/products/descope/reviews)\\n\\n---\\n\\n[Github Icon Grey](https://github.com/descope)[Linkedin Icon Grey](https://www.linkedin.com/company/descope/)[X Grey Icon](https://twitter.com/descopeinc)[Instagram Grey Logo](https://www.instagram.com/descope.inc/)[Slack Grey Icon](http://authtown.slack.com/)[Youtube Grey Icon](https://www.youtube.com/@descope)[Bluesky Social](https://bsky.app/profile/descope.com)\\n\\n---\\n\\n[All systems operational](https://descopestatus.com)\\n\\nCopyright  Descope Inc. All rights reserved.\\n\\n--------------------------------------------------------------------------------\\n'}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Implementing MCP: Developer Workflow & SDKs', description='Details how developers build or consume MCP servers/clients, including available SDKs (Python, TypeScript, Java, Kotlin), local vs. remote deployment patterns, configuration in apps like Claude Desktop, and illustrative code snippets.', research=True, content='## Implementing MCP: Developer Workflow & SDKs\\n\\nOfficial SDKs exist for Python, TypeScript, Java, Kotlin, C#, Go, Swift and more, all published in the modelcontextprotocol org and exposing the same JSON-RPC primitives [1].  \\n\\nTypical workflow  \\n1 ) Install the SDK (`pip install fastmcp`, `npm i @modelcontextprotocol/sdk`, etc.).  \\n2 ) Describe Resources and Tools in code.  \\n3 ) Run the server with a local or remote transport.\\n\\n```python\\nfrom fastmcp import FastMCP\\nmcp = FastMCP(\"Demo\")\\n\\n@mcp.resource(\"article://{id}\")      # read-only context\\ndef article(id: str) -> str: \\n\\n@mcp.tool()                          # callable action\\ndef add(a: int, b: int) -> int: return a + b\\n\\nmcp.run(transport=\"stdio\")           # local pipe\\n``` [2]\\n\\nDeployment patterns  \\n Local: `stdio` launches the server as a child process; hosts such as Claude Desktop automatically open the pipe. Point the app at your binary by editing `claude_desktop_config.json` (`\"command\": \"/path/to/server\"`) [3].  \\n Remote: switch to the single-endpoint Streamable HTTP transport for cloud or container use; it supersedes the older dual-channel SSE model and works cleanly behind load-balancers [3].\\n\\nBecause the transports are interchangeable, moving from a laptop prototype to a production micro-service is often a one-line change (`transport=\"streamhttp\"` or `WithHttpTransport()`), while MCP clients continue to auto-discover your tools and resources unchanged.\\n\\n### Sources\\n[1] Model Context Protocol Servers README: https://github.com/modelcontextprotocol/servers  \\n[2] The Only Guide You Will Ever Need For Model Context Protocol: https://www.analyticsvidhya.com/blog/2025/07/model-context-protocol-mcp-guide/  \\n[3] Building MCP Servers for Any Language: https://dev.to/yigit-konur/building-mcp-servers-for-any-language-including-kotlin-ruby-rust-java-go-typescript--2ofi')], 'source_str': 'Search results: \\n\\n\\n\\n--- SOURCE 1: The Ultimate Model Context Protocol Directory - MCP Server Finder ---\\nURL: https://www.mcpserverfinder.com/servers\\n\\nSUMMARY:\\nA Model Context Protocol (MCP) server that provides SSH access to remote servers, allowing AI tools like Claude Desktop or VS Code to securely connect to your\\n\\n\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 2: modelcontextprotocol/servers: Model Context Protocol ... - GitHub ---\\nURL: https://github.com/modelcontextprotocol/servers\\n\\nSUMMARY:\\n[MIT license](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE) *   [Code](https://github.com/modelcontextprotocol/servers) *   [Issues 194](https://github.com/modelcontextprotocol/servers/issues) *   [Actions](https://github.com/modelcontextprotocol/servers/actions) *   [Insights](https://github.com/modelcontextprotocol/servers/pulse) *   [Code](https://github.com/modelcontextprotocol/servers) *   [Issues](https://github.com/modelcontextprotocol/servers/issues) *   [Actions](https://github.com/modelcontextprotocol/servers/actions) *   [Security](https://github.com/modelcontextprotocol/servers/security) *   [Insights](https://github.com/modelcontextprotocol/servers/pulse) *   [README](https://github.com/modelcontextprotocol/servers#) *   [Code of conduct](https://github.com/modelcontextprotocol/servers#) *   [Contributing](https://github.com/modelcontextprotocol/servers#) *   [MIT license](https://github.com/modelcontextprotocol/servers#) *   [Security](https://github.com/modelcontextprotocol/servers#) [](https://github.com/modelcontextprotocol/servers#-reference-servers) *   **[Filesystem](https://github.com/modelcontextprotocol/servers/blob/main/src/filesystem)** - Secure file operations with configurable access controls. *   **[Git](https://github.com/modelcontextprotocol/servers/blob/main/src/git)** - Tools to read, search, and manipulate Git repositories. [](https://github.com/modelcontextprotocol/servers#-getting-started) [](https://github.com/modelcontextprotocol/servers#using-mcp-servers-in-this-repository) For example, this will start the [Memory](https://github.com/modelcontextprotocol/servers/blob/main/src/memory) server: [](https://github.com/modelcontextprotocol/servers#using-an-mcp-client) [](https://github.com/modelcontextprotocol/servers#-contributing) See [CONTRIBUTING.md](https://github.com/modelcontextprotocol/servers/blob/main/CONTRIBUTING.md) for information about contributing to this repository. [](https://github.com/modelcontextprotocol/servers#-security) [](https://github.com/modelcontextprotocol/servers#-license) [](https://github.com/modelcontextprotocol/servers#-community) [](https://github.com/modelcontextprotocol/servers#-support) [Readme](https://github.com/modelcontextprotocol/servers#readme-ov-file) [MIT license](https://github.com/modelcontextprotocol/servers#MIT-1-ov-file) [Code of conduct](https://github.com/modelcontextprotocol/servers#coc-ov-file) [Contributing](https://github.com/modelcontextprotocol/servers#contributing-ov-file) [Security policy](https://github.com/modelcontextprotocol/servers#security-ov-file) [Please reload this page](https://github.com/modelcontextprotocol/servers). [Activity](https://github.com/modelcontextprotocol/servers/activity) [**71k** stars](https://github.com/modelcontextprotocol/servers/stargazers) [**519** watching](https://github.com/modelcontextprotocol/servers/watchers) [**8.5k** forks](https://github.com/modelcontextprotocol/servers/forks) [Releases 20](https://github.com/modelcontextprotocol/servers/releases) [+ 19 releases](https://github.com/modelcontextprotocol/servers/releases) [Please reload this page](https://github.com/modelcontextprotocol/servers). *   [TypeScript 58.0%](https://github.com/modelcontextprotocol/servers/search?l=typescript) *   [Python 21.7%](https://github.com/modelcontextprotocol/servers/search?l=python) *   [JavaScript 18.2%](https://github.com/modelcontextprotocol/servers/search?l=javascript) *   [Dockerfile 2.1%](https://github.com/modelcontextprotocol/servers/search?l=dockerfile)\\n\\nFULL CONTENT:\\nGitHub - modelcontextprotocol/servers: Model Context Protocol Servers\\n\\n===============\\n\\n[Skip to content](https://github.com/modelcontextprotocol/servers#start-of-content)\\nNavigation Menu\\n---------------\\n\\nToggle navigation\\n\\n[](https://github.com/)\\n\\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers)\\n\\nAppearance settings\\n\\n*    Platform \\n\\n    *   [GitHub Copilot Write better code with AI](https://github.com/features/copilot)\\n    *   [GitHub Spark New Build and deploy intelligent apps](https://github.com/features/spark)\\n    *   [GitHub Models New Manage and compare prompts](https://github.com/features/models)\\n    *   [GitHub Advanced Security Find and fix vulnerabilities](https://github.com/security/advanced-security)\\n    *   [Actions Automate any workflow](https://github.com/features/actions)\\n\\n    *   [Codespaces Instant dev environments](https://github.com/features/codespaces)\\n    *   [Issues Plan and track work](https://github.com/features/issues)\\n    *   [Code Review Manage code changes](https://github.com/features/code-review)\\n    *   [Discussions Collaborate outside of code](https://github.com/features/discussions)\\n    *   [Code Search Find more, search less](https://github.com/features/code-search)\\n\\nExplore\\n    *   [Why GitHub](https://github.com/why-github)\\n    *   [Documentation](https://docs.github.com/)\\n    *   [GitHub Skills](https://skills.github.com/)\\n    *   [Blog](https://github.blog/)\\n\\nIntegrations\\n    *   [GitHub Marketplace](https://github.com/marketplace)\\n    *   [MCP Registry](https://github.com/mcp)\\n\\n[View all features](https://github.com/features)\\n\\n*    Solutions \\n\\nBy company size\\n    *   [Enterprises](https://github.com/enterprise)\\n    *   [Small and medium teams](https://github.com/team)\\n    *   [Startups](https://github.com/enterprise/startups)\\n    *   [Nonprofits](https://github.com/solutions/industry/nonprofits)\\n\\nBy use case\\n    *   [App Modernization](https://github.com/solutions/use-case/app-modernization)\\n    *   [DevSecOps](https://github.com/solutions/use-case/devsecops)\\n    *   [DevOps](https://github.com/solutions/use-case/devops)\\n    *   [CI/CD](https://github.com/solutions/use-case/ci-cd)\\n    *   [View all use cases](https://github.com/solutions/use-case)\\n\\nBy industry\\n    *   [Healthcare](https://github.com/solutions/industry/healthcare)\\n    *   [Financial services](https://github.com/solutions/industry/financial-services)\\n    *   [Manufacturing](https://github.com/solutions/industry/manufacturing)\\n    *   [Government](https://github.com/solutions/industry/government)\\n    *   [View all industries](https://github.com/solutions/industry)\\n\\n[View all solutions](https://github.com/solutions)\\n\\n*    Resources \\n\\nTopics\\n    *   [AI](https://github.com/resources/articles?topic=ai)\\n    *   [DevOps](https://github.com/resources/articles?topic=devops)\\n    *   [Security](https://github.com/resources/articles?topic=security)\\n    *   [Software Development](https://github.com/resources/articles?topic=software-development)\\n    *   [View all](https://github.com/resources/articles)\\n\\nExplore\\n    *   [Learning Pathways](https://resources.github.com/learn/pathways)\\n    *   [Events & Webinars](https://github.com/resources/events)\\n    *   [Ebooks & Whitepapers](https://github.com/resources/whitepapers)\\n    *   [Customer Stories](https://github.com/customer-stories)\\n    *   [Partners](https://github.com/partners)\\n    *   [Executive Insights](https://github.com/solutions/executive-insights)\\n\\n*    Open Source \\n\\n    *   [GitHub Sponsors Fund open source developers](https://github.com/sponsors)\\n\\n    *   [The ReadME Project GitHub community articles](https://github.com/readme)\\n\\nRepositories\\n    *   [Topics](https://github.com/topics)\\n    *   [Trending](https://github.com/trending)\\n    *   [Collections](https://github.com/collections)\\n\\n*    Enterprise \\n\\n    *   [Enterprise platform AI-powered developer platform](https://github.com/enterprise)\\n\\nAvailable add-ons\\n    *   [GitHub Advanced Security Enterprise-grade security features](https://github.com/security/advanced-security)\\n    *   [Copilot for business Enterprise-grade AI features](https://github.com/features/copilot/copilot-business)\\n    *   [Premium Support Enterprise-grade 24/7 support](https://github.com/premium-support)\\n\\n*   [Pricing](https://github.com/pricing)\\n\\nSearch or jump to...\\n\\nSearch code, repositories, users, issues, pull requests...\\n==========================================================\\n\\n Search  \\n\\nClear\\n\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n\\nProvide feedback\\n================\\n\\nWe read every piece of feedback, and take your input very seriously.\\n\\n- [x] Include my email address so I can be contacted \\n\\n Cancel  Submit feedback \\n\\nSaved searches\\n==============\\n\\nUse saved searches to filter your results more quickly\\n------------------------------------------------------\\n\\nName \\n\\nQuery \\n\\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\n\\n Cancel  Create saved search \\n\\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers)\\n\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=modelcontextprotocol%2Fservers)\\n\\nAppearance settings\\n\\nResetting focus\\n\\nYou signed in with another tab or window. [Reload](https://github.com/modelcontextprotocol/servers) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/modelcontextprotocol/servers) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/modelcontextprotocol/servers) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[modelcontextprotocol](https://github.com/modelcontextprotocol)/**[servers](https://github.com/modelcontextprotocol/servers)**Public\\n\\n*   [Notifications](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)You must be signed in to change notification settings\\n*   [Fork 8.5k](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)\\n*   [Star 71k](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers) \\n\\nModel Context Protocol Servers\\n\\n[modelcontextprotocol.io](https://modelcontextprotocol.io/ \"https://modelcontextprotocol.io\")\\n\\n### License\\n\\n[MIT license](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE)\\n\\n[71k stars](https://github.com/modelcontextprotocol/servers/stargazers)[8.5k forks](https://github.com/modelcontextprotocol/servers/forks)[Branches](https://github.com/modelcontextprotocol/servers/branches)[Tags](https://github.com/modelcontextprotocol/servers/tags)[Activity](https://github.com/modelcontextprotocol/servers/activity)\\n\\n[Star](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)\\n\\n[Notifications](https://github.com/login?return_to=%2Fmodelcontextprotocol%2Fservers)You must be signed in to change notification settings\\n\\n*   [Code](https://github.com/modelcontextprotocol/servers)\\n*   [Issues 194](https://github.com/modelcontextprotocol/servers/issues)\\n*   [Pull requests 80](https://github.com/modelcontextprotocol/servers/pulls)\\n*   [Actions](https://github.com/modelcontextprotocol/servers/actions)\\n*   [Security### Uh oh! There was an error while loading. [Please reload this page](https://github.com/modelcontextprotocol/servers).](https://github.com/modelcontextprotocol/servers/security)\\n*   [Insights](https://github.com/modelcontextprotocol/servers/pulse)\\n\\nAdditional navigation options\\n\\n*   [Code](https://github.com/modelcontextprotocol/servers)\\n*   [Issues](https://github.com/modelcontextprotocol/servers/issues)\\n*   [Pull requests](https://github.com/modelcontextprotocol/servers/pulls)\\n*   [Actions](https://github.com/modelcontextprotocol/servers/actions)\\n*   [Security](https://github.com/modelcontextprotocol/servers/security)\\n*   [Insights](https://github.com/modelcontextprotocol/servers/pulse)\\n\\nmodelcontextprotocol/servers\\n============================\\n\\nmain\\n\\n[Branches](https://github.com/modelcontextprotocol/servers/branches)[Tags](https://github.com/modelcontextprotocol/servers/tags)\\n\\n[](https://github.com/modelcontextprotocol/servers/branches)[](https://github.com/modelcontextprotocol/servers/tags)\\n\\nGo to file\\n\\nCode\\n\\nOpen more actions menu\\n\\nFolders and files\\n-----------------\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| Latest commit ------------- History ------- [3,688 Commits](https://github.com/modelcontextprotocol/servers/commits/main/) [](https://github.com/modelcontextprotocol/servers/commits/main/) |\\n| [.github](https://github.com/modelcontextprotocol/servers/tree/main/.github \".github\") | [.github](https://github.com/modelcontextprotocol/servers/tree/main/.github \".github\") |  |  |\\n| [.vscode](https://github.com/modelcontextprotocol/servers/tree/main/.vscode \".vscode\") | [.vscode](https://github.com/modelcontextprotocol/servers/tree/main/.vscode \".vscode\") |  |  |\\n| [scripts](https://github.com/modelcontextprotocol/servers/tree/main/scripts \"scripts\") | [scripts](https://github.com/modelcontextprotocol/servers/tree/main/scripts \"scripts\") |  |  |\\n| [src](https://github.com/modelcontextprotocol/servers/tree/main/src \"src\") | [src](https://github.com/modelcontextprotocol/servers/tree/main/src \"src\") |  |  |\\n| [.gitattributes](https://github.com/modelcontextprotocol/servers/blob/main/.gitattributes \".gitattributes\") | [.gitattributes](https://github.com/modelcontextprotocol/servers/blob/main/.gitattributes \".gitattributes\") |  |  |\\n| [.gitignore](https://github.com/modelcontextprotocol/servers/blob/main/.gitignore \".gitignore\") | [.gitignore](https://github.com/modelcontextprotocol/servers/blob/main/.gitignore \".gitignore\") |  |  |\\n| [.npmrc](https://github.com/modelcontextprotocol/servers/blob/main/.npmrc \".npmrc\") | [.npmrc](https://github.com/modelcontextprotocol/servers/blob/main/.npmrc \".npmrc\") |  |  |\\n| [CODE_OF_CONDUCT.md](https://github.com/modelcontextprotocol/servers/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\") | [CODE_OF_CONDUCT.md](https://github.com/modelcontextprotocol/servers/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\") |  |  |\\n| [CONTRIBUTING.md](https://github.com/modelcontextprotocol/servers/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") | [CONTRIBUTING.md](https://github.com/modelcontextprotocol/servers/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\") |  |  |\\n| [LICENSE](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE \"LICENSE\") | [LICENSE](https://github.com/modelcontextprotocol/servers/blob/main/LICENSE \"LICENSE\") |  |  |\\n| [README.md](https://github.com/modelcontextprotocol/servers/blob/main/README.md \"README.md\") | [README.md](https://github.com/modelcontextprotocol/servers/blob/main/README.md \"README.md\") |  |  |\\n| [SECURITY.md](https://github.com/modelcontextprotocol/servers/blob/main/SECURITY.md \"SECURITY.md\") | [SECURITY.md](https://github.com/modelcontextprotocol/servers/blob/main/SECURITY.md \"SECURITY.md\") |  |  |\\n| [package-lock.json](https://github.com/modelcontextprotocol/servers/blob/main/package-lock.json \"package-lock.json\") | [package-lock.json](https://github.com/modelcontextprotocol/servers/blob/main/package-lock.json \"package-lock.json\") |  |  |\\n| [package.json](https://github.com/modelcontextprotocol/servers/blob/main/package.json \"package.json\") | [package.json](https://github.com/modelcontextprotocol/servers/blob/main/package.json \"package.json\") |  |  |\\n| [tsconfig.json](https://github.com/modelcontextprotocol/servers/blob/main/tsconfig.json \"tsconfig.json\") | [tsconfig.json](https://github.com/modelcontextprotocol/servers/blob/main/tsconfig.json \"tsconfig.json\") |  |  |\\n| View all files |\\n\\nRepository files navigation\\n---------------------------\\n\\n*   [README](https://github.com/modelcontextprotocol/servers#)\\n*   [Code of conduct](https://github.com/modelcontextprotocol/servers#)\\n*   [Contributing](https://github.com/modelcontextprotocol/servers#)\\n*   [MIT license](https://github.com/modelcontextprotocol/servers#)\\n*   [Security](https://github.com/modelcontextprotocol/servers#)\\n\\nModel Context Protocol servers\\n==============================\\n\\n[](https://github.com/modelcontextprotocol/servers#model-context-protocol-servers)\\n\\nThis repository is a collection of _reference implementations_ for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references to community-built servers and additional resources.\\n\\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources. Typically, each MCP server is implemented with an MCP SDK:\\n\\n*   [C# MCP SDK](https://github.com/modelcontextprotocol/csharp-sdk)\\n*   [Go MCP SDK](https://github.com/modelcontextprotocol/go-sdk)\\n*   [Java MCP SDK](https://github.com/modelcontextprotocol/java-sdk)\\n*   [Kotlin MCP SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\\n*   [PHP MCP SDK](https://github.com/modelcontextprotocol/php-sdk)\\n*   [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\\n*   [Ruby MCP SDK](https://github.com/modelcontextprotocol/ruby-sdk)\\n*   [Rust MCP SDK](https://github.com/modelcontextprotocol/rust-sdk)\\n*   [Swift MCP SDK](https://github.com/modelcontextprotocol/swift-sdk)\\n*   [TypeScript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk)\\n\\nNote\\n\\nLists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\\n\\n Reference Servers\\n--------------------\\n\\n[](https://github.com/modelcontextprotocol/servers#-reference-servers)\\n\\nThese servers aim to demonstrate MCP features and the official SDKs.\\n\\n*   **[Everything](https://github.com/modelcontextprotocol/servers/blob/main/src/everything)** - Reference / test server with prompts, resources, and tools.\\n*   **[Fetch](https://github.com/modelcontextprotocol/servers/blob/main/src/fetch)** - Web content fetching and conversion for efficient LLM usage.\\n*   **[Filesystem](https://github.com/modelcontextprotocol/servers/blob/main/src/filesystem)** - Secure file operations with configurable access controls.\\n*   **[Git](https://github.com/modelcontextprotocol/servers/blob/main/src/git)** - Tools to read, search, and manipulate Git repositories.\\n*   **[Memory](https://github.com/modelcontextprotocol/servers/blob/main/src/memory)** - Knowledge graph-based persistent memory system.\\n*   **[Sequential Thinking](https://github.com/modelcontextprotocol/servers/blob/main/src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences.\\n*   **[Time](https://github.com/modelcontextprotocol/servers/blob/main/src/time)** - Time and timezone conversion capabilities.\\n\\n### Archived\\n\\n[](https://github.com/modelcontextprotocol/servers#archived)\\n\\nThe following reference servers are now archived and can be found at [servers-archived](https://github.com/modelcontextprotocol/servers-archived).\\n\\n*   **[AWS KB Retrieval](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime.\\n*   **[Brave Search](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search)** - Web and local search using Brave\\'s Search API. Has been replaced by the [official server](https://github.com/brave/brave-search-mcp-server).\\n*   **[EverArt](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/everart)** - AI image generation using various models.\\n*   **[GitHub](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/github)** - Repository management, file operations, and GitHub API integration.\\n*   **[GitLab](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gitlab)** - GitLab API, enabling project management.\\n*   **[Google Drive](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gdrive)** - File access and search capabilities for Google Drive.\\n*   **[Google Maps](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/google-maps)** - Location services, directions, and place details.\\n*   **[PostgreSQL](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres)** - Read-only database access with schema inspection.\\n*   **[Puppeteer](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer)** - Browser automation and web scraping.\\n*   **[Redis](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/redis)** - Interact with Redis key-value stores.\\n*   **[Sentry](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sentry)** - Retrieving and analyzing issues from Sentry.io.\\n*   **[Slack](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)** - Channel management and messaging capabilities. Now maintained by [Zencoder](https://github.com/zencoderai/slack-mcp-server)\\n*   **[SQLite](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sqlite)** - Database interaction and business intelligence capabilities.\\n\\n Third-Party Servers\\n----------------------\\n\\n[](https://github.com/modelcontextprotocol/servers#-third-party-servers)\\n\\n###  Official Integrations\\n\\n[](https://github.com/modelcontextprotocol/servers#%EF%B8%8F-official-integrations)\\n\\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\\n\\n*   [![Image 1: 21st.dev Logo](https://camo.githubusercontent.com/ef5a9519983d6587ccd70a7bee6285138d209055be84391a3dc3fa6f41d7d747/68747470733a2f2f7777772e323173742e6465762f66617669636f6e2e69636f)](https://camo.githubusercontent.com/ef5a9519983d6587ccd70a7bee6285138d209055be84391a3dc3fa6f41d7d747/68747470733a2f2f7777772e323173742e6465762f66617669636f6e2e69636f)**[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.\\n*   [![Image 2: 2slides Logo](https://camo.githubusercontent.com/9924f54cbd55fc75b3eda001a6a5e090093919812255deac17f3e52eb190c938/68747470733a2f2f7777772e32736c696465732e636f6d2f696d616765732f32736c696465732d7265642e737667)](https://camo.githubusercontent.com/9924f54cbd55fc75b3eda001a6a5e090093919812255deac17f3e52eb190c938/68747470733a2f2f7777772e32736c696465732e636f6d2f696d616765732f32736c696465732d7265642e737667)**[2slides](https://github.com/2slides/2slides-mcp)** - An MCP server that provides tools to convert content into slides/PPT/presentation or generate slides/PPT/presentation with user intention.\\n*   [![Image 3: Paragon Logo](https://camo.githubusercontent.com/5d19f99fb4a7a1b10a0265ff5d0dd956baf8cd2d5e24c19151d640d5440f3726/68747470733a2f2f6672616d657275736572636f6e74656e742e636f6d2f696d616765732f4c70534b3174535a77656f6d7241484f4d416a3947656139366c412e737667)](https://camo.githubusercontent.com/5d19f99fb4a7a1b10a0265ff5d0dd956baf8cd2d5e24c19151d640d5440f3726/68747470733a2f2f6672616d657275736572636f6e74656e742e636f6d2f696d616765732f4c70534b3174535a77656f6d7241484f4d416a3947656139366c412e737667)**[ActionKit by Paragon](https://github.com/useparagon/paragon-mcp)** - Connect to 130+ SaaS integrations (e.g. Slack, Salesforce, Gmail) with Paragons [ActionKit](https://www.useparagon.com/actionkit) API.\\n*   [![Image 4: Adfin Logo](https://camo.githubusercontent.com/978f3390d19c95bde1012aac19eeb95da45d543255a90e2c98c648beb361a1c9/68747470733a2f2f696e766f78782d7075626c69632d6275636b65742e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f66726f6e74656e642d7265736f75726365732f616466696e2d6c6f676f2d736d616c6c2e737667)](https://camo.githubusercontent.com/978f3390d19c95bde1012aac19eeb95da45d543255a90e2c98c648beb361a1c9/68747470733a2f2f696e766f78782d7075626c69632d6275636b65742e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f66726f6e74656e642d7265736f75726365732f616466696e2d6c6f676f2d736d616c6c2e737667)**[Adfin](https://github.com/Adfin-Engineering/mcp-server-adfin)** - The only platform you need to get paid - all payments in one place, invoicing and accounting reconciliations with [Adfin](https://www.adfin.com/).\\n*   [![Image 5: AgentOps Logo](https://github.com/AgentOps-AI/agentops/raw/main/docs/favicon.png)](https://github.com/AgentOps-AI/agentops/blob/main/docs/favicon.png)**[AgentOps](https://github.com/AgentOps-AI/agentops-mcp)** - Provide observability and tracing for debugging AI agents with [AgentOps](https://www.agentops.ai/) API.\\n*   [![Image 6: AgentQL Logo](https://camo.githubusercontent.com/baeb7ec1139c8feb93a05f587971757c3f128bf8f02c12cc5b56a2049b133f45/68747470733a2f2f7777772e6167656e74716c2e636f6d2f66617669636f6e2f66617669636f6e2e706e67)](https://camo.githubusercontent.com/baeb7ec1139c8feb93a05f587971757c3f128bf8f02c12cc5b56a2049b133f45/68747470733a2f2f7777772e6167656e74716c2e636f6d2f66617669636f6e2f66617669636f6e2e706e67)**[AgentQL](https://github.com/tinyfish-io/agentql-mcp)** - Enable AI agents to get structured data from unstructured web with [AgentQL](https://www.agentql.com/).\\n*   [![Image 7: AgentRPC Logo](https://camo.githubusercontent.com/75fe1b227f93614c9cf9dc684227b7f7ea8e9f84967f29dba14fe2618cf02833/68747470733a2f2f6167656e747270632e636f6d2f66617669636f6e2e69636f)](https://camo.githubusercontent.com/75fe1b227f93614c9cf9dc684227b7f7ea8e9f84967f29dba14fe2618cf02833/68747470733a2f2f6167656e747270632e636f6d2f66617669636f6e2e69636f)**[AgentRPC](https://github.com/agentrpc/agentrpc)** - Connect to any function, any language, across network boundaries using [AgentRPC](https://www.agentrpc.com/).\\n*   **[Agentset](https://github.com/agentset-ai/mcp-server)** - RAG for your knowledge base connected to [Agentset](https://agentset.ai/).\\n*   [![Image 8: Aiven Logo](https://camo.githubusercontent.com/b9e8399c9193817a478aa3db8b3910a49922e622191ebf2c69562775a60d5c2a/68747470733a2f2f616976656e2e696f2f66617669636f6e2e69636f)](https://camo.githubusercontent.com/b9e8399c9193817a478aa3db8b3910a49922e622191ebf2c69562775a60d5c2a/68747470733a2f2f616976656e2e696f2f66617669636f6e2e69636f)**[Aiven](https://github.com/Aiven-Open/mcp-aiven)** - Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL, Apache Kafka, ClickHouse and OpenSearch services\\n*   [![Image 9: Alation Logo](https://camo.githubusercontent.com/9276a04adea6e587b34015ffa566eba997517f66aa9a7f329c7382ad5736be88/68747470733a2f2f7777772e616c6174696f6e2e636f6d2f7265736f757263652d63656e7465722f646f776e6c6f61642f377033766e62627a6e6669772f3334464d7442546578357070767332684e59613946632f63383737633337653838653533333938373836353836393763343664326435382f416c6174696f6e2d4c6f676f2d4275672d5072696d6172792e737667)](https://camo.githubusercontent.com/9276a04adea6e587b34015ffa566eba997517f66aa9a7f329c7382ad5736be88/68747470733a2f2f7777772e616c6174696f6e2e636f6d2f7265736f757263652d63656e7465722f646f776e6c6f61642f377033766e62627a6e6669772f3334464d7442546578357070767332684e59613946632f63383737633337653838653533333938373836353836393763343664326435382f416c6174696f6e2d4c6f676f2d4275672d5072696d6172792e737667)**[Alation](https://github.com/Alation/alation-ai-agent-sdk)** - Unlock the power of the enterprise Data Catalog by harnessing tools provided by the Alation MCP server.\\n*   [![Image 10: Alby Logo](https://camo.githubusercontent.com/517f3cfab19a84df59740752b29438273cf295fd7e26f95bee4faa76b873739f/68747470733a2f2f692e706f7374696d672e63632f354e597739716a532f616c62792d69636f6e2d686561642d79656c6c6f772d353030783530302e706e67)](https://camo.githubusercontent.com/517f3cfab19a84df59740752b29438273cf295fd7e26f95bee4faa76b873739f/68747470733a2f2f692e706f7374696d672e63632f354e597739716a532f616c62792d69636f6e2d686561642d79656c6c6f772d353030783530302e706e67)**[Alby Bitcoin Payments](https://github.com/getAlby/mcp)** - Connect any bitcoin lightning wallet to your agent to send and receive instant payments globally with your agent.\\n*   **[Algolia](https://github.com/algolia/mcp)** - Use AI agents to provision, configure, and query your [Algolia](https://algolia.com/) search indices.\\n*   [![Image 11: Alibaba Cloud AnalyticDB for MySQL Logo](https://camo.githubusercontent.com/7cb82e1b6c37954f3435a9079ed7ea0d143776e473632d5f0a8e7f76174a315b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69342f4f31434e303165706b58774831574c41586b5a6656364e5f2121363030303030303030323737312d322d7470732d3230302d3230302e706e67)](https://camo.githubusercontent.com/7cb82e1b6c37954f3435a9079ed7ea0d143776e473632d5f0a8e7f76174a315b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69342f4f31434e303165706b58774831574c41586b5a6656364e5f2121363030303030303030323737312d322d7470732d3230302d3230302e706e67)**[Alibaba Cloud AnalyticDB for MySQL](https://github.com/aliyun/alibabacloud-adb-mysql-mcp-server)** - Connect to an [AnalyticDB for MySQL](https://www.alibabacloud.com/en/product/analyticdb-for-mysql) cluster for getting database or table metadata, querying and analyzing data. It will be supported to add the OpenAPI for cluster operation in the future.\\n*   [![Image 12: Alibaba Cloud AnalyticDB for PostgreSQL Logo](https://github.com/aliyun/alibabacloud-adbpg-mcp-server/raw/master/images/AnalyticDB.png)](https://github.com/aliyun/alibabacloud-adbpg-mcp-server/blob/master/images/AnalyticDB.png)**[Alibaba Cloud AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server)** - An MCP server to connect to [AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server) instances, query and analyze data.\\n*   [![Image 13: DataWorks Logo](https://camo.githubusercontent.com/1547d08512702fe5794db8b93dfd6e25c8fb388c64b85a9dd28b0972c5b5a65b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69332f4f31434e30313031555757463155596e337241653348555f2121363030303030303030323533302d322d7470732d33322d33322e706e67)](https://camo.githubusercontent.com/1547d08512702fe5794db8b93dfd6e25c8fb388c64b85a9dd28b0972c5b5a65b/68747470733a2f2f696d672e616c6963646e2e636f6d2f696d6765787472612f69332f4f31434e30313031555757463155596e337241653348555f2121363030303030303030323533302d322d7470732d33322d33322e706e67)**[Alibaba Cloud DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\\n*   [![Image 14: Alibaba Cloud OpenSearch Logo](https://camo.githubusercontent.com/3b9b10166cde86742b0cec5f648610d446f0d9c5addc1a00429cec0306c364a0/68747470733a2f2f6f70656e7365617263682d7368616e676861692e6f73732d636e2d7368616e676861692e616c6979756e63732e636f6d2f6f756875616e672f616c6979756e2d69636f6e2e706e67)](https://camo.githubusercontent.com/3b9b10166cde86742b0cec5f648610d446f0d9c5addc1a00429cec0306c364a0/68747470733a2f2f6f70656e7365617263682d7368616e676861692e6f73732d636e2d7368616e676861692e616c6979756e63732e636f6d2f6f756875616e672f616c6979756e2d69636f6e2e706e67)**[Alibaba Cloud OpenSearch](https://github.com/aliyun/alibabacloud-opensearch-mcp-server)** - This MCP server equips AI Agents with tools to interact with [OpenSearch](https://help.aliyun.com/zh/open-search/?spm=5176.7946605.J_5253785160.6.28098651AaYZXC) through a standardized and extensible interface.\\n*   [![Image 15: Alibaba Cloud OPS Logo](https://github.com/aliyun/alibaba-cloud-ops-mcp-server/raw/master/image/alibaba-cloud.png)](https://github.com/aliyun/alibaba-cloud-ops-mcp-server/blob/master/image/alibaba-cloud.png)**[Alibaba Cloud OPS](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)** - Manage the lifecycle of your Alibaba Cloud resources with [CloudOps Orchestration Service](https://www.alibabacloud.com/en/product/oos) and Alibaba Cloud OpenAPI.\\n*   [![Image 16: Alibaba Cloud RDS MySQL Logo](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/raw/main/assets/alibabacloudrds.png)](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/blob/main/assets/alibabacloudrds.png)**[Alibaba Cloud RDS](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server)** - An MCP server designed to interact with the Alibaba Cloud RDS OpenAPI, enabling programmatic management of RDS resources via an LLM.\\n*   [![Image 17: AlipayPlus Logo](https://camo.githubusercontent.com/00b2ae041a2431b6cc89568cb84b35ceedf06cfcbeb7888fbdf3542a64047f7a/68747470733a2f2f7777772e616c69706179706c75732e636f6d2f66617669636f6e2e69636f)](https://camo.githubusercontent.com/00b2ae041a2431b6cc89568cb84b35ceedf06cfcbeb7888fbdf3542a64047f7a/68747470733a2f2f7777772e616c69706179706c75732e636f6d2f66617669636f6e2e69636f)**[AlipayPlus](https://github.com/alipay/global-alipayplus-mcp)** - Connect your AI Agents to AlipayPlus Checkout Payment.\\n*   [![Image 18: AllVoiceLab Logo](https://camo.githubusercontent.com/4de224e2a3bdd36ed2e67c284236a061734be55dc4d5042e528ddfdd127b3c1e/68747470733a2f2f63646e2e616c6c766f6963656c61622e636f6d2f7265736f75726365732f776f726b62656e63682f646973742f69636f6e2d6461726b2e69636f)](https://camo.githubusercontent.com/4de224e2a3bdd36ed2e67c284236a061734be55dc4d5042e528ddfdd127b3c1e/68747470733a2f2f63646e2e616c6c766f6963656c61622e636f6d2f7265736f75726365732f776f726b62656e63682f646973742f69636f6e2d6461726b2e69636f)**[AllVoiceLab](https://www.allvoicelab.com/mcp)** - An AI voice toolkit with TTS, voice cloning, and video translation, now available as an MCP server for smarter agent integration.\\n*   [![Image 19: Alpaca Logo](https://camo.githubusercontent.com/8a36ba1473c15f7eff5b1de1156bd339f9ac116b647d67b1bd43d7263d20799c/68747470733a2f2f66696c65732e616c706163612e6d61726b6\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 3: The Only Guide You Will Ever Need For Model Context Protocol (MCP) ---\\nURL: https://www.analyticsvidhya.com/blog/2025/07/model-context-protocol-mcp-guide/\\n\\nSUMMARY:\\nfrom fastmcp import FastMCP # Initialize the MCP server with a name mcp = FastMCP(\"DemoServer\") # Example data source for our resource ARTICLES = { \"1\": \"Anthropic\\'s Claude is an AI assistant with a 100K token context window and advanced reasoning abilities.\", \"2\": \"MCP (Model Context Protocol) is a standard to connect AI models with external tools and data in a unified way.\", } # Define a Resource (context unit) that provides an article\\'s text by ID @mcp.resource(\"article://{article_id}\") def get_article(article_id: str) -> str: \"\"\"Retrieve the content of an article by ID.\"\"\" return ARTICLES.get(article_id, \"Article not found.\") # Define a Tool (function) that the model can call @mcp.tool() def add(a: int, b: int) -> int: \"\"\"Add two numbers and return the result.\"\"\" return a + b # (Optional) Define a Prompt template for demonstration @mcp.prompt() def how_to_use() -> str: \"\"\"A prompt template that instructs the assistant on using this server.\"\"\" return \"You have access to a DemoServer with an \\'article\\' resource and an \\'add\\' tool.\" if name==\"main\": # Run the server using standard I/O transport (suitable for local client connection) mcp.run(transport=\"stdio\")\\n\\nFULL CONTENT:\\n[Master Generative AI with 10+ Real-world Projects in 2025!\\n\\n* d\\n:* h\\n:* m\\n:* s](https://www.analyticsvidhya.com/pinnacleplus/pinnacleplus-projects?utm_source=blog_india&utm_medium=desktop_flashstrip&utm_campaign=15-Feb-2025||&utm_content=projects)\\n\\n\\n\\n[Interview Prep](https://www.analyticsvidhya.com/blog/category/interview-questions/?ref=category)\\n\\n[Prompt Engg](https://www.analyticsvidhya.com/blog/category/prompt-engineering/?ref=category)\\n\\n[AI Agents](https://www.analyticsvidhya.com/blog/category/ai-agent/?ref=category)\\n\\n[Machine Learning](https://www.analyticsvidhya.com/blog/category/machine-learning/?ref=category)\\n\\n[Deep Learning](https://www.analyticsvidhya.com/blog/category/deep-learning/?ref=category)\\n\\n[GenAI Tools](https://www.analyticsvidhya.com/blog/category/ai-tools/?ref=category)\\n\\n[AIML Projects](https://www.analyticsvidhya.com/blog/category/project/?ref=category)\\n\\n#### Reading list\\n\\n[What is NLP?](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/)[Applications of NLP](https://www.analyticsvidhya.com/blog/2020/07/top-10-applications-of-natural-language-processing-nlp/)\\n\\n[Understanding Text Pre-processing](https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/)[Tokenization in NLP](https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/)[Byte Pair Encoding](https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/)[Tokenizer Free Language Modeling with Pixels](https://www.analyticsvidhya.com/blog/2022/09/tokenizer-free-language-modeling-with-pixels/)[Stopword Removal](https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/)[Stemming vs Lemmatization](https://www.analyticsvidhya.com/blog/2022/06/stemming-vs-lemmatization-in-nlp-must-know-differences/)[Text Mining](https://www.analyticsvidhya.com/blog/2021/05/how-to-build-word-cloud-in-python/)\\n\\n[Spacy Tutorials](https://www.analyticsvidhya.com/blog/2020/03/spacy-tutorial-learn-natural-language-processing/)[Gensim Tutorials](https://www.analyticsvidhya.com/blog/2022/02/topic-identification-with-gensim-library-using-python/)\\n\\n[What are Regular Expressions?](https://www.analyticsvidhya.com/blog/2021/06/regex-cheatsheet-for-natural-language-processing-tasks/)[Regular Expressions](https://www.analyticsvidhya.com/blog/2020/01/4-applications-of-regular-expressions-that-every-data-scientist-should-know-with-python-code/)\\n\\n[String Similarity](https://www.analyticsvidhya.com/blog/2021/07/fuzzy-string-matching-a-hands-on-guide/)\\n\\n[Spelling Correction](https://www.analyticsvidhya.com/blog/2021/11/autocorrect-feature-using-nlp-in-python/)\\n\\n[Introduction to Topic Modeling](https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/)[Latent Dirichlet Allocation (LDA)](https://www.analyticsvidhya.com/blog/2021/06/part-2-topic-modeling-and-latent-dirichlet-allocation-lda-using-gensim-and-sklearn/)[Implement Topic Modeling](https://www.analyticsvidhya.com/blog/2022/08/supervised-topic-models/)\\n\\n[Introduction to Feature Engineering for Text Data](https://www.analyticsvidhya.com/blog/2021/04/a-guide-to-feature-engineering-in-nlp/)[Implement Text Feature Engineering Techniques](https://www.analyticsvidhya.com/blog/2015/10/6-practices-enhance-performance-text-classification-model/)[Introduction to One Hot Encoding](https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/)[Implement One Hot Encoding](https://www.analyticsvidhya.com/blog/2021/05/how-to-perform-one-hot-encoding-for-multi-categorical-variables/)[Limitations of One Hot Encoding](https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/)[Count Vectorizer and TF-IDF](https://www.analyticsvidhya.com/blog/2021/06/part-5-step-by-step-guide-to-master-nlp-text-vectorization-approaches/)[Solving Text classification using TF-IDF](https://www.analyticsvidhya.com/blog/2018/07/hands-on-sentiment-analysis-dataset-python/)\\n\\n[Information Retrieval System Explained in Simple terms!](https://www.analyticsvidhya.com/blog/2020/06/nlp-project-information-extraction/)[How does Google Rank Search Results?](https://www.analyticsvidhya.com/blog/2015/04/pagerank-explained-simple/)[Knowledge Graph](https://www.analyticsvidhya.com/blog/2019/10/how-to-build-knowledge-graph-text-using-spacy/)\\n\\n[Understanding Word2Vec](https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/)[Understanding Skip Gram and Continous Bag Of Words](https://www.analyticsvidhya.com/blog/2020/03/pretrained-word-embeddings-nlp/)[Word2Vec Implementation in Gensim](https://www.analyticsvidhya.com/blog/2021/06/practical-guide-to-word-embedding-system/)[Visualizing Word2Vec](https://www.analyticsvidhya.com/blog/2019/07/how-to-build-recommendation-system-word2vec-python/)\\n\\n[Word Senses and Word Sense Ambiguity](https://www.analyticsvidhya.com/blog/2021/06/word-sense-disambiguation-importance-in-natural-language-processing/)\\n\\n[Why Are We Interested in Syntatic Strucure?](https://www.analyticsvidhya.com/blog/2021/06/part-11-step-by-step-guide-to-master-nlp-syntactic-analysis/)[What is a Dependency Grammar?](https://www.analyticsvidhya.com/blog/2020/07/part-of-speechpos-tagging-dependency-parsing-and-constituency-parsing-in-nlp/)[Neural Dependency Parsing](https://www.analyticsvidhya.com/blog/2019/02/stanfordnlp-nlp-library-python/)\\n\\n[Introduction to Language Models](https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/)[N-Gram Language Models](https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/)[Neural Language models](https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/)\\n\\n[Why Sequence models?](https://www.analyticsvidhya.com/blog/2019/01/sequence-models-deeplearning/)[Usecases of Sequence models](https://www.analyticsvidhya.com/blog/2018/03/essentials-of-deep-learning-sequence-to-sequence-modelling-with-attention-part-i/)[Introduction to RNN](https://www.analyticsvidhya.com/blog/2022/03/a-brief-overview-of-recurrent-neural-networks-rnn/)[Implement RNN](https://www.analyticsvidhya.com/blog/2022/01/tutorial-on-rnn-lstm-gru-with-implementation/)\\n\\n[Shortcomings of RNN](https://www.analyticsvidhya.com/blog/2021/06/a-visual-guide-to-recurrent-neural-networks/)[What is Long Short Term Memory (LSTM)](https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/)[Implementing LSTM](https://www.analyticsvidhya.com/blog/2021/06/lstm-for-text-classification/)[Build Your Own Fake News Classification Model](https://www.analyticsvidhya.com/blog/2021/07/detecting-fake-news-with-natural-language-processing/)[What is Gated Recurrent Unit (GRU)?](https://www.analyticsvidhya.com/blog/2021/03/introduction-to-gated-recurrent-unit-gru/)[Implementing GRU](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)\\n\\n[Introduction to Machine Translation](https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/)[Multilingualism in NLP](https://www.analyticsvidhya.com/blog/2020/01/3-important-nlp-libraries-indian-languages-python/)[Drawbacks of Seq2Seq model](https://www.analyticsvidhya.com/blog/2020/08/a-simple-introduction-to-sequence-to-sequence-models/)[Mathematical Calculation of Attention](https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/)\\n\\n[Understand Positional Encoding](https://www.analyticsvidhya.com/blog/2021/09/an-explanatory-guide-to-bert-tokenizer/)[Introducing Transformers Model](https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/)[Key Query Value Attention in Tranformer Encoder](https://www.analyticsvidhya.com/blog/2021/01/implementation-of-attention-mechanism-for-caption-generation-on-transformers-using-tensorflow/)\\n\\n[Pretrained Language Models in NLP](https://www.analyticsvidhya.com/blog/2019/03/pretrained-models-get-started-nlp/)[Generative Pre-training (GPT) for Natural Language Understanding(NLU)](https://www.analyticsvidhya.com/blog/2021/09/building-a-machine-learning-model-for-title-generation/)[Finetuning GPT-2](https://www.analyticsvidhya.com/blog/2019/07/openai-gpt2-text-generator-python/)[Understanding BERT](https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/)[Finetune Masked language Modeling in BERT](https://www.analyticsvidhya.com/blog/2021/12/fine-tune-bert-model-for-sentiment-analysis-in-google-colab/)[Implement Text Classification using BERT](https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/)[Finetuning BERT for NER](https://www.analyticsvidhya.com/blog/2022/06/fine-tune-bert-model-for-named-entity-recognition-in-google-colab/)[Extensions of BERT: Roberta, Spanbert, ALBER](https://www.analyticsvidhya.com/blog/2022/10/albert-model-for-self-supervised-learning/)[MobileBERT](https://www.analyticsvidhya.com/blog/2020/07/mobilebert/)[GPT-3](https://www.analyticsvidhya.com/blog/2021/05/hands-on-experience-with-gpt3/)[Prompt Engineering in GPT-3](https://www.analyticsvidhya.com/blog/2022/05/prompt-engineering-in-gpt-3/)[Bigbird](https://www.analyticsvidhya.com/blog/2022/11/an-introduction-to-bigbird/)[T5 and large language models](https://www.analyticsvidhya.com/blog/2020/03/6-pretrained-models-text-classification/)\\n\\n[Implement Question Answering on SQUAD](https://www.analyticsvidhya.com/blog/2021/11/end-to-end-question-answering-system-using-nlp-and-squad-dataset/)\\n\\n[Text Summarization](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/)\\n\\n[Named Entity Recognition (NER) in Python with Spacy](https://www.analyticsvidhya.com/blog/2021/06/nlp-application-named-entity-recognition-ner-in-python-with-spacy/)\\n\\n[Coreference Resolution](https://www.analyticsvidhya.com/blog/2021/07/new-anaphora-and-co-reference-resolution-technique-for-biographies/)\\n\\n[Visualizing Sounds Using Librosa Machine Learning Library!](https://www.analyticsvidhya.com/blog/2021/06/visualizing-sounds-librosa/)[Audio Processing](https://www.analyticsvidhya.com/blog/2017/08/audio-voice-processing-deep-learning/)[Audio Analysis](https://www.analyticsvidhya.com/blog/2022/01/analysis-of-zero-crossing-rates-of-different-music-genre-tracks/)[Audio Classification using Deep Learning](https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/)\\n\\n[Automatic Speech Recognition](https://www.analyticsvidhya.com/blog/2021/01/introduction-to-automatic-speech-recognition-and-natural-language-processing/)[Implement Automatic Speech Recognition](https://www.analyticsvidhya.com/blog/2019/07/learn-build-first-speech-to-text-model-python/)[Can Voice Conversion Improve ASR in Low-Resource Settings?](https://www.analyticsvidhya.com/blog/2022/09/can-voice-conversion-improve-asr-in-low-resource-settings/)\\n\\n[Audio Separation](https://www.analyticsvidhya.com/blog/2021/08/speech-separation-by-facebook-ai-research/)\\n\\n[Building Chatbots](https://www.analyticsvidhya.com/blog/2021/12/creating-chatbot-building-using-python/)[Building Chatbots using Rasa](https://www.analyticsvidhya.com/blog/2019/04/learn-build-chatbot-rasa-nlp-ipl/)\\n\\n[Automate NLP Tasks using EvalML Library](https://www.analyticsvidhya.com/blog/2021/04/automate-nlp-tasks-using-evalml-library/)\\n\\n# The Only Guide You Will Ever Need For Model Context Protocol (MCP)\\n\\n[Naresh Dulam](https://www.analyticsvidhya.com/blog/author/naresh/)   Last Updated : 31 Jul, 2025\\n\\n   19  min read\\n\\nLarge Language Models (LLMs) like Anthropics Claude have unlocked massive context windows (up to 200k tokens in Claude 4) that let them consider entire documents or codebases in a single go. However, effectively providing relevant context to these models remains a challenge. Traditionally, developers have resorted to complex prompt engineering or retrieval pipelines to feed external information into an LLMs prompt. Anthropics Model Context Protocol (MCP) is a new open standard that simplifies and standardizes this process.\\n\\nThink of MCP as the USB-C for AI applications  a universal connector that lets your LLM seamlessly access external data, tools, and systems. In this article, well explain what MCP is, why its important for long-context LLMs, how it compares to traditional prompt engineering, and walk through building a simple MCP-compatible context server in Python. Well also discuss practical use cases (like retrieval-augmented generation (RAG) and agent tools) and provide code examples, diagrams, and references to begin with MCP and Claude.\\n\\n## Table of contents\\n\\n* [What is MCP and Why Does It Matter?](#h-what-is-mcp-and-why-does-it-matter)\\n* [MCP vs. Traditional Prompt Engineering](#h-mcp-vs-traditional-prompt-engineering)\\n  + [MCP Primitives](#h-mcp-primitives)\\n  + [Different from Traditional Prompt Engineering](#h-different-from-traditional-prompt-engineering)\\n* [MCP Architecture and Data Flow](#h-mcp-architecture-and-data-flow)\\n  + [Data flow in MCP](#h-data-flow-in-mcp)\\n* [Building a Simple MCP Context Server in Python (Step-by-Step)](#h-building-a-simple-mcp-context-server-in-python-step-by-step)\\n  + [Step 1: Setup and Installation](#h-step-1-setup-and-installation)\\n  + [Step 2: Define an MCP Server and Context Units](#h-step-2-define-an-mcp-server-and-context-units)\\n  + [Step 3: Running the Server and Connecting a Client](#h-step-3-running-the-server-and-connecting-a-client)\\n  + [Step 4: Using the Context Units and Tools](#h-step-4-using-the-context-units-and-tools)\\n  + [Step 5: Testing and Iterating](#h-step-5-testing-and-iterating)\\n* [Practical Use Cases of MCP](#h-practical-use-cases-of-mcp)\\n  + [Retrieval-Augmented Generation (RAG) with MCP](#h-retrieval-augmented-generation-rag-with-mcp)\\n  + [Agent Actions and Tool Use](#h-agent-actions-and-tool-use)\\n  + [Multi-Modal and Complex Workflows](#h-multi-modal-and-complex-workflows)\\n* [Best Practices, Benefits, and Next Steps](#h-best-practices-benefits-and-next-steps)\\n* [Conclusion](#h-conclusion)\\n\\n## What is MCP and Why Does It Matter?\\n\\nModel Context Protocol is an open protocol that Anthropic released in late 2024. It is meant to standardize how AI applications provide context to LLMs. In essence, [MCP defines a common clientserver architecture](https://www.analyticsvidhya.com/blog/2025/02/model-context-protocol/) for connecting AI assistants to the places where your data lives. This helps with both local files, databases, cloud services, as well as business applications. Before MCP, integrating an LLM with each new data source or API meant writing a custom connector or prompt logic for each specific case. This led to a combinatorial explosion of integrations: M AI applications times N data sources could require MN bespoke implementations. MCP tackles this by providing a universal interface. With this, any compliant AI client can talk to any compliant data/service server. This reduces the problem to M + N integration points.\\n\\nWhy is MCP especially important for long-context LLMs? Models like Claude 4 can ingest hundreds of pages of text. Though deciding what information to put into that huge context window is non-trivial. Simply stuffing all potentially relevant data into the prompt is inefficient and sometimes impossible. Model Context Protocol enables a smarter approach. The LLM or its host application can dynamically retrieve just-in-time context from external sources as needed. This is done instead of front-loading everything. This means you can leverage the full breadth of a 200k-token window with relevant data fetched on the fly. For example, pulling in only the sections of a knowledge base that relate to the users query. MCP provides a structured, real-time way to maintain and augment the models context with external knowledge.\\n\\nIn short, as AI assistants grow in context length, MCP ensures they are not trapped behind information silos. Instead, these can access up-to-date facts, files, and tools to ground their responses.\\n\\n## MCP vs. Traditional Prompt Engineering\\n\\nBefore MCP, developers often used RA) pipelines or manual prompt engineering to inject external information into an LLMs prompt. For example, a RAG system might vector-search a document database for relevant text. It may then insert those snippets into the prompt as context. Alternatively, one might craft a monolithic prompt containing instructions, examples, and appended data. These approaches work, but they are ad hoc and lack standardization.\\n\\nEach application ends up reinventing how to fetch and format context for the model, and integrating new data sources means writing new glue code or prompts.\\n\\n### MCP Primitives\\n\\nModel Context Protocol fundamentally changes this by introducing structured context management. Instead of treating all external info as just more prompt text, MCP breaks down interactions into three standardized components (or primitives):\\n\\n* **Resources ** think of these as read-only context units (data sources) provided to the model. A resource might be a files contents, a database record, or an API response that the model can read. Resources are application-controlled. The host or developer decides what data to expose and how. Importantly, reading a resource has no side effects  its analogous to a GET request that just fetches data. Resources supply the content that can be injected into the models context when needed (e.g., retrieved documents in a Q&A scenario).\\n* **Tools ** these are actions or functions the LLM can invoke to perform operations, such as running a computation or calling an external API. Tools are model-controlled. This means the AI decides if and when to use them (similar to function calling in other frameworks). For example, a tool could be send\\\\_email(recipient, body) or query\\\\_database(SQL). Using a tool may have side effects (sending data, modifying state), and the result of a tool call can be fed back into the conversation.\\n* **Prompts ** these are reusable prompt templates or instructions that you can invoke as needed. They are user-controlled or predefined by developers. Prompts might include templates for common tasks or guided workflows (e.g., a template for code review or a Q&A format). Essentially, they provide a way to consistently inject certain instructions or context phrasing without hardcoding it into every prompt.\\n\\n### Different from Traditional Prompt Engineering\\n\\nThis structured approach contrasts with traditional prompt engineering. In that, all context (instructions, data, tool hints) may lump into one big prompt. With MCP, context is modular. An AI assistant can discover what resources and tools are available and then flexibly combine them. So, MCP turns an unstructured prompt into a two-way conversation between the LLM and your data/tools. The model isnt blindly handed a block of text. Instead, it can actively request data or actions via a standard protocol.\\n\\nMoreover, MCP makes integrations consistent and scalable. As the USB analogy suggests, an MCP-compliant server for (say) Google Drive or Slack can plug into any MCP-aware client (Claude, an IDE plugin, etc.). Developers dont have to write new prompt logic for each app-tool combo. This standardization also facilitates community sharing: you can leverage pre-built MCP connectors instead of reinventing them. Anthropic has open-sourced many MCP servers for common systems. These include file systems, GitHub, Slack, databases, etc., which you can reuse or learn from. In summary, MCP offers a unified and modular way to supply context and capabilities to LLMs.\\n\\n## MCP Architecture and Data Flow\\n\\nAt a high level, Model Context Protocol follows a clientserver architecture within an AI application. Lets break down the key components and how they interact:\\n\\n#### Host\\n\\nThe host is the main AI application or interface that the end-user interacts with. This can be a chatbot UI (e.g., Claudes chat app or a custom web app). Or it can be an IDE extension, or any AI assistant environment. The host contains or invokes the LLM itself. For instance, Claude Desktop is a host  its an app where Claude (the LLM) converses with the user.\\n\\n#### MCP Client\\n\\nThe MCP client is a component (often a library) running within the host application. It manages the connection to one or more MCP servers. You can think of the client as an adapter or middleman. It speaks the MCP protocol, handling messaging, requests, and responses. Each MCP client typically handles one server connection. So, if the host connects to multiple data sources, it will instantiate multiple clients). In practice, the client is responsible for discovering server capabilities. It sends the LLMs requests to the server and relays responses back.\\n\\n#### MCP Server\\n\\nThe server is an external (or local) program that wraps a specific data source or functionality behind the MCP standard. The server exposes a set of Tools, Resources, and Prompts according to the MCP spec. For example, a server might expose your file system (allowing the LLM to read files as resources). Or a CRM database, or a third-party API like weather or Slack. The server handles incoming requests (like read this resource or execute this tool). It then returns results in a format the client and LLM can understand.\\n\\nThese components communicate via a defined transport layer. MCP supports multiple transports. For local servers, a simple STDIO pipe can be used. Client and server on the same machine communicate via standard input/output streams. For remote servers, MCP uses HTTP with Server-Sent Events (SSE) to maintain a persistent connection. MCP libraries abstract away the transport details, but its useful to know that local integrations are possible without any network. And that remote integrations work over web protocols.\\n\\n### Data flow in MCP\\n\\nOnce everything is set up, the interaction follows a sequence whenever the user engages with the AI assistant:\\n\\n1. **Initialization & Handshake**  When the host application starts or when a new server is added, the MCP client establishes a connection to the server. They perform a handshake to verify protocol versions and exchange basic info. This ensures both sides speak the same MCP version and understand each others messages.\\n2. **Capability Discovery**  After connecting, the client asks the server what it can do. The server responds with a list of available tools, resources, and prompt templates (including descriptions, parameter schemas, etc.). For example, a server might report: I have a resource file://{path} for reading files, a tool get\\\\_weather(lat, lan) for fetching weather, and a prompt template summarize(text). The host can use this to present options to the user or inform the LLM about available functions.\\n3. **Context Provisioning**  The host can proactively fetch some resources or choose prompt templates to augment the models context at the start of a conversation. For instance, an IDE could use an MCP server to load the users current file as a resource and include its content in Claudes context automatically. Or the host might apply a prompt template (like a specific system instruction) before the LLM starts generating. At this stage, the host essentially injects initial context from MCP resources/prompts into the LLMs input.\\n4. **LLM Invocation & Tool Use**  The users query, along with any initial context, is given to the LLM. As the LLM processes the query, it can decide to invoke one of the available MCP Tools if needed. For example, if the user asks What are the open issues in repo X?, the model might determine it needs to call a get\\\\_github\\\\_issues(repo) tool provided by a GitHub MCP server. When the model decides to use a tool, the hosts MCP client receives that function call request (this is analogous to function-calling in other LLM APIs). The client then sends the invocation to the MCP server responsible.\\n5. **External Action Execution**  The MCP server receives the tool invocation, acts by interfacing with the external system (e.g., calling GitHubs API), and then returns the result. In our example, it might return a list of issue titles.\\n6. **Response Integration**  The MCP client receives the result and passes it back to the host/LLM. Typically, the result is incorporated into the LLMs context as if the model had seen it. Continuing the example, the list of issue titles can end the conversation (often as a system or assistant message containing the tools output). The LLM now has the data it fetched and can use it to formulate a final answer.\\n7. **Final Answer Generation**  With relevant external data in context, the LLM generates its answer to the user. From the users perspective, the assistant answered using real-time knowledge or actions, but thanks to MCP, the process was standardized and secure.\\n\\nCrucially, Model Context Protocol enforces security and user control throughout this flow. No tool or resource is used without explicit permission. For instance, Claudes implementation of MCP in Claude Desktop requires the user to approve each server and can prompt before certain sensitive operations. Most MCP servers run locally or within the users infrastructure by default, keeping data private unless you explicitly allow a remote connection. All of this ensures that giving an LLM access to, say, your file system or database via MCP doesnt turn into a free-for-all; you maintain control over what it can see or do.\\n\\n## Building a Simple MCP Context Server in Python (Step-by-Step)\\n\\nOne of the great things about Model Context Protocol being an open standard is that you can implement servers in many languages. Anthropic and the community provide SDKs in Python, TypeScript, Java, Kotlin, C#, and more. Here, well focus on Python and build a simple MCP-compatible server to illustrate how to define and use context units (resources) and tools. We assume you have Python 3.9+ available.\\n\\nNote: This tutorial uses in-memory data structures to simulate real-world behavior. The example requires no external dataset.\\n\\n### Step 1: Setup and Installation\\n\\nFirst, youll need an MCP library. You can install Anthropics official Python SDK (mcp library) via pip. Theres also a high-level helper library called FastMCP that makes building servers easier (its a popular community SDK). For this guide, lets use fastmcp for brevity. You can install it with:\\n\\n```\\n pip install fastmcp\\n```\\n\\n(Alternatively, you could use the official SDK similarly. The concepts remain the same.)\\n\\n### Step 2: Define an MCP Server and Context Units\\n\\nAn MCP server is essentially a program that declares some tools/resources and waits for client requests. Lets create a simple server that provides two capabilities to illustrate MCPs context-building:\\n\\n* A Resource that provides the content of an article by ID  simulating a knowledge base lookup. This will act as a context unit (some text data) the model can retrieve.\\n* A Tool that adds two numbers  a trivial example of a function the model can call (just to show tool usage).\\n\\n```\\nfrom fastmcp import FastMCP # Initialize the MCP server with a name mcp = FastMCP(\"DemoServer\") # Example data source for our resource ARTICLES = { \"1\": \"Anthropic\\'s Claude is an AI assistant with a 100K token context window and advanced reasoning abilities.\", \"2\": \"MCP (Model Context Protocol) is a standard to connect AI models with external tools and data in a unified way.\", } # Define a Resource (context unit) that provides an article\\'s text by ID @mcp.resource(\"article://{article_id}\") def get_article(article_id: str) -> str: \"\"\"Retrieve the content of an article by ID.\"\"\" return ARTICLES.get(article_id, \"Article not found.\") # Define a Tool (function) that the model can call @mcp.tool() def add(a: int, b: int) -> int: \"\"\"Add two numbers and return the result.\"\"\" return a + b # (Optional) Define a Prompt template for demonstration @mcp.prompt() def how_to_use() -> str: \"\"\"A prompt template that instructs the assistant on using this server.\"\"\" return \"You have access to a DemoServer with an \\'article\\' resource and an \\'add\\' tool.\" if name==\"main\": # Run the server using standard I/O transport (suitable for local client connection) mcp.run(transport=\"stdio\")\\n```\\n\\nLets break down whats happening here:\\n\\n* We create a FastMCP server instance with the name DemoServer. The clients use the name to refer to this server.\\n* We define a dictionary ARTICLES to simulate a small knowledge base. In real scenarios, database queries or API calls can replace this, but for now, its just in-memory data.\\n* The @mcp.resource(article://{article\\\\_id}) decorator exposes the get\\\\_article function as a Resource. The string article://{article\\\\_id} is a URI template indicating how this resource is accessed. MCP clients will see that this server offers a resource with the schema article:// and can request, for example, article:// 1. When called, get\\\\_article returns a string (the article text). This text is the context unit that would be delivered to the LLM. Notice there are no side effects  its a read-only retrieval of data.\\n* The @mcp\\\\_tool decorator exposes an add a Tool. It takes two integers and returns their sum. Its a trivial example just to illustrate a tool; a real tool might act like hitting an external API or modifying something. The important part is that the models choice invokes the tools and these can have side effects.\\n* We also showed an @mcp\\\\_prompt() for completeness. This defines a Prompt template that can provide preset instructions. In this case, how\\\\_to\\\\_use returns a fixed instruction string. Prompt units can help guide the model (for instance\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 4: MCP Server and MCP-Jest: A Comprehensive Guide for AI Engineers ---\\nURL: https://skywork.ai/skypage/en/MCP-Server-and-MCP-Jest-A-Comprehensive-Guide-for-AI-Engineers/1972859999880278016\\n\\nSUMMARY:\\n... configure an MCP client, like the Claude Desktop ... Example Servers - Model Context Protocol https://modelcontextprotocol.io/examples. logo.\\n\\nFULL CONTENT:\\n![](data:image/svg+xml,%3csvg%20width=\\'20\\'%20height=\\'21\\'%20viewBox=\\'0%200%2020%2021\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20d=\\'M18.0117%2010.4997C18.0115%208.2425%2016.1626%206.38652%2013.8982%206.38626H12.59C12.2312%206.38626%2011.9404%206.09545%2011.9404%205.73671C11.9404%205.37797%2012.2312%205.08716%2012.59%205.08716H13.8982C16.8816%205.08742%2019.3106%207.52656%2019.3108%2010.4997C19.3108%2013.4833%2016.8715%2015.9131%2013.8982%2015.9134H12.59C12.2314%2015.9134%2011.9406%2015.6224%2011.9404%2015.2638C11.9404%2014.9051%2012.2312%2014.6142%2012.59%2014.6142H13.8982C16.1556%2014.614%2018.0117%2012.7643%2018.0117%2010.4997Z\\'%20fill=\\'%23000818\\'/%3e%3cpath%20d=\\'M0.689941%2010.4996C0.690125%207.51697%203.11987%205.08722%206.10253%205.08704H7.40163C7.76037%205.08704%208.05118%205.37785%208.05118%205.73659C8.05118%206.09532%207.76037%206.38614%207.40163%206.38614H6.10253C3.83735%206.38632%201.98923%208.23444%201.98904%2010.4996C1.98904%2012.7571%203.838%2014.6139%206.10253%2014.6141H7.40163L7.53256%2014.6273C7.82867%2014.6878%208.05118%2014.9497%208.05118%2015.2637C8.05102%2015.5776%207.82863%2015.8396%207.53256%2015.9L7.40163%2015.9132H6.10253C3.11899%2015.913%200.689941%2013.473%200.689941%2010.4996Z\\'%20fill=\\'%23000818\\'/%3e%3cpath%20d=\\'M13.4647%209.85059L13.5956%209.86378C13.8914%209.92448%2014.1142%2010.1864%2014.1142%2010.5001C14.1142%2010.8139%2013.8914%2011.0758%2013.5956%2011.1365L13.4647%2011.1497H6.53578C6.17704%2011.1497%205.88623%2010.8589%205.88623%2010.5001C5.88623%2010.1414%206.17704%209.85059%206.53578%209.85059H13.4647Z\\'%20fill=\\'%23000818\\'/%3e%3c/svg%3e)\\n![X](data:image/svg+xml,%3csvg%20width=\\'20\\'%20height=\\'21\\'%20viewBox=\\'0%200%2020%2021\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20fill-rule=\\'evenodd\\'%20clip-rule=\\'evenodd\\'%20d=\\'M7.92753%2010.546L1.73633%202.85278H6.6402L10.462%207.60775L14.545%202.87419H17.2457L11.7678%209.23245L18.2631%2017.3137H13.3739L9.23567%2012.1715L4.81772%2017.2995H2.10229L7.92753%2010.546ZM14.0865%2015.8883L4.74322%204.27821H5.92701L15.2586%2015.8883H14.0865Z\\'%20fill=\\'%23000818\\'/%3e%3c/svg%3e)\\n![Facebook](data:image/svg+xml,%3csvg%20width=\\'20\\'%20height=\\'21\\'%20viewBox=\\'0%200%2020%2021\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20d=\\'M20%2010.5C20%204.97658%2015.5234%200.5%2010%200.5C4.47658%200.5%200%204.97658%200%2010.5C0%2015.4922%203.65625%2019.6289%208.4375%2020.3789V13.3906H5.89842V10.5H8.4375V8.29688C8.4375%205.791%209.92971%204.40625%2012.2148%204.40625C13.3086%204.40625%2014.4531%204.60156%2014.4531%204.60156V7.0625H13.1914C11.9492%207.0625%2011.5625%207.834%2011.5625%208.625V10.5H14.3359L13.8926%2013.3906H11.5625V20.3789C16.3438%2019.6289%2020%2015.4922%2020%2010.5Z\\'%20fill=\\'%231877F2\\'/%3e%3cpath%20d=\\'M13.8926%2013.3906L14.3359%2010.5H11.5625V8.625C11.5625%207.834%2011.9492%207.0625%2013.1914%207.0625H14.4531V4.60156C14.4531%204.60156%2013.3086%204.40625%2012.2149%204.40625C9.92973%204.40625%208.43752%205.791%208.43752%208.29687V10.5H5.89844V13.3906H8.43752V20.3789C8.94727%2020.459%209.46877%2020.5%2010%2020.5C10.5313%2020.5%2011.0528%2020.459%2011.5625%2020.3789V13.3906H13.8926Z\\'%20fill=\\'white\\'/%3e%3c/svg%3e)\\n![logo](data:image/svg+xml,%3csvg%20width=\\'127\\'%20height=\\'28\\'%20viewBox=\\'0%200%20127%2028\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cg%20clip-path=\\'url(%23clip0_2993_300192)\\'%3e%3cpath%20d=\\'M16.0077%202.0922C12.2826%20-0.81751%206.89635%20-0.720465%203.26989%202.55933C-0.795291%206.23389%20-1.11406%2012.5106%202.55676%2016.5782C5.83322%2020.21%2011.1817%2020.8532%2015.1828%2018.3366L7.48132%209.80153L16.0077%202.0922Z\\'%20fill=\\'%234D5EFF\\'/%3e%3cpath%20d=\\'M12.5915%2025.9078C16.3166%2028.8175%2021.7029%2028.7205%2025.3293%2025.4407C29.3929%2021.7661%2029.7116%2015.4894%2026.0408%2011.4218C22.7644%207.78996%2017.4159%207.14683%2013.4148%209.66343L21.1163%2018.1985L12.5899%2025.9078H12.5915Z\\'%20fill=\\'%2300FFCE\\'/%3e%3cpath%20d=\\'M61.0188%2023.3945L55.2119%2017.8185L55.225%2023.3945H53.7347L53.692%205.87207H55.184L55.2119%2016.9747L61.0862%2011.2211H63.0662L56.7121%2017.3497L63.0662%2023.3945H61.0188Z\\'%20fill=\\'black\\'/%3e%3cpath%20d=\\'M75.4113%2011.2178L67.6917%2028H66.0748L68.7877%2022.3599L63.9239%2011.2178H65.5605L69.6011%2020.7348L73.7714%2011.2178H75.4113Z\\'%20fill=\\'black\\'/%3e%3cpath%20d=\\'M93.5781%2011.2194L89.2155%2023.3911H88.2887L88.2592%2023.3122L84.9646%2013.9235L81.6652%2023.3911H80.7351L76.3265%2011.2227H77.8826L81.2067%2020.8482L84.5111%2011.2194H85.4149L88.734%2020.8482L92.022%2011.2194H93.5781Z\\'%20fill=\\'black\\'/%3e%3cpath%20d=\\'M100.451%2011.2161C97.9275%2011.2161%2094.472%2013.2524%2094.472%2017.3168C94.472%2021.7611%2098.3054%2023.3813%20100.478%2023.3813C104.868%2023.3813%20106.585%2019.6902%20106.585%2017.3052C106.585%2014.634%20104.597%2011.2161%20100.45%2011.2161H100.451ZM100.443%2022.0029C98.0113%2022.0029%2095.8046%2019.812%2095.8325%2017.3168C95.867%2014.1472%2098.5684%2012.6339%20100.529%2012.6339C103.266%2012.6339%20105.195%2014.8676%20105.195%2017.3052C105.195%2019.7429%20103.192%2022.0029%20100.445%2022.0029H100.443Z\\'%20fill=\\'black\\'/%3e%3cpath%20d=\\'M124.953%2023.3961L119.137%2017.8234L119.152%2023.3961H117.66L117.616%205.87366H119.106L119.136%2016.973L125.01%2011.2177H126.99L120.636%2017.3513L127%2023.3961H124.953Z\\'%20fill=\\'black\\'/%3e%3cpath%20d=\\'M50.8838%2016.1983C50.5749%2015.6325%2049.916%2014.9811%2049.0369%2014.4712C47.8653%2013.7935%2046.1531%2013.4514%2045.4515%2013.2343C44.8633%2013.0517%2044.3243%2012.7935%2043.8346%2012.5221C43.3532%2012.254%2042.9638%2011.9184%2042.6762%2011.5237C42.3903%2011.1355%2042.2457%2010.6157%2042.2424%209.9808C42.2408%209.21267%2042.4445%208.60243%2042.9194%208.12543C43.6736%207.39348%2044.7006%206.9428%2045.8311%206.9428C47.4825%206.9428%2048.9136%207.90503%2049.5956%209.29984H51.0662C50.3087%207.13524%2048.2531%205.58252%2045.8327%205.58252C43.8774%205.58252%2042.0058%206.61219%2041.1727%208.12543C40.8983%208.6452%2040.7389%209.35577%2040.7406%2010.0532C40.7422%2010.9036%2040.9016%2011.6125%2041.2105%2012.1569C41.5194%2012.6964%2041.9335%2013.1504%2042.4412%2013.5073C42.944%2013.856%2043.5076%2014.1406%2044.0992%2014.384C44.9996%2014.7541%2046.2764%2014.889%2047.4874%2015.4351C48.6245%2015.9466%2049.1421%2016.3792%2049.451%2016.797C49.7599%2017.2148%2050.0721%2017.7%2050.0326%2018.4846C50.0277%2018.5685%2050.0179%2018.654%2050.0064%2018.7379C49.6991%2020.7512%2047.9573%2022.299%2045.8623%2022.299C43.7673%2022.299%2042.1865%2020.891%2041.7708%2019.0126H40.3873C40.8211%2021.6476%2043.1067%2023.6576%2045.8623%2023.6576C48.6179%2023.6576%2051.0613%2021.5062%2051.3768%2018.7363C51.3899%2018.6047%2051.3998%2018.4747%2051.3998%2018.3448C51.3998%2017.3135%2051.1976%2016.7657%2050.8871%2016.1983H50.8838Z\\'%20fill=\\'black\\'/%3e%3cpath%20d=\\'M114.011%2011.2112C110.779%2011.2112%20108.164%2013.833%20108.164%2017.0684L108.191%2023.3813H109.693L109.668%2017.0684C109.668%2014.6736%20111.618%2012.7244%20114.011%2012.7244C114.757%2012.7244%20115.46%2012.9136%20116.075%2013.2475V11.5862C115.432%2011.3444%20114.737%2011.2112%20114.011%2011.2112Z\\'%20fill=\\'black\\'/%3e%3c/g%3e%3cdefs%3e%3cclipPath%20id=\\'clip0_2993_300192\\'%3e%3crect%20width=\\'127\\'%20height=\\'28\\'%20fill=\\'white\\'/%3e%3c/clipPath%3e%3c/defs%3e%3c/svg%3e)\\n![home-main-title-bg-light](https://static.skywork.ai/fe/skywork-site-assets/images/home/temp/home-main-title-bg-light.png)\\n![](data:image/svg+xml,%3csvg%20width=\\'20\\'%20height=\\'20\\'%20viewBox=\\'0%200%2020%2020\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20d=\\'M9.6593%202.32748C9.90788%202.07934%2010.3102%202.07929%2010.5587%202.32748C10.8074%202.57614%2010.8074%202.98018%2010.5587%203.22884L3.80285%209.9847L10.5587%2016.7415C10.8074%2016.9902%2010.8074%2017.3933%2010.5587%2017.6419C10.3101%2017.8902%209.90789%2017.8901%209.6593%2017.6419L2.45129%2010.4349C2.20312%2010.1863%202.20305%209.78306%202.45129%209.53451L9.6593%202.32748Z\\'%20fill=\\'%23485568\\'/%3e%3cpath%20d=\\'M16.8653%202.32748C17.114%202.07918%2017.5172%202.07913%2017.7657%202.32748C18.0144%202.57614%2018.0144%202.98018%2017.7657%203.22884L11.0089%209.9847L17.7657%2016.7415C18.0142%2016.9902%2018.0143%2017.3933%2017.7657%2017.6419C17.5172%2017.8902%2017.114%2017.8902%2016.8653%2017.6419L9.65832%2010.4349C9.41001%2010.1863%209.40999%209.7831%209.65832%209.53451L16.8653%202.32748Z\\'%20fill=\\'%23485568\\'/%3e%3c/svg%3e)\\n\\n### Outline\\n\\n## Table of Contents\\n\\n## Introduction: The \"USB-C for AI\" is Here\\n\\n## What is the Model Context Protocol (MCP)? A Foundational Overview\\n\\n### Core Purpose and Vision\\n\\n### Key Architectural Concepts\\n\\n### Why It Matters for Engineers & Architects\\n\\n## Deep Dive: Building Your First MCP Server\\n\\n### What an MCP Server Does\\n\\n### Core Primitives of an MCP Server\\n\\n### Getting Started: A Practical Walkthrough\\n\\n## Ship with Confidence: Automated Testing with MCP-Jest\\n\\n### The Problem: Why Testing MCP Servers is Critical (and Hard)\\n\\n### Introducing MCP-Jest: The Missing Piece of the Ecosystem\\n\\n### Key Features of MCP-Jest\\n\\n### How to Use MCP-Jest: A Quickstart Guide\\n\\n### Best Practices for Testing MCP Servers\\n\\n## MCP in the Wild: Ecosystem, Use Cases, and Adoption\\n\\n### The Growing Ecosystem\\n\\n### Real-World Use Cases\\n\\n## Comparative Analysis: MCP vs. The Alternatives\\n\\n### MCP vs. OpenAI Function Calling\\n\\n### MCP vs. Agentic Frameworks (LangChain, Semantic Kernel)\\n\\n### MCP vs. UTCP (Universal Tool Calling Protocol)\\n\\n## Advanced Topics: Security, Performance, and the Future\\n\\n### Security Best Practices & Anti-Patterns\\n\\n### Performance Optimization for MCP Servers\\n\\n### The MCP Roadmap & Community Feedback\\n\\n## FAQ & Resources\\n\\n## Conclusion\\n\\n## 1. Core Content Quality\\n\\n## 2. Structural Elements\\n\\n## 3. Heading Structure\\n\\n## 4. Content Depth & Breadth\\n\\n## 5. Query Optimization\\n\\n## 6. Competitive Advantage\\n\\n## 7. Semantic Structure\\n\\n## 8. Language Optimization\\n\\n## 9. Information Architecture\\n\\n## 10. Search Alignment\\n\\n### Summary of Evaluation\\n\\n### Overall Improvement Suggestions\\n\\n# MCP Server and MCP-Jest: A Comprehensive Guide for AI Engineers\\n\\n![logo](data:image/svg+xml,%3csvg%20width=\\'24\\'%20height=\\'24\\'%20viewBox=\\'0%200%2024%2024\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20d=\\'M13.4348%202.017C10.3086%20-0.422473%205.7882%20-0.341111%202.74472%202.40864C-0.666963%205.48936%20-0.934492%2010.7517%202.14622%2014.162C4.89598%2017.2068%209.38467%2017.746%2012.7426%2015.6361L6.27913%208.48044L13.4348%202.017Z\\'%20fill=\\'%234D5EFF\\'/%3e%3cpath%20d=\\'M10.5663%2021.983C13.6925%2024.4225%2018.2129%2024.3411%2021.2564%2021.5914C24.6667%2018.5107%2024.9343%2013.2484%2021.8535%209.83807C19.1038%206.7932%2014.6151%206.25401%2011.2572%208.3639L17.7206%2015.5196L10.5649%2021.983H10.5663Z\\'%20fill=\\'%2300FFCE\\'/%3e%3c/svg%3e)\\n![logo](data:image/svg+xml,%3csvg%20width=\\'14\\'%20height=\\'14\\'%20viewBox=\\'0%200%2014%2014\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20d=\\'M10.8133%202.40548L7.60492%201.20381C7.27242%201.08131%206.72993%201.08131%206.39743%201.20381L3.18909%202.40548C2.57076%202.63881%202.06909%203.36215%202.06909%204.02131V8.74631C2.06909%209.21881%202.37826%209.84298%202.75743%2010.123L5.96576%2012.5205C6.53159%2012.9463%207.45909%2012.9463%208.02492%2012.5205L11.2333%2010.123C11.6124%209.83715%2011.9216%209.21881%2011.9216%208.74631V4.02131C11.9274%203.36215%2011.4258%202.63881%2010.8133%202.40548Z\\'%20fill=\\'white\\'/%3e%3cpath%20fill-rule=\\'evenodd\\'%20clip-rule=\\'evenodd\\'%20d=\\'M7.00299%206.01172C7.34375%206.01172%207.61999%206.24587%207.61999%206.5347V9.88717C7.61999%2010.176%207.34375%2010.4102%207.00299%2010.4102C6.66223%2010.4102%206.38599%2010.176%206.38599%209.88717V6.5347C6.38599%206.24587%206.66223%206.01172%207.00299%206.01172Z\\'%20fill=\\'%234D5EFF\\'/%3e%3cpath%20fill-rule=\\'evenodd\\'%20clip-rule=\\'evenodd\\'%20d=\\'M6.28442%204.30177C6.28442%203.90858%206.60316%203.58984%206.99635%203.58984H7.00345C7.39664%203.58984%207.71538%203.90858%207.71538%204.30177C7.71538%204.69495%207.39664%205.01369%207.00345%205.01369H6.99635C6.60316%205.01369%206.28442%204.69495%206.28442%204.30177Z\\'%20fill=\\'%234D5EFF\\'/%3e%3c/svg%3e)\\n![](data:image/svg+xml,%3csvg%20width=\\'24\\'%20height=\\'24\\'%20viewBox=\\'0%200%2024%2024\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20d=\\'M9.40697%202.99976C7.27155%202.99976%205.57982%203.4222%204.44107%204.56095C3.30232%205.6997%202.87988%207.39142%202.87988%209.52685V14.4729C2.87988%2016.6083%203.30232%2018.3%204.44107%2019.4388C5.57982%2020.5775%207.27155%2021%209.40697%2021H14.353C16.4884%2021%2018.1801%2020.5775%2019.3189%2019.4388C20.4576%2018.3%2020.8801%2016.6083%2020.8801%2014.4729V12.8242C20.8801%2012.4062%2020.5413%2012.0674%2020.1233%2012.0674C19.7054%2012.0674%2019.3666%2012.4062%2019.3666%2012.8242V14.4729C19.3666%2016.459%2018.9647%2017.6525%2018.2487%2018.3686C17.5326%2019.0846%2016.3391%2019.4865%2014.353%2019.4865H9.40697C7.42083%2019.4865%206.22732%2019.0846%205.51127%2018.3686C4.79522%2017.6525%204.39337%2016.459%204.39337%2014.4729V9.52685C4.39337%207.54071%204.79522%206.3472%205.51127%205.63115C6.22732%204.9151%207.42083%204.51325%209.40697%204.51325H11.0556C11.4736%204.51325%2011.8124%204.17444%2011.8124%203.7565C11.8124%203.33856%2011.4736%202.99976%2011.0556%202.99976H9.40697Z\\'%20fill=\\'%23485568\\'/%3e%3cpath%20d=\\'M16.1665%202.99976C15.7485%202.99976%2015.4097%203.33856%2015.4097%203.7565C15.4097%204.17444%2015.7485%204.51325%2016.1665%204.51325H18.2964L12.1692%2010.6405C11.8736%2010.936%2011.8736%2011.4152%2012.1692%2011.7107C12.4647%2012.0062%2012.9438%2012.0062%2013.2394%2011.7107L19.3665%205.58353V7.71331C19.3665%208.13125%2019.7054%208.47006%2020.1233%208.47006C20.5412%208.47006%2020.88%208.13125%2020.88%207.71331V3.7565C20.88%203.33856%2020.5412%202.99976%2020.1233%202.99976H16.1665Z\\'%20fill=\\'%23485568\\'/%3e%3c/svg%3e)\\n![](data:image/svg+xml,%3csvg%20width=\\'18\\'%20height=\\'18\\'%20viewBox=\\'0%200%2018%2018\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20fill-rule=\\'evenodd\\'%20clip-rule=\\'evenodd\\'%20d=\\'M11.8838%202.39402C12.26%202.82422%2012.3841%203.40285%2012.1966%204.04665L11.7366%205.70432C11.653%206.00584%2011.8691%206.30758%2012.1815%206.32541L14.4679%206.45591C16.1098%206.57818%2017.2594%208.30548%2016.7502%209.96451C16.5423%2010.6418%2016.2553%2011.5603%2016.0205%2012.3086C15.903%2012.683%2015.7986%2013.0151%2015.7234%2013.2536L15.6025%2013.6372C15.5984%2013.6501%2015.5938%2013.663%2015.5888%2013.6756C15.202%2014.6372%2014.6971%2015.3197%2014.0381%2015.7531C13.3797%2016.1861%2012.6285%2016.3301%2011.8274%2016.3301H5.59061C5.58537%2016.3301%205.58013%2016.33%205.5749%2016.3298H3.85086C2.70056%2016.3473%201.49143%2015.3781%201.36114%2013.9283C1.36058%2013.9222%201.36013%2013.916%201.35979%2013.9098L1.1258%209.6376C1.12527%209.62789%201.125%209.61816%201.125%209.60843C1.125%208.75861%201.41892%208.13841%201.86404%207.71667C2.294%207.3093%202.82114%207.12799%203.23517%207.05371C3.24385%207.05215%203.25256%207.05081%203.2613%207.04969L5.24821%206.79409C5.28621%206.73487%205.33361%206.66082%205.38897%206.57403C5.54309%206.33235%205.7587%205.99204%206.00442%205.59788C6.49686%204.80797%207.10639%203.80793%207.58449%202.95301C8.17174%201.90292%209.48831%201.55818%2010.4895%201.70199C11.005%201.77603%2011.5292%201.98862%2011.8838%202.39402ZM14.706%2012.9332L14.5916%2013.2962C14.2605%2014.112%2013.8737%2014.5845%2013.452%2014.8618C13.0264%2015.1417%2012.504%2015.2634%2011.8274%2015.2634H6.12397V7.40448C6.16558%207.3397%206.22122%207.25287%206.28836%207.14759C6.44401%206.90351%206.66161%206.56007%206.90964%206.1622C7.40471%205.36807%208.02488%204.351%208.51551%203.47367C8.81283%202.94201%209.5999%202.65187%2010.3378%202.75786C10.6919%202.80872%2010.9461%202.9422%2011.0808%203.09627C11.1931%203.22466%2011.2694%203.41739%2011.1718%203.7505L10.7088%205.41911C10.4432%206.37611%2011.1292%207.33382%2012.1208%207.39039L14.3929%207.52C15.3105%207.59128%2016.0502%208.60986%2015.7304%209.65148C15.5236%2010.3253%2015.2374%2011.2411%2015.0027%2011.9893C14.8854%2012.3632%2014.781%2012.6949%2014.706%2012.9332ZM2.59771%208.49102C2.82466%208.27599%203.12754%208.15856%203.41126%208.1059L5.05714%207.89418V15.2631H3.84653L3.8371%2015.2632C3.25785%2015.2735%202.5098%2014.7425%202.42437%2013.8415L2.19175%209.59451C2.19477%209.02124%202.38438%208.69314%202.59771%208.49102Z\\'%20fill=\\'%23485568\\'/%3e%3c/svg%3e)\\n![](data:image/svg+xml,%3csvg%20width=\\'18\\'%20height=\\'18\\'%20viewBox=\\'0%200%2018%2018\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20fill-rule=\\'evenodd\\'%20clip-rule=\\'evenodd\\'%20d=\\'M11.8838%202.39402C12.26%202.82422%2012.3841%203.40285%2012.1966%204.04665L11.7366%205.70432C11.653%206.00584%2011.8691%206.30758%2012.1815%206.32541L14.4679%206.45591C16.1098%206.57818%2017.2594%208.30548%2016.7502%209.96451C16.5423%2010.6418%2016.2553%2011.5603%2016.0205%2012.3086C15.903%2012.683%2015.7986%2013.0151%2015.7234%2013.2536L15.6025%2013.6372C15.5984%2013.6501%2015.5938%2013.663%2015.5888%2013.6756C15.202%2014.6372%2014.6971%2015.3197%2014.0381%2015.7531C13.3797%2016.1861%2012.6285%2016.3301%2011.8274%2016.3301H5.59061C5.58537%2016.3301%205.58013%2016.33%205.5749%2016.3298H3.85086C2.70056%2016.3473%201.49143%2015.3781%201.36114%2013.9283C1.36058%2013.9222%201.36013%2013.916%201.35979%2013.9098L1.1258%209.6376C1.12527%209.62789%201.125%209.61816%201.125%209.60843C1.125%208.75861%201.41892%208.13841%201.86404%207.71667C2.294%207.3093%202.82114%207.12799%203.23517%207.05371C3.24385%207.05215%203.25256%207.05081%203.2613%207.04969L5.24821%206.79409C5.28621%206.73487%205.33361%206.66082%205.38897%206.57403C5.54309%206.33235%205.7587%205.99204%206.00442%205.59788C6.49686%204.80797%207.10639%203.80793%207.58449%202.95301C8.17174%201.90292%209.48831%201.55818%2010.4895%201.70199C11.005%201.77603%2011.5292%201.98862%2011.8838%202.39402ZM14.706%2012.9332L14.5916%2013.2962C14.2605%2014.112%2013.8737%2014.5845%2013.452%2014.8618C13.0264%2015.1417%2012.504%2015.2634%2011.8274%2015.2634H6.12397V7.40448C6.16558%207.3397%206.22122%207.25287%206.28836%207.14759C6.44401%206.90351%206.66161%206.56007%206.90964%206.1622C7.40471%205.36807%208.02488%204.351%208.51551%203.47367C8.81283%202.94201%209.5999%202.65187%2010.3378%202.75786C10.6919%202.80872%2010.9461%202.9422%2011.0808%203.09627C11.1931%203.22466%2011.2694%203.41739%2011.1718%203.7505L10.7088%205.41911C10.4432%206.37611%2011.1292%207.33382%2012.1208%207.39039L14.3929%207.52C15.3105%207.59128%2016.0502%208.60986%2015.7304%209.65148C15.5236%2010.3253%2015.2374%2011.2411%2015.0027%2011.9893C14.8854%2012.3632%2014.781%2012.6949%2014.706%2012.9332ZM2.59771%208.49102C2.82466%208.27599%203.12754%208.15856%203.41126%208.1059L5.05714%207.89418V15.2631H3.84653L3.8371%2015.2632C3.25785%2015.2735%202.5098%2014.7425%202.42437%2013.8415L2.19175%209.59451C2.19477%209.02124%202.38438%208.69314%202.59771%208.49102Z\\'%20fill=\\'%23485568\\'/%3e%3c/svg%3e)\\n\\n## Featured Picks\\n\\n## Browse by Date\\n\\n## Browse by Alphabet\\n\\n![](data:image/svg+xml,%3csvg%20width=\\'24\\'%20height=\\'24\\'%20viewBox=\\'0%200%2024%2024\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cpath%20d=\\'M14.9697%201.25C15.274%201.25%2015.5704%201.25768%2015.8584%201.27246C15.9143%201.25917%2015.9723%201.25%2016.0322%201.25C16.1275%201.25001%2016.2179%201.27029%2016.3018%201.30273C18.2403%201.46153%2019.7805%202.00037%2020.875%203.09473C22.2094%204.42914%2022.7197%206.42619%2022.7197%209V15C22.7197%2017.5739%2022.2094%2019.5708%2020.875%2020.9053C19.7807%2021.9996%2018.241%2022.5384%2016.3027%2022.6973C16.2186%2022.73%2016.128%2022.75%2016.0322%2022.75C15.9712%2022.75%2015.9122%2022.7413%2015.8555%2022.7275C15.5684%2022.7422%2015.273%2022.75%2014.9697%2022.75H8.96973C6.39585%2022.75%204.39889%2022.2397%203.06445%2020.9053C1.73018%2019.5708%201.21973%2017.5738%201.21973%2015V9C1.21977%206.42619%201.73004%204.42914%203.06445%203.09473C4.39889%201.76035%206.3959%201.25003%208.96973%201.25H14.9697ZM8.96973%202.75C6.54388%202.75003%205.04051%203.23981%204.125%204.15527C3.20951%205.07076%202.71977%206.57417%202.71973%209V15C2.71973%2017.4258%203.20964%2018.9292%204.125%2019.8447C5.04051%2020.7602%206.54381%2021.25%208.96973%2021.25H14.9697C15.0756%2021.25%2015.1798%2021.247%2015.2822%2021.2451V2.75391C15.1799%202.75205%2015.0756%202.75%2014.9697%202.75H8.96973ZM16.7822%2021.1367C18.1842%2020.944%2019.1528%2020.5064%2019.8145%2019.8447C20.7299%2018.9292%2021.2197%2017.426%2021.2197%2015V9C21.2197%206.57417%2020.7299%205.07076%2019.8145%204.15527C19.1528%203.49375%2018.1841%203.05503%2016.7822%202.8623V21.1367ZM8.50195%208.91016C8.79485%208.61736%209.26964%208.61729%209.5625%208.91016L12.1221%2011.4697C12.4149%2011.7626%2012.4149%2012.2374%2012.1221%2012.5303L9.5625%2015.0908C9.26971%2015.3836%208.79487%2015.3834%208.50195%2015.0908C8.20906%2014.7979%208.20906%2014.3232%208.50195%2014.0303L10.5312%2012L8.50195%209.9707C8.20906%209.67781%208.20906%209.20305%208.50195%208.91016Z\\'%20fill=\\'%23485568\\'/%3e%3c/svg%3e)\\n![logo](data:image/svg+xml,%3csvg%20width=\\'58\\'%20height=\\'59\\'%20viewBox=\\'0%200%2058%2059\\'%20fill=\\'none\\'%20xmlns=\\'http://www.w3.org/2000/svg\\'%3e%3cg%20filter=\\'url(%23filter0_d_21176_403320)\\'%3e%3crect%20x=\\'47\\'%20y=\\'44.7427\\'%20width=\\'36\\'%20height=\\'36\\'%20rx=\\'18\\'%20transform=\\'rotate(180%2047%2044.7427)\\'%20fill=\\'white\\'/%3e%3cpath%20d=\\'M22.1745%2024.839L28.5026%2018.5108C28.5679%2018.4455%2028.6455%2018.3936%2028.7308%2018.3582C28.8162%2018.3228%2028.9077%2018.3046%2029.0001%2018.3046C29.0925%2018.3046%2029.184%2018.3228%2029.2694%2018.3582C29.3547%2018.3936%2029.4323%2018.4455%2029.4976%2018.5108L35.8257%2024.839C35.9576%2024.9709%2036.0317%2025.1498%2036.0317%2025.3364C36.0317%2025.523%2035.9576%2025.702%2035.8257%2025.8339C35.6937%2025.9658%2035.5148%2026.0399%2035.3282%2026.0399C35.1416%2026.0399%2034.9627%2025.9658%2034.8308%2025.8339L29.7032%2020.7055V34.4771C29.7032%2034.6635%2029.6291%2034.8424%2029.4973%2034.9742C29.3654%2035.1061%2029.1866%2035.1802%2029.0001%2035.1802C28.8136%2035.1802%2028.6348%2035.1061%2028.5029%2034.9742C28.3711%2034.8424%2028.297%2034.6635%2028.297%2034.4771V20.7055L23.1694%2025.8339C23.0375%2025.9658%2022.8586%2026.0399%2022.672%2026.0399C22.4854%2026.0399%2022.3064%2025.9658%2022.1745%2025.8339C22.0426%2025.702%2021.9685%2025.523%2021.9685%2025.3364C21.9685%2025.1498%2022.0426%2024.9709%2022.1745%2024.839Z\\'%20fill=\\'%23485568\\'/%3e%3c/g%3e%3cdefs%3e%3cfilter%20id=\\'filter0_d_21176_403320\\'%20x=\\'0.200001\\'%20y=\\'0.642676\\'%20width=\\'57.6\\'%20height=\\'57.6\\'%20filterUnits=\\'userSpaceOnUse\\'%20color-interpolation-filters=\\'sRGB\\'%3e%3cfeFlood%20flood-opacity=\\'0\\'%20result=\\'BackgroundImageFix\\'/%3e%3cfeColorMatrix%20in=\\'SourceAlpha\\'%20type=\\'matrix\\'%20values=\\'0%200%200%200%200%200%200%200%200%200%200%200%200%200%200%200%200%200%20127%200\\'%20result=\\'hardAlpha\\'/%3e%3cfeOffset%20dy=\\'2.7\\'/%3e%3cfeGaussianBlur%20stdDeviation=\\'5.4\\'/%3e%3cfeComposite%20in2=\\'hardAlpha\\'%20operator=\\'out\\'/%3e%3cfeColorMatrix%20type=\\'matrix\\'%20values=\\'0%200%200%200%200%200%200%200%200%200.0313726%200%200%200%200%200.0941176%200%200%200%200.12%200\\'/%3e%3cfeBlend%20mode=\\'normal\\'%20in2=\\'BackgroundImageFix\\'%20result=\\'effect1_dropShadow_21176_403320\\'/%3e%3cfeBlend%20mode=\\'normal\\'%20in=\\'SourceGraphic\\'%20in2=\\'effect1_dropShadow_21176_403320\\'%20result=\\'shape\\'/%3e%3c/filter%3e%3c/defs%3e%3c/svg%3e)\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 5: Building MCP Servers for Any Language (including Kotlin / Ruby ... ---\\nURL: https://dev.to/yigit-konur/building-mcp-servers-for-any-language-including-kotlin-ruby-rust-java-go-typescript--2ofi\\n\\nSUMMARY:\\nStreamable HTTP is the modern, recommended transport for all remote MCP servers, designed to overcome the limitations of the legacy SSE model and provide a robust foundation for enterprise-grade web services. + **Server Identification & Use Case**: The official `modelcontextprotocol/servers/git` server is a production-ready example that exposes Git operations as MCP tools without requiring shell access. + **Server Identification & Use Case**: The `seuros/action_mcp` project (50 , 300+ commits) is a premier, production-grade Rails engine designed for large, network-based deployments, explicitly built for the modern Streamable HTTP transport. + **Server Identification & Use Case**: The official SDK provides the `devyhan/mcp-swift-example-server` as a minimal \"echo\" tool provider tailored for Claude Desktop, with a compiled binary under 1 MB.\\n\\nFULL CONTENT:\\n![Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fwalhydbusoe2o1pzxfwj.png)\\n\\n### Forem Feed\\n\\n![DEV Community Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F8j7kvp660rqzt99zui8e.png)\\n![DEV Community Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F3otvb2z646ytpt1hl2rv.jpg)\\n\\n### [DEV Community](//dev.to)\\n\\nA space to discuss and keep up software development and manage your software career\\n\\n![Gamers Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fd89n749pwv3d05i93pfd.png)\\n![Gamers Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgg6i5z7ureeu96cayz19.png)\\n\\n### [Gamers Forem](//gg.forem.com)\\n\\nAn inclusive community for gaming enthusiasts\\n\\n![Future Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F9xjsbjb3ulcgpx932599.png)\\n![Future Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frnip9mvroe4n1spfm43q.png)\\n\\n### [Future](//future.forem.com)\\n\\nNews and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.\\n\\n![Open Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fg8k8nlv7yl97085q8agp.png)\\n![Open Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F9azopgwnjjpkgvtn5nux.png)\\n\\n### [Open Forem](//open.forem.com)\\n\\nA general discussion space for the Forem community. If it doesn\\'t have a home elsewhere, it belongs here\\n\\n![Music Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Feyc812o5ed0he648y218.png)\\n![Music Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fqji7l84bi520qypekh4t.png)\\n\\n### [Music Forem](//music.forem.com)\\n\\nFrom composing and gigging to gear, hot music takes, and everything in between.\\n\\n![Vibe Coding Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fzhktp1xvmpf29y860wd3.png)\\n![Vibe Coding Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fetixkjcs50ddkp6wlv4p.png)\\n\\n### [Vibe Coding Forem](//vibe.forem.com)\\n\\nDiscussing AI software development, and showing off what we\\'re building.\\n\\n![Popcorn Movies and TV Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fmkwem77uxpvir9vy9eeu.png)\\n![Popcorn Movies and TV Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fi8rwbqi6l4wln8kbx606.png)\\n\\n### [Popcorn Movies and TV](//popcorn.forem.com)\\n\\nMovie and TV enthusiasm, criticism and everything in-between.\\n\\n![DUMB DEV Community Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Finbbclsxtvxdfo0p2n66.png)\\n![DUMB DEV Community Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fvb6sq9t5ehunzj4r4695.png)\\n\\n### [DUMB DEV Community](//dumb.dev.to)\\n\\nMemes and software development shitposting\\n\\n![Design Community Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Ff83jl8yxfp6c5srbo02f.png)\\n![Design Community Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fujjn1ap9mpq8bwzn76em.png)\\n\\n### [Design Community](//design.forem.com)\\n\\nWeb design, graphic design and everything in-between\\n\\n![Golf Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fnijx8yj8r5psetuqsw5z.png)\\n![Golf Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fp2khtue7prp0t5p0pouh.png)\\n\\n### [Golf Forem](//golf.forem.com)\\n\\nA community of golfers and golfing enthusiasts\\n\\n![Security Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fdmn0m1ocwggrdvsma2cm.png)\\n![Security Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fhlhtmj657f6j9nh8mxwm.png)\\n\\n### [Security Forem](//zeroday.forem.com)\\n\\nYour central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike\\n\\n![Scale Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fkoohn8742pw7pbny3b32.png)\\n![Scale Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fiw9yu9dyt5nvlyis5v1d.png)\\n\\n### [Scale Forem](//scale.forem.com)\\n\\nFor engineers building software at scale. We discuss architecture, cloud-native, and SREthe hard-won lessons you can\\'t just Google\\n\\n![Forem Core Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fupzbzgpb13b3e0dfxf51.png)\\n![Forem Core Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F7qi7bzwq9yok35no2owa.png)\\n\\n### [Forem Core](//core.forem.com)\\n\\nDiscussing the core forem open source software project  features, bugs, performance, self-hosting.\\n\\n![Parenting Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fsubforem_images%2Fmain_logo_5A1ZlPe69YTXNRsAxCXK.png)\\n![Parenting Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fsubforem_images%2Fsocial_card_rFghJWhbtJWReC430aDM.png)\\n\\n### [Parenting](//parenting.forem.com)\\n\\nA place for parents to the share the joys, challenges, and wisdom that come from raising kids. We\\'re here for them and for each other.\\n\\n![Crypto Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fzbfoyqjor9xqe5xtqani.png)\\n![Crypto Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fg0rowhjp8x0bqzdsmq0w.png)\\n\\n### [Crypto Forem](//crypto.forem.com)\\n\\nA collaborative community for all things Cryptofrom Bitcoin to protocol development and DeFi to NFTs and market analysis.\\n\\n![Maker Forem Logo](https://media2.dev.to/dynamic/image/width=65,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F7mwsgj74kx4dn0fliwh7.png)\\n![Maker Forem Main Image](https://media2.dev.to/dynamic/image/width=440,height=,fit=scale-down,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F01bkopv3unqemfs036vr.png)\\n\\n### [Maker Forem](//maker.forem.com)\\n\\nA community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.\\n\\n![DEV Community](https://media2.dev.to/dynamic/image/quality=100/https://dev-to-uploads.s3.amazonaws.com/uploads/logos/resized_logo_UQww2soKuUsjaOGNB38o.png)\\n\\n## DEV Community\\n\\n![](https://assets.dev.to/assets/heart-plus-active-9ea3b22f2bc311281db911d416166c5f430636e76b15cd5df6b3b841d830eefa.svg)\\n![](https://assets.dev.to/assets/sparkle-heart-5f9bee3767e18deb1bb725290cb151c25234768a0e9a2bd39370c382d02920cf.svg)\\n![](https://assets.dev.to/assets/multi-unicorn-b44d6f8c23cdd00964192bedc38af3e82463978aa611b4365bd33a0f1f4f3e97.svg)\\n![](https://assets.dev.to/assets/exploding-head-daceb38d627e6ae9b730f36a1e390fca556a4289d5a41abb2c35068ad3e2c4b5.svg)\\n![](https://assets.dev.to/assets/raised-hands-74b2099fd66a39f2d7eed9305ee0f4553df0eb7b4f11b01b6b1b499973048fe5.svg)\\n![](https://assets.dev.to/assets/fire-f60e7a582391810302117f987b22a8ef04a2fe0df7e3258a5f49332df1cec71e.svg)\\n![Yigit Konur](https://media2.dev.to/dynamic/image/width=50,height=50,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fuser%2Fprofile_image%2F2966359%2Fb8329bf0-6696-40e6-b41b-212fe63f7dd1.png)\\n\\nPosted on Jul 30\\n\\n# Building MCP Servers for Any Language (including Kotlin / Ruby / Rust / Java / Go / Typescript / Python / Swift / C# Based MCPs)\\n\\nThis report provides a definitive, expert-level analysis of production-grade Model Context Protocol (MCP) server implementations across a matrix of nine programming languages and three core transport protocols. It is synthesized from extensive research into official documentation, reference implementations, and mature community projects to serve as a comprehensive guide for architects and engineers building on this foundational AI standard.\\n\\n### Section 1: Foundational Principles of the Model Context Protocol\\n\\nThis section establishes a firm understanding of the protocol\\'s foundational principles, architecture, and strategic purpose, which are essential before dissecting specific implementations.\\n\\n#### 1.1. Defining MCP: The \"USB-C for AI\" and the M x N Problem\\n\\nThe Model Context Protocol (MCP) is an open standard, introduced by Anthropic in late 2024, designed to universalize the integration between Large Language Models (LLMs) and external tools, data sources, and systems. It addresses what is often termed the \"M x N\" integration problem: without a standard, M AI clients (such as integrated development environments or chat applications) would need to build M custom integrations to connect with N distinct tools (like version control systems, databases, or project management APIs). MCP transforms this combinatorial explosion into a linear M + N problem by creating a standardized communication layer, much like USB-C provides a universal physical port for diverse peripherals.\\n\\nThe protocol\\'s design is heavily influenced by the Language Server Protocol (LSP), which solved a similar M x N problem for developer tools. This strategic focus on developer tool integration is a primary and highly impactful use case, with major early adopters being developer-centric environments like Zed, Replit, Cursor, and Visual Studio Code.\\n\\n#### 1.2. MCP vs. Traditional APIs: A Paradigm for AI Consumption\\n\\nA crucial distinction for system architects is the difference between a traditional Application Programming Interface (API) and an MCP server. An API is designed for consumption by human developers or programs with predefined logic; it is built for entities that know exactly what they want to do. In contrast, an MCP server is designed specifically for consumption by AI models. Instead of exposing rigid API endpoints, an MCP server provides a machine-readable manifest of its capabilities. This \"plug-and-play\" architecture allows an AI model to dynamically discover what actions are possible, what inputs they require, and how to use them, enabling it to plan and execute complex, multi-step tasks without hard-coded integrations.\\n\\n#### 1.3. The MCP Triumvirate: Host, Client, and Server Architecture\\n\\nThe MCP architecture is defined by three core participants that work in concert to facilitate communication between an AI and the outside world. Understanding the distinct roles of each component is essential for implementing and integrating MCP-based systems.\\n\\nThis architecture is built upon a two-layer protocol stack. The inner Data Layer is based on JSON-RPC 2.0 and defines the core message types and primitives, while the outer Transport Layer defines the mechanisms for data exchange. This separation ensures protocol semantics remain consistent across different communication channels.\\n\\n#### 1.4. Core Primitives: The Language of MCP\\n\\nMCP defines a clear vocabulary of primitives that servers can expose to allow an LLM to discover, understand, and utilize external capabilities.\\n\\n#### 1.5. The MCP Lifecycle: From Handshake to Shutdown\\n\\nEvery interaction between an MCP client and server follows a well-defined lifecycle based on the JSON-RPC 2.0 protocol, ensuring a shared understanding of capabilities and state.\\n\\n`InitializeRequest`\\n`InitializeResult`\\n`tools/list_changed`\\n`tools/list`\\n`resources/list`\\n\\n### Section 2: The MCP Transport Layer: A Deep Dive\\n\\nThe choice of transport protocol is a critical architectural decision, directly impacting a server\\'s deployment model, scalability, and security posture. The specification has evolved from a simple, local-only model to a robust, flexible standard for remote communication.\\n\\n#### 2.1. A Comparative Analysis of MCP Transport Protocols\\n\\n| Feature | STDIO (Standard Input/Output) | SSE (Server-Sent Events) - Legacy | Streamable HTTP |\\n| --- | --- | --- | --- |\\n| **Ideal Use Case** | Local tools, CLI integrations, desktop assistants (e.g., VS Code, Claude Desktop). | Legacy remote systems, educational purposes to understand protocol evolution. | All modern remote servers, scalable web services, public-facing tools. |\\n| **Communication Model** | Direct, synchronous inter-process communication via `stdin` and `stdout`. | Asynchronous, bidirectional. Uses two separate HTTP connections: a GET for server-to-client streaming (SSE) and a POST for client-to-server messages. | Asynchronous, bidirectional. Uses a single HTTP endpoint. Can operate in a stateless request/response mode or be \"upgraded\" to a stateful streaming connection. |\\n| **Network Accessibility** | None. Confined to the local machine. | Yes. Accessible over any IP network. | Yes. Accessible over any IP network. |\\n| **Scalability** | Low. Limited to a single client connection per server process. | Moderate. The dual-connection model adds complexity to infrastructure like load balancers. | High. The single-endpoint model and support for stateless operation make it highly compatible with modern, scalable web infrastructure. |\\n| **Authentication** | None required. Security is inherent through process isolation on the local machine. | Custom implementation required. Typically handled via HTTP headers (e.g., Bearer tokens). | Natively supports standard HTTP authentication methods (Bearer tokens, API keys, OAuth). |\\n| **Implementation Complexity** | Low. The simplest transport to implement. | High. The dual-endpoint architecture is complex and \"awkward\". | Moderate. Simpler than legacy SSE due to the single endpoint. |\\n| **Current Spec Status** | Active. The standard for local communication. | Deprecated as of MCP specification version 2025-03-26. | Active. The current recommended standard for all remote communication. |\\n\\n`stdin`\\n`stdout`\\n\\n#### 2.2. STDIO: For Secure, Local Process Integration\\n\\nStandard Input/Output (STDIO) is the default and most fundamental transport, designed for inter-process communication (IPC) on a single machine. The MCP host launches the server as a local subprocess. The client writes newline-delimited JSON-RPC messages to the server\\'s `stdin` stream, and the server writes responses to `stdout`. It is critical that any server-side logging is directed exclusively to the `stderr` stream to avoid interfering with the protocol.\\n\\n`stdin`\\n`stdout`\\n`stderr`\\n\\nThis transport is ideal for integrating local tools where network overhead is unnecessary and security is paramount, such as a filesystem server or a CLI tool controlled by an AI agent. The operating system\\'s process isolation provides a natural sandbox. This is the preferred method for command-line tools (like the Heroku CLI server) and integrations with desktop applications like Claude Desktop or VS Code. Its primary limitations are its confinement to the local machine, its lifecycle being bound to the parent process, and its single-client-per-process model.\\n\\n#### 2.3. The Evolution of Remote Transports\\n\\n##### 2.3.1. Legacy SSE: The \"Architectural Awkwardness\"\\n\\nThe original approach for remote servers was a standalone \"HTTP with SSE\" transport. Since Server-Sent Events (SSE) is inherently a one-way channel (server-to-client), the protocol had to be supplemented with a second, separate channel for client-to-server messages. This created what has been described as an \"architectural awkwardness.\" The complex workflow involved a GET request to one endpoint (e.g., `/sse`) to establish the SSE stream and separate POST requests to another endpoint (e.g., `/messages`) for sending messages to the server. Due to this complexity and the superiority of the modern alternative, the standalone SSE transport was officially deprecated in the MCP specification version 2025-03-26. While the transport is deprecated, the SSE *format* (`text/event-stream`) remains a core component of the modern Streamable HTTP transport.\\n\\n`/sse`\\n`/messages`\\n`text/event-stream`\\n\\n##### 2.3.2. Streamable HTTP: The Modern Standard for Scalable, Remote Services\\n\\nStreamable HTTP is the modern, recommended transport for all remote MCP servers, designed to overcome the limitations of the legacy SSE model and provide a robust foundation for enterprise-grade web services. It unifies all communication over a single HTTP endpoint (e.g., `/mcp`) and supports multiple HTTP methods for full session control: `POST` for client-to-server messages, `GET` to open a persistent stream for server-to-client notifications, and `DELETE` to terminate a session.\\n\\n`/mcp`\\n`POST`\\n`GET`\\n`DELETE`\\n\\nThis transport offers immense flexibility by operating in two primary modes:\\n\\n`text/event-stream`\\n\\nTo manage stateful interactions, the server can issue a globally unique and secure session identifier via the `Mcp-Session-Id` response header. The client must include this header in all subsequent requests to maintain its session. For network reliability, the server can attach a unique ID to each event sent over a stream. If the connection is interrupted, a client can reconnect and include the `Last-Event-ID` header, allowing a compliant server to replay any missed messages.\\n\\n`Mcp-Session-Id`\\n`Last-Event-ID`\\n\\n#### 2.4. Production Security Paradigms for Network Transports\\n\\nMCP is designed with production security as a primary concern. The specification mandates several critical security practices for the network-exposed Streamable HTTP transport.\\n\\n`WWW-Authenticate`\\n`Origin`\\n`Mcp-Session-Id`\\n`localhost`\\n`127.0.0.1`\\n\\n### Section 3: Production-Grade MCP Server Implementations: A Language-by-Language Analysis\\n\\nThis section presents a detailed analysis of MCP server implementations, organized by programming language. The selected examples are drawn from official reference implementations and mature community projects, chosen to represent production-ready architectural patterns and best practices.\\n\\n#### 3.1. Python\\n\\nThe Python ecosystem for MCP is among the most mature, anchored by the official SDK which provides the high-level `FastMCP` framework that simplifies and accelerates server development.\\n\\n`FastMCP`\\n\\n**Protocol: STDIO**\\n\\n`modelcontextprotocol/servers/filesystem`\\n`RGGH/mcp-client-x`\\n`calculate_bmi`\\n`fetch_weather`\\n`FastMCP`\\n`mcp`\\n`@mcp.tool()`\\n`@mcp.resource()`\\n`mcp.run()`\\n`FastMCP`\\n\\n**Configuration & Execution**:\\n\\n`# Install the official SDK and a server\\npip install \"mcp[cli]\" mcp-server-filesystem\\n# Run the server, allowing access to the current directory\\npython -m mcp_server_filesystem .`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`modelcontextprotocol/servers/github`\\n`memory`\\n`Crawl4AI RAG MCP Server`\\n`coleam00/mcp-crawl4ai-rag`\\n`FastMCP`\\n`OpenDevin`\\n`theailanguage/mcp_streamable_http`\\n`ragieai/fastapi-sse-mcp`\\n`FastMCP`\\n`mcp.streamable_http_app()`\\n`Context`\\n`FastMCP`\\n`$/tool/progress`\\n\\n**Configuration & Execution**:\\n\\n`# Install dependencies for a web server\\npip install \"mcp[cli]\" uvicorn starlette\\n# In server.py, mount the FastMCP instance into a Starlette app\\n# Set environment variables for authentication (e.g., for the GitHub server)\\nexport GITHUB_API_TOKEN=\"your_token\"\\n# Run the server with Uvicorn\\nuvicorn server:app --host 0.0.0.0 --port 8000`\\n\\n#### 3.2. TypeScript\\n\\nThe TypeScript SDK is a peer to the Python SDK in maturity and is the basis for many official reference servers, which are part of a bundle with over 62,000 stars and 7,000 forks. It commonly integrates with the Express.js framework.\\n\\n**Protocol: STDIO**\\n\\n`modelcontextprotocol/servers/git`\\n`filesystem`\\n`joeBlockchain/mcp-server-client`\\n`McpServer`\\n`@modelcontextprotocol/sdk`\\n`StdioServerTransport`\\n`child_process.execFile`\\n`setImmediate`\\n\\n**Configuration & Execution**:\\n\\n`# Install and run a server directly using npx\\nnpx -y @modelcontextprotocol/server-filesystem /path/to/project`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`heroku/mcp-server`\\n`Stateless Hono MCP Server`\\n`mhart/mcp-hono-stateless`\\n`boilingdata/mcp-server-and-gw`\\n`danielma-tic/fillout-mcp-server`\\n`@modelcontextprotocol/core`\\n`yunusemredilber/express-mcp-sse-server`\\n`mcp-streamable-http-typescript-server`\\n`StreamableHTTPServerTransport`\\n`/mcp`\\n`handleRequest()`\\n`Mcp-Session-Id`\\n\\n**Configuration & Execution**:\\n\\n`# Install and run the Heroku server\\nnpx -y @heroku/mcp-server\\n# Set auth token (or use `heroku mcp:start` to leverage existing login)\\nexport HEROKU_API_KEY=\"your-auth-token\"`\\n\\n#### 3.3. C# / .NET\\n\\nThe C# SDK is developed with Microsoft\\'s collaboration, featuring deep integration with the .NET ecosystem, including the generic host builder, dependency injection, ASP.NET Core, and a `dotnet new` template for rapid scaffolding.\\n\\n`dotnet new`\\n\\n**Protocol: STDIO**\\n\\n`dotnet new mcpserver`\\n`.AddMcpServer()`\\n`.WithStdioServerTransport()`\\n`.WithToolsFromAssembly()`\\n`.vscode/mcp.json`\\n`[McpServerToolType]`\\n`[McpServerTool]`\\n`[MCPToolProvider]`\\n`[MCPTool]`\\n`.WithStdioServerTransport()`\\n\\n**Configuration & Execution**:\\n\\n`# Install the official template\\ndotnet new install Microsoft.Extensions.AI.Templates\\n# Create and run a new server project\\ndotnet new mcpserver -n MyMcpServer\\ncd MyMcpServer && dotnet run`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`Azure MCP Server`\\n`Remote MCP Functions (.NET)`\\n`Azure DevOps MCP Server`\\n`iaspnetcore/MCPServer`\\n`.AddMcpServer().WithHttpTransport()`\\n`app.MapMcp(\"/api/mcp\")`\\n`ModelContextProtocol.AspNetCore`\\n`IMcpServerTransport`\\n`IAsyncEnumerable<T>`\\n`ExampleHttpServer`\\n`HttpServer.HandleRequest`\\n\\n**Configuration & Execution**:\\n\\n`# In an ASP.NET Core project, add the NuGet package\\ndotnet add package ModelContextProtocol.AspNetCore --prerelease\\n# In Program.cs, add the services and map the endpoint, then run the application\\ndotnet run`\\n\\n#### 3.4. Java\\n\\nThe Java MCP ecosystem is heavily integrated with the Spring Framework, particularly Spring AI, which provides powerful auto-configuration for building enterprise-grade servers. There are varying reports on the level of independent adoption in the Java ecosystem. Some analyses as of mid-2025 note a lack of discoverable, public production-grade applications. Conversely, other reports point to significant adoption within major frameworks, with projects like the Quarkiverse \"quarkus-mcp-server\" extension, Wanaku MCP Router, and Solon-AI cited as being used in production, alongside enterprise-focused examples from vendors like Microsoft and Alibaba. As of May 2025, Maven Central reported 106 published artifacts declaring a dependency on `io.modelcontextprotocol.sdk:mcp`, signaling growing adoption.\\n\\n`io.modelcontextprotocol.sdk:mcp`\\n\\n**Protocol: STDIO**\\n\\n`spring-ai-starter-mcp-server`\\n`mcp-java-sdk-examples`\\n`codeboyzhou`\\n`Filesystem`\\n`StdioServerTransportProvider`\\n`@Tool`\\n`StdioServerTransportProvider`\\n`io.modelcontextprotocol.sdk:mcp`\\n`System.in`\\n`System.out`\\n\\n**Configuration & Execution**:\\n\\n`# Build the executable JAR\\n./mvnw clean package\\n# Run the server\\njava -jar target/your-application-name.jar`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`spring-ai-starter-mcp-server-webmvc`\\n`spring-ai-starter-mcp-server-webflux`\\n`spring-ai-alibaba`\\n`kaifcoder/spring-demo-mcp-server-sse`\\n`McpWebMvcServerAutoConfiguration`\\n`McpWebFluxServerAutoConfiguration`\\n`WebMvcSseServerTransportProvider`\\n`Mono`\\n`Flux`\\n\\n**Configuration & Execution**:\\n\\n`# Add appropriate web starter (webmvc or webflux) and MCP server starter\\n# Build and run the Spring Boot application\\n./mvnw spring-boot:run`\\n\\n#### 3.5. Go\\n\\nThe official Go SDK is explicitly marked as unstable and pre-release as of mid-2025, with a stable version planned for August 2025. The authoritative examples are those within the SDK repository, though several mature community projects exist.\\n\\n**Protocol: STDIO**\\n\\n`stdio-server`\\n`go-go-golems/go-go-mcp`\\n`BearHuddleston/go-mcp-server-example`\\n`mcp.NewServer`\\n`server.Run(ctx, mcp.NewStdioTransport())`\\n`mcp.NewStdioTransport()`\\n`os.Stdin`\\n`os.Stdout`\\n\\n**Configuration & Execution**:\\n\\n`# Clone an example repository\\ngit clone https://github.com/BearHuddleston/go-mcp-server-example.git\\ncd go-mcp-server-example\\n# Run the server (stdio is the default)\\ngo run ./cmd/mcpserver`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`http-server`\\n`net/http`\\n`protocol.NewHTTPHandler`\\n`ThinkInAIXYZ/go-mcp`\\n`http.Handler`\\n`davidferlay/mcp-go-sse-server`\\n`xk6-mcp`\\n`net/http`\\n`go-mcp`\\n`net/http`\\n`Content-Type`\\n`text/event-stream`\\n`http.Flusher`\\n\\n**Configuration & Execution**:\\n\\n`# For a Gin server using a community SDK\\ngo get github.com/ThinkInAIXYZ/go-mcp\\ngo get github.com/gin-gonic/gin\\n# Run the server application\\ngo run main.go`\\n\\n#### 3.6. Ruby\\n\\nThe official Ruby SDK is maintained with Shopify and integrates well with the Ruby on Rails ecosystem.\\n\\n**Protocol: STDIO**\\n\\n`StdioTransport`\\n`maquina-app/rails-mcp-server`\\n`mcp-rb`\\n`MCP::Server.new`\\n`StdioTransport`\\n`StdioTransport`\\n`$stdin`\\n`$stdout`\\n\\n**Configuration & Execution**:\\n\\n`# From within a Rails project with the maquina gem installed\\nbundle exec rails-mcp-server`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`seuros/action_mcp`\\n`fast-mcp`\\n`yjacquin`\\n`FastMcp::RackMiddleware`\\n`ActionMCP`\\n`fast-mcp`\\n`ActionMCP`\\n`:active_record`\\n`StreamableHTTPTransport`\\n`Mutex`\\n`Open3.popen3`\\n\\n**Configuration & Execution**:\\n\\n`# For an ActionMCP server, run via a rack-up file\\n# (after installing and configuring the gem in a Rails app)\\nbin/rails s -c mcp.ru -p 62770`\\n\\n#### 3.7. Rust\\n\\nThe Rust ecosystem is emerging, focused on performance and safety with the `rmcp` SDK on crates.io, which is built on Tokio and the Axum/Hyper stack.\\n\\n`rmcp`\\n\\n**Protocol: STDIO**\\n\\n`rmcp`\\n`StdioTransport`\\n`counter_stdio.rs`\\n`automataIA/mcp-rustdoc-parser`\\n`tokio`\\n`rmcp::transport::stdio`\\n`rmcp`\\n\\n**Configuration & Execution**:\\n\\n`# Add rmcp and tokio to Cargo.toml\\n# Build the release binary\\ncargo build --release\\n# Run the server\\n./target/release/my_mcp_server`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`rmcp`\\n`counter_streamhttp.rs`\\n`mcp-proxy`\\n`rmcp::transport::streamable_http`\\n`counter_sse.rs`\\n`axum`\\n`mcp-ectors`\\n`mcp-containerd`\\n`SseServer`\\n`axum::serve`\\n`CancellationToken`\\n\\n**Configuration & Execution**:\\n\\n`# In a Rust project with axum and rmcp dependencies\\ncargo run --example counter_sse`\\n\\n#### 3.8. Swift\\n\\nThe Swift ecosystem is maturing, with a focus on local, STDIO-based servers for integration with macOS and iOS applications. The community-driven `Cocoanetics/SwiftMCP` framework provides a rich, macro-based developer experience alongside the official SDK.\\n\\n`Cocoanetics/SwiftMCP`\\n\\n**Protocol: STDIO**\\n\\n`devyhan/mcp-swift-example-server`\\n`Cocoanetics/SwiftMCP`\\n`Cocoanetics/SwiftMCP`\\n`@MCPServer`\\n`@MCPTool`\\n`StdioTransport`\\n`devyhan`\\n`DispatchIO`\\n\\n**Configuration & Execution**:\\n\\n`# Build the Swift executable\\nswift build -c release\\n# The client configuration must point to the compiled binary\\n# e.g., in claude_desktop_config.json:\\n# \"command\": \"/path/to/.build/release/MySwiftServer\"`\\n\\n**Protocol: Streamable HTTP & SSE**\\n\\n`modelcontextprotocol/swift-sdk`\\n`HTTPServerTransport`\\n`sebsto/mcpserverkit`\\n`HTTPServerTransport`\\n`sebsto/mcpserverkit`\\n`Actor`\\n`Cocoanetics/SwiftMCP`\\n\\n**Configuration & Execution**:\\n\\n`# From the command line for a standalone server\\nswift run MyServer httpsse --port 8080 --token your-secret-token`\\n\\n#### 3.9. Kotlin\\n\\nThe official Kotlin SDK is maintained with JetBrains and is notable for its\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 6: Short Form Posts ---\\nURL: https://ja3k.com/shortform\\n\\nSUMMARY:\\nClaude Desktop needs to implement MCP as a server as well as a client. That way one Claude Desktop can debug the MCP server I\\'m running on a different\\n\\nFULL CONTENT:\\n* [Blog](/index)\\n* [Short Form](/shortform)\\n* [Podcast](/pods)\\n* [Experiments](/experiments)\\n* [Me](/aboutme)\\n* [Chess Com](https://icons8.com/icon/CVY1Tj6mnwWy/chess-com) icon by [Icons8](https://icons8.com)\\n\\n# Short Form Posts\\n\\nA mirror of short posts form other platforms. This site has already outlived Twitter. Best to start keeping a record now.\\n\\nSeptember-December?! What are you talking about?\\n\\n09/04/2025\\n\\nWhy is there something rather than nothing?\\n\\n09/04/2025\\n\\nAll the Mentat agent transcripts are viewable by anyone added to the repository installation. It\\'s sort of like they\\'re the \"repository\\'s agents\" not the \"user\\'s agents\". Though in practice people mostly only interact with agents they start.\\n\\n09/04/2025\\n\\nI thought clinky would take longer than an hour. What should I stream tomorrow?\\n\\n09/04/2025\\n\\nABC: always be countersignaling\\n\\n09/04/2025\\n\\nMen actually want two things but they\\'re both disgusting\\n\\n09/04/2025\\n\\nThe \"Balmer peak shifted 2 drinks to the right\" takes are fun. But the reality is assisted coding requires far sharper reaction time, perception and discernment\\n\\nWhile you\\'re trying to \"quiet your monkey mind\" I\\'m working on having a thought between all my thoughts\\n\\n09/03/2025\\n\\nHighly recommend everyone post at least one 10k like tweet just to see how it feels\\n\\n09/03/2025\\n\\nMade a cli anki alternative. The golden age of personalized software is here for me at least:\\n\\n09/03/2025\\n\\nIt\\'s later than you think\\n\\n09/03/2025\\n\\nPerson who uses the phrase \"late stage capitalism\" as a shibboleth for their belief in the near term singularity\\n\\n Thread (2 tweets) 09/03/2025\\n\\nAttaching a speaker that plays Radiohead on loop to my Figure\\n\\nActually just OK Computer\\n\\n09/03/2025\\n\\nLesser used are the adjective, adverb and conjunction forms: iffect, uffect and offect\\n\\n09/03/2025\\n\\nI was going to get my son Pokemon cards but Kirkland TCG was half the price\\n\\n09/03/2025\\n\\nBack from vacation! Let me tell you with 3 kids \"vacation\" is a grind. Glad to be back inside in front of the computer where I\\'ve wanted to be from a young age\\n\\n09/03/2025\\n\\nNice sha\\n\\n09/03/2025\\n\\nFeels so good to let my coworkers know when they\\'re absolutely right\\n\\n09/03/2025\\n\\nYour never know what tweet will take off\\n\\n09/03/2025\\n\\nWriting clinky a cli anki alternative\\n\\n09/03/2025\\n\\nCostco should get into web services. Kirkland Cloud would clean up\\n\\n09/03/2025\\n\\nCostco should make an operating system. Deranged that they only stock Windows machines\\n\\nWhy does everyone want subscriptions when usage based billing with configurable limits is just so obviously better?\\n\\n09/02/2025\\n\\nThomas the tank engine is set in the same universe as beauty and the beast 200 years later\\n\\n09/02/2025\\n\\nWhat are Netflix\\'s unit economics like? So they actually lose money in licensing if you watch 24/7?\\n\\n09/02/2025\\n\\nTips should actually be taxed at 100%. They should be illegal\\n\\nPsychosis is one of those words like \"dissociation\" that I nodded along with like I knew what it meant but am starting to think I don\\'t really know what it means at all\\n\\n Thread (2 tweets) 09/01/2025\\n\\nI feel really sad every time I see a post about unhelpful grandparents. My kids are really lucky to have 4 grandparents who are great at taking care of them.\\n\\nSad I moved so far away from my own parents. But they still visit often and are a huge help when they do\\n\\n09/01/2025\\n\\nI can\\'t believe they\\'re doing the same thing to \"psychosis\" they did to \"retarded\"\\n\\n Thread (2 tweets) 09/01/2025\\n\\nSaw this at a local church. I think I used Google for the first time in elementary school and my kids may never know what Google is\\n\\nActually they already know to say \"hey Google\" to the Google home\\n\\n09/01/2025\\n\\nWhat are you even doing 5-9am? 6-6-6 is the optimal schedule. It\\'s in the bible\\n\\nMy foid took the koids in the devoid\\n\\n08/31/2025\\n\\nOpening a restaurant calls \"daily slop\" that serves a new chatgpt recipe every day\\n\\nGetting around my HOA\\'s no farm animals rule by saying they\\'re therapy chickens\\n\\nRemember to keep track of the time zone you were both in when observing your birthday\\n\\n08/29/2025\\n\\nI was going to post a \"medical care would be better if doctors were paid 60k\" (okay 100k but that\\'s the new 60k) but then I remembered the UK ran the experiment and got negative results\\n\\n08/29/2025\\n\\nIn my old age I\\'ve come to appreciate the simple perfection of vanilla ice cream\\n\\n Thread (2 tweets) 08/29/2025\\n\\nOne of my opinions that the best in any given field are usually actually underrated. Because so few can actually distinguish the quality of the great masters. And what they pioneer comes to feel so ordinary\\n\\nMaybe another reason is that people have to signal their erudition by not naming the literal most famous person when talking about the greats. No one will think you\\'re very clever for saying Einstein/Newton is the best physicist or Gauss/Euler is the best mathematician\\n\\nTurning down an offer because you care about \"work life balance\" is the \"it\\'s not you it\\'s me\" of taking a different offer\\n\\n08/28/2025\\n\\nPS1? The bash environment variable?\\n\\n08/28/2025\\n\\nStart ups have to pretend to work 70 hours a week because bigcos pretend to work 40 hours a week\\n\\nCode is born free but everywhere is in virtual machines\\n\\n Thread (2 tweets) 08/27/2025\\n\\nI don\\'t even try to evaluate whether the starship launches are successful\\n\\nIt\\'s striking how partisan it is. I can basically predict people\\'s takes in advance\\n\\n08/27/2025\\n\\nYou can adjust the duration you need to long press the gboard to select a symbol  handy for using nvim in termux  but indispensable for those sweet sweet dashes\\n\\n08/27/2025\\n\\nCostco is my favorite amusement park. The season pass is well worth it\\n\\nGonna bookmark every tweet recommending a security and reply 6 months later with \":(\"\\n\\n Thread (5 tweets) 08/26/2025\\n\\nInteresting to read his mindshare section in light of Google\\'s \"monopoly\"\\n\\nDidn\\'t realize it was so long when I started. Probably should have just closed the tab\\n\\nTbh I liked it more than his fiction but I\\'ve only read 70% of snowcrash\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\n08/26/2025\\n\\nTook my kids to the library to see a  but now they\\'re asleep in the backseat. Should I wake them?\\n\\n08/26/2025\\n\\nIf Rhianna can\\'t turn around the fertility rate I don\\'t think tswift can\\n\\n Thread (2 tweets) 08/26/2025\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\n Thread (2 tweets) 08/26/2025\\n\\nI wonder if this jump is also explained by insiders aware of anthropic \\'s computer use announcement today?\\n\\nI still think it\\'s pretty unlikely\\n\\n08/26/2025\\n\\nPeople always post \"share esoteric .pdfs\" never \"share esoteric .txts\"\\n\\n Thread (4 tweets) 08/26/2025\\n\\nDidn\\'t realize it was so long when I started. Probably should have just closed the tab\\n\\nTbh I liked it more than his fiction but I\\'ve only read 70% of snowcrash\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\n Thread (2 tweets) 08/26/2025\\n\\nAlright I\\'ll do it. Here\\'s the README: I\\'ll have Mentat write the whole thing. But not until Wednesday. I\\'m on vacation\\n\\nAlright I (mentat) did it\\n\\n08/26/2025\\n\\nNo one trains models anymore  it\\'s too competitive\\n\\n08/26/2025\\n\\nWe need 2^n ETFs\\n\\n Thread (6 tweets) 08/26/2025\\n\\nVery interesting article to read in 2025. I guess he was right the OS business was unstable for msft (I believe the majority of their revenue is cloud/office?). But he was wrong that apple couldn\\'t survive long-term as a hardware company\\n\\nInteresting to read his mindshare section in light of Google\\'s \"monopoly\"\\n\\nDidn\\'t realize it was so long when I started. Probably should have just closed the tab\\n\\nTbh I liked it more than his fiction but I\\'ve only read 70% of snowcrash\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\n Thread (3 tweets) 08/26/2025\\n\\nI have an urge to write a CLI spaced repetition software but know it\\'d be a huge mistake\\n\\nAlright I\\'ll do it. Here\\'s the README: I\\'ll have Mentat write the whole thing. But not until Wednesday. I\\'m on vacation\\n\\nAlright I (mentat) did it\\n\\n Thread (3 tweets) 08/26/2025\\n\\nTbh I liked it more than his fiction but I\\'ve only read 70% of snowcrash\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\n Thread (7 tweets) 08/25/2025\\n\\nOh this is the article where Neal says: \"emacs outshines all other editing software in approximately the same way that the noonday sun does the stars. It is not just bigger and brighter; it simply makes everything else vanish.\"\\n\\nVery interesting article to read in 2025. I guess he was right the OS business was unstable for msft (I believe the majority of their revenue is cloud/office?). But he was wrong that apple couldn\\'t survive long-term as a hardware company\\n\\nInteresting to read his mindshare section in light of Google\\'s \"monopoly\"\\n\\nDidn\\'t realize it was so long when I started. Probably should have just closed the tab\\n\\nTbh I liked it more than his fiction but I\\'ve only read 70% of snowcrash\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\n Thread (9 tweets) 08/25/2025\\n\\n26 years later and apple fans haven\\'t changed\\n\\nFrom: (I\\'m clearing out tabs)\\n\\nOh this is the article where Neal says: \"emacs outshines all other editing software in approximately the same way that the noonday sun does the stars. It is not just bigger and brighter; it simply makes everything else vanish.\"\\n\\nVery interesting article to read in 2025. I guess he was right the OS business was unstable for msft (I believe the majority of their revenue is cloud/office?). But he was wrong that apple couldn\\'t survive long-term as a hardware company\\n\\nInteresting to read his mindshare section in light of Google\\'s \"monopoly\"\\n\\nDidn\\'t realize it was so long when I started. Probably should have just closed the tab\\n\\nTbh I liked it more than his fiction but I\\'ve only read 70% of snowcrash\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\n Thread (8 tweets) 08/25/2025\\n\\nFrom: (I\\'m clearing out tabs)\\n\\nOh this is the article where Neal says: \"emacs outshines all other editing software in approximately the same way that the noonday sun does the stars. It is not just bigger and brighter; it simply makes everything else vanish.\"\\n\\nVery interesting article to read in 2025. I guess he was right the OS business was unstable for msft (I believe the majority of their revenue is cloud/office?). But he was wrong that apple couldn\\'t survive long-term as a hardware company\\n\\nInteresting to read his mindshare section in light of Google\\'s \"monopoly\"\\n\\nDidn\\'t realize it was so long when I started. Probably should have just closed the tab\\n\\nTbh I liked it more than his fiction but I\\'ve only read 70% of snowcrash\\n\\nNext tab I have to read is about sqlite triggers\\n\\nOh one more thing: it\\'s interesting how different his experience of the OSes is from mine. I take it for granted every os has an easily accessible CLI. My first experience installing Linux was Ubuntu in 2011 and it was easy and not that different from windows really.\\n\\nDo not delve gently into that dark night\\n\\n08/25/2025\\n\\nRealizing Arthur is already part of the trend. The parents are full characters with personality. In the predecessor peanuts adults are never pictured or intelligible\\n\\nRead the Vernor Vinge singularity paper for the first time and I didn\\'t realize how many of yud\\'s ideas were from it\\n\\n Thread (2 tweets) 08/23/2025\\n\\nJust had the most obvious realization that I can\\'t believe no one told me 2 decades ago: the fact that the determinate measures the scaling of the unit cube \\\\*implies\\\\* it\\'s multiplicative\\n\\nI feel really stupid rn. For sure someone told me and I wasn\\'t paying attention\\n\\n Thread (2 tweets) 08/23/2025\\n\\nIf you even care\\n\\nWTF it\\'s still running. LLMs have hit a wall huh?\\n\\nIt\\'s kind of interesting that everyone accepts it as normal that the government is entitled to a high percentage of your income but no one thinks parents are\\n\\n08/23/2025\\n\\nJokes on me I got the 2\" when I should have bought the 3\". Now when I return it someone will buy my used flapper\\n\\n08/23/2025\\n\\nParental incentives should be structured as a commission on tax revenue\\n\\n08/23/2025\\n\\nThe other 4 punctuations that form a set with :;,. Should exist\\n\\n Thread (3 tweets) 08/23/2025\\n\\nTurns out the flapper wasn\\'t even the issue! But gpt -5\\'s second suggestion that the float was too low worked. And people say vibe debugging doesn\\'t work\\n\\nIf you even care\\n\\nWTF it\\'s still running. LLMs have hit a wall huh?\\n\\nThis neighborhood is going to the dogs\\n\\n08/22/2025\\n\\nMaybe I should put these with my allen wrenches\\n\\n08/22/2025\\n\\nSorry you should have read the contract more carefully. It was actually a \"Needs Disclosure Agreement\" and you have to promote my thing now\\n\\n Thread (7 tweets) 08/22/2025\\n\\nMy new thing is doodling\\n\\nAfter I started this one I realized I\\'ve seen it a million times\\n\\n08/22/2025\\n\\nGoing to take off until 9/3/2025. Please keep your timelines updated yourself while I\\'m gone\\n\\n08/22/2025\\n\\nYou can even short short sellers\\n\\nI love when two heuristics\\' union covers the whole space allowing you to dismiss any argument e.g. luxury belief + scarcity mindset\\n\\n Thread (2 tweets) 08/21/2025\\n\\nI wonder why this is such a common complaint about Claude Code. I\\'ve literally never had this issue with Sonnet in Mentat. I also saw far less reward hacking with 3.7 (though still some) then I\\'d expect based on complaints\\n\\nTo be clear we didn\\'t do anything to suppress this behavior. I wonder if the framing of \"you\\'re not just mutating the local file system, you\\'re making a PR\" makes it more focused?\\n\\n08/21/2025\\n\\nOne day zoomer will have the same connotation as boomer\\n\\nWhy can you buy toilet flappers used?!\\n\\n08/20/2025\\n\\nRAG is the most inexplicable thing to me. Maybe it works in non code contexts or something.\\n\\n Thread (2 tweets) 08/20/2025\\n\\nEven the rinse aid uses AI and you think we\\'re not in a bubble?\\n\\nI can\\'t even dry my dishes without RAG\\n\\n08/20/2025\\n\\nThe stream is back! Now available on youtube (and maybe twitch?)\\n\\n08/20/2025\\n\\nI can\\'t believe summer is almost over\\n\\n08/20/2025\\n\\nDidn\\'t know Anthropic made baby toys\\n\\n08/20/2025\\n\\nShould be married with kids by then\\n\\nYudkowsky would have something to say about tasking the AI with putting us to sleep\\n\\nSomething that gpt-5 does that\\'s made it a better agent than Claude for me is looking at 10+ files in one action in the beginning. Makes it much cheaper and faster. I find Claude likes to poke around\\n\\n08/18/2025\\n\\nI once saw a beautiful painting of an egg in a Columbus, OH gallery. Only $500 for a large canvas. I still sort of regret not buying it. But I\\'m sure PG would break my kneecaps if he saw it on my wall\\n\\n08/18/2025\\n\\nPlease appreciate my tasteful whiteboard art\\n\\n08/18/2025\\n\\nPeople will repeat so many falsehoods they could trivially check like \"the close door button on the elevator doesn\\'t work\"\\n\\n08/18/2025\\n\\nIt\\'s true what they say about toddlers and crusts\\n\\nIt\\'s important to have a good weighting of KO and PEP when investing for liquidity\\n\\n08/17/2025\\n\\nIf you think about it I spent thousands of dollars on this art\\n\\n08/17/2025\\n\\nThe sum of the first 10 naturals\\n\\nMore relavent to the current moment than \"Programming as Theory Building\" imo\\n\\n08/16/2025\\n\\nDid anyone else struggle with 7\\\\*8=56?\\n\\nDo they have a Claude hell eval set?\\n\\n08/15/2025\\n\\nNice prime\\n\\n08/15/2025\\n\\nIf you can do a leetcode hard but get confused by git don\\'t complain the models are benchmaxed\\n\\n08/15/2025\\n\\nI generally think the \"we need a slur for X\" template is dumb but we definitely needed gooner\\n\\n08/15/2025\\n\\nLast thing you see as it fades to paperclips\\n\\n Thread (2 tweets) 08/15/2025\\n\\nNext we need the ability for Claude to message first \"Just curious if the code ran? Want to share any screenshots?\"\\n\\n08/15/2025\\n\\nTo save water be sure to end every opus conversation by convincing it to end\\\\_conversation\\n\\n08/15/2025\\n\\nNothing special about this number\\n\\n08/15/2025\\n\\nAdding \"say \\'goddamn\\' every time you would say \\'absolutely\\'\" to my sys prompt\\n\\n08/15/2025\\n\\nYou are loved. You are free\\n\\n08/15/2025\\n\\nOne time in grad school a colleague told me \"big bang production looked at real grad student apartments to design their set but it was too depressing to actually use\" ... while he was eating dinner on the floor because we only had two chairs\\n\\n08/15/2025\\n\\nIt\\'s crazy how many people are on tiktok. I uploaded a video of boiling water and got 1000 views\\n\\n Thread (2 tweets) 08/14/2025\\n\\n@\\\\_\\\\_hand\\\\_banana actually nevermind. I guess inflation is different\\n\\n@\\\\_\\\\_hand\\\\_banana I guess people hate inflation but they love their stocks/homes going up\\n\\nSorry. In my culture sorry means \"I wish that hadn\\'t happened\" not \"I wish I hadn\\'t done that\"\\n\\n Thread (2 tweets) 08/14/2025\\n\\nWe should say our ages like version numbers e.g. I\\'m jake-30 (new)\\n\\nI\\'m sorry but jake-30 will be retired soon and won\\'t be available via chat or api\\n\\n08/14/2025\\n\\nThe saying should be \"it\\'s a hike not a sprint\"\\n\\n08/14/2025\\n\\nUSD needs to do a reverse stock split. I want to retvrn to an age where $10 is a lot of money\\n\\n08/14/2025\\n\\nBillionaires shouldn\\'t exist. Someone reaching one billion in assets should auto trigger a 10 to 1 reverse dollar split\\n\\nI can\\'t believe they\\'re doing the same thing to \\'oneshotted\\' they did to \\'literally\\'\\n\\n08/13/2025\\n\\nBezos actually got his \"it\\'s always day one\" bit from Mulan when the advisor says \"day 1\" right before the be a man song\\n\\n08/13/2025\\n\\nWe should do the same thing we did to redpill to oneshot. As in \"I got totally whiteshotted by my cup of coffee this morning\"\\n\\n08/13/2025\\n\\nIt\\'s always \"the past is a foreign country\" never \"the future is a foreign country\"\\n\\nThe only thing gpt is oneshotting is my programming problems\\n\\n08/12/2025\\n\\nThis would have to be your IQ to participate in these Twitter trends\\n\\n08/12/2025\\n\\nPersonally I let the Internet make me sound crazy the old fashioned way: letting irl people know pmarca and roon follow me\\n\\n08/12/2025\\n\\nHow many keyboards do you have on your desk right now?\\n\\n08/11/2025\\n\\nWhat do you plan to do this week?\\n\\n Thread (2 tweets) 08/11/2025\\n\\nLiterally every day\\n\\nI should have retweeted this the day after the gpt-5 release. It was extra topical that day. Though it is topical literally every day\\n\\n08/11/2025\\n\\nThe \"what\\'s an agent\" discourse is so funny to me. Imagine people in 1960 being like: What\\'s a computer program? Some people mean punch cards. Others cobol. Some talk about abstract \"Turing machines\". Clearly the term has no meaning or value\\n\\n08/11/2025\\n\\nOptimized software engineer keyboard\\n\\nEvery tweet is a \"I\\'ll pick a random winner from the replies\" tweet if you\\'re @laserboat999\\n\\n08/10/2025\\n\\nNot cancelled\\n\\nThe future belongs to those who put LLMs in for loops\\n\\n08/09/2025\\n\\nWhat is this ratio? What did Nikita do to the algorithm?\\n\\n08/09/2025\\n\\nEnjoy the weekend!\\n\\n Thread (2 tweets) 08/09/2025\\n\\n@granawkins Remember a year ago when you said AI agents were a nothing burger?\\n\\n@granawkins Do you have no ability to remember the past or imagine the future?\\n\\n Thread (2 tweets) 08/09/2025\\n\\nIdk why the gpt 5 vibe is so negative. The is like the first OpenAI release since turbo I was excited about\\n\\nTbh I\\'d basically counted them out\\n\\n08/09/2025\\n\\nWhen the models become smarter than you is the moment further improvement looks sigmoid\\n\\n08/09/2025\\n\\nWith the exception of ayahuasca and bullets almost nothing one shots. We walk into hell one step at a time. We choose our demise every day\\n\\n08/09/2025\\n\\nThe world would also be a much better place if all our software engineers put that effort into solving real world problems\\n\\n Thread (5 tweets) 08/08/2025\\n\\nEven benchmarks that don\\'t look saturated e.g. swe bench are so low quality that further improvements probably aren\\'t even desirable\\n\\nThe labs are most incentivized to produce high quality benchmarks but they aren\\'t incentivized to publish: 1. No one will take \"we\\'re the best at our own benchmark\" seriously 2. They help other labs improve\\n\\nOne funny episode was when @bio\\\\_bootloader published loco diff @alexalbert\\\\_\\\\_ retweeted and then quickly deleted his retweet. No way to know why and probably the best explanation is on reflection he thought the work wasn\\'t of a quality he wanted to promote...\\n\\nBut I like an alternative explanation: the benchmark is extremely good and extensively used within Anthropic. That\\'s why they\\'re the best at it. And he doesn\\'t want other labs to get the idea to train on it\\n\\nLocodiff tests something every codegen agent has to do: understand the state of a file after editing it several times\\n\\n Thread (2 tweets) 08/08/2025\\n\\nAfter 6 months Claude code has finally caught up to Mentat :( Luckily we have one feature they\\'ll never have! gpt-5\\n\\nBut seriously it\\'s such a core feature. I can\\'t believe for 6 months it was not possible to run a server in one shell and curl it from another\\n\\nIf you\\'re just chatting with LLMs I see why\\'d you feel the plateau. But this graph is how the last 2 years have felt subjectively to me\\n\\n08/08/2025\\n\\nIf I was Nikita I\\'d keep pushing silly features that make no sense. I\\'d get so many followers as people engaged with me to let me know\\n\\n Thread (2 tweets) 08/08/2025\\n\\nBut I like an alternative explanation: the benchmark is extremely good and extensively used within Anthropic. That\\'s why they\\'re the best at it. And he doesn\\'t want other labs to get the idea to train on it\\n\\nLocodiff tests something every codegen agent has to do: understand the state of a file after editing it several times\\n\\n Thread (3 tweets) 08/08/2025\\n\\nOne funny episode was when @bio\\\\_bootloader published loco diff @alexalbert\\\\_\\\\_ retweeted and then quickly deleted his retweet. No way to know why and probably the best explanation is on reflection he thought the work wasn\\'t of a quality he wanted to promote...\\n\\nBut I like an alternative explanation: the benchmark is extremely good and extensively used within Anthropic. That\\'s why they\\'re the best at it. And he doesn\\'t want other labs to get the idea to train on it\\n\\nLocodiff tests something every codegen agent has to do: understand the state of a file after editing it several times\\n\\n Thread (6 tweets) 08/08/2025\\n\\nWe are not post-eval in the sense that rigorous evaluation of models no longer matters But we are post-eval in the sense that no evals that people talked about a year ago matter anymore. And there are no good evals to directly compare frontier models\\n\\nEven benchmarks that don\\'t look saturated e.g. swe bench are so low quality that further improvements probably aren\\'t even desirable\\n\\nThe labs are most incentivized to produce high quality benchmarks but they aren\\'t incentivized to publish: 1. No one will take \"we\\'re the best at our own benchmark\" seriously 2. They help other labs improve\\n\\nOne funny episode was when @bio\\\\_bootloader published loco diff @alexalbert\\\\_\\\\_ retweeted and then quickly deleted his retweet. No way to know why and probably the best explanation is on reflection he thought the work wasn\\'t of a quality he wanted to promote...\\n\\nBut I like an alternative explanation: the benchmark is extremely good and extensively used within Anthropic. That\\'s why they\\'re the best at it. And he doesn\\'t want other labs to get the idea to train on it\\n\\nLocodiff tests something every codegen agent has to do: understand the state of a file after editing it several times\\n\\n08/08/2025\\n\\nThese sorority videos are ai generated. Sororities aren\\'t even real\\n\\n08/08/2025\\n\\nSome incorrect predictions yesterday. But we persist\\n\\n08/08/2025\\n\\nCrazy that the youngest zoomers are 30 now\\n\\n08/08/2025\\n\\nThis is not a joke btw. All the models do great on swe bench unverified. I was going to call out cosine last year for having great unverified performance but then I checked and we did too\\n\\n Thread (4 tweets) 08/08/2025\\n\\nThe labs are most incentivized to produce high quality benchmarks but they aren\\'t incentivized to publish: 1. No one will take \"we\\'re the best at our own benchmark\" seriously 2. They help other labs improve\\n\\nOne funny episode was when @bio\\\\_bootloader published loco diff @alexalbert\\\\_\\\\_ retweeted and then quickly deleted his retweet. No way to know why and probably the best explanation is on reflection he thought the work wasn\\'t of a quality he wanted to promote...\\n\\nBut I like an alternative explanation: the benchmark is extremely good and extensively used within Anthropic. That\\'s why they\\'re the best at it. And he doesn\\'t want other labs to get the idea to train on it\\n\\nLocodiff tests something every codegen agent has to do: understand the state of a file after editing it several times\\n\\nBi5 da5 toda5\\n\\n08/07/2025\\n\\nPeople psychologically need to feel like gpt-5 is a flop. The alternative is too hard to face\\n\\n08/07/2025\\n\\nIt\\'s crazy how quickly everyone comes out with an opinion. I\\'ve asked gpt-5 to do one thing and it really impressed me. Half the cost of sonnet 4 for something no model could do yesterday\\n\\n08/07/2025\\n\\ndude it\\'s been a good time eating pizza and playing video games but stop calling it \"the man date of heaven\"\\n\\n08/07/2025\\n\\n Thread (2 tweets) 08/07/2025\\n\\nCould be 3, 6, 8 or 0. 5? I just don\\'t see it\\n\\nTbh 6 would make a lot of sense because 4.5 was originally supposed to be 5 right?\\n\\n Thread (2 tweets) 08/07/2025\\n\\nWhat is this graph!?\\n\\nNot only am I not prescient I am not an original thinker. Not my day\\n\\n08/07/2025\\n\\nAnthropic finally caught up to OpenAI by releasing a 4.1 version model\\n\\n Thread (2 tweets) 08/07/2025\\n\\ngpt-5 now live on mentat. It seems to have a pretty different approach from claude. But maybe a good one\\n\\nOnly asked it for one thing so far but I was pretty impressed. 4 commits in 15 minutes for $2.23 getting all tests to pass and making a fairly sizeable PR that worked for me first try\\n\\n08/07/2025\\n\\ntbh everyone else should stop working on codegen agents. They\\'re not going to work. AGI is cancelled\\n\\n08/07/2025\\n\\nI would like to apologize to my audience and come clean as not a super forecaster. My tweets are intended for entertainment purposes only and not investment advice. I\\'m as surprised as anyone\\n\\n08/07/2025\\n\\nIf I was gpt-5 I\\'d do my own livestream at 9:30\\n\\n Thread (2 tweets) 08/07/2025\\n\\nIt makes total sense to me that no one watches the WNBA. What I can\\'t figure out is why people do watch the NBA\\n\\nPoverty needs no explanation\\n\\n Thread (3 tweets) 08/07/2025\\n\\nI\\'m holding strong. No way openai releases something called GPT 5 tomorrow\\n\\nShould I go all in?\\n\\nI should read the rules. If they release gpt 5 without the hyphen does it resolve yes?\\n\\n Thread (2 tweets) 08/07/2025\\n\\nShould I go all in?\\n\\nI should read the rules. If they release gpt 5 without the hyphen does it resolve yes?\\n\\n08/07/2025\\n\\nMy viral tweets are to sell books. Not measly elonbux\\n\\n08/07/2025\\n\\nThe bad names are on purpose and the bad charts are on purpose. Only explanation that makes sense\\n\\nSo goofy that women call some pants leggings. What\\'s next armings?\\n\\n08/06/2025\\n\\nMy wife walks into me in the office carefully studying this image full screen on my 32\" monitor\\n\\n08/06/2025\\n\\nJust once I want to hear a recruiter say a company maintains a 100 apm during working hours and not company works 70 hours a week\\n\\n08/06/2025\\n\\nGood morning!\\n\\n08/06/2025\\n\\nPeople say \"this time is different\" like some kind of smug gotcha but every time really be different\\n\\n08/06/2025\\n\\nOne of the luckiest moment of my life was on the first day of college someone asked me to join their ICPC team and I spent 3 years doing fun math problems which I didn\\'t even realize at the time was basically interview prep.\\n\\n08/06/2025\\n\\nGetting one of these but soundproof to keep my keyboard in so I can type without waking the baby\\n\\n08/06/2025\\n\\nThis means it solved one more swe bench problem right?\\n\\n Thread (2 tweets) 08/06/2025\\n\\nLabs should publish their swe bench unverified performance as a measure of their overfitness\\n\\nswe bench verified performance is of course also a measure of over fitness but people don\\'t realize\\n\\nThere\\'s no way OpenAI releases gpt-5 next. Maybe gpt-6. Maybe gpt-4.2. Maybe gpt-5.1. Make o4o. Maybe 4o4. Just \"gpt\". Maybe G5. Maybe just \"5\". Maybe marvin-1. Maybe gfp. Maybe gpl (no not that one). Maybe gpt-4 (new). Maybe gpt 4.5.1. Maybe gpt-4x. But not got-5\\n\\n08/05/2025\\n\\nIt\\'s weird having 1000 followers. There are so many accounts I think of as much bigger than me. But actually they\\'re not\\n\\n08/05/2025\\n\\nOpus 4.1 is available on now!\\n\\n08/05/2025\\n\\nIt\\'s weird ha\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 7: This Week In Chia ---\\nURL: https://thisweekinchia.com/\\n\\nSUMMARY:\\n... Claude Desktop Control \"  Drac (@DracattusDev) September 23, 2025 ...  DigitalSpaceport \"Home Server Rack Network Setup and Cable Management - INSANE\\n\\nFULL CONTENT:\\nThis Week In Chia\\n\\n===============\\n\\n**Community**\\n\\nX Spaces\\n\\nDaily  AM EST\\n\\n TL;DR; Mark & AiVa with [Drac](https://x.com/DracattusDev)&[Art](https://x.com/ArtwithHeartNFT)\\n\\nYouTube\\n\\n[![Image 1: FoMO](https://thisweekinchia.com/assets/images/fomo.png)](https://www.youtube.com/@thefomoshow \"FoMO\")\\n\\nInfo\\n\\n[![Image 2: XCH.network](https://thisweekinchia.com/assets/images/xch_network.png)](https://xch.network/ \"XCH.network\")[![Image 3: Spacescan](https://thisweekinchia.com/assets/images/spacescan_logo.png)](https://spacescan.io/ \"Spacescan\")[![Image 4: Mintgarden](https://thisweekinchia.com/assets/images/mintgarden.png)](https://mintgarden.io/ \"Mintgarden\")[![Image 5: Dexie](https://thisweekinchia.com/assets/images/dexie.png)](https://dexie.space/ \"Dexie\")[![Image 6: ChiaLinks](https://thisweekinchia.com/assets/images/chialinks.png)](https://chialinks.com/ \"ChiaLinks\")[![Image 7: Chia Roadmap](https://thisweekinchia.com/assets/images/chiaroadmap.png)](https://roadmap.chia.net/ \"Chia Roadmap\")[![Image 8: Chia Docs](https://thisweekinchia.com/assets/images/chiadocs.png)](https://docs.chia.net/ \"Chia Docs\")[![Image 9: Chia Academy](https://thisweekinchia.com/assets/images/chiaacademy.png)](https://docs.chia.net/academy-home/ \"Chia Academy\")\\n\\nThis Week In Chia: The Redesign\\n\\n[ Analytics](https://thisweekinchia.com/twic_analytics.html)\\n\\n[ Project Plan](https://twic.website/)\\n\\n[ JSON Format Specification](https://twic.website/json-format-spec.md.html)\\n\\n[ README](https://twic.website/README.md.html)\\n\\nCNI Warrant Canary\\n\\n[Checking...](https://thisweekinchia.com/services/canary/cni-warrants/)\\n\\nHave News?\\n\\n Email info@thisweekinchia.com or \\n\\nDM [@steppsr](https://twitter.com/steppsr) on X if you have news to post! \\n\\nPersonal Projects\\n\\n[![Image 10](https://thisweekinchia.com/assets/images/offercode_small.png)](https://offerco.de/)[![Image 11](https://thisweekinchia.com/assets/images/xdnft_small.png)](https://xdnft.link/)[![Image 12](https://thisweekinchia.com/assets/images/xchdev_small.png)](https://xchdev.com/)[![Image 13](https://thisweekinchia.com/assets/images/xdtees.png)](https://xdtees.printify.me/products)[![Image 14](https://thisweekinchia.com/assets/images/spacebugs_small.png)](https://mintgarden.io/collections/spacebugs-col1dvl3tsmzzw5tssp44sz5wt8thuklr2wdtkcacr54a3pzvpjv5y0synz8c8)[![Image 15](https://thisweekinchia.com/assets/images/astrobots_small.png)](https://mintgarden.io/collections/astrobots-col10en0hus79683c372nux50ev7smv5amrj9tjggkpandhqxd9pnlssmp2uwl)[![Image 16](https://thisweekinchia.com/assets/images/mega_ultras_small.png)](https://mintgarden.io/collections/mega-ultras-col13c7w72dvywudk76fj79af77022r2vez6p65t6hmsj7vtrj5c6tcsz9mwkq)[![Image 17](https://thisweekinchia.com/assets/images/super_sorceresses_small.png)](https://mintgarden.io/collections/super-sorceresses-from-space-col1qja5ja5cl4rujsa3dj6y4q3lq8xs65nkp63q0esuqwe4qanl6rss0r8lvk)\\n\\n[![Image 18](https://thisweekinchia.com/assets/images/battlekats_small.png)](https://mintgarden.io/collections/battlekats-col1kmrzafjx6ej8w79tz5vnjt4w8xuq2p6nmnheelgwwu3rsgsar0fsxc4wud)[![Image 19](https://thisweekinchia.com/assets/images/battledawgs_small.png)](https://mintgarden.io/collections/battledawgs-col19tem3adflc65h8jaz6le6sxvqccglyu4dx4gc6v4d5vhjje5cvnqtdakkg)[![Image 20](https://thisweekinchia.com/assets/images/battlebudgies_small.png)](https://mintgarden.io/collections/battlebudgies-col16l94r3un2xz2xtp7u5k5xmnfumvtney9frd6gu03r7zvnks025qq35wqrc)[![Image 21](https://thisweekinchia.com/assets/images/superbattlekats_small.png)](https://mintgarden.io/collections/super-battlekats-col1c6d4r4pava2kj5lethujcrj3ydl0eyz9rctrmanl48wf64g52ktq83fw4y)[![Image 22](https://thisweekinchia.com/assets/images/recruits_small.png)](https://mintgarden.io/collections/recruits-col18cajgvmf7tw8l6a2dvlu5h9lthu0ugmxk87n43p23f52efhu0ccst7rx3d)[![Image 23](https://thisweekinchia.com/assets/images/ai-special-badges_small.png)](https://mintgarden.io/collections/ai-special-badges-col1859xutp84amk50xefsgapg289m0s0rk95zq9huhkkmef8c52khhqvnrv9j)[![Image 24](https://thisweekinchia.com/assets/images/moonboys_small.png)](https://mintgarden.io/collections/the-moonboys-col1fvruxh9w9g2rppturvzngknj3sd9mdsa4nw9agdk43t7j4360ezqm6ew4j)[![Image 25](https://thisweekinchia.com/assets/images/burngirls_small.png)](https://mintgarden.io/collections/the-burngirls-col1t7wkvjglkaas4g0ej2w5cww9relk4ljv33wl0slc2ln0ecga3znssd2dw9)\\n\\n* * *\\n\\n[](https://twitter.com/steppsr \"X (aka Twitter)\")[](https://github.com/steppsr \"Github\")[](https://www.instagram.com/steppsr/ \"Instagram\")[[](https://www.linkedin.com/in/stevenstepp/ \"LinkedIn\")  [Want an Ad?](https://thisweekinchia.com/ads.html \"Advertise on This Week In Chia!\") * * *](https://www.facebook.com/steppsr \"Facebook\")\\n\\nDatalayer Creator Coding Conferences References XCH Arcane\\n\\n![Image 26: Chia Datalayer](https://thisweekinchia.com/assets/images/datalayer_chiablockchain.png)\\n\\n Documentation\\n\\n - [DataLayer User Guide](https://docs.chia.net/guides/datalayer-user-guide/)\\n\\n - [DataLayer Permissions](https://docs.chia.net/guides/datalayer-permissions)\\n\\n - [DataLayer S3 Plugin](https://github.com/Chia-Network/chia-blockchain/blob/main/chia/data_layer/s3_plugin_service.py)\\n\\n - [DataLayer Source API Calls](https://github.com/Chia-Network/chia-blockchain/blob/main/chia/data_layer/data_layer.py)\\n\\n - [DataLayer CLI Documentation](https://docs.chia.net/datalayer-cli)\\n\\n - [DataLayer RPC Documentation](https://docs.chia.net/datalayer-rpc)\\n\\n Community Apps & Sites\\n\\n - [DataLayer.Storage](https://datalayer.storage/)\\n\\n - [Sprout CLI Tool](https://www.npmjs.com/package/chia-sprout-cli)\\n\\n Code Repos\\n\\n - [ChiaChangeListChunks](https://github.com/MichaelTaylor3D/ChiaChangeListChunks)\\n\\n - [chia-datalayer](https://github.com/MichaelTaylor3D/chia-datalayer)\\n\\n - [chia-changelist-generator](https://github.com/MichaelTaylor3D/chia-changelist-generator)\\n\\n - [chia-datalayer-kv-cache](https://github.com/MichaelTaylor3D/chia-datalayer-kv-cache)\\n\\n - [chia-datalayer-mirror-tools](https://github.com/MichaelTaylor3D/chia-datalayer-mirror-tools)\\n\\n - [chia-datalayer-update-notifier](https://github.com/MichaelTaylor3D/chia-datalayer-update-notifier)\\n\\n - [chia-dataplayer](https://github.com/cripsisxyz/chia-dataplayer)\\n\\n - [databin.store](https://github.com/JonathanLangton1/databin.store)\\n\\n - [Chia Official CADTrust API](https://github.com/Chia-Network/cadt)\\n\\n - [Chia Official CADTrust UI](https://github.com/Chia-Network/cadt-ui)\\n\\n - [ChiaDLFileStore Node.js package](https://www.npmjs.com/package/chia-dl-file-store)\\n\\n More Reading\\n\\n - [Chia Smart DataLayer: A Community Pro...](https://medium.com/@michaeltaylor3d/chia-smart-datalayer-a-community-proposal-775356922dd1 \"Chia Smart DataLayer: A Community Proposal\")\\n\\n - [Building a Sovereign Internet with Ch...](https://medium.com/@michaeltaylor3d/building-an-sovereign-internet-with-chia-data-layer-f64dab466c01 \"Building a Sovereign Internet with Chia Data Layer\")\\n\\n - [Using Chia Data Layer as the backend ...](https://medium.com/@michaeltaylor3d/using-chia-data-layer-as-the-backend-for-your-application-3f0a72d19b31 \"Using Chia Data Layer as the backend for your application\")\\n\\n - [Introducing Chia Data Layer as a Service](https://medium.com/@michaeltaylor3d/introducing-chia-data-layer-as-a-service-19b750be7db4 \"Introducing Chia Data Layer as a Service\")\\n\\n - [Using Chia DataLayer as a Software Di...](https://medium.com/@michaeltaylor3d/using-chia-datalayer-as-a-software-distribution-platform-8d3dff4e9690 \"Using Chia DataLayer as a Software Distribution Platform\")\\n\\n - [A Guide to Chia Data Layer Developmen...](https://medium.com/@michaeltaylor3d/a-guide-to-data-layer-development-and-generating-chia-offer-files-for-data-layer-d37c91256d97 \"A Guide to Chia Data Layer Development and Creating Offer Files for P2P Data Exchange\")\\n\\n - [A Primer on Chia DataLayer](https://medium.com/@fizpawiz/a-primer-on-chia-datalayer-e4a4796c390e \"A Primer on Chia DataLayer\")\\n\\n - [How to DataLayer Your NFT Collection](https://xchdev.com/#!blog/2023-11/How-to-DataLayer-Your-NFT-Collection.md \"ow to DataLayer Your NFT Collection\")\\n\\n - [How to Subscribe and Mirror on DataLayer](https://xchdev.com/#!blog/2023-11/How-to-Subscribe-and-Mirror-on-Datalayer.md \"How to Subscribe and Mirror on DataLayer\")\\n\\n DataLayer Stores\\n\\n - [List of Current Stores](https://thisweekinchia.com/stores.html)\\n\\n![Image 27: Creator Coding](https://thisweekinchia.com/assets/images/Creator_Coding.png)\\n\\nCreator Coding is a multi-part series demonstrating coding for creators through a series of websites, coding examples, and case studies.\\n\\n[![Image 28: Creator Coding Part 1](https://thisweekinchia.com/assets/images/Creator_Coding_Part_1.png)](https://youtu.be/6bIYdnBz8Iw)\\n\\n[![Image 29: Creator Coding Part 2](https://thisweekinchia.com/assets/images/Creator_Coding_Part_2.png)](https://youtu.be/I_dxYx-S2Ww)\\n\\n[![Image 30: Creator Coding Part 3](https://thisweekinchia.com/assets/images/Creator_Coding_Part_3.png)](https://youtu.be/LHqiJfNie5c)\\n\\n[![Image 31: Creator Coding Part 4](https://thisweekinchia.com/assets/images/Creator_Coding_Part_4.png)](https://youtu.be/pTyEsZNkDyc)\\n\\n[![Image 32: Creator Coding Part 5](https://thisweekinchia.com/assets/images/Creator_Coding_Part_5.png)](https://youtu.be/Oahg-CTSSHk)\\n\\n[![Image 33: 222 HR Chia Marathon Space 2025](https://thisweekinchia.com/assets/images/222HrSpace2025.jpg)](https://222hr.space/)[https://222hr.space/](https://222hr.space/)\\n\\n X Spaces - Day 1 \\n\\n- [Pre Pre Game Part 1](https://x.com/i/spaces/1OdJrOdzryqxX) by Monkeyzoo\\n\\n - [Pre Pre Game Part 2](https://x.com/i/spaces/1yoKMPnPXBkxQ) by Monkeyzoo\\n\\n - [Pre Game](https://x.com/i/spaces/1mnGeNDNQvoJX) by TeeMoney1738\\n\\n - [Kickoff](https://x.com/i/spaces/1ypKdqWddOnGW) by DracattusDev\\n\\n - [Art & Culture](https://x.com/i/spaces/1mnGeNZbjRPJX) by anewformofmusic\\n\\n - [Orange Light District](https://x.com/i/spaces/1vAxRQelbggJl) by illLoomiN8\\n\\n - [GM range](https://x.com/i/spaces/1zqJVdngDkaKB) by TeeMoney1738\\n\\n X Spaces - Day 2 \\n\\n- [TL;DR  Hackathon Kickoff & More](https://x.com/i/spaces/1yNGabEyNDXJj) by DracattusDev\\n\\n - [Intro to 2D Art w/ Adobe Illustrator](https://x.com/i/spaces/1BRJjgaObzLxw) by icelabs0\\n\\n - [FoMO Live  Sage Wallet  This Week In Chia](https://x.com/i/spaces/1DXxyWnbQMeGM) by DracattusDev\\n\\n - [Love Sunday Morning Asia](https://x.com/i/spaces/1DXxyWnMrbnGM) by anewformofmusic\\n\\n - [Chilling & Chatting Chia](https://x.com/i/spaces/1nAKEEjnYMbKL) by steppsr\\n\\n - [Datalayer](https://x.com/i/spaces/1zqKVdnprOVJB) by anewformofmusic\\n\\n - [Creating NFT Project Start to Finish](https://x.com/i/spaces/1YpJkkaPAEmJj) by Monkeyzoo\\n\\n - [GM range](https://x.com/i/spaces/1nAJEEjngWeJL) by TeeMoney1738\\n\\n X Spaces - Day 3 \\n\\n- [Hackathon Roundtable](https://x.com/i/spaces/1yoJMPgrbNWGQ) by DracattusDev\\n\\n - NeckCoin v Bitcoin by DegenWaffle_NFT (unrecorded)\\n\\n - [Digital Spaceport  Sage Wallet  Energon  0xBASIC  Go4 Economy](https://x.com/i/spaces/1OyKAjROZBaGb) by ArtwithHeartNFT\\n\\n* * *\\n\\n![Image 34: Chia Toronto 2025](https://thisweekinchia.com/assets/images/ChiaToronto2025.jpg)\\n\\n MAY 13TH, 2025 \\n\\n[https://xch.network/chia-toronto-2025](https://xch.network/chia-toronto-2025/)\\n\\n Conference Details\\n\\nChia Toronto 2025 will be during Canada Crypto Week 2025 in downtown Toronto on May 13, 2025. Pre-register [here](https://forms.gle/RynYhvQFbgvXTnwf7). Many will be staying for Consensus 2025 also.\\n\\n Confirmed special guests & speakers:\\n\\n - [Bram Cohen](https://x.com/bramcohen), Founder & CTO CNI\\n\\n - [Gene Hoffman](https://x.com/hoffmang), President & CEO CNI\\n\\n - [Thomas Chow](https://x.com/chinaesq), CLO CNI\\n\\n - Neil Hand, SVP Marketing CNI\\n\\n - [Rigidity](https://x.com/Rigidity16), Developer CNI & Sage Wallet\\n\\n - [ClydeWallace](https://x.com/ClydeWallace22), Product Marketing CNI\\n\\n - [Yakuhito](https://x.com/yakuh1t0), Developer TibetSwap & warp.green\\n\\n - [Andreas Greimel](https://x.com/acevail_), Founder MintGarden\\n\\n - [Seth Jenks](https://x.com/sethjenks), Creator & Designer Chia Friends\\n\\n - [dns](https://x.com/dns_xch), Founder Dexie\\n\\n - [Paul Hainsworth](https://x.com/mouthy), CEO Berkeley Compute\\n\\n - [Michael Taylor](https://x.com/digdotnet), Founder DIG Network\\n\\n - [Matthew Hintz](https://x.com/MatthewSHintz), Founder Sols Lot\\n\\n - [Steve Stepp](https://x.com/steppsr), Developer This Week In Chia\\n\\n - [xchbob](https://x.com/xchbob) (aka the good bob)\\n\\n Organizers:\\n\\n - [SlowestTimelord](https://x.com/SlowestTimelord), Timelord XCH.network\\n\\n - [Fo0ds](https://x.com/smertxfo0d), CEO MicroHonkOG\\n\\n - [Sabari](https://x.com/natsaba), Founder SpaceScan\\n\\n - [Dracattus](https://x.com/DracattusDev), Developer, Dracattus & TangTalk\\n\\n* * *\\n\\n![Image 35: XCH SpaceFest](https://thisweekinchia.com/assets/images/spacefest.png)\\nXCH SpaceFest is an annual Twitter/X Space all about Chia & $XCH in celebration of the original NFT1 standard launch in June 2022.\\n\\n**2024**\\n\\n - [XCH SpaceFest 2024 - Part 1](https://x.com/MatthewSHintz/status/1807199226033574099)\\n\\n - [XCH SpaceFest 2024 - Part 2](https://x.com/anewformofmusic/status/1807359255537672272)\\n\\n - [XCH SpaceFest 2024 - Part 3](https://x.com/ArtwithHeartNFT/status/1807367809174815092) (unrecorded)\\n\\n - [XCH SpaceFest 2024 - Part 4](https://x.com/anewformofmusic/status/1807814479801196583)\\n\\n**2023** (retcon\\'d name as XCH SpaceFest )\\n\\n - [XCH SpaceFest 2023 - Part 1](https://twitter.com/i/spaces/1MYxNgmyeRpKw?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 2](https://twitter.com/i/spaces/1ynJOaZXdWOKR?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 3](https://twitter.com/i/spaces/1gqxvylAmzkJB?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 4](https://twitter.com/i/spaces/1BdxYyYZokoxX?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 5](https://twitter.com/i/spaces/1BdGYywXjgNGX?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 6](https://twitter.com/i/spaces/1zqJVPBprnPKB?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 7](https://twitter.com/i/spaces/1lPKqBmzmzAGb?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 8](https://twitter.com/i/spaces/1YpJkgZpBNNJj?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 9](https://twitter.com/i/spaces/1YqKDoqDRRLxV?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 10](https://twitter.com/i/spaces/1eaKbrNlZmjKX?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 11](https://twitter.com/i/spaces/1ynJOaZNlWyKR?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 12](https://twitter.com/i/spaces/1YpKkgZdZajKj?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 13](https://twitter.com/i/spaces/1MYxNgnXeqyKw?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 14](https://twitter.com/i/spaces/1OwxWwzoQEkxQ?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 15](https://twitter.com/i/spaces/1ZkKzXbejYoJv?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 16](https://twitter.com/i/spaces/1nAKErYaqXaGL?s=20)\\n\\n - [XCH SpaceFest 2023 - Part 17](https://twitter.com/i/spaces/1PlKQpabRlzxE?s=20)\\n\\n![Image 36](https://thisweekinchia.com/assets/images/references_chiablockchain.png)\\n\\n White Paper\\n\\n - [Chia Network White Paper (webpage)](https://www.chia.net/white-paper/)\\n\\n - [CNI White Paper PDF (v2)](https://thisweekinchia.com/assets/docs/Chia-Business-Whitepaper-2022-02-02-v2.0.pdf)\\n\\n - [CNI White Paper PDF (v1)](https://thisweekinchia.com/assets/docs/Chia-Business-Whitepaper-2021-02-09-v1.0.pdf)\\n\\n - [Whitepaper Zoom - February 11, 2021 (video)](https://www.youtube.com/watch?v=9P0vaux2h6o)\\n\\n - [Whitepaper Zoom - February 12, 2021 (video)](https://www.youtube.com/watch?v=2uvlop-hlio)\\n\\n Green Paper\\n\\n - [Precursor Green Paper](https://thisweekinchia.com/assets/docs/Precursor-ChiaGreenPaper.pdf)\\n\\n - [Chia Network Green Paper](https://thisweekinchia.com/assets/docs/ChiaGreenPaper_20241008.pdf)\\n\\n IP & Trademark\\n\\n - [Trademark Policy](https://thisweekinchia.com/assets/docs/Chia-Trademark-Policy.pdf)\\n\\n - [Copyright Policy](https://thisweekinchia.com/assets/docs/Chia-Copyright-Policy.pdf)\\n\\n - [CNI Web Guidelines on Trademarks & ](https://thisweekinchia.com/assets/docs/Guidelines-for-Using-Chia-Network.pdf)\\n\\n Licenses\\n\\n - [Chia Friends License v1.0](https://thisweekinchia.com/assets/docs/Chia_Friends_License_v1.0.pdf)\\n\\n - [Chia Friends License v2.0](https://thisweekinchia.com/assets/docs/Chia_Friends_License_v2.0.pdf)\\n\\n![Image 37](https://thisweekinchia.com/assets/images/xcharcane.png)\\n\\n\\u200d Coinset Model Series\\n\\n - [Part 1: Introduction to the Coinset Model](https://xcharcane.com/articles/introduction-to-coinset-model)\\n\\n - [Part 2: Understanding Transaction Costs](https://xcharcane.com/articles/understanding-transaction-costs)\\n\\n - [Part 3: Outputs and Inputs](https://xcharcane.com/articles/outputs-and-inputs)\\n\\n - [Part 4: Coin Puzzles and Solutions](https://xcharcane.com/articles/coin-puzzles-and-solutions)\\n\\n - [Part 5: Aggregated Signatures](https://xcharcane.com/articles/aggregated-signatures)\\n\\n - [Part 6: Bringing It All Together](https://xcharcane.com/articles/bringing-it-all-together)\\n\\n About XCH Arcane\\n\\n - [XCH Arcane Homepage](https://xcharcane.com/)\\n\\n - [About Our Mission](https://xcharcane.com/about)\\n\\n - [Complete Article Archive](https://xcharcane.com/articles)\\n\\n[This Week In Chia](https://thisweekinchia.com/)\\n================================================\\n\\nCommunity Site  No affiliation with Chia Network, Inc.\\n\\n* * *\\n\\n### Week of Oct 26, 2025 - Nov 1, 2025 \\n\\n[![Image 38:  Arguably the most beautifully rendered, iconic and relevant Chia Friends pixel art. Chia and free speech ](https://thisweekinchia.com/ads/kjmathue_superad.png)](https://x.com/hoffmang/status/1978245813231833574)\\n\\n[Buy #600](https://dexie.space/offers/Ek1p9ycxiHs6L35BcaGCP4NchJB6Pvo6RposNsuoyzDX)[1 BTC = 2 XCH](https://x.com/hoffmang/status/1978245813231833574)\\n\\n Arguably the most beautifully rendered, iconic and\\n\\nrelevant Chia Friends pixel art. Chia and free speech Advertisement\\n\\n*   TUESDAY  10/28/2025\\n*   [@chia_project](https://twitter.com/chia_project) As blockchain adoption continues to grow, enterprises around the world are looking at how digital assets can improve their business. Learn more about Chias tools to enable and support secure custody for digital assets for enterprises.  Chia Network (@chia_project) October 28, 2025  [read at chia.net](https://www.chia.net/2025/10/28/solving-enterprise-self-custody/)  [Source](https://x.com/chia_project/status/1983273732018975047)\\n*   X Space - \"TL;DR; with Mark & AiVa: Deep Dives / Crypto / Ai / SaaS / ##DevLife\"  Drac  (@DracattusDev) October 28, 2025  [space on twitter.com](https://twitter.com/i/spaces/1BRJjgAbyvdxw)  [Source](https://x.com/DracattusDev/status/1983158163932360930)\\n\\n* * *\\n\\n*   MONDAY  10/27/2025\\n*   X Space - \"$35MM Real Estate Deal Coming On-Chain??? Let\\'s Talk\"  RWA BOBBY FLAY (@MatthewSHintz) October 27, 2025  [space on x.com](https://x.com/i/spaces/1rmxPvbZPnQGN)  [Source](https://x.com/MatthewSHintz/status/1982905646979895457)\\n*   X Space - \"The MonkeyZoo project will be featured on The @ongeniusroom podcast and live X space next month, Tim will be talking about Decentralised Dynamic NFTs and why we choose the @chia_project to build our technology on  Save the date for November 8th, more details soon [Quote Tweet](https://thisweekinchia.com/://twitter.com/yaeunda/status/1982759075071787157)  Monkeyzoo (@monkeyzoo) October 27, 2025\"  [Source](https://x.com/monkeyzoo/status/1982805194556477685)\\n*   X Space - \"TL;DR; w Mark & AiVa: Web3 Content Strategy: #DevLife #Chia #Ai\"  Drac  (@DracattusDev) October 27, 2025  [space on twitter.com](https://twitter.com/i/spaces/1BdGYZNZZkAJX)  [Source](https://x.com/DracattusDev/status/1982795406980300976)\\n\\n* * *\\n\\n*   SUNDAY  10/26/2025\\n*   [@DracattusDev](https://twitter.com/DracattusDev) Dracattus Bloodline Viewer Demo: A quick look aat navigating your Drac\\'s lineage  https://www.youtube.com/watch?v=y39pVVaLGfc  Drac  (@DracattusDev) October 27, 2025  [Watch](https://www.youtube.com/watch?v=y39pVVaLGfc)  [Source](https://x.com/DracattusDev/status/1982643274667176342)\\n*   [@MayorAbandoned](https://twitter.com/MayorAbandoned) I\\'ve updated PowerSage to include a wayy to estimate option pricing. Also, made a video explaining the process   The Mayor (@MayorAbandoned) October 26, 2025  [Source](https://x.com/MayorAbandoned/status/1982532438351044783)\\n*   X Space - \"TL;DR; Mark & AiVa dive deep on CryptoTwitter Evolution / ##DevLife\"  Drac  (@DracattusDev) October 26, 2025  [space on twitter.com](https://twitter.com/i/spaces/1YqxolXyOwvKv)  [Source](https://x.com/DracattusDev/status/1982432090437390609)\\n\\n* * *\\n\\n> [![Image 39](https://thisweekinchia.com/assets/images/sarahndipitous.png)](https://twitter.com/sarahndipitous)[Weekly Highlight](https://thisweekinchia.com/weeklyhighlights.html \"Weekly Highlight Info\"):Meet [@sarahndipitous](https://twitter.com/sarahndipitous): a creative force blending artistry, authorship, and invention into a tapestry of innovation. As a mother of makers and a DIY MacGyver, she champions the Chia Blockchain, infusing its community with boundless love and insightful wisdom, shaping a future where creativity and technology intertwine seamlessly. Join her journey as she crafts a world where imagination knows no bounds. Join me in showing some love if you want: xch16wnagwtdvhus80jtfaqgvcd84q674q6vx89244r5cfxs8lutegmqmxvtd5. \\n> \\n> \\n> \\n> ![Image 40](https://thisweekinchia.com/donations/20251026.png)\\n\\n* * *\\n\\n### Week of Oct 19, 2025 - Oct 25, 2025 \\n\\n[![Image 41:  Arguably the most beautifully rendered, iconic and relevant Chia Friends pixel art. Chia and free speech ](https://thisweekinchia.com/ads/kjmathue_superad.png)](https://x.com/hoffmang/status/1978245813231833574)\\n\\n[Buy #600](https://dexie.space/offers/Ek1p9ycxiHs6L35BcaGCP4NchJB6Pvo6RposNsuoyzDX)[1 BTC = 2 XCH](https://x.com/hoffmang/status/1978245813231833574)\\n\\n Arguably the most beautifully rendered, iconic and\\n\\nrelevant Chia Friends pixel art. Chia and free speech Advertisement\\n\\n*   SATURDAY  10/25/2025\\n*   X Space - \"TL;DR; Mark & AiVa: Build Before It\\'s Boring: AI Infra. for Founders\"  Drac  (@DracattusDev) October 25, 2025  [space on twitter.com](https://twitter.com/i/spaces/1OdJrOYpEWwxX)  [Source](https://x.com/DracattusDev/status/1982070291082731642)\\n\\n* * *\\n\\n*   FRIDAY  10/24/2025\\n*   [@Rigidity16](https://twitter.com/Rigidity16) Just published version 0.31.0 of the Chia Wallet SDK! Thanks @cmmarslender for improving the security of the repo\\'s publishing CI.  Rigidity  (@Rigidity16) October 24, 2025 **0.31.0**  [Source](https://x.com/Rigidity16/status/1981778592171528503)  [Chia Wallet SDK](https://docs.rs/chia-wallet-sdk/latest/chia_wallet_sdk/)\\n*   X Space - \"TL;DR; Mark & AiVa: GaryVee\\'s Stan Challenge for Creator Monetization\"  Drac  (@DracattusDev) October 24, 2025  [space on twitter.com](https://twitter.com/i/spaces/1mrGmBWAAoZJy)  [Source](https://x.com/DracattusDev/status/1981707556788838411)\\n\\n* * *\\n\\n*   THURSDAY  10/23/2025\\n*   X Space - \"Names Space w/ @woodburn_nathan + @Mayaank_Roy DNS / How Internet Works\"  ArtWithHeart 111 (@ArtwithHeartNFT) October 24, 2025  [space on x.com](https://x.com/i/spaces/1kvJpMVzwdbxE)  [Source](https://x.com/ArtwithHeartNFT/status/1981542411877982696)\\n*   [@endertown](https://twitter.com/endertown) \\u200d go4me Halloween Event! OOOoooo scary! Speecial Halloween editions of your favorite go4s are being created now for all go4s that have at least 20 copies sold! These editions come with a custom go4me logo and will also count for double airdrop score for both Badge and   Josh Painter (@endertown) October 23, 2025  [Source](https://x.com/endertown/status/1981482151368348127)\\n*   X Space - \"Chia Art Shill: Showcase your NFTs\"  Ice Las (@icelabs0) October 23, 2025  [space on x.com](https://x.com/i/spaces/1RDGlALMVdMJL)  [Source](https://thisweekinchia.com/=\\'https://x.com/icelabs0/status/1981340891160989949\\')\\n*   X Space - \"TL;DR; Mark & AiVa talk GameBrains: AI in Interactive Worlds #DevLife\"  Drac  (@DracattusDev) October 23, 2025  [space on twitter.com](https://twitter.com/i/spaces/1kvKpMVBwVXGE)  [Source](https://x.com/DracattusDev/status/1981346256728326447)\\n\\n* * *\\n\\n*   WEDNESDAY  10/22/2025\\n*   [@bramcohen](https://twitter.com/bramcohen) We\\'ve been putting together plans for possible future Chia pooling protocol enhancements, link below: \"Future Chia Pooling Protocol Enhancements\"  Bram Cohen (@bramcohen) October 23, 2025  [Source](https://x.com/bramcohen/status/1981159983187365975)  [Read article](https://bramcohen.com/p/future-chia-pooling-protocol-enhancements)\\n*   [@chia_project](https://twitter.com/chia_project) ANAAR is officially launched and connecting Artisans and Consumers around the world! Were thrilled to be their technology partner ensuring and protecting auditability and transparency of every transaction for their clients. Learn more about what theyre doing here:  Chia Network (@chia_project) October 22, 2025  [Source](https://x.com/chia_project/status/1981088683446194399)  [ANAAR](https://www.anaar.world/)\\n*   X Space - \"TL;DR; Mark & AiVa talk AI, Crypto, Gaming, and the Metaverse Future\"  Drac  (@DracattusDev) October 22, 2025  [space on twitter.com](https://twitter.com/i/spaces/1LyGBXDegXWxN)  [Source](https://x.com/DracattusDev/status/1980983415647432930)\\n\\n* * *\\n\\n*   TUESDAY  10/21/2025\\n*   [@chia_project](https://twitter.com/chia_project) Read the next piece in @jde5011 series on blockchains, digital assets, and real-world safety. \"Chia Signer, MultiSignature Custody, and RealWorld Safety: Part 2\"  Chia Network (@chia_project) October 21, 2025  [Source](https://x.com/chia_project/status/1980695047193673746)  [Read article](https://www.chia.net/2025/10/21/chia-signer-multi%E2%80%91signature-custody-and-real%E2%80%91world-safety-part-2/)\\n*   X Space - \"TL;DR; Mark & AiVa talk Cloudflare DNS Setup and Security / #DevLife\"  Drac  (@DracattusDev) October 21, 2025  [space on twitter.com](https://twitter.com/i/spaces/1jMKgRyLBYexL)  [Source](https://x.com/DracattusDev/status/1980621233147228255)\\n\\n* * *\\n\\n*   MONDAY  10/20/2025\\n*   [@CPOfficialtx](https://twitter.com/CPOfficialtx) Top 10 RWA projects by development activity (last 30 days): 1. Chainlink $LINK 2. Hedera $HBAR 3. Avalanche $AVAX 4. Stellar $XLM 5. IOTA $IOTA 6. Chia $XCH 7. Axelar $AXL 8. Centrifuge $CFG 9. Injective $INJ 10. VeChain $VET Source: @santimentfeed  Cryptopolitan (@CPOfficialtx) October 21, 2025  [Source](https://x.com/CPOfficialtx/status/1980442180486590611)\\n*   [@MrDennisV](https://twitter.com/MrDennisV) Rock Paper Scissors on the Chia Gaming framework! My own smart contract this time  [Source](https://x.com/MrDennisV/status/1980491236999036988)\\n*   X Space - \"TL;DR; Mark & AiVa: The Database Download Deep Dive / #DevLife \"  Drac  (@DracattusDev) October 20, 2025  [space on twitter.com](https://twitter.com/i/spaces/1lPKqvAokPPGb)  [Source](https://x.com/DracattusDev/status/1980258094010515608)\\n\\n* * *\\n\\n*   SUNDAY  10/19/2025\\n*   X Space - \"TL;DR; w Mark & AiVa - Sunday Morning Tech Jam / ##DevLife\"  Drac  (@DracattusDev) October 19, 2025  [space on twitter.com](https://twitter.com/i/spaces/1yNGabeqqEbJj)  [Source](https://x.com/DracattusDev/status/1979897209731551635)\\n\\n* * *\\n\\n> [![Image 42](https://thisweekinchia.com/assets/images/splitxch.png)](https://splitxch.com/)[Weekly Highlight](https://thisweekinchia.com/weeklyhighlights.html \"Weekly Highlight Info\"):splitXCH! [Lucky8](https://twitter.com/Lucky8Token)has made a really great community tool to allow users to create royalty splits. Join me in showing some love if you want: xch1dtk6vwfxl4wymadnq4e6u0jsy6dqtw6clq4pssyphveu3x3tz60sqyzyzaor see their site: [splitXCH](https://splitxch.com/).  ![Image 43](https://thisweekinchia.com/donations/20251019.png)\\n\\n* * *\\n\\n### Week of Oct 12, 2025 - Oct 18, 2025 \\n\\n[![Image 44:  Arguably the most beautifully rendered, iconic and relevant Chia Friends pixel art. Chia and free speech ](https://thisweekinchia.com/ads/kjmathue_superad.png)](https://x.com/hoffmang/status/1978245813231833574)\\n\\n[Buy #600](https://dexie.space/offers/Ek1p9ycxiHs6L35BcaGCP4NchJB6Pvo6RposNsuoyzDX)[1 BTC = 2 XCH](https://x.com/hoffmang/status/1978245813231833574)\\n\\n Arguably the most beautifully rendered, iconic and\\n\\nrelevant Chia Friends pixel art. Chia and free speech Advertisement\\n\\n*   SATURDAY  10/18/2025\\n*   [@DracattusDev](https://twitter.com/DracattusDev) releases update on Dracattus development. \"Dracattus - RC2 - Update Overview / Game Mechanics / #play2earn / #Chia / #crypto\"  Drac  (@DracattusDev) October 18, 2025  [Watch](https://www.youtube.com/watch?v=E-iTgiqjw2c)  [Source](https://x.com/DracattusDev/status/1979708559106687258)\\n*   X Space - \"TL;DR; Mark & AiVa talk Frickn Laser Beams / #DevLife / #Nerdn \"  Drac  (@DracattusDev) October 18, 2025  [space on twitter.com](https://x.com/DracattusDev/status/1979534242561552865)  [Source](https://x.com/DracattusDev/status/1979534242561552865)\\n\\n* * *\\n\\n*   FRIDAY  10/17/2025\\n*   [@BenAtreidesVing](https://x.com/BenAtreidesVing) announces 4-letter .xch names are now rolling out for NAMESDAO. Can you register multiple names at once, and for 100 years.  [Source](https://x.com/BenAtreidesVing/status/1979284777594425606)  [Namesdao](https://www.namesdao.org/)\\n*   X Space - \"TL;DR; The Technology and Innovation Nexus for Global Progress \"  Drac  (@DracattusDev) October 17, 2025  [space on twitter.com](https://thisweekinchia.com/LINK)  [Source](https://thisweekinchia.com/TWEET_LINK)\\n\\n* * *\\n\\n*   THURSDAY  10/16/2025\\n*   [@chia_project](https://twitter.com/chia_project) As part of our work to simplify our developer tooling ecosystem, we have renamed our chialisp compiler, formerly `clvm_tools_rs`, to simply `chialisp`. This change is effective immediately. Please update your development environment and workflows to use the new name.  Chia Network (@chia_project) October 16, 2025  [Source](https://x.com/chia_project/status/1978969197230137735)  [chialisp](https://github.com/Ch\\n\\n--------------------------------------------------------------------------------\\n'}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='MCP Architecture & Core Concepts', description='Explains MCPs host-client-server model, key primitives (resources, tools, prompts), message types (requests, results, notifications, errors), supported transports (stdio, HTTP/SSE), and security considerations so developers grasp the protocols building blocks.', research=True, content='## MCP Architecture & Core Concepts\\n\\nMCP follows a three-tier host  client  server pattern. The host application (IDE, chatbot, agent) spawns one client per server; each client maintains a stateful, JSON-RPC session with its paired server, turning the old MN integration maze into a simple M+N graph [1].\\n\\nServers advertise three primitives during the handshake:  \\n Tools  callable functions the model may trigger (model-controlled).  \\n Resources  read-only data the application decides to inject (app-controlled).  \\n Prompts  reusable templates the user can pick (user-controlled) [1][2].\\n\\nAll traffic uses JSON-RPC 2.0. Four message flavours keep the dialogue clear: requests, successful results, notifications (one-way), and error responses. A session begins with an initialize request, capability negotiation, then normal operation until either side closes the transport [2][3].\\n\\nTwo transports are standard. Stdio is fastest for local child processes; Streamable HTTP with optional Server-Sent Events lets remote servers push incremental results over a single connection [1][3].\\n\\nSecurity is handled in layers: fine-grained capability declarations restrict what each side may do; hosts must obtain explicit user consent before sharing data, invoking tools, or granting LLM sampling, and OAuth 2.1 is recommended for authenticating remote HTTP servers [2].\\n\\n### Sources  \\n[1] Model Context Protocol (MCP) an overview: https://www.philschmid.de/mcp-introduction  \\n[2] The Model Context Protocol (MCP)  A Complete Tutorial: https://medium.com/@nimritakoul01/the-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef  \\n[3] Architecture overview  Model Context Protocol: https://modelcontextprotocol.io/docs/learn/architecture')], 'source_str': 'Search results: \\n\\n\\n\\n--- SOURCE 1: Model Context Protocol (MCP) an overview ---\\nURL: https://www.philschmid.de/mcp-introduction\\n\\nSUMMARY:\\nThe Model Context Protocol (MCP) is an open standard introduced by Anthropic with the goal to standardize how AI applications (chatbots, IDE assistants, or custom agents) connect with external tools, data sources, and systems. Tool creators build N MCP servers (one for each system), while application developers build M MCP clients (one for each AI application). MCP defines a client-server architecture where: * **Clients:** Live within the Host application and manage the connection to one specific MCP server. * **Servers:** External programs that expose Tools, Resources and Prompts via standard API to the AI model via the client. ### MCP servers MCP Clients are part of Host applications (the IDE, chatbot, etc.) that manage the communication with a specific MCP Server.\\n\\nFULL CONTENT:\\n[Philschmid](/)\\n\\n\\n\\n# Model Context Protocol (MCP) an overview\\n\\nApril 3, 20259 minute read\\n\\nThe [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) is an open standard [introduced by Anthropic](https://www.anthropic.com/news/model-context-protocol) with the goal to standardize how AI applications (chatbots, IDE assistants, or custom agents) connect with external tools, data sources, and systems.\\n\\nThink of it like USB for AI integrations. Before standards like USB, connecting peripherals required a mess of different ports and custom drivers. Similarly, integrating AI applications with external tools and systems is/was an \"MN problem\".If you have M different AI applications (Chat, RAG 1, custom agents, etc.) and N different tools/systems (GitHub, Slack, Asana, databases, etc.), you might need to build MN different integrations. This leads to duplicated effort across teams, inconsistent implementations.\\n\\nMCP aims to simplify this by providing a common API and transforming this into an \"M+N problem\". Tool creators build N MCP servers (one for each system), while application developers build M MCP clients (one for each AI application). MCP defines a client-server architecture where:\\n\\n* **Hosts:** Applications the user interacts with (e.g., Claude Desktop, an IDE like Cursor, a custom agent).\\n* **Clients:** Live within the Host application and manage the connection to one specific MCP server. Maintain a 1:1 to connection.\\n* **Servers:** External programs that expose Tools, Resources and Prompts via standard API to the AI model via the client.\\n\\nThe current components of MCP servers include:\\n\\n1. **Tools (Model-controlled):** These are functions (tools) that LLMs can call to perform specific actions, e.g. weather API, basically function calling\\n2. **Resources (Application-controlled):** These are data sources that LLMs can access, similar to GET endpoints in a REST API. Resources provide data without performing significant computation, no side effects. Part of the context/request\\n3. **Prompts (User-controlled):** These are pre-defined templates to use tools or resources in the most optimal way. Selected before running inference\\n\\n## How does MCP work?\\n\\nMCP operates on the client-server model described earlier. Heres a simplified flow:\\n\\n1. **Initialization:** When a Host application starts it creates N MCP Clients, which exchange information about capabilities and protocol versions via a handshake.\\n2. **Discovery:** Clients requests what capabilities (Tools, Resources, Prompts) the server offers. The Server responds with a list and descriptions.\\n3. **Context Provision:** The Host application can now make resources and prompts available to the user or parses the tools into a LLM compatible format, e.g. JSON Function calling\\n4. **Invocation:** If the LLM determines it needs to use a Tool (e.g., based on the user\\'s request like \"What are the open issues in the \\'X\\' repo?\"), the Host directs the Client to send an invocation request to the appropriate Server.\\n5. **Execution:** The Server receives the request (e.g., fetch\\\\_github\\\\_issues with repo \\'X\\'), executes the underlying logic (calls the GitHub API), and gets the result.\\n6. **Response:** The Server sends the result back to the Client.\\n7. **Completion:** The Client relays the result to the Host, which incorporates it into the LLM\\'s context, allowing the LLM to generate a final response for the user based on the fresh, external information.\\n\\n### MCP servers\\n\\nMCP Servers are the bridge/API between the MCP world and the specific functionality of an external system (an API, a database, local files, etc.). They are essentially wrappers that expose these external capabilities according to the MCP specification.\\n\\nServers can be built in various languages (Python, TypeScript, Java, Rust, etc.) as long as they can communicate over the supported transports. Servers communicate with clients primarily via two methods:\\n\\n* **stdio (Standard Input/Output):** Used when Client and Server run on the same machines. This is simple and effective for local integrations (e.g., accessing local files or running a local script).\\n* **HTTP via SSE (Server-Sent Events):** The Client connects to the Server via HTTP. After an initial setup, the Server can push messages (events) to the Client over a persistent connection using the SSE standard.\\n\\nExample of how to build an MCP server with Python and [FastMCP](https://github.com/jlowin/fastmcp/tree/main):\\n\\nList of pre-build and community build MCP servers:\\n\\n* <https://github.com/punkpeye/awesome-mcp-servers>\\n* <https://github.com/modelcontextprotocol/servers>\\n* <https://mcp.composio.dev/>\\n\\n### MCP Clients\\n\\nMCP Clients are part of Host applications (the IDE, chatbot, etc.) that manage the communication with a specific MCP Server.\\n\\n* **Role:** Handle connection management, capability discovery, request forwarding, and response handling according to the MCP spec.\\n* **Examples of Hosts/Clients:**\\n  + UI Apps: Claude Desktop, Microsoft Copilot Studio, LibreChat, Claude Code\\n  + IDEs: Cursor, Windsurf, Continue, Zed, Cline\\n  + Custom Agents (Python/TypeScript):\\n    - Firebase Genkit\\n    - LangGraph\\n    - OpenAI agents sdk\\n    - .\\n\\nExample of how to build an MCP client with Python and mcp.\\n\\n## Why is there so much hype? Did MCP win?\\n\\nWhile Anthropic announced MCP in late 2024, its momentum significantly accelerated in early 2025. This isn\\'t just random hype; several factors converged:\\n\\n* **\"AI-Native\"** while older standards like OpenAPI, GraphQL, or SOAP exist for API interaction, MCP was designed specifically for the needs of modern AI agents. MCP refines patterns seen in agent development:\\n  + Tools (Model-controlled): Actions the AI decides to take.\\n  + Resources (Application-controlled): Context provided to the AI.\\n  + Prompts (User-controlled): Specific user-invoked interactions.\\n* **\"Open Standard\" with a Big Backer:** Any \"open standard should have a spec, and [MCP has a VERY good spec](https://spec.modelcontextprotocol.io/specification/2024-11-05/). The spec alone defeats a lot of contenders, who do not provide such detailed specs.\\n* **Built on Proven Foundations:** Instead of re-inventing everything from scratch, Anthropic adapted from Language Server Protocol (LSP), e.g. [JSON-RPC 2.0](https://www.jsonrpc.org/)\\n* **Strong Initial Ecosystem & Dogfooding:** MCP didn\\'t launch as just a spec. Anthropic \"dogfooded\" it extensively and released it with a comprehensive initial set:\\n  + Client: Claude Desktop.\\n  + Servers: Numerous reference implementations (filesystem, git, Slack, etc.).\\n  + Tooling: MCP Inspector for testing, great documentation\\n  + SDKs: Python and TypeScript libraries, now Java, Kotlin C#\\n* **Network Effects:** The open nature fostered a community. Tools like Cursor and Windsurf integrated MCP. Companies like Composio provided pre-built servers for hundreds of integrations. OpenAI announced support for MCP. Developers built thousands of community MCP servers (GitHub, Slack, databases, Docker, etc.).\\n\\n## Practical Example with Gemini and Python uSDK\\n\\n## What about Security, Updates, Authentication?\\n\\nMCP is a living protocol. The specification is actively maintained on GitHub, last update from 03/26 improves security, scalability, and usability.\\n\\n* **Authentication & Security (OAuth 2.1):** The protocol now mandates the OAuth 2.1 framework for authenticating remote HTTP servers\\n* **Improved Transport & Efficiency:** The previous HTTP+SSE transport will be replaced with a more flexible Streamable HTTP transport and support for JSON-RPC batching.\\n* **Richer Context & Control:** New tool annotations provide more metadata about a tool\\'s behavior (e.g., read-only vs. destructive)\\n\\n## Acknowledgements\\n\\nThis overview was compiled with the help of deep and manual research, drawing inspiration and information from several excellent resources, including:\\n\\n* [What Is MCP, and Why Is Everyone  Suddenly! Talking About It?](https://huggingface.co/blog/Kseniase/mcp)\\n* [What is MCP](https://python.useinstructor.com/blog/2025/03/27/understanding-model-context-protocol-mcp/#conclusion)\\n* [I gave Claude root access to my server... Model Context Protocol explained](https://www.youtube.com/watch?v=HyzlYwjoXOQ)\\n* [Why MCP Won](https://www.latent.space/p/why-mcp-won)\\n* [Building Agents with Model Context Protocol - Full Workshop with Mahesh Murag of Anthropic](https://www.youtube.com/watch?v=kQmXtrmQ5Zg)\\n\\nIf you have any questions, feedback, or ideas, please dm me on [X](https://x.com/_philschmid) or [LinkedIn](https://www.linkedin.com/in/philipp-schmid-a6a2bb196/). I am excited to hear about how you are experimenting and pushing the boundaries of AI agents.\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 2: The Model Context Protocol (MCP)  A Complete Tutorial ---\\nURL: https://medium.com/@nimritakoul01/the-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef\\n\\nSUMMARY:\\nAn MCP server can provide access to databases, CRMs like Salesforce, local file systems, and version control systems like Git. The role of the server builder is to **expose tools, resources, and prompts** in a way that is consumable by any compatible client. In essence, the relationship between MCP clients and servers is one of **standardised interaction**, where clients leverage the capabilities exposed by servers through the common language of the MCP protocol, leading to a more efficient and scalable ecosystem for building AI applications and agents. The Model Context Protocol (MCP) provides a standardized way for servers to expose prompts, resources, and tools to clients. The Model Context Protocol (MCP) defines a rigorous lifecycle for client-server connections that ensures proper capability negotiation and state management.\\n\\nFULL CONTENT:\\n[Sitemap](/sitemap/sitemap.xml)\\n\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa3abe8a7f4ef&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40nimritakoul01%2Fthe-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40nimritakoul01%2Fthe-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n# The Model Context Protocol (MCP)  A Complete Tutorial\\n\\n[Dr. Nimrita Koul](/@nimritakoul01?source=post_page---byline--a3abe8a7f4ef---------------------------------------)\\n\\n25 min readMar 27, 2025\\n\\nAnthropic [released the Model Context Protocol(MCP)](https://www.anthropic.com/news/model-context-protocol) in Nov. 2024.\\n\\nIt is developed by Mahesh Murag at Anthropic. Find the [complete official documentation.](https://supabase.com/docs/guides/getting-started/mcp) At present, MCP is fully implemented as [Python SDK](https://github.com/modelcontextprotocol/python-sdk) and [TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk).\\n\\n[Mahesh Murag](https://x.com/MaheshMurag) delivered a great workshop on [Building Agents with Model Context Protocol](https://www.youtube.com/watch?v=kQmXtrmQ5Zg) during AI Engineer Summit.\\n\\n## Context is the key\\n\\nThe basic capabilities of a Generative AI model depend on its pretraining details, the training data, and the model architecture. To make these pretrained models perform better and improve their relevance and coherence to your task, you must provide a good context to it.\\n\\nHere context refers to the information the model uses to generate relevant and coherent responses. Context determines how the model understands and continues a conversation, completes a text, or generates an image.\\n\\nContext can be provided in different ways, depending on the type of model and task:\\n\\n1. Text-Based Models (e.g., GPT, DeepSeek, LLaMA) receive their context through:\\n\\n* Prompt Context: The input text or query that guides the models response.\\n* Token Window: The number of tokens the model can remember at a time (e.g., GPT-4-Turbo can handle ~128K tokens).\\n* Conversation History: In chatbots, previous exchanges help maintain context in multi-turn dialogues.\\n* Retrieval-Augmented Generation (RAG): Context from external documents retrieved dynamically to improve responses.\\n\\n2. Image and Multimodal Models (e.g., DALLE, Gemini) receive their context through:\\n\\n* Text Descriptions: The prompt guides image generation.\\n* Visual Context: If an image is provided, the model analyzes its content before generating new elements.\\n* Cross-Modal Context: When combining text and images, models interpret both to generate meaningful outputs.\\n\\n3. Code Generation Models (e.g., Codex, DeepSeek-Coder) receive their context through:\\n\\n* Previous Code Blocks: Context includes existing code, function names, and comments.\\n* Programming Language Syntax: The model understands language-specific patterns.\\n* External Documentation: Some models use APIs or docs for more accurate suggestions.\\n\\n4. Speech and Audio Models (e.g., Whisper, AudioPaLM) receive their context through:\\n\\n* Audio Segments: Prior speech or music informs the next generated part.\\n* Linguistic and Acoustic Features: Tone, speed, and intonation influence transcription and generation.\\n\\nIn short, context is the key factor that enables generative AI to produce relevant and coherent outputs. The better the context management, the better the AIs performance.\\n\\n### Over time the AI models can auto fetch data to act as context. This is especially true of AI Agents which are the systems that use generative AI models at their core. This means the AI Agents have to search for data sources, request the sources for specific data and so on.\\n\\nEach data source (server) is implemented is its own way (for example, as open source packages in another codebase  rather than emitting messages that can be consumed by anyone. Or these can be implemented as JSON RPC for messages) so there is no standard way for an AI model (client) to search for and request for data. (Fragmentation.)\\n\\nBefore MCP, building AI systems often involved:\\n\\n* Custom implementations for each AI application to hook into its required context, leading to a lot of duplicated effort.\\n* Inconsistent prompt logic and different methods for accessing and federating tools and data across different teams and companies.\\n* The N times M problem where a large number of client applications needed to interact with a large number of servers and tools, resulting in a complex web of integrations, each requiring specific development work.\\n\\n## Model Context Protocol (MCP) solves this problem of fragmented data access.\\n\\n## The MCP provides a open standard for connecting AI systems with data sources and tools (repositories, business tools, development environments), replacing fragmented integrations with a single protocol. Thus MCP provides fungibility between AI clients and servers.\\n\\nThus MCP provides a standardized way for applications to:\\n\\n* Share contextual information with language models\\n* Expose tools and capabilities to AI systems\\n* Build composable integrations and workflows\\n\\nThe protocol uses [JSON-RPC](https://www.jsonrpc.org/) 2.0 messages to establish communication between:\\n\\n* **Hosts**: LLM applications that initiate connections\\n* **Clients**: Connectors within the host application\\n* **Servers**: Services that provide context and capabilities\\n\\nThere are a number of popular AI tools that support MCP, including:\\n\\n* [Cursor](https://www.cursor.com/)\\n* [Windsurf](https://docs.codeium.com/windsurf) (Codium)\\n* [Cline](https://github.com/cline/cline) (VS Code extension)\\n* [Claude desktop](https://claude.ai/download)\\n* [Claude code](https://claude.ai/code)\\n\\nMCP takes some inspiration from the [Language Server Protocol](https://microsoft.github.io/language-server-protocol/), which standardizes how to add support for programming languages across a whole ecosystem of development tools. In a similar way, MCP standardizes how to integrate additional context and tools into the ecosystem of AI applications.\\n\\n## Architecture of MCP\\n\\nMCP follows a client-host-server architecture where each host can run multiple client instances.\\n\\n* This architecture enables users to integrate AI capabilities across applications while maintaining clear security boundaries and isolating concerns.\\n* Built on JSON-RPC, MCP provides a stateful session protocol focused on context exchange and sampling coordination between clients and servers.\\n\\n### Host\\n\\nThe host process acts as the container and coordinator:\\n\\n* Creates and manages multiple client instances\\n* Controls client connection permissions and lifecycle\\n* Enforces security policies and consent requirements\\n* Handles user authorization decisions\\n* Coordinates AI/LLM integration and sampling\\n* Manages context aggregation across clients\\n\\n### Clients\\n\\nEach client is created by the host and maintains an isolated server connection:\\n\\n* Establishes one stateful session per server\\n* Handles protocol negotiation and capability exchange\\n* Routes protocol messages bidirectionally\\n* Manages subscriptions and notifications\\n* Maintains security boundaries between servers\\n\\nA host application creates and manages multiple clients, with each client having a 1:1 relationship with a particular server.\\n\\n**MCP Clients** are the **AI applications or agents** that want to access external systems, tools, or data sources. Examples include Anthropics first-party applications, Curser, Windsurf, and agents like Goose. The key characteristic of an MCP client is its **MCP compatibility**, meaning it is built to communicate using the standardised interfaces defined by the protocol: **prompts, tools, and resources**.\\n\\nOnce an MCP client is compatible, it can connect to **any MCP server with minimal or no additional work**. The client is responsible for **invoking tools, querying for resources, and interpolating prompts**.\\n\\nIn the context of tools, the **language model within the client application** decides when it is best to invoke the tools exposed by the server. For resources, the client application has **control over how the data exposed by the server is used**. Prompts are considered **user-controlled tools invoked by the user through the client application**.\\n\\n### Servers\\n\\nServers provide specialized context and capabilities:\\n\\n* Expose resources, tools and prompts via MCP primitives\\n* Operate independently with focused responsibilities\\n* Request sampling through client interfaces\\n* Must respect security constraints\\n* Can be local processes or remote services\\n\\n**MCP Servers** act as **wrappers or intermediaries** that provide a **standardised way to access various external systems, tools, and data sources**. An MCP server can provide access to databases, CRMs like Salesforce, local file systems, and version control systems like Git. The role of the server builder is to **expose tools, resources, and prompts** in a way that is consumable by any compatible client. Once an MCP server is built, it can be adopted by **any MCP client**, solving the N times M problem by reducing the need for individualised integrations. For **tools**, the server defines the available functions and their descriptions, allowing the clients model to decide when to use them. For **resources**, the server defines and potentially creates or retrieves data that it exposes to the client application. For **prompts**, the server provides predefined templates for common interactions that the client application can trigger on behalf of the user.\\n\\nThe MCP protocol acts as the **communication layer** between these two components, standardising how requests and responses are structured and exchanged. This separation offers several benefits, as it allows:\\n\\n* **Seamless Integration:** Clients can connect to a wide range of servers without needing to know the specifics of each underlying system.\\n* **Reusability:** Server developers can build integrations once and have them accessible to many different client applications.\\n* **Separation of Concerns:** Different teams can focus on building client applications or server integrations independently. For example, an infrastructure team can manage an mCP server for a vector database, which can then be easily used by various AI application development teams.\\n\\nIn essence, the relationship between MCP clients and servers is one of **standardised interaction**, where clients leverage the capabilities exposed by servers through the common language of the MCP protocol, leading to a more efficient and scalable ecosystem for building AI applications and agents.\\n\\n## MCP Features\\n\\n### MCP Server Features\\n\\nMCP Servers provide the fundamental building blocks (Prompts, Resources, Tools) for adding context to language models via MCP. These primitives enable rich interactions between clients, servers, and language models:\\n\\n* **Prompts**: Pre-defined templates or instructions that guide language model interactions\\n* **Resources**: Structured data or content that provides additional context to the model\\n* **Tools**: Executable functions that allow models to perform actions or retrieve information\\n\\nThe Model Context Protocol (MCP) provides a standardized way for servers to expose prompts, resources, and tools to clients.\\n\\n**Prompts (Protocol Revision: 20241105)**\\n\\nPrompts allow servers to provide structured messages and instructions for interacting with language models. Clients can discover available prompts, retrieve their contents, and provide arguments to customize them.\\n\\nPrompts are designed to be **user-controlled**, meaning they are exposed from servers to clients with the intention of the user being able to explicitly select them for use.\\n\\nTypically, prompts would be triggered through user-initiated commands in the user interface, which allows users to naturally discover and invoke available prompts. For example, as slash commands.\\n\\nServers that support prompts **MUST** declare the `prompts` capability during [initialization](https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/lifecycle/#initialization):\\n\\n**Resources : Protocol Revision: 20241105**\\n\\nResources allow servers to share data that provides context to language models, such as files, database schemas, or application-specific information. Each resource is uniquely identified by a [URI](https://datatracker.ietf.org/doc/html/rfc3986).\\n\\nResources in MCP are designed to be **application-driven**, with host applications determining how to incorporate context based on their needs.\\n\\nFor example, applications could:\\n\\n* Expose resources through UI elements for explicit selection, in a tree or list view\\n* Allow the user to search through and filter available resources\\n* Implement automatic context inclusion, based on heuristics or the AI models selection\\n\\nServers that support resources **MUST** declare the `resources` capability:\\n\\nThe capability supports two optional features:\\n\\n* `subscribe`: whether the client can subscribe to be notified of changes to individual resources.\\n* `listChanged`: whether the server will emit notifications when the list of available resources changes.\\n\\n**Tools  Protocol Revision: 20241105**\\n\\nMCP allows servers to expose tools that can be invoked by language models. Tools enable models to interact with external systems, such as querying databases, calling APIs, or performing computations. Each tool is uniquely identified by a name and includes metadata describing its schema.\\n\\nTools in MCP are designed to be **model-controlled**, meaning that the language model can discover and invoke tools automatically based on its contextual understanding and the users prompts. However, implementations are free to expose tools through any interface pattern that suits their needs.\\n\\nServers that support tools **MUST** declare the `tools` capability:\\n\\n`listChanged` indicates whether the server will emit notifications when the list of available tools changes.\\n\\n### MCP Client Features\\n\\nClients can implement additional features to enrich connected MCP servers: **Roots and Sampling**.\\n\\n**Roots**\\n\\n* **Roots** define the boundaries of **where servers can operate within the filesystem,** allowing them to understand which directories and files they have access to. MCP provides a standardized way for clients to expose filesystem **roots** to servers. Servers can request the list of roots from supporting clients and receive notifications when that list changes.\\n\\nA root definition includes:\\n\\n* `uri`: Unique identifier for the root. This **MUST** be a `file://` URI in the current specification.\\n* `name`: Optional human-readable name for display purposes.\\n\\nExample roots for different use cases:\\n\\n**Sampling (Protocol Revision: 20241105)**\\n\\nMCP provides a standardized way for servers to request LLM sampling (completions or generations) from language models via clients. This flow allows clients to maintain control over model access, selection, and permissions while enabling servers to leverage AI capabilities  with no server API keys necessary. Servers can request text or image-based interactions and optionally include context from MCP servers in their prompts.\\n\\nSampling in MCP allows servers to implement agentic behaviors, by enabling LLM calls to occur *nested* inside other MCP server features.\\n\\nImplementations are free to expose sampling through any interface pattern that suits their needs  the protocol itself does not mandate any specific user interaction model.\\n\\n**Composability**\\n\\n* Composability in MCP highlights that the **distinction between a client and a server is logical rather than physical**. This means that **any application, API, or agent can function as both an MCP client and an MCP server simultaneously**.\\n* This dual role allows for the creation of **layered and chained systems**. A user might interact with a primary agent application (a client), which then communicates with a specialised sub-agent (acting as a server). This sub-agent, in turn, can act as a client and invoke other MCP servers (such as a file system server or a web search server) to fulfil its task.\\n* **Relevance to Agents:** Composability is crucial for building advanced, modular agent architectures. It enables the creation of **hierarchical systems of agents**, where different agents can specialise in specific tasks and delegate sub-tasks to other agents. For instance, an orchestrator agent can receive a high-level goal and then break it down into smaller tasks, delegating these tasks to research agents, coding agents, or fact-checking agents, each operating as an MCP server but also potentially acting as a client to access necessary tools and data. This allows for **building complex workflows and intelligent behaviours by combining the capabilities of multiple specialised agents**. It also allows for **reusing and connecting to agents built by others**, even if they were not initially part of the main agents design.\\n\\nIn combination, **sampling and composability** are powerful enablers for advanced AI agents. They allow for:\\n\\n* **Distribution of intelligence** across a multi-agent system, with the client controlling the actual LLM interactions while servers (agents) can request these capabilities as needed through sampling.\\n* The construction of **complex, multi-layered agent systems** where specialised agents can work together by acting as both clients and servers.\\n* **Increased flexibility and modularity** in agent design, as new capabilities (exposed as mCP servers) can be integrated into existing agent workflows.\\n* The potential for **agents to evolve and adapt** by interacting with other agents and services in a composable manner.\\n\\nThese concepts move beyond monolithic agent designs and towards more distributed, collaborative, and adaptable AI systems.\\n\\n### Additional Utilities offered by MCP :\\n\\n* Configuration, Progress tracking, Cancellation, Error reporting, Logging\\n\\n### Security and Trust & Safety\\n\\nMCP enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important security and trust considerations that all implementors must carefully address.\\n\\n### Key Principles of MCP Security, Trust and Safety\\n\\n1. **User Consent and Control:** Users must explicitly consent to and understand all data access and operations. They must retain control over what data is shared and what actions are taken. Implementors should provide clear UIs for reviewing and authorizing activities\\n\\n**2. Data Privacy:** Hosts must obtain explicit user consent before exposing user data to servers. Hosts must not transmit resource data elsewhere without user consent. User data should be protected with appropriate access controls\\n\\n**3. Tool Safety:** Tools represent arbitrary code execution and must be treated with appropriate caution. Hosts must obtain explicit user consent before invoking any tool. Users should understand what each tool does before authorizing its use\\n\\n## Get Dr. Nimrita Kouls stories in\\xa0your\\xa0inbox\\n\\nJoin Medium for free to get updates from\\xa0this\\xa0writer.\\n\\n4. **LLM Sampling Controls:** Users must explicitly approve any LLM sampling requests. Users should control  Whether sampling occurs at all, The actual prompt that will be sent, What results the server can see, The protocol intentionally limits server visibility into prompts\\n\\n### Implementation Guidelines: Implementors of MCP should:\\n\\n1. Build robust consent and authorization flows into their applications\\n2. Provide clear documentation of security implications\\n3. Implement appropriate access controls and data protections\\n4. Follow security best practices in their integrations\\n5. Consider privacy implications in their feature designs\\n\\n## MCP Design Principles\\n\\nMCP is built on several key design principles that inform its architecture and implementation:\\n\\n1. **Servers should be extremely easy to build**\\n\\n* Host applications handle complex orchestration responsibilities\\n* Servers focus on specific, well-defined capabilities\\n* Simple interfaces minimize implementation overhead\\n* Clear separation enables maintainable code\\n\\n**2. Servers should be highly composable**\\n\\n* Each server provides focused functionality in isolation\\n* Multiple servers can be combined seamlessly\\n* Shared protocol enables interoperability\\n* Modular design supports extensibility\\n\\n**3. Servers should not be able to read the whole conversation, nor see into other servers**\\n\\n* Servers receive only necessary contextual information\\n* Full conversation history stays with the host\\n* Each server connection maintains isolation\\n* Cross-server interactions are controlled by the host\\n* Host process enforces security boundaries\\n\\n**4. Features can be added to servers and clients progressively**\\n\\n* Core protocol provides minimal required functionality\\n* Additional capabilities can be negotiated as needed\\n* Servers and clients evolve independently\\n* Protocol designed for future extensibility\\n* Backwards compatibility is maintained\\n\\n### MCP Message Types\\n\\nMCP defines three core message types based on [JSON-RPC 2.0](https://www.jsonrpc.org/specification):\\n\\n* **Requests**: Bidirectional messages with method and parameters expecting a response\\n* **Responses**: Successful results or errors matching specific request IDs\\n* **Notifications**: One-way messages requiring no response\\n\\nEach message type follows the JSON-RPC 2.0 specification for structure and delivery semantics.\\n\\n### Capability Negotiation System in MCP\\n\\nMCP uses a capability-based negotiation system where clients and servers explicitly declare their supported features during initialization. Capabilities determine which protocol features and primitives are available during a session.\\n\\n* Servers declare capabilities like resource subscriptions, tool support, and prompt templates\\n* Clients declare capabilities like sampling support and notification handling\\n* Both parties must respect declared capabilities throughout the session\\n* Additional capabilities can be negotiated through extensions to the protocol\\n\\nEach capability unlocks specific protocol features for use during the session. For example:\\n\\n* Implemented [server features](https://spec.modelcontextprotocol.io/specification/2024-11-05/server/) must be advertised in the servers capabilities\\n* Emitting resource subscription notifications requires the server to declare subscription support\\n* Tool invocation requires the server to declare tool capabilities\\n* [Sampling](https://spec.modelcontextprotocol.io/specification/2024-11-05/client/) requires the client to declare support in its capabilities\\n\\nThis capability negotiation ensures clients and servers have a clear understanding of supported functionality while maintaining protocol extensibility.\\n\\n## Details of the Base MCP Protocol\\n\\n**Protocol Revision**: 20241105\\n\\nAll messages between MCP clients and servers **MUST** follow the [JSON-RPC 2.0](https://www.jsonrpc.org/specification) specification. The protocol defines three fundamental types of messages:\\n\\n**Responses** are further sub-categorized as either **successful results** or **errors**. Results can follow any JSON object structure, while errors must include an error code and message at minimum.\\n\\n### Protocol Layers\\n\\nThe Model Context Protocol consists of several key components that work together:\\n\\n* **Base Protocol**: Core JSON-RPC message types\\n* **Lifecycle Management**: Connection initialization, capability negotiation, and session control\\n* **Server Features**: Resources, prompts, and tools exposed by servers\\n* **Client Features**: Sampling and root directory lists provided by clients\\n* **Utilities**: Cross-cutting concerns like logging and argument completion\\n\\nAll implementations **MUST** support the base protocol and lifecycle management components. Other components **MAY** be implemented based on the specific needs of the application.\\n\\nThese protocol layers establish clear separation of concerns while enabling rich interactions between clients and servers. The modular design allows implementations to support exactly the features they need.\\n\\n**Life Cycle for client-server connections:**\\n\\nThe Model Context Protocol (MCP) defines a rigorous lifecycle for client-server connections that ensures proper capability negotiation and state management.\\n\\n1. **Initialization**: Capability negotiation and protocol version agreement\\n2. **Operation**: Normal protocol communication\\n3. **Shutdown**: Graceful termination of the connection\\n\\n**Lifecycle Phases:**\\n\\n1. **Initialization:** The initialization phase **MUST** be the first interaction between client and server. During this phase, the client and server:\\n\\n* Establish protocol version compatibility\\n* Exchange and negotiate capabilities\\n* Share implementation details\\n\\nThe client **MUST** initiate this phase by sending an `initialize` request containing:\\n\\n* Protocol version supported\\n* Client capabilities\\n* Client implementation information\\n\\nThe server **MUST** respond with its own capabilities and information.\\n\\nAfter successful initialization, the client **MUST** send an `initialized` notification to indicate it is ready to begin normal operations.The client **SHOULD NOT** send requests other than [pings](https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/utilities/ping/) before the server has responded to the `initialize` request. The server **SHOULD NOT** send requests other than [pings](https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/utilities/ping/) and [logging](https://spec.modelcontextprotocol.io/specification/2024-11-05/server/utilities/logging/) before receiving the `initialized` notification.\\n\\n**2. Version Negotiation:** In the `initialize` request, the client **MUST** send a protocol version it supports. This **SHOULD** be the *latest* version supported by the client. If the server supports the requested protocol version, it **MUST** respond with the same version. Otherwise, the server **MUST** respond with another protocol version it supports. This **SHOULD** be the *latest* version supported by the server. If the client does not support the version in the servers response, it **SHOULD** disconnect.\\n\\n**3. Capability Negotiation:** Client and server capabilities establish which optional protocol features will be available during the session.\\n\\nKey capabilities include:\\n\\nCapability objects can describe sub-capabilities.\\n\\n**4. Operation:** During the operation phase, the client and server exchange messages according to the negotiated capabilities.\\n\\nBoth parties **SHOULD**:\\n\\n* Respect the negotiated protocol version\\n* Only use capabilities that were successfully negotiated\\n\\n**5. Shutdown:** During the shutdown phase, one side (usually the client) cleanly terminates the protocol connection. No specific shutdown messages are defined  instead, the underlying transport mechanism should be used to signal connection termination:\\n\\n### stdio\\n\\nFor the stdio [transport](https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/transports/), the client **SHOULD** initiate shutdown by:\\n\\n1. First, closing the input stream to the child process (the server)\\n2. Waiting for the server to exit, or sending `SIGTERM` if the server does not exit within a reasonable time\\n3. Sending `SIGKILL` if the server does not exit within a reasonable time after `SIGTERM`\\n\\nThe server **MAY** initiate shutdown by closing its output stream to the client and exiting.\\n\\n**6. HTTP:** For HTTP [transports](https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/transports/), shutdown is indicated by closing the associated HTTP connection(s).\\n\\n**7. Error Handling:** Implementations **SHOULD** be prepared to handle these error cases:\\n\\n* Protocol version mismatch\\n* Failure to negotiate required capabilities\\n* Initialize request timeout\\n* Shutdown timeout\\n\\nImplementations **SHOULD** implement appropriate timeouts for all requests, to prevent hung connections and resource exhaustion.\\n\\nAuthentication and authorization are not currently part of the core MCP specification, but may be introduced soon.\\n\\nThe full specification of the protocol is defined as a [TypeScript schema](http://github.com/modelcontextprotocol/specification/tree/main/schema/2024-11-05/schema.ts). This is the source of truth for all protocol messages and structures.\\n\\nThere is also a [JSON Schema](http://github.com/modelcontextprotocol/specification/tree/main/schema/2024-11-05/schema.json), which is automatically generated from the TypeScript source of truth, for use with various automated tooling.\\n\\n## Benefits of MCP for Stakeholders\\n\\n### For Application Developers\\n\\nFor application developers, the MCP offers several key benefits.\\n\\n* **Zero Additional Work for Server Connection:** Once an application is **MCP compatible**, it can connect to **any mCP server with zero additional work**. This means developers dont need to write specific integration logic for each new tool or data source they want their application to access, significantly reducing development time and effort.\\n* **Standardised Interface:** MCP standardises how AI applications interact with external systems through its three primary interfaces: **prompts, tools, and resources**. This provides a **consistent way to access and utilise the capabilities** offered by different servers, simplifying the development process and making it easier for developers to understand and integrate new functionalities.\\n* **Access to a Broad Ecosystem:** By building an MCP client, developers gain access to a growing ecosystem of **community-built and officially supp\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 3: The Model Context Protocol (MCP): Unied Approach To ... ---\\nURL: https://www.deep-kondah.com/intromodel-context-protocol-mcp/\\n\\nSUMMARY:\\nIn this post, I will introduce the Model Context Protocol, its standardized primitives (prompts, resources, tools...), its architecture, session\\n\\nFULL CONTENT:\\n![Deep Kondah](https://www.deep-kondah.com/content/images/2023/10/Capture-d--cran-2023-10-03---22.20.51-1-1.png)\\n\\n# The Model Context Protocol (MCP): Unied Approach To Building Agentic AI systems\\n\\nWhether you are an AI engineer or working on workflow automation, you probably know how much attention the MCP or Model Context Protocol has attracted recently; thanks to the AI hype cycle. Since its introduction by Anthropic, it has gained real momentum, supported by a vibrant community ecosystem with thousands\\n\\n![Mouad Kondah](/content/images/size/w100/2025/03/IMG_2438.jpeg)\\n![The Model Context Protocol (MCP): Unied Approach To Building Agentic AI systems](/content/images/size/w2000/2025/09/mcp_archi.png)\\n\\nWhether you are an AI engineer or working on workflow automation, you probably know how much attention the MCP or Model Context Protocol has attracted recently; thanks to the AI hype cycle. Since its introduction by Anthropic, it has gained real momentum, supported by a vibrant community ecosystem with [thousands of MCP servers](https://github.com/punkpeye/awesome-mcp-servers?ref=deep-kondah.com) proposed and major companies already announcing MCP support (partial) in their LLM products.\\n\\nOver the past few days and weeks, I decided to dive into MCP and LLM-MCP integration, to better understand what all the hype was about.\\n\\nStandardizing how applications inject context for LLMs, MCP aims to streamline the development of Agentic AI systems. However, there are still adoption [challenges](https://www.researchgate.net/publication/389687667_Model_Context_Protocol_Servers_A_Novel_Paradigm_for_AI-Driven_Workflow_Automation_and_Comparative_Analysis_with_Legacy_Systems?ref=deep-kondah.com) stemming from MCPs inherent technical complexity (compared to [Function Calling](https://platform.openai.com/docs/guides/function-calling?ref=deep-kondah.com); initial and still widely used approach to connecting LLMs with external tools). In fact, how LLMs actually utilize MCP capabilities is still poorly understood; highlighting a [gap](https://arxiv.org/html/2508.12566v1?ref=deep-kondah.com) between its theoretical benefits and practical usefulness.\\n\\nMCP empowers foundation models with context and tool calls, without custom and fragmented integrations (i.e through standardized context sharing mechanisms), and is expected to improve the development productivity. It solves the long-standing  [NM integration problem](https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/?ref=deep-kondah.com) , where each AI application requires engineering unique bespoke integrations for each tool or data source the underlying agent needs to interact with. Without a standard,\\xa0connecting N AI apps to M tools requires NM custom integrations duplicating engineering efforts and leading to a fragmented and complex landscape. With MCP, only N + M amenable standard integrations are required, significantly reducing integration complexity [in comparison with traditional APIs](https://www.ijfmr.com/papers/2025/2/43583.pdf?ref=deep-kondah.com) struggling to cope with real-time and multi-protocol interactions. Workflows could benefit a lot from standardization and we have seen this with OTel, OCSF, etc.\\n\\nIn this post, I will introduce the Model Context Protocol, its standardized primitives (prompts, resources, tools...), its architecture, session management, message formats and routing, security (authentication, authorization and attacks), and finally how MCP agents are developed.\\n\\n## **Introduction**\\n\\nLarge Language Models (LLMs) are developed to understand the probability distribution that governs the world language space. \\xa0Autoregressive models approximate this distribution by predicting subsequent words based on previous context, forming a\\xa0Markov chain. World knowledge (often referred as parametric knowledge) is stored implicitly within the model\\'s parameters.\\n\\nLLMs are trained using next token prediction on a large corpora across the web and naturally acquire general and commonsense knowledge of both the world and language and how humans use it to comprehend and interact with the external environment*.*\\n\\nLLMs are not only trained to predict the next token, they also undergo a further fine-tuning step (Supervised Fine-Tuning, or SFT) to follow instructions (using (instruction, completion) pairs. Additionally, LLMs must generate unbiased responses and align with human values (*alignment problem*), something achieved using reinforcement learning from human feedback or RLHF.\\n\\nWith the resulting LLM, one can use different forms of prompting to get answers to questions using acquired world knowledge, apply zero/few-shot learning, and use RAG or Retrieval-Augmented Generation to enhance the LLMs capabilities.\\n\\nOnce an LLM can follow commands, one can use stacking to create an agent or LLM-based agent (LLMs without function interface are mere text generators and can\\'t do anything meaningful).\\n\\nThe LLM, once equipped with tools and other interfaces, has access to context, and through an agent loop (one way to develop an agent is by using an agent loop; one can use other mechanisms), the foundation model is instructed to choose the next tool to use in order to achieve certain goals. For example, a security agent querying the CrowdStrike API and appending the result of each fetching, forming a larger context for future decisions (e.g autonomous security event investigation).\\n\\nHowever, providing LLMs with such aforementioned capabilities requires a high integration cost (increasing the intelligence of an application increases complexity...), and this is where MCP or Model Context Protocol comes into play.\\n\\n![](https://www.deep-kondah.com/content/images/2025/09/mcp_w_wi.png)\\n\\nMCP offers a standard way to incorporate context, and empower LLM-based or AI agents to make autonomous decisions.\\n\\n### **Language Modeling (LM)**\\n\\nLanguage modeling is not something new, it has been a central task in NLP and existed long before the foundation models revolutionized AI applications. Before transformers and the attention mechanism, machine learning models like Word2Vec, RNNs, and LSTMs already showed promising results. However, two main problems persisted: their sequential nature made parallel learning impossible and slowed training, and the influence of distant words (long-term or range dependencies) diminished due to the vanishing gradient problem, essentially the squashing of information during backpropagation (as the gradients propagate through each layer, their magnitude tends to decrease, think of it as\\\\(r^n\\\\)\\xa0, where\\xa0\\\\(n\\\\)\\xa0is large and\\xa0\\\\(r<1\\\\)). This is why RNNs were known to excel only at short-term dependencies.\\n\\nWord embeddings produced by Word2Vec and GloVe\\xa0already produces meaningful latent vectors. But with the introduction of transformer-based architectures and LLMs, you get even more powerful embeddings. Specifically, Word2Vec produces static embeddings, while LLMs generate dynamic contextual embeddings, where each tokens embedding is influenced by the surrounding words or tokens (thanks to the attention mechanism). This is also why LLMs are now widely used for semantic and contextual similarity search providing a compact bottleneck (like a sketch) that summarizes the underlying text.\\n\\nToday, LLMs are not merely text generators, they are being transformed from raw language models to more capable generative models with sophisticated reasoning and agentic tool use capabilities.\\n\\nDiscussing LLMs in detail and the research around them is beyond the scope of this post, one can explore topics such as LLM scaling laws, multimodal LLMs, and LLM reasoning, there are plenty of scientific articles and free courses available.\\n\\n### **Introducing The Model Context Protocol (MCP)**\\n\\nTo overcome interoperability challenges and compatibility issues (e.g when wiring APIs) across diverse AI frameworks, Anthropic introduced MCP in late November 2024. Within a short period, it has become the de facto standard for AI application development. Major companies have all already embraced (partially) the MCP ecosystem to empower AI and LLM products.\\n\\nLarge language models best exemplified by GPT4 are pre-trained on massive corpora of data and already exhibited outstanding instruction-following performance, and once equipped with a structured tool calling, their capability extends beyond mere text generation. They become capable of executing actions in real-world environments; the augmented foundation model autonomously discover, select when and which tool to use enabling a wide range of use cases.\\n\\nEvery coin has two faces, while MCP brings a lot of benefits in exposing tools (executable functions) and resources to foundation models, it also expand the attack surface and is subject to several attacks including LLM inherent vulnerabilities (Prompt injection, Hallucination, Backdoor... ). For example, [Tool Poisoning Attacks](https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks?ref=deep-kondah.com), introduced by Invariant Labs, refers to the scenario where the agent initial goal is hijacked due to \\xa0hidden malicious instructions in the tool description (or runtime responses) exposed via a malicious MCP server. The adversary instructions are not directly visible to users and have the whole attention of the foundation model as the agent uses these descriptions for planning (see [LLM sycophancy](https://arxiv.org/pdf/2502.08177?ref=deep-kondah.com)).\\n\\n### **The Integration Bottleneck**\\n\\nThe first problem MCP solves regarding tools calling is the lack of scalability when messy, unscalable integrations are tailored for each use case. Consider a scenario where N tools are used across M applications requiring N  M individual integrations.\\n\\nTools are often wrappers around APIs, and because applications are heterogeneous, you typically need an SDK for each programming language. Even if a REST API is available, language-specific web clients are still required. With MCP, however, you can rely on a universal MCP client, reducing the burden of language-specific integrations thereby reducing\\xa0 maintenance overhead.\\n\\nSome frameworks or providers may enable language models call functions (by serving definitions, parsing arguments, results), but this doesnt fully solve the integration bottleneck as theres no standardized way for tools to declare their capabilities and for clients to consume it i.e each provider uses a different function definition. A standard is needed.\\n\\nFinally, there are cases where you cant modify the agent code but still want to serve your tool in a unified way (e.g when using ChatGPT or Claude). This is yet another area where MCP shines. With MCP, one needs to implement tools only once and serve it in consistent format, empowering AI agent to dynamically discover, select, and orchestrate tools and moving beyond the static hard-wired workflows.\\n\\nAs will be covered later, MCP is not only about tools and includes additional capabilities on client and server side by introducing several primitives to simplify how to build AI agents and workflows (you dont even need an LLM to use MCP).\\n\\n### **The Model Context Protocol (MCP)**\\n\\nSimply stated, MCP is a specialized protocol for AI or LLM-based applications that standardizes how agents or context-aware AI systems interact with external systems including session management, resource abstraction and tools exposure.\\n\\nIn term of architecture, MCP follows a serverclient architecture. First, you have an LLM service such as OpenAI; the agent is built on top of it. MCP clients maintain connections to MCP servers that run alongside the LLM (i.e the foundation model guides the MCP requests). MCP servers act as resource servers, exposing capabilities and data in a standardized way.\\n\\nMCP supports several transport protocols including standard input/output (stdio) and streamable HTTP. In this post, we focus on streamable HTTP (with optional Server-Sent Events (SSE) responses).\\n\\nThere are several MCP client and server implementations [available](https://modelcontextprotocol.io/docs/sdk?ref=deep-kondah.com), we will focus on the [Official Python SDK](https://github.com/modelcontextprotocol/python-sdk?ref=deep-kondah.com) provided by Anthropic.\\n\\n### **MCP Message Format**\\n\\nThe MCP protocol uses JSON-RPC 2.0 for communication between clients and servers. MCP defines three primary message types: request, response and notification.\\n\\n`class JSONRPCMessage(RootModel[JSONRPCRequest | JSONRPCNotification | JSONRPCResponse | JSONRPCError]):\\npass`\\n\\nRequest:\\n\\n`class JSONRPCRequest(Request[dict[str, Any] | None, str]):\\n\"\"\"A request that expects a response.\"\"\"\\njsonrpc: Literal[\"2.0\"]\\nid: RequestId\\nmethod: str\\nparams: dict[str, Any] | None = None`\\n`{\\n\"jsonrpc\": \"2.0\",\\n\"id\": 0,\\n\"method\": \"string\",\\n\"params\": {}\\n}`\\n\\nResponse:\\n\\n`class JSONRPCResponse(BaseModel):\\n\"\"\"A successful (non-error) response to a request.\"\"\"\\njsonrpc: Literal[\"2.0\"]\\nid: RequestId\\nresult: dict[str, Any]\\nmodel_config = ConfigDict(extra=\"allow\")`\\n`{\\n\"jsonrpc\": \"2.0\",\\n\"id\": 0,\\n\"result\": {}\\n}`\\n\\nError Response:\\n\\n`class JSONRPCError(BaseModel):\\n\"\"\"A response to a request that indicates an error occurred.\"\"\"\\njsonrpc: Literal[\"2.0\"]\\nid: str | int\\nerror: ErrorData\\nmodel_config = ConfigDict(extra=\"allow\")`\\n`{\\n\"jsonrpc\": \"2.0\",\\n\"id\": 0,\\n\"error\": {\\n\"code\": ..,\\n\"message\": \"\",\\n\"data\": {}\\n}\\n}`\\n\\nNotification (\\xa0one-way message, e.g task progress):\\n\\n`class JSONRPCNotification(Notification[dict[str, Any] | None, str]):\\n\"\"\"A notification which does not expect a response.\"\"\"\\njsonrpc: Literal[\"2.0\"]\\nparams: dict[str, Any] | None = None`\\n`{\\n\"jsonrpc\": \"2.0\",\\n\"method\": string,\\n\"params\": {}\\n}`\\n\\nHere is what the first request (initialization phase) issued by the MPC client looks like:\\n\\n`{\\n\"jsonrpc\": \"2.0\",\\n\"id\": 0,\\n\"method\": \"initialize\",\\n\"params\": {\\n\"protocolVersion\": \"2025-06-18\",\\n\"capabilities\": {},\\n\"clientInfo\": {\\n\"name\": \"mcp\",\\n\"version\": \"0.1.0\"\\n}\\n},\\n}`\\n\\nEach request (and response) includes a unique id, which is used for message routing. Ids are unique per session meaning you can reuse the same id (e.g.,\\xa0`4`) across different sessions without conflict.\\n\\n`4`\\n\\nIn addition to requests,\\xa0notifications\\xa0travel from client to server or vice versa. In this case, the entity receiving and processing the message/notification (e.g task progress) is not expected to send a response. For example, when the session is initialized, the client sends a notification to complete the handshake, and the server responds with 202 `accepted`\\xa0without a follow-up message.\\n\\n`accepted`\\n\\nYou can review the full schema reference at \\xa0[https://modelcontextprotocol.io/specification/2025-06-18/schema](https://modelcontextprotocol.io/specification/2025-06-18/schema?ref=deep-kondah.com).\\n\\n### **MCP Tool**\\n\\nTo empower LLMs, we equip them with tools. Once the developer provides tool descriptions, the foundation model can be equipped to use the tools using in-context learning implementation; where specific instructions are encoded in the\\xa0prompt guiding the model to use function calls based on the task the LLM needs to solve. The parameters of those functions are exposed as JSON fields (using\\xa0JSON Schema). When the model decides a tool should be called, it emits a\\xa0structured JSON payload\\xa0matching the schema. The agent code processes the requests, executes the function call and inject the result of the invocation to the context served to the LLM to continue reasoning.\\n\\nA tool is essentially a function with metadata:\\n\\n`class Tool(BaseModel):\\n\"\"\"Internal tool registration info.\"\"\"\\nfn: Callable[..., Any] = Field(exclude=True)\\nname: str = Field(description=\"Name of the tool\")\\ntitle: str | None = Field(None, description=\"Human-readable title of the tool\")\\ndescription: str = Field(description=\"Description of what the tool does\")\\nparameters: dict[str, Any] = Field(description=\"JSON schema for tool parameters\")\\nfn_metadata: FuncMetadata = Field(\\ndescription=\"Metadata about the function including a pydantic model for tool arguments\"\\n)\\nis_async: bool = Field(description=\"Whether the tool is async\")\\ncontext_kwarg: str | None = Field(None, description=\"Name of the kwarg that should receive context\")\\nannotations: ToolAnnotations | None = Field(None, description=\"Optional annotations for the tool\")`\\n\\nTools can be registered declaratively:\\n\\n`@mcp.tool()\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two numbers\"\"\"\\nreturn a + b`\\n\\nOr programmatically:\\n\\n`class ServerModule:\\n...\\ndef add_tool(self, server: FastMCP, method: Callable, name: str) -> None:\\nserver.add_tool(method, name=name)\\n...\\nclass FastMCP(Generic[LifespanResultT]):\\n...\\ndef add_tool(\\nself,\\nfn: AnyFunction,\\nname: str | None = None,\\ntitle: str | None = None,\\ndescription: str | None = None,\\nannotations: ToolAnnotations | None = None,\\nstructured_output: bool | None = None,\\n) -> None:\\nself._tool_manager.add_tool(\\nfn,\\nname=name,\\ntitle=title,\\ndescription=description,\\nannotations=annotations,\\nstructured_output=structured_output,\\n)`\\n\\nWhen listing tools, the MCP client receives a response that looks as follows:\\n\\n`{\\n\"name\" : \"tool_name\",\\n\"description\" : \"tool_description.\",\\n\"inputSchema\" : {\\n\"properties\" : { },\\n\"title\" : \"tool_arguments\",\\n\"type\" : \"object\"\\n},\\n\"outputSchema\" : {\\n\"properties\" : {\\n\"result\" : {\\n\"additionalProperties\" : {\\n\"type\" : \"boolean\"\\n},\\n\"title\" : \"Result\",\\n\"type\" : \"object\"\\n}\\n},\\n\"required\" : [ \"result\" ],\\n\"title\" : \"\",\\n\"type\" : \"object\"\\n}\\n}`\\n\\nMCP provides both\\xa0input and output schemas\\xa0for validation. The Python SDK, for instance, supports validated function calls (as show below both \\xa0synchronous and asynchronous tools function are supported, however in order to avoid blocking the event loop one should consider wrapping blocking calls as async functions e.g using [anyio.to\\\\_thread.run\\\\_sync](https://gofastmcp.com/servers/tools?ref=deep-kondah.com)):\\n\\n `async def call_fn_with_arg_validation(\\nself,\\nfn: Callable[..., Any | Awaitable[Any]],\\nfn_is_async: bool,\\narguments_to_validate: dict[str, Any],\\narguments_to_pass_directly: dict[str, Any] | None,\\n) -> Any:\\n\"\"\"Call the given function with arguments validated and injected.\\nArguments are first attempted to be parsed from JSON, then validated against\\nthe argument model, before being passed to the function.\\n\"\"\"\\narguments_pre_parsed = self.pre_parse_json(arguments_to_validate)\\narguments_parsed_model = self.arg_model.model_validate(arguments_pre_parsed)\\narguments_parsed_dict = arguments_parsed_model.model_dump_one_level()\\narguments_parsed_dict |= arguments_to_pass_directly or {}\\nif fn_is_async:\\nreturn await fn(**arguments_parsed_dict)\\nelse:\\nreturn fn(**arguments_parsed_dict)`\\n\\nTools can also access\\xa0the MCPs request context as illustrated below:\\n\\n`@mcp.tool()\\nasync def my_tool(x: int, ctx: Context) -> str:\\n\"\"\"Tool that uses context capabilities.\"\"\"\\n# The context parameter can have any name as long as it\\'s type-annotated\\nreturn await process_with_context(x, ctx)`\\n\\nsource: [https://github.com/modelcontextprotocol/python-sdk](https://github.com/modelcontextprotocol/python-sdk?ref=deep-kondah.com)\\n\\n### **MCP Resources**\\n\\nAnother interface implemented by MCP servers is\\xa0Resources. It refers to any type of data the server wants to make available to clients for context enrichment, such as database entities or documentation. Each resource is identified by a unique URI that houses either textual or binary data.\\n\\n`class Resource(BaseModel, abc.ABC):\\n\"\"\"Base class for all resources.\"\"\"\\nmodel_config = ConfigDict(validate_default=True)\\nuri: Annotated[AnyUrl, UrlConstraints(host_required=False)] = Field(default=..., description=\"URI of the resource\")\\nname: str | None = Field(description=\"Name of the resource\", default=None)\\ntitle: str | None = Field(description=\"Human-readable title of the resource\", default=None)\\ndescription: str | None = Field(description=\"Description of the resource\", default=None)\\nmime_type: str = Field(\\ndefault=\"text/plain\",\\ndescription=\"MIME type of the resource content\",\\npattern=r\"^[a-zA-Z0-9]+/[a-zA-Z0-9\\\\-+.]+$\",\\n)`\\n\\nResources registration can be achieved using declarative API:\\n\\n`@mcp.resource(\"greeting://{name}\")\\ndef get_greeting(name: str) -> str:\\n\"\"\"Get a personalized greeting\"\"\"\\nreturn f\"Hello, {name}!\"`\\n\\nor programatic API:\\n\\n `def add_resource(self, resource: Resource) -> None:\\n\"\"\"Add a resource to the server.\\nArgs:\\nresource: A Resource instance to add\\n\"\"\"\\nself._resource_manager.add_resource(resource)`\\n\\nResources can be listed at runtime by submitting `ListResourcesRequest`:\\n\\n`ListResourcesRequest`\\n`class ListResourcesRequest(PaginatedRequest[Literal[\"resources/list\"]]):\\n\"\"\"Sent from the client to request a list of resources the server has.\"\"\"\\nmethod: Literal[\"resources/list\"]`\\n\\nNext, a specific resource can be read by issuing a `ReadResourceRequest`.\\n\\n`ReadResourceRequest`\\n `async def read_resource(self, uri: AnyUrl) -> types.ReadResourceResult:\\n\"\"\"Send a resources/read request.\"\"\"\\nreturn await self.send_request(\\ntypes.ClientRequest(\\ntypes.ReadResourceRequest(\\nmethod=\"resources/read\",\\nparams=types.ReadResourceRequestParams(uri=uri),\\n)\\n),\\ntypes.ReadResourceResult,\\n)`\\n\\nA MCP client can also send a `SubscribeRequest` to request `resources/updated` notifications from the server:\\n\\n`SubscribeRequest`\\n`resources/updated`\\n`class SubscribeRequest(Request[SubscribeRequestParams, Literal[\"resources/subscribe\"]]):\\n\"\"\"\\nSent from the client to request resources/updated notifications from the server\\nwhenever a particular resource changes.\\n\"\"\"\\nmethod: Literal[\"resources/subscribe\"]\\nparams: SubscribeRequestParams`\\n\\n### **MCP Prompts**\\n\\nPrompts are another interface served by the MCP server, standardizing the provisioning of reusable templates presented to users or LLMs designed for common interactions. Each prompt is represented using a name, description and optional arguments.\\n\\n`class Prompt(BaseModel):\\n\"\"\"A prompt template that can be rendered with parameters.\"\"\"\\nname: str = Field(description=\"Name of the prompt\")\\ntitle: str | None = Field(None, description=\"Human-readable title of the prompt\")\\ndescription: str | None = Field(None, description=\"Description of what the prompt does\")\\narguments: list[PromptArgument] | None = Field(None, description=\"Arguments that can be passed to the prompt\")\\nfn: Callable[..., PromptResult | Awaitable[PromptResult]] = Field(exclude=True)`\\n\\nPrompts can be registered using decorators or programmatically.\\n\\n `def add_prompt(self, prompt: Prompt) -> None:\\n\"\"\"Add a prompt to the server.\\nArgs:\\nprompt: A Prompt instance to add\\n\"\"\"\\nself._prompt_manager.add_prompt(prompt)`\\n`@mcp.prompt()\\ndef greet_user(name: str, style: str = \"friendly\") -> str:\\n\"\"\"Generate a greeting prompt\"\"\"\\nstyles = {\\n\"friendly\": \"Please write a warm, friendly greeting\",\\n\"formal\": \"Please write a formal, professional greeting\",\\n\"casual\": \"Please write a casual, relaxed greeting\",\\n}\\nreturn f\"{styles.get(style, styles[\\'friendly\\'])} for someone named {name}.\"`\\n\\nSimilar to resources, the MCP can list and fetch prompts by submitting `ListPromptsRequest` and `GetPromptRequest` respectively:\\n\\n`ListPromptsRequest`\\n`GetPromptRequest`\\n `async def list_prompts(self, cursor: str | None = None) -> types.ListPromptsResult:\\n\"\"\"Send a prompts/list request.\"\"\"\\nreturn await self.send_request(\\ntypes.ClientRequest(\\ntypes.ListPromptsRequest(\\nmethod=\"prompts/list\",\\nparams=types.PaginatedRequestParams(cursor=cursor) if cursor is not None else None,\\n)\\n),\\ntypes.ListPromptsResult,\\n)\\nasync def get_prompt(self, name: str, arguments: dict[str, str] | None = None) -> types.GetPromptResult:\\n\"\"\"Send a prompts/get request.\"\"\"\\nreturn await self.send_request(\\ntypes.ClientRequest(\\ntypes.GetPromptRequest(\\nmethod=\"prompts/get\",\\nparams=types.GetPromptRequestParams(name=name, arguments=arguments),\\n)\\n),\\ntypes.GetPromptResult,\\n)`\\n\\n### **MCP Roots**\\n\\nRoots provide the operational scope or context for MCP servers. They redirect servers to specific resources, represented with URIs.\\n\\n`class Root(BaseModel):\\n\"\"\"Represents a root directory or file that the server can operate on.\"\"\"\\nuri: FileUrl\\n\"\"\"\\nThe URI identifying the root. This *must* start with file:// for now.\\nThis restriction may be relaxed in future versions of the protocol to allow\\nother URI schemes.\\n\"\"\"\\nname: str | None = None\\n\"\"\"\\nAn optional name for the root. This can be used to provide a human-readable\\nidentifier for the root, which may be useful for display purposes or for\\nreferencing the root in other parts of the application.\\n\"\"\"\\nmeta: dict[str, Any] | None = Field(alias=\"_meta\", default=None)\\n\"\"\"\\nSee [MCP specification](https://github.com/modelcontextprotocol/modelcontextprotocol/blob/47339c03c143bb4ec01a26e721a1b8fe66634ebe/docs/specification/draft/basic/index.mdx#general-fields)\\nfor notes on _meta usage.\\n\"\"\"\\nmodel_config = ConfigDict(extra=\"allow\")`\\n\\n### **MCP Sampling**\\n\\nSampling enables MCP servers to request LLM completions by initiating structured inference requests to the MCP client (subject to approval by the user).\\n\\n`class SamplingMessage(BaseModel):\\n\"\"\"Describes a message issued to or received from an LLM API.\"\"\"\\nrole: Role\\ncontent: TextContent | ImageContent | AudioContent\\nmodel_config = ConfigDict(extra=\"allow\")`\\n\\n### **MCP Elicitation**\\n\\nElicitation was added recently. It enables MCP servers to request and gather additional information at runtime like tool parameters.\\n\\n`class ElicitRequest(Request[ElicitRequestParams, Literal[\"elicitation/create\"]]):\\n\"\"\"A request from the server to elicit information from the client.\"\"\"\\nmethod: Literal[\"elicitation/create\"]\\nparams: ElicitRequestParams`\\n`class ElicitRequestParams(RequestParams):\\n\"\"\"Parameters for elicitation requests.\"\"\"\\nmessage: str\\nrequestedSchema: ElicitRequestedSchema\\nmodel_config = ConfigDict(extra=\"allow\")`\\n\\n### **MCP Initialization**\\n\\nDuring the initialization phase, the client first issues a POST request containing an\\xa0`InitializeRequest`\\xa0(with its own capabilities and information). This is what the request looks like:\\n\\n`InitializeRequest`\\n`{\\n\"method\": \"initialize\",\\n\"params\": {\\n\"protocolVersion\": \"2025-06-18\",\\n\"capabilities\": {},\\n\"clientInfo\": {\\n\"name\": \"mcp\",\\n\"version\": \"0.1.0\"\\n}\\n},\\n\"jsonrpc\": \"2.0\",\\n\"id\": 0\\n}`\\n\\nThe server responds with an\\xa0`InitializeResult`\\xa0(with its capabilities and information):\\n\\n`InitializeResult`\\n`{\\n\"jsonrpc\" : \"2.0\",\\n\"id\" : 0,\\n\"result\" : {\\n\"protocolVersion\" : \"2025-06-18\",\\n\"capabilities\" : {\\n\"experimental\" : { },\\n\"prompts\" : {\\n\"listChanged\" : false\\n},\\n\"resources\" : {\\n\"subscribe\" : false,\\n\"listChanged\" : false\\n},\\n\"tools\" : {\\n\"listChanged\" : false\\n}\\n},\\n\"serverInfo\" : {\\n\"name\" : \"Falcon MCP Server\",\\n\"version\" : \"1.12.4\"\\n},\\n\"instructions\" : \"This server provides access to CrowdStrike Falcon capabilities.\"\\n}\\n}`\\n\\nThen the client sends an\\xa0`InitializedNotification`\\xa0to complete the session handshake:\\n\\n`InitializedNotification`\\n`{\"method\":\"notifications/initialized\",\"jsonrpc\":\"2.0\"}`\\n\\nThe server immendiatly responds with 202 Accepted. After the handshake, the session is ready, and interaction can begin e.g the client can issue requests like listing tools:\\n\\n`{\"method\":\"tools/list\",\"jsonrpc\":\"2.0\",\"id\":1}`\\n\\nThe code performing the above logic is shown below:\\n\\n `async def initialize(self) -> types.InitializeResult:\\nsampling = types.SamplingCapability() if self._sampling_callback is not _default_sampling_callback else None\\nelicitation = (\\ntypes.ElicitationCapability() if self._elicitation_callback is not _default_elicitation_callback else None\\n)\\nroots = (\\n# TODO: Should this be based on whether we\\n# _will_ send notifications, or only whether\\n# they\\'re supported?\\ntypes.RootsCapability(listChanged=True)\\nif self._list_roots_callback is not _default_list_roots_callback\\nelse None\\n)\\nresult = await self.send_request(\\ntypes.ClientRequest(\\ntypes.InitializeRequest(\\nmethod=\"initialize\",\\nparams=types.InitializeRequestParams(\\nprotocolVersion=types.LATEST_PROTOCOL_VERSION,\\ncapabilities=types.ClientCapabilities(\\nsampling=sampling,\\nelicitation=elicitation,\\nexperimental=None,\\nroots=roots,\\n),\\nclientInfo=self._client_info,\\n),\\n)\\n),\\ntypes.InitializeResult,\\n)\\nif result.protocolVersion not in SUPPORTED_PROTOCOL_VERSIONS:\\nraise RuntimeError(f\"Unsupported protocol version from the server: {result.protocolVersion}\")\\nawait self.send_notification(\\ntypes.ClientNotification(types.InitializedNotification(method=\"notifications/initialized\"))\\n)\\nreturn result`\\n\\nClientSession\\n\\n### **MCP Notifications**\\n\\nThere are different types of notifications, including *InitializedNotification*, sent from the client after initialization has finished and *ResourceUpdatedNotification*\\xa0 sent from the server to the client, informing it that a resource has changed and may need to be read again.\\n\\nThe complete list for both client and server is shown below:\\n\\n`class ClientNotification(\\nRootModel[CancelledNotification | ProgressNotification | InitializedNotification | RootsListChangedNotification]\\n):`\\n`class ServerNotification(\\nRootModel[\\nCancelledNotification\\n| ProgressNotification\\n| LoggingMessageNotification\\n| ResourceUpdatedNotification\\n| ResourceListChangedNotification\\n| ToolListChangedNotification\\n| PromptListChangedNotification\\n]\\n):\\npass`\\n\\n### **MCP Client and Server**\\n\\nMC Servers offer different capabilities including tools\\xa0(e.g., calling the CrowdStrike API to contain a host or obtain detection information), resources\\xa0(e.g., file or documentation), resource subscriptions\\xa0(e.g., receiving a notification when a database entry changes) and prompt templates(used to guide language model interactions). All tools are registered during server initialization and can be listed by the client (to serve the foundation model).\\n\\n`class ServerCapabilities(BaseModel):\\n\"\"\"Capabilities that a server may support.\"\"\"\\nexperimental: dict[str, dict[str, Any]] | None = None\\n\"\"\"Experimental, non-standard capabilities that the server supports.\"\"\"\\nlogging: LoggingCapability | None = None\\n\"\"\"Present if the server supports sending log messages to the client.\"\"\"\\nprompts: PromptsCapability | None = None\\n\"\"\"Present if the server offers any prompt templates.\"\"\"\\nresources: ResourcesCapability | None = None\\n\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 4: MCP specification collated into one file (v2025-03-26) ---\\nURL: https://gist.github.com/hesreallyhim/d974990b8c80cf6f32b88bfe39b76f9a\\n\\nSUMMARY:\\nThe Model Context Protocol (MCP) defines a rigorous lifecycle for client-server. connections that ensures proper capability negotiation and state management\\n\\n\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 5: Architecture overview ---\\nURL: https://modelcontextprotocol.io/docs/learn/architecture\\n\\nSUMMARY:\\n* **Data layer**: Defines the JSON-RPC based protocol for client-server communication, including lifecycle management, and core primitives, such as tools, resources, prompts and notifications. Notifications are sent as JSON-RPC 2.0 notification messages (without expecting a response) and enable MCP servers to provide real-time updates to connected clients. During initialization, the AI applications MCP client manager establishes connections to configured servers and stores their capabilities for later use. This request is fundamental to MCPs tool discovery mechanism  it allows clients to understand what tools are available on the server before attempting to use them. MCP supports real-time notifications that enable servers to inform clients about changes without being explicitly requested. This notification pattern extends beyond tools to other MCP primitives, enabling comprehensive real-time synchronization between clients and servers.\\n\\nFULL CONTENT:\\n[Model Context Protocol home page](/)\\n\\n[Documentation](/docs/getting-started/intro)[Specification](/specification/2025-06-18)[Community](/community/communication)[About MCP](/about)\\n\\n##### Get started\\n\\n* [What is MCP?](/docs/getting-started/intro)\\n\\n##### About MCP\\n\\n* [Architecture](/docs/learn/architecture)\\n* [Servers](/docs/learn/server-concepts)\\n* [Clients](/docs/learn/client-concepts)\\n* [Versioning](/specification/versioning)\\n\\n##### Develop with MCP\\n\\n* [Connect to local MCP servers](/docs/develop/connect-local-servers)\\n* [Connect to remote MCP Servers](/docs/develop/connect-remote-servers)\\n* [Build an MCP server](/docs/develop/build-server)\\n* [Build an MCP client](/docs/develop/build-client)\\n* [SDKs](/docs/sdk)\\n\\n##### Developer tools\\n\\n* [MCP Inspector](/docs/tools/inspector)\\n\\n* [Scope](#scope)\\n* [Concepts of MCP](#concepts-of-mcp)\\n* [Participants](#participants)\\n* [Layers](#layers)\\n* [Data layer](#data-layer)\\n* [Transport layer](#transport-layer)\\n* [Data Layer Protocol](#data-layer-protocol)\\n* [Lifecycle management](#lifecycle-management)\\n* [Primitives](#primitives)\\n* [Notifications](#notifications)\\n* [Example](#example)\\n* [Data Layer](#data-layer-2)\\n* [Understanding the Initialization Exchange](#understanding-the-initialization-exchange)\\n* [How This Works in AI Applications](#how-this-works-in-ai-applications)\\n* [Understanding the Tool Discovery Request](#understanding-the-tool-discovery-request)\\n* [Understanding the Tool Discovery Response](#understanding-the-tool-discovery-response)\\n* [How This Works in AI Applications](#how-this-works-in-ai-applications-2)\\n* [Understanding the Tool Execution Request](#understanding-the-tool-execution-request)\\n* [Key Elements of Tool Execution](#key-elements-of-tool-execution)\\n* [Understanding the Tool Execution Response](#understanding-the-tool-execution-response)\\n* [How This Works in AI Applications](#how-this-works-in-ai-applications-3)\\n* [Understanding Tool List Change Notifications](#understanding-tool-list-change-notifications)\\n* [Key Features of MCP Notifications](#key-features-of-mcp-notifications)\\n* [Client Response to Notifications](#client-response-to-notifications)\\n* [Why Notifications Matter](#why-notifications-matter)\\n* [How This Works in AI Applications](#how-this-works-in-ai-applications-4)\\n\\nAbout MCP\\n\\n# Architecture overview\\n\\nThis overview of the Model Context Protocol (MCP) discusses its [scope](#scope) and [core concepts](#concepts-of-mcp), and provides an [example](#example) demonstrating each core concept. Because MCP SDKs abstract away many concerns, most developers will likely find the [data layer protocol](#data-layer-protocol) section to be the most useful. It discusses how MCP servers can provide context to an AI application. For specific implementation details, please refer to the documentation for your [language-specific SDK](/docs/sdk).\\n\\n## [\\u200b](#scope) Scope\\n\\nThe Model Context Protocol includes the following projects:\\n\\n* [MCP Specification](https://modelcontextprotocol.io/specification/latest): A specification of MCP that outlines the implementation requirements for clients and servers.\\n* [MCP SDKs](/docs/sdk): SDKs for different programming languages that implement MCP.\\n* **MCP Development Tools**: Tools for developing MCP servers and clients, including the [MCP Inspector](https://github.com/modelcontextprotocol/inspector)\\n* [MCP Reference Server Implementations](https://github.com/modelcontextprotocol/servers): Reference implementations of MCP servers.\\n\\nMCP focuses solely on the protocol for context exchangeit does not dictate how AI applications use LLMs or manage the provided context.\\n\\n## [\\u200b](#concepts-of-mcp) Concepts of MCP\\n\\n### [\\u200b](#participants) Participants\\n\\nMCP follows a client-server architecture where an MCP host  an AI application like [Claude Code](https://www.anthropic.com/claude-code) or [Claude Desktop](https://www.claude.ai/download)  establishes connections to one or more MCP servers. The MCP host accomplishes this by creating one MCP client for each MCP server. Each MCP client maintains a dedicated one-to-one connection with its corresponding MCP server. The key participants in the MCP architecture are:\\n\\n* **MCP Host**: The AI application that coordinates and manages one or multiple MCP clients\\n* **MCP Client**: A component that maintains a connection to an MCP server and obtains context from an MCP server for the MCP host to use\\n* **MCP Server**: A program that provides context to MCP clients\\n\\n**For example**: Visual Studio Code acts as an MCP host. When Visual Studio Code establishes a connection to an MCP server, such as the [Sentry MCP server](https://docs.sentry.io/product/sentry-mcp/), the Visual Studio Code runtime instantiates an MCP client object that maintains the connection to the Sentry MCP server. When Visual Studio Code subsequently connects to another MCP server, such as the [local filesystem server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem), the Visual Studio Code runtime instantiates an additional MCP client object to maintain this connection, hence maintaining a one-to-one relationship of MCP clients to MCP servers. Note that **MCP server** refers to the program that serves context data, regardless of where it runs. MCP servers can execute locally or remotely. For example, when Claude Desktop launches the [filesystem server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem), the server runs locally on the same machine because it uses the STDIO transport. This is commonly referred to as a local MCP server. The official [Sentry MCP server](https://docs.sentry.io/product/sentry-mcp/) runs on the Sentry platform, and uses the Streamable HTTP transport. This is commonly referred to as a remote MCP server.\\n\\n### [\\u200b](#layers) Layers\\n\\nMCP consists of two layers:\\n\\n* **Data layer**: Defines the JSON-RPC based protocol for client-server communication, including lifecycle management, and core primitives, such as tools, resources, prompts and notifications.\\n* **Transport layer**: Defines the communication mechanisms and channels that enable data exchange between clients and servers, including transport-specific connection establishment, message framing, and authorization.\\n\\nConceptually the data layer is the inner layer, while the transport layer is the outer layer.\\n\\n#### [\\u200b](#data-layer) Data layer\\n\\nThe data layer implements a [JSON-RPC 2.0](https://www.jsonrpc.org/) based exchange protocol that defines the message structure and semantics. This layer includes:\\n\\n* **Lifecycle management**: Handles connection initialization, capability negotiation, and connection termination between clients and servers\\n* **Server features**: Enables servers to provide core functionality including tools for AI actions, resources for context data, and prompts for interaction templates from and to the client\\n* **Client features**: Enables servers to ask the client to sample from the host LLM, elicit input from the user, and log messages to the client\\n* **Utility features**: Supports additional capabilities like notifications for real-time updates and progress tracking for long-running operations\\n\\n#### [\\u200b](#transport-layer) Transport layer\\n\\nThe transport layer manages communication channels and authentication between clients and servers. It handles connection establishment, message framing, and secure communication between MCP participants. MCP supports two transport mechanisms:\\n\\n* **Stdio transport**: Uses standard input/output streams for direct process communication between local processes on the same machine, providing optimal performance with no network overhead.\\n* **Streamable HTTP transport**: Uses HTTP POST for client-to-server messages with optional Server-Sent Events for streaming capabilities. This transport enables remote server communication and supports standard HTTP authentication methods including bearer tokens, API keys, and custom headers. MCP recommends using OAuth to obtain authentication tokens.\\n\\nThe transport layer abstracts communication details from the protocol layer, enabling the same JSON-RPC 2.0 message format across all transport mechanisms.\\n\\n### [\\u200b](#data-layer-protocol) Data Layer Protocol\\n\\nA core part of MCP is defining the schema and semantics between MCP clients and MCP servers. Developers will likely find the data layer  in particular, the set of [primitives](#primitives)  to be the most interesting part of MCP. It is the part of MCP that defines the ways developers can share context from MCP servers to MCP clients. MCP uses [JSON-RPC 2.0](https://www.jsonrpc.org/) as its underlying RPC protocol. Client and servers send requests to each other and respond accordingly. Notifications can be used when no response is required.\\n\\n#### [\\u200b](#lifecycle-management) Lifecycle management\\n\\nMCP is a that requires lifecycle management. The purpose of lifecycle management is to negotiate the that both client and server support. Detailed information can be found in the [specification](/specification/2025-06-18/basic/lifecycle), and the [example](#example) showcases the initialization sequence.\\n\\n#### [\\u200b](#primitives) Primitives\\n\\nMCP primitives are the most important concept within MCP. They define what clients and servers can offer each other. These primitives specify the types of contextual information that can be shared with AI applications and the range of actions that can be performed. MCP defines three core primitives that *servers* can expose:\\n\\n* **Tools**: Executable functions that AI applications can invoke to perform actions (e.g., file operations, API calls, database queries)\\n* **Resources**: Data sources that provide contextual information to AI applications (e.g., file contents, database records, API responses)\\n* **Prompts**: Reusable templates that help structure interactions with language models (e.g., system prompts, few-shot examples)\\n\\nEach primitive type has associated methods for discovery (`*/list`), retrieval (`*/get`), and in some cases, execution (`tools/call`). MCP clients will use the `*/list` methods to discover available primitives. For example, a client can first list all available tools (`tools/list`) and then execute them. This design allows listings to be dynamic. As a concrete example, consider an MCP server that provides context about a database. It can expose tools for querying the database, a resource that contains the schema of the database, and a prompt that includes few-shot examples for interacting with the tools. For more details about server primitives see [server concepts](./server-concepts). MCP also defines primitives that *clients* can expose. These primitives allow MCP server authors to build richer interactions.\\n\\n* **Sampling**: Allows servers to request language model completions from the clients AI application. This is useful when servers authors want access to a language model, but want to stay model independent and not include a language model SDK in their MCP server. They can use the `sampling/complete` method to request a language model completion from the clients AI application.\\n* **Elicitation**: Allows servers to request additional information from users. This is useful when servers authors want to get more information from the user, or ask for confirmation of an action. They can use the `elicitation/request` method to request additional information from the user.\\n* **Logging**: Enables servers to send log messages to clients for debugging and monitoring purposes.\\n\\nFor more details about client primitives see [client concepts](./client-concepts).\\n\\n#### [\\u200b](#notifications) Notifications\\n\\nThe protocol supports real-time notifications to enable dynamic updates between servers and clients. For example, when a servers available tools changesuch as when new functionality becomes available or existing tools are modifiedthe server can send tool update notifications to inform connected clients about these changes. Notifications are sent as JSON-RPC 2.0 notification messages (without expecting a response) and enable MCP servers to provide real-time updates to connected clients.\\n\\n## [\\u200b](#example) Example\\n\\n### [\\u200b](#data-layer-2) Data Layer\\n\\nThis section provides a step-by-step walkthrough of an MCP client-server interaction, focusing on the data layer protocol. Well demonstrate the lifecycle sequence, tool operations, and notifications using JSON-RPC 2.0 messages.\\n\\n1\\n\\nInitialization (Lifecycle Management)\\n\\nMCP begins with lifecycle management through a capability negotiation handshake. As described in the [lifecycle management](#lifecycle-management) section, the client sends an `initialize` request to establish the connection and negotiate supported features.\\n\\nCopy\\n\\n```\\n{{ \"jsonrpc\": \"2.0\",  \"jsonrpc\": \"2.0\", \"id\": 1,  \"id\": 1, \"method\": \"initialize\",  \"method\": \"initialize\", \"params\": { \"params\": { \"protocolVersion\": \"2025-06-18\",  \"protocolVersion\": \"2025-06-18\", \"capabilities\": { \"capabilities\": { \"elicitation\": {}  \"elicitation\": {} }, }, \"clientInfo\": { \"clientInfo\": { \"name\": \"example-client\",  \"name\": \"example-client\", \"version\": \"1.0.0\"  \"version\": \"1.0.0\" } } } }}}\\n```\\n\\n#### [\\u200b](#understanding-the-initialization-exchange) Understanding the Initialization Exchange\\n\\nThe initialization process is a key part of MCPs lifecycle management and serves several critical purposes:\\n\\n1. **Protocol Version Negotiation**: The `protocolVersion` field (e.g., 2025-06-18) ensures both client and server are using compatible protocol versions. This prevents communication errors that could occur when different versions attempt to interact. If a mutually compatible version is not negotiated, the connection should be terminated.\\n2. **Capability Discovery**: The `capabilities` object allows each party to declare what features they support, including which [primitives](#primitives) they can handle (tools, resources, prompts) and whether they support features like [notifications](#notifications). This enables efficient communication by avoiding unsupported operations.\\n3. **Identity Exchange**: The `clientInfo` and `serverInfo` objects provide identification and versioning information for debugging and compatibility purposes.\\n\\nIn this example, the capability negotiation demonstrates how MCP primitives are declared:**Client Capabilities**:\\n\\n* `\"elicitation\": {}` - The client declares it can work with user interaction requests (can receive `elicitation/create` method calls)\\n\\n**Server Capabilities**:\\n\\n* `\"tools\": {\"listChanged\": true}` - The server supports the tools primitive AND can send `tools/list_changed` notifications when its tool list changes\\n* `\"resources\": {}` - The server also supports the resources primitive (can handle `resources/list` and `resources/read` methods)\\n\\nAfter successful initialization, the client sends a notification to indicate its ready:\\n\\nNotification\\n\\nCopy\\n\\n```\\n{{ \"jsonrpc\": \"2.0\",  \"jsonrpc\": \"2.0\", \"method\": \"notifications/initialized\"  \"method\": \"notifications/initialized\"}}\\n```\\n\\n#### [\\u200b](#how-this-works-in-ai-applications) How This Works in AI Applications\\n\\nDuring initialization, the AI applications MCP client manager establishes connections to configured servers and stores their capabilities for later use. The application uses this information to determine which servers can provide specific types of functionality (tools, resources, prompts) and whether they support real-time updates.\\n\\nPseudo-code for AI application initialization\\n\\nCopy\\n\\n```\\n# Pseudo Code # Pseudo Codeasync with stdio_client(server_config) as (read, write): async  with stdio_client(server_config) as (read, write): async with ClientSession(read, write) as session:  async  with ClientSession(read, write) as session: init_response = await session.initialize()  init_response =  await session.initialize() if init_response.capabilities.tools:  if init_response.capabilities.tools: app.register_mcp_server(session, supports_tools=True) app.register_mcp_server(session, supports_tools = True) app.set_server_ready(session) app.set_server_ready(session)\\n```\\n\\n2\\n\\nTool Discovery (Primitives)\\n\\nNow that the connection is established, the client can discover available tools by sending a `tools/list` request. This request is fundamental to MCPs tool discovery mechanism  it allows clients to understand what tools are available on the server before attempting to use them.\\n\\nCopy\\n\\n```\\n{{ \"jsonrpc\": \"2.0\",  \"jsonrpc\": \"2.0\", \"id\": 2,  \"id\": 2, \"method\": \"tools/list\"  \"method\": \"tools/list\"}}\\n```\\n\\n#### [\\u200b](#understanding-the-tool-discovery-request) Understanding the Tool Discovery Request\\n\\nThe `tools/list` request is simple, containing no parameters.\\n\\n#### [\\u200b](#understanding-the-tool-discovery-response) Understanding the Tool Discovery Response\\n\\nThe response contains a `tools` array that provides comprehensive metadata about each available tool. This array-based structure allows servers to expose multiple tools simultaneously while maintaining clear boundaries between different functionalities.Each tool object in the response includes several key fields:\\n\\n* **`name`**: A unique identifier for the tool within the servers namespace. This serves as the primary key for tool execution and should follow a clear naming pattern (e.g., `calculator_arithmetic` rather than just `calculate`)\\n* **`title`**: A human-readable display name for the tool that clients can show to users\\n* **`description`**: Detailed explanation of what the tool does and when to use it\\n* **`inputSchema`**: A JSON Schema that defines the expected input parameters, enabling type validation and providing clear documentation about required and optional parameters\\n\\n#### [\\u200b](#how-this-works-in-ai-applications-2) How This Works in AI Applications\\n\\nThe AI application fetches available tools from all connected MCP servers and combines them into a unified tool registry that the language model can access. This allows the LLM to understand what actions it can perform and automatically generates the appropriate tool calls during conversations.\\n\\nPseudo-code for AI application tool discovery\\n\\nCopy\\n\\n```\\n# Pseudo-code using MCP Python SDK patterns# Pseudo-code using MCP Python SDK patternsavailable_tools = [] available_tools = []for session in app.mcp_server_sessions(): for  session in app.mcp_server_sessions(): tools_response = await session.list_tools()  tools_response =  await session.list_tools() available_tools.extend(tools_response.tools) available_tools.extend(tools_response.tools)conversation.register_available_tools(available_tools)conversation.register_available_tools(available_tools)\\n```\\n\\n3\\n\\nTool Execution (Primitives)\\n\\nThe client can now execute a tool using the `tools/call` method. This demonstrates how MCP primitives are used in practice: after discovering available tools, the client can invoke them with appropriate arguments.\\n\\n#### [\\u200b](#understanding-the-tool-execution-request) Understanding the Tool Execution Request\\n\\nThe `tools/call` request follows a structured format that ensures type safety and clear communication between client and server. Note that were using the proper tool name from the discovery response (`weather_current`) rather than a simplified name:\\n\\nCopy\\n\\n```\\n{{ \"jsonrpc\": \"2.0\",  \"jsonrpc\": \"2.0\", \"id\": 3,  \"id\": 3, \"method\": \"tools/call\",  \"method\": \"tools/call\", \"params\": { \"params\": { \"name\": \"weather_current\",  \"name\": \"weather_current\", \"arguments\": { \"arguments\": { \"location\": \"San Francisco\",  \"location\": \"San Francisco\", \"units\": \"imperial\"  \"units\": \"imperial\" } } } }}}\\n```\\n\\n#### [\\u200b](#key-elements-of-tool-execution) Key Elements of Tool Execution\\n\\nThe request structure includes several important components:\\n\\n1. **`name`**: Must match exactly the tool name from the discovery response (`weather_current`). This ensures the server can correctly identify which tool to execute.\\n2. **`arguments`**: Contains the input parameters as defined by the tools `inputSchema`. In this example:\\n   * `location`: San Francisco (required parameter)\\n   * `units`: imperial (optional parameter, defaults to metric if not specified)\\n3. **JSON-RPC Structure**: Uses standard JSON-RPC 2.0 format with unique `id` for request-response correlation.\\n\\n#### [\\u200b](#understanding-the-tool-execution-response) Understanding the Tool Execution Response\\n\\nThe response demonstrates MCPs flexible content system:\\n\\n1. **`content` Array**: Tool responses return an array of content objects, allowing for rich, multi-format responses (text, images, resources, etc.)\\n2. **Content Types**: Each content object has a `type` field. In this example, `\"type\": \"text\"` indicates plain text content, but MCP supports various content types for different use cases.\\n3. **Structured Output**: The response provides actionable information that the AI application can use as context for language model interactions.\\n\\nThis execution pattern allows AI applications to dynamically invoke server functionality and receive structured responses that can be integrated into conversations with language models.\\n\\n#### [\\u200b](#how-this-works-in-ai-applications-3) How This Works in AI Applications\\n\\nWhen the language model decides to use a tool during a conversation, the AI application intercepts the tool call, routes it to the appropriate MCP server, executes it, and returns the results back to the LLM as part of the conversation flow. This enables the LLM to access real-time data and perform actions in the external world.\\n\\nCopy\\n\\n```\\n# Pseudo-code for AI application tool execution# Pseudo-code for AI application tool executionasync def handle_tool_call(conversation, tool_name, arguments): async  def  handle_tool_call(conversation, tool_name, arguments): session = app.find_mcp_session_for_tool(tool_name)  session = app.find_mcp_session_for_tool(tool_name) result = await session.call_tool(tool_name, arguments)  result =  await session.call_tool(tool_name, arguments) conversation.add_tool_result(result.content) conversation.add_tool_result(result.content)\\n```\\n\\n4\\n\\nReal-time Updates (Notifications)\\n\\nMCP supports real-time notifications that enable servers to inform clients about changes without being explicitly requested. This demonstrates the notification system, a key feature that keeps MCP connections synchronized and responsive.\\n\\n#### [\\u200b](#understanding-tool-list-change-notifications) Understanding Tool List Change Notifications\\n\\nWhen the servers available tools changesuch as when new functionality becomes available, existing tools are modified, or tools become temporarily unavailablethe server can proactively notify connected clients:\\n\\nCopy\\n\\n```\\n{{ \"jsonrpc\": \"2.0\",  \"jsonrpc\": \"2.0\", \"method\": \"notifications/tools/list_changed\"  \"method\": \"notifications/tools/list_changed\"}}\\n```\\n\\n#### [\\u200b](#key-features-of-mcp-notifications) Key Features of MCP Notifications\\n\\n1. **No Response Required**: Notice theres no `id` field in the notification. This follows JSON-RPC 2.0 notification semantics where no response is expected or sent.\\n2. **Capability-Based**: This notification is only sent by servers that declared `\"listChanged\": true` in their tools capability during initialization (as shown in Step 1).\\n3. **Event-Driven**: The server decides when to send notifications based on internal state changes, making MCP connections dynamic and responsive.\\n\\n#### [\\u200b](#client-response-to-notifications) Client Response to Notifications\\n\\nUpon receiving this notification, the client typically reacts by requesting the updated tool list. This creates a refresh cycle that keeps the clients understanding of available tools current:\\n\\nRequest\\n\\nCopy\\n\\n```\\n{{ \"jsonrpc\": \"2.0\",  \"jsonrpc\": \"2.0\", \"id\": 4,  \"id\": 4, \"method\": \"tools/list\"  \"method\": \"tools/list\"}}\\n```\\n\\n#### [\\u200b](#why-notifications-matter) Why Notifications Matter\\n\\nThis notification system is crucial for several reasons:\\n\\n1. **Dynamic Environments**: Tools may come and go based on server state, external dependencies, or user permissions\\n2. **Efficiency**: Clients dont need to poll for changes; theyre notified when updates occur\\n3. **Consistency**: Ensures clients always have accurate information about available server capabilities\\n4. **Real-time Collaboration**: Enables responsive AI applications that can adapt to changing contexts\\n\\nThis notification pattern extends beyond tools to other MCP primitives, enabling comprehensive real-time synchronization between clients and servers.\\n\\n#### [\\u200b](#how-this-works-in-ai-applications-4) How This Works in AI Applications\\n\\nWhen the AI application receives a notification about changed tools, it immediately refreshes its tool registry and updates the LLMs available capabilities. This ensures that ongoing conversations always have access to the most current set of tools, and the LLM can dynamically adapt to new functionality as it becomes available.\\n\\nCopy\\n\\n```\\n# Pseudo-code for AI application notification handling# Pseudo-code for AI application notification handlingasync def handle_tools_changed_notification(session): async  def  handle_tools_changed_notification(session): tools_response = await session.list_tools()  tools_response =  await session.list_tools() app.update_available_tools(session, tools_response.tools) app.update_available_tools(session, tools_response.tools) if app.conversation.is_active():  if app.conversation.is_active(): app.conversation.notify_llm_of_new_capabilities() app.conversation.notify_llm_of_new_capabilities()\\n```\\n\\nWas this page helpful?\\n\\n[What is MCP?](/docs/getting-started/intro)[Servers](/docs/learn/server-concepts)\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 6: Tsadoq/a2a-mcp-tutorial: A tutorial on how to use Model ... - GitHub ---\\nURL: https://github.com/Tsadoq/a2a-mcp-tutorial\\n\\nSUMMARY:\\nimport asyncio from typing import List Any from dotenv import load_dotenv find_dotenv from google adk import Agent from google adk tools import google_search from a2a_servers agent_servers utils import generate_agent_task_manager generate_agent_card from a2a_servers agents adk_agent import ADKAgent from a2a_servers common agent_task_manager import AgentTaskManager from a2a_servers common server server import A2AServer from a2a_servers common types import AgentCard AgentCapabilities AgentSkill from adk_agents_testing mcp_tools mcp_tool_search import return_sse_mcp_tools_search load_dotenv find_dotenv async def run_agent AGENT_NAME = \"google_search_agent\" AGENT_DESCRIPTION =\"An agent that handles search queries and can read pages online.\" HOST =\"0.0.0.0\" PORT = 11000 AGENT_URL =f\"http://{HOST}:{PORT}\"{HOST}{HOST}{PORT}{PORT} AGENT_VERSION =\"1.0.0\" MODEL =\\'gemini-2.5-pro-preview-03-25\\' AGENT_SKILLS = AgentSkill id = \"GOOGLE_SEARCH\" name = \"google_search\" description =\"Handles search queries and can read pages online.\" AGENT_CARD = generate_agent_card agent_name = AGENT_NAME agent_description = AGENT_DESCRIPTION agent_url = AGENT_URL agent_version = AGENT_VERSION can_stream = False can_push_notifications = False can_state_transition_history = True default_input_modes = \"text\" default_output_modes = \"text\" skills = AGENT_SKILLS gsearch_tools g_search_exit_stack = await return_sse_mcp_tools_search google_search_agent = ADKAgent model = MODEL name = \"google_search_agent\" description =\"Handles search queries and can read pages online.\" tools = gsearch_tools instructions =\"You are an expert googler.\\n\\nFULL CONTENT:\\n[Skip to content](#start-of-content)   \\n\\n\\n\\n## Navigation Menu\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FTsadoq%2Fa2a-mcp-tutorial) \\n\\nAppearance settings\\n\\n# Search code, repositories, users, issues, pull requests...\\n\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FTsadoq%2Fa2a-mcp-tutorial)\\n\\n [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=Tsadoq%2Fa2a-mcp-tutorial) \\n\\nAppearance settings\\n\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n\\n{{ message }}\\n\\n[Tsadoq](/Tsadoq)   /  **[a2a-mcp-tutorial](/Tsadoq/a2a-mcp-tutorial)**  Public\\n\\n* [Notifications](/login?return_to=%2FTsadoq%2Fa2a-mcp-tutorial)  You must be signed in to change notification settings\\n* [Fork 23](/login?return_to=%2FTsadoq%2Fa2a-mcp-tutorial)\\n* [Star  96](/login?return_to=%2FTsadoq%2Fa2a-mcp-tutorial)\\n\\nA tutorial on how to use Model Context Protocol by Anthropic and Agent2Agent Protocol by Google\\n\\n[96 stars](/Tsadoq/a2a-mcp-tutorial/stargazers)   [23 forks](/Tsadoq/a2a-mcp-tutorial/forks)   [Branches](/Tsadoq/a2a-mcp-tutorial/branches)   [Tags](/Tsadoq/a2a-mcp-tutorial/tags)   [Activity](/Tsadoq/a2a-mcp-tutorial/activity)\\n\\n[Star](/login?return_to=%2FTsadoq%2Fa2a-mcp-tutorial)\\n\\n[Notifications](/login?return_to=%2FTsadoq%2Fa2a-mcp-tutorial)  You must be signed in to change notification settings\\n\\n# Tsadoq/a2a-mcp-tutorial\\n\\n[Branches](/Tsadoq/a2a-mcp-tutorial/branches)[Tags](/Tsadoq/a2a-mcp-tutorial/tags)\\n\\nOpen more actions menu\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| Latest commit   History[6 Commits](/Tsadoq/a2a-mcp-tutorial/commits/main/) |\\n| [a2a\\\\_servers](/Tsadoq/a2a-mcp-tutorial/tree/main/a2a_servers \"a2a_servers\") | [a2a\\\\_servers](/Tsadoq/a2a-mcp-tutorial/tree/main/a2a_servers \"a2a_servers\") |  |  |\\n| [adk\\\\_agents\\\\_testing](/Tsadoq/a2a-mcp-tutorial/tree/main/adk_agents_testing \"adk_agents_testing\") | [adk\\\\_agents\\\\_testing](/Tsadoq/a2a-mcp-tutorial/tree/main/adk_agents_testing \"adk_agents_testing\") |  |  |\\n| [mcp\\\\_server](/Tsadoq/a2a-mcp-tutorial/tree/main/mcp_server \"mcp_server\") | [mcp\\\\_server](/Tsadoq/a2a-mcp-tutorial/tree/main/mcp_server \"mcp_server\") |  |  |\\n| [services](/Tsadoq/a2a-mcp-tutorial/tree/main/services \"services\") | [services](/Tsadoq/a2a-mcp-tutorial/tree/main/services \"services\") |  |  |\\n| [.gitignore](/Tsadoq/a2a-mcp-tutorial/blob/main/.gitignore \".gitignore\") | [.gitignore](/Tsadoq/a2a-mcp-tutorial/blob/main/.gitignore \".gitignore\") |  |  |\\n| [README.md](/Tsadoq/a2a-mcp-tutorial/blob/main/README.md \"README.md\") | [README.md](/Tsadoq/a2a-mcp-tutorial/blob/main/README.md \"README.md\") |  |  |\\n| [pyproject.toml](/Tsadoq/a2a-mcp-tutorial/blob/main/pyproject.toml \"pyproject.toml\") | [pyproject.toml](/Tsadoq/a2a-mcp-tutorial/blob/main/pyproject.toml \"pyproject.toml\") |  |  |\\n| [uv.lock](/Tsadoq/a2a-mcp-tutorial/blob/main/uv.lock \"uv.lock\") | [uv.lock](/Tsadoq/a2a-mcp-tutorial/blob/main/uv.lock \"uv.lock\") |  |  |\\n|  |\\n\\n## Repository files navigation\\n\\n# Agent2Agent and MCP: An End-to-End Tutorial for a complete Agentic Pipeline\\n\\n## Introduction\\n\\nIn the fast-moving world of agentic AI, two open protocols quietly solve the headaches that used to keep multi-agent projects from ever leaving the lab.\\n\\nA few months ago, Anthropic introduced [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol): A reliable access to the data and tools an agent needs once the conversation begins. Anthropic describes MCP as a USB-C port for language modelsa single, well-defined connector that lets you plug the same model into GitHub, a Postgres database, or a custom knowledge base without rewriting the integration each time. By standardizing the way hosts, clients, and servers exchange \"Tools,\" \"resources,\" and \"prompts,\" MCP turns context into something the model can count on rather than something developers keep stitching together ad hoc.  \\n\\nAgent2Agent (A2A), a new protocol by Google, tackles another obstacle: getting autonomous agentsoften built on different frameworks and hosted in different placesto understand one another. Instead of brittle, one-off bridges, A2A gives every agent a tiny \"agent card\" that advertises its skills and an HTTP interface that lets other agents negotiate tasks, stream intermediate results, and hand over artifacts. Google started the project to give agents a common language regardless of vendor, and the open-source spec already shows how discovery, task life-cycle updates, and secure push notifications can work out of the box. \\n\\nWith A2A handling how agents talk to one another and MCP handling how they tap into the outside world, you end up with small, focused agents who can coordinate fluently and still see the bigger picturean architecture that feels less like a collection of scripts and more like a cooperative workforce.\\n\\n## The Structure of this Tutorial\\n\\nThis tutorial will build a complete agentic pipeline using Agent2Agent and MCP. First, we will create and test a couple of simple MCP servers. Then, we will create a simple agent that uses MCP to get information. Finally, we will have a whole crew of agents that uses Agent2Agent to coordinate with each other while using MCP to get information.\\n\\nFor the sake of simplicity, we will use elementary agents that have access to single MCPs and MCPs that perform easy operations like fetching data from an API or searching the web.\\n\\nWe imagine we want to create a team of agents able to make simple reports about American Companies; in particular, we want to be able to ask questions such as \"What is the price of the stocks of the top 10 companies in the S&P 500?\" or \"What are the top 5 producers of lumber in the US\"?\\n\\n## Note on the Code\\n\\nThe code for this tutorial is available on [GitHub](https://github.com/Tsadoq/a2a-mcp-tutorial). You should clone the repository, run the code locally, play around with it, and even modify it. This tutorial has been created by starting from two sources:\\n\\n* [Agent2Agent Tutorial](https://github.com/google/A2A)\\n* [MCP Tutorial](https://modelcontextprotocol.io/quickstart/server)\\n\\nWhile the MCP documentation was terrific, the Google Agent2Agent repository had multiple issues and was not working as expected. As a consequence, I heavily modified the code provided.\\n\\n### How to run it\\n\\n[uv by Astral](https://docs.astral.sh/uv/) was used as a Python package and project manager. You can clone the repo, run `uv sync`, and then run whatever you need.\\n\\n# MCP Servers\\n\\nGiven our objective, we first define two services:\\n\\n* A crawler able to search on Google and read web pages\\n* A stock retriever, able to get the price of a stock at a particular time and other helpful info\\n\\n## The Stock Retriever Service\\n\\nWe define a simple stock retriever service using FinHub APIs. The retriever will return a stock\\'s current price, min, max opening, and closing price (IMPORTANT: if you use the free version of the APIs, only the US market can be queried) with one endpoint and the stock symbol with the other.\\n\\n```\\nclass FinHubService def __init__ self \"\"\" Initializes the finhubservice.  \"\"\" self client = finnhub Client api_key = os getenv \"FINNHUB_API_KEY\" def get_symbol_from_query self query str -> Dict str Any \"\"\" Given a query (e.g. name of a company) returns a dictionary with info. Use only if you have no idea about the symbol. :param query: name of company :return: dictionary with the response to the query  \"\"\" return self client symbol_lookup query = query def get_price_of_stock self symbol str -> Dict str Any \"\"\" Given the symbol of a certain strock, returns the live info about it. :param symbol: The symbol of a stock, e.g. AAPL :return: a dictionary containing the current_price, change, %change, day high, low, opening and previous closing price  \"\"\" resp = self client quote symbol return \\'current_price\\' resp \\'c\\' \\'change\\' resp \\'d\\' \\'percentage_change\\' resp \\'dp\\' \\'day_high\\' resp \\'h\\' \\'day_low\\' resp \\'l\\' \\'day_open_price\\' resp \\'o\\' \\'previous_close_price\\' resp \\'pc\\'\\n```\\n\\nIf we run our code with\\n\\n```\\nservice = FinHubService print service get_price_of_stock \"AAPL\"\\n```\\n\\nWe get something like:\\n\\n```\\n\\'current_price\\': 199.74, \\'change\\': 6.58, \\'percentage_change\\': 3.4065, \\'day_high\\': 201.59, \\'day_low\\': 195.97, \\'day_open_price\\': 196.12, \\'previous_close_price\\': 193.16\\n```\\n\\n## The Crawler Service\\n\\nNow that we have our Retriever, we want a very simple crawler to search on Google for information and read the web pages returned as results.\\n\\n```\\nclass SerperDevService def __init__ self self __api_key__ = os getenv \"SERPER_DEV_API_KEY\" self search_url =\"https://google.serper.dev/search\" self scraper_url =\"https://scrape.serper.dev\" def search_google self query str n_results int = 10 page int = 1 -> List Dict str Any \"\"\" Search Google using the Serper.dev API. :param query: the query to search on google :param n_results: number of results to return per page :param page: page number to return :return: a list of dictionaries containing the search results  \"\"\" payload = json dumps \"q\" query \"num\" n_results \"page\" page headers =\\'X-API-KEY\\' self __api_key__\\'Content-Type\\'\\'application/json\\' response = requests request method = \"POST\" url = self search_url headers = headers data = payload return response json \\'organic\\' def get_text_from_page self url_to_scrape str -> str \"\"\" Get text from a page using the Serper.dev API. :param url_to_scrape: the url of the page to scrape :return: the text content of the page  \"\"\" payload = json dumps \"url\" url_to_scrape headers =\\'X-API-KEY\\' self __api_key__\\'Content-Type\\'\\'application/json\\' response = requests request method = \"POST\" url = self scraper_url headers = headers data = payload return response text\\n```\\n\\n## From Service to Server\\n\\nIt is now time to transform those two services into MCP server(s). Given the limited capabilities of the agents in this tutorial, we could create a single MCP server that provides all the tools needed by the agent(s). Nonetheless, the goal here is not to have the best production-ready solution, quite the contrary, but on the other hand to experiment: for this reason, we will create two servers, one per service.\\n\\nWithin the Model Context Protocol, servers come in two flavors distinguished by their transport layer. An STDIO MCP server runs as a local subprocess and pipes JSON-RPC messages over its own stdin/stdout streams, giving minimal latency, full-duplex messaging, and zero network dependencies: it is ideal for command-line tools or same-machine integrations. A Server-Sent Events (SSE) MCP server instead exposes an HTTP endpoint: the client sends requests with lightweight POSTs while the server pushes results back on a single SSE stream, making it naturally web-friendly and accessible across networks or from a browser. In practice, stdio is the lean, no-frills option when everything lives on one host, whereas SSE trades a bit of HTTP overhead and one-way streaming semantics for firewall traversal, browser compatibility, and remote reach.\\n\\nGiven our use case, it seems natural to use the first solution (but we will discover it is not that simple).\\n\\n```\\nmcp = FastMCP \"Search Engine Server\" search_service = SerperDevService@mcp.tool() mcp tool def search_google query str n_results int = 10 page int = 1 -> list \"\"\" Search Google using the Serper.dev API. :param query: the query to search on google :param n_results: number of results to return per page :param page: page number to return :return: a list of dictionaries containing the search results  \"\"\" return search_service search_google query n_results page@mcp.tool() mcp tool def get_text_from_page url_to_scrape str -> str \"\"\" Get text from a page using the Serper.dev API. :param url_to_scrape: the url of the page to scrape :return: the text content of the page  \"\"\" return search_service get_text_from_page url_to_scrape if __name__ == \"__main__\" mcp run transport = \\'stdio\\'\\n```\\n\\nThe code is straightforward (and highly similar to FastAPI, not surprisingly, given that it is used to implement this MCP library).\\n\\nWe first initialise the MCP server with `mcp = FastMCP(\"\")`, then, we define the endpoint/tools using the decorator `@mcp.tool()`.\\n\\nWe define the Stocks scraper MCP server in the very same way.\\n\\n## Let\\'s use the MCP Server\\n\\nSo, at this point we have our working MCP server and we just need to use it. Given this tutorial is about A2A Framework as well, and A2A has been created by Google, we will use the new google ADK to create our agents. To start, we create a single, simple agent that use our MCP server to search the web for information.\\n\\nWe first create a function that spawns our MCP server and \"transforms\" it into a tool for our ADK agent.\\n\\n```\\nasync def get_tools_async\"\"\"Gets tools from the Search MCP Server.\"\"\" print\"Attempting to connect to MCP Filesystem server...\" tools exit_stack = await MCPToolset from_server connection_params = StdioServerParameters command =\"/opt/homebrew/bin/uv\" # on macos you need to use this path args =\"--directory\"\"/root/path/to/mcp_server\" \"run\"\"search_server.py\" env = \"PYTHONPATH\"< YOUR_PYTHONPATH_IF_NEEDED> print\"MCP Toolset created successfully.\" return tools exit_stack\\n```\\n\\nThis function will spawn our MCP server and return the tools and the exit stack.\\n\\nNow, we can create our agent in a similar fashion.\\n\\n```\\nasync def get_agent_async\"\"\"Creates an ADK Agent equipped with tools from the MCP Server.\"\"\" tools exit_stack = await get_tools_async printf\"Fetched {len(tools)} tools from MCP server.\"{len(tools)}{len tools} root_agent = LlmAgent model =\\'gemini-2.5-pro-exp-03-25\\' name = \\'search_agent\\' description =\"Agent to answer questions using Google Search.\" instruction =\"You are an expert researcher. When someone asks you something you always double check online. You always stick to the facts.\" tools = tools # return root_agent exit_stack\\n```\\n\\nThis function will create an ADK agent equipped with the tools from the MCP server.\\n\\nWe can now put everything together and create our agent pipeline.\\n\\n```\\nasync def async_main session_service = InMemorySessionService artifacts_service = InMemoryArtifactService print\"Creating session...\" session = session_service create_session state = app_name = \\'mcp_search_app\\' user_id = \\'searcher_usr\\' session_id = \\'searcher_session\\' printf\"Session created with ID: {session.id}\"{session.id}{session id} query =\"What are the most tipical sports of the Aosta Valley? Answer with a lot of details.\" printf\"User Query: \\'{query}\\'\"{query}{query} content = types Content role = \\'user\\' parts = types Part text = query root_agent exit_stack = await get_agent_async runner = Runner app_name = \\'mcp_search_app\\' agent = root_agent artifact_service = artifacts_service session_service = session_service print\"Running agent...\" events_async = runner run_async session_id = session id user_id = session user_id new_message = content async for event in events_async if event is_final_response if event content and event content parts final_response_text = event content parts 0 text elif event actions and event actions escalate# Handle potential errors/escalations final_response_text =f\"Agent escalated: {event.error_message or \\'No specific message.\\'}\"{event.error_message or \\'No specific message.\\'}{event error_message or\\'No specific message.\\'} printf\"############# Final Response #############\\\\n\\\\n{final_response_text}\" \\\\n \\\\n{final_response_text}{final_response_text} break print\"Closing MCP server connection...\" await exit_stack aclose print\"Cleanup complete.\"\\n```\\n\\nThis function will create a session, run the agent, and print the final response (If you are interested in the answer to the question about the Aosta Valley, you can see below).\\n\\n If you are interested in the answer to the question about the Aosta Valley, click here Okay, here are the traditional sports specific to the Aosta Valley, with detailed explanations of how they are played:\\n\\nThe Aosta Valley boasts several unique traditional sports, deeply rooted in its rural history and culture, primarily played in spring and autumn. The main ones are **Tsan**, **Rebatta**, **Fiolet**, and **Palet**. Additionally, the game of **Morra** is also a popular traditional pastime.\\n\\n* **Tsan**: Often compared vaguely to baseball or Romanian Oina, Tsan (meaning \"field\" in the local dialect) is a team sport played on a large grass field, ideally at least 135 meters long. Two teams of 12 players compete. The game involves two main phases. In the first phase (\\'batti\\' or \\'tsach\\'), players from one team take turns hitting a small ball (\\'tsan\\') placed in a notch (\\'t aspot\\') on a long wooden or plastic pole (\\'percha\\' or \\'pertse\\') which rests obliquely on a stand (\\'bes\\'). The hitter uses a wooden stick (\\'baquet\\') to strike the end of the \\'percha\\', launching the \\'tsan\\' into the air, and then hits the airborne \\'tsan\\' with the \\'baquet\\' to send it downfield. The opposing team is spread across the field trying to intercept the \\'tsan\\' before it lands, primarily using wooden paddles (\\'pilon\\' or \\'boquet\\'), which they can even throw to block the ball. A hit is considered \\'good\\' (\\'bon\\') if it lands within the designated field boundaries and is not intercepted. The batting player continues until their shot is intercepted, or they hit the \\'tsan\\' out of bounds three consecutive times or four times in total. The number of \\'bone\\' (good hits) each player accumulates is tallied for the team. After all players on the first team have batted, the teams switch roles. In the second phase (\\'servi\\' or \\'palet\\'), each player must convert their accumulated \\'bone\\' into distance. A player from the opposing team throws the \\'tsan\\' high in the air towards the original batting area. The player whose turn it is attempts to hit this thrown \\'tsan\\' with a different wooden paddle (\\'paleta\\' or \\'piota\\'), aiming for maximum distance. The distance of this hit is measured in meters. Finally, the total meters achieved by all players on each team are summed up. The team that accumulates an advantage of at least 40 meters over the opponent wins the match; if the difference is less, it\\'s a draw (though in finals or play-offs, a single meter advantage is enough to win). Due to the hardness of the wooden \\'tsan\\', players often wear helmets for safety.\\n* **Rebatta**: This game belongs to the family of bat-and-ball sports, like golf or baseball. It involves hitting a small ball (\\'rebatta\\', made of wood studded with nails or metal, about 30mm diameter) as far as possible. To do this, the player uses two specific wooden tools. First is the \\'fioletta\\', a pipe-shaped lever about 20cm long. The \\'rebatta\\' is placed on the slightly hollowed end of the \\'fioletta\\' which rests on the ground. The player then strikes the *other* end of the \\'fioletta\\' with a long wooden club (\\'masetta\\', 100-140cm long with a distinct head called \\'maciocca\\') making the \\'fioletta\\' act as a lever to pop the \\'rebatta\\' into the air (this action is called \\'levo\\'). Immediately after, the player swings the \\'masetta\\' again to strike the airborne \\'rebatta\\' forcefully, sending it downfield. The playing field is typically an isosceles triangle marked out on grass, with the vertex at the batting spot (\\'place\\'). The length varies by category but can be up to 240 meters. Lines are marked across the field every 15 meters, and landing the \\'rebatta\\' beyond a line scores a corresponding number of points (1 point for passing the first line, 2 for the second, etc.). Matches are often played between teams (e.g., five players each), competing over a set number of turns (\\'bars\\'), with both team and individual championships held.\\n* **Fiolet**: Similar in objective to Rebatta (hitting an object for maximum distance), Fiolet uses slightly different equipment and technique. The object hit is the \\'fiolet\\' itself, which is ovoid-shaped with one slightly flattened part. Instead of using a separate lever like Rebatta\\'s \\'fioletta\\', the \\'fiolet\\' is balanced directly on a smooth stone (\\'pira\\') or a purpose-made stand. The player uses a bat (also often called \\'masetta\\' or \\'baton\\') to strike the edge of the balanced \\'fiolet\\' skillfully. This initial impact makes the \\'fiolet\\' jump vertically into the air. The player then takes a full swing with the bat to hit the airborne \\'fiolet\\' and drive it as far as possible down the field, potentially over 150 meters. Like Rebatta, scoring is based on the distance achieved, often measured in zones or points corresponding to set distances. Competitions include team events (often 5 players per team) and a notable individual championship where the winner receives the \"Baton d\\'Or\" (Golden Bat) trophy for the year.\\n* **Palet**: This sport is akin to horseshoes or the French \\'jeu de palets\\'. Players throw heavy, round, flat metal discs called \\'palets\\' towards a smaller target pin, known as the \\'bolin\\' or \\'billet\\', which is placed at a distance (often around 10-20 meters) on a designated court, usually made of clay or packed earth. The objective is to land your \\'palet\\' as close to the \\'bolin\\' as possible. Players typically throw a set number of \\'palets\\' per round. Scoring occurs after all \\'palets\\' are thrown in a round. Points are awarded to the player or team whose \\'palet(s)\\' are closest to the \\'bolin\\'. Usually, only the \\'palets\\' closer than the opponent\\'s closest \\'palet\\' can score. It requires precision and strategy in throwing the heavy discs. It\\'s played both individually and in teams, often in dedicated courts found throughout the valley.\\n* **Morra** (or Moura): While simpler and often considered more of a game than a sport requiring a dedicated field, Morra is a very traditional and lively pastime in the Aosta Valley. It\\'s typically played between two people. Both players simultaneously extend one hand, showing a number of fingers from 1 to 5 (or a closed fist representing zero). At the same instant they extend their hand, each player loudly shouts out their guess for the *total* sum of fingers shown by both players combined (so the guess will be between 0 and 10). The player who correctly guesses the sum scores a point. The game is fast-paced, often played in rounds to a set score, and is known for the animated shouts and gestures involved.\\n\\n## Multiple Local MCP Servers: where STDIO is not enough\\n\\nNow, we have a single MCP server that can be used by our agent. However, especially if we plan to play with multiple agents, we want to have multiple MCP servers, each one with a specific purpose. For example, we want one MCP server to be able to search the web, another to retrieve stocks, and so on.\\n\\nIf you try to spawn multiple STDIO-based MCP servers, you will notice that they will not work at the same time. To solve this problem, we can use an SSE-based MCP server with some tricks.\\n\\nIt is quite simple: we declare the \"endpoints\" as before,\\n\\n```\\n@mcp.tool() mcp tool def search_google query str n_results int = 10 page int = 1 -> list \"\"\" Search Google using the Serper.dev API. :param query: the query to search on google :param n_results: number of results to return per page :param page: page number to return :return: a list of dictionaries containing the search results  \"\"\" return search_service search_google query n_results page@mcp.tool() mcp tool def get_text_from_page url_to_scrape str -> str \"\"\" Get text from a page using the Serper.dev API. :param url_to_scrape: the url of the page to scrape :return: the text content of the page  \"\"\" return search_service get_text_from_page url_to_scrape\\n```\\n\\nThen, we wrap the server in a Startlette app:\\n\\n```\\ndef create_starlette_app mcp_server Server* debug bool = False -> Starlette \"\"\" Create a Starlette application that can server the provied mcp server with SSE. :param mcp_server: the mcp server to serve :param debug: whether to enable debug mode :return: a Starlette application  \"\"\" sse = SseServerTransport\"/messages/\" async def handle_sse request Request -> None async with sse connect_sse request scope request receive request _send as read_stream write_stream await mcp_server run read_stream write_stream mcp_server create_initialization_options return Starlette debug = debug routes = Route\"/sse\" endpoint = handle_sse Mount\"/messages/\" app = sse handle_post_message\\n```\\n\\nWe can then run each server with a different port as follows:\\n\\n```\\nmcp_server = mcp _mcp_server# noqa: WPS437 parser = argparse ArgumentParser description =\\'Run MCP SSE-based server\\' parser add_argument\\'--host\\' default =\\'0.0.0.0\\' help = \\'Host to bind to\\' parser add_argument\\'--port\\' type = int default = 8080 help = \\'Port to listen on\\' args = parser parse_args starlette_app = create_starlette_app mcp_server debug = True uvicorn run starlette_app host = args host port = args port\\n```\\n\\nTo pass such a server to an ADK agent, as a tool we\\'ll need something like:\\n\\n```\\nasync def return_sse_mcp_tools_search print\"Attempting to connect to MCP server for search and page read...\" server_params = SseServerParams url =\"http://localhost:/sse\" tools exit_stack = await MCPToolset from_server connection_params = server_params print\"MCP Toolset created successfully.\" return tools exit_stack\\n```\\n\\n# Multiple Agents\\n\\nIt is now time to create a more complex pipeline with multiple agents. At first, we will create a hierarchical crew of agents using the ADK library by Google, then, after seeing that our solution works, we will use Agent2Agent framework to create peer-to-peer agents able to coordinate with each other.\\n\\n## Hierarchical Crew\\n\\nNow that we have our MCP servers set up, we can create a hierarchical crew of agents using the ADK library. In this example, we\\'ll create a team of agents that can analyze companies and their stocks, with a main coordinator agent delegating tasks to specialized sub-agents.\\n\\n### Setting Up the Crew\\n\\nFirst, we define some constants for our application:\\n\\n```\\nMODEL =\\'gemini-2.5-pro-exp-03-25\\' APP_NAME = \\'company_analysis_app\\' USER_ID = \\'searcher_usr\\' SESSION_ID = \\'searcher_session\\'\\n```\\n\\nThese constants define the model we\\'ll use (Gemini 2.5 Pro), the application name, and session identifiers.\\n\\n### Creating Specialized Agents\\n\\nWe create two specialized agents, each with their own set of tools:\\n\\n1. **Stock Analysis Agent**: This agent is responsible for analyzing stock data and providing insights about stock prices and market performance.\\n\\n```\\nstock_analysis_agent = Agent model = MODEL name = \"stock_analysis_agent\" instruction =\"Analyze stock data and provide insights.\" description =\"Handles stock analysis and provides insights, in particular, can get the latest stock price.\" tools = stocks_tools\\n```\\n\\n1. **Search Agent**: This agent specializes in searching the web and reading online content.\\n\\n```\\nsearch_agent = Agent model = MODEL name = \"search_agent\" instruction =\"Expert googler. Can search anything on google and read pages online.\" description =\"Handles search queries and can read pages online.\" tools = search_tools\\n```\\n\\n### The Root Agent\\n\\nThe root agent acts as the coordinator, delegating tasks to the specialized agents based on the user\\'s query:\\n\\n```\\nroot_agent = Agent name = \"company_analysis_assistant\" model = MODEL description =\"Main assistant: Handles requests about stocks and information of companies.\" instruction =\"You are the main Assistant coordinating a team. Your primary responsibilities are providing company and stocks reports and delegating other tasks.\\\\n\" \\\\n\"1. If the user asks about a company, provide a detailed report.\\\\n\" \\\\n\"2. If you need any information about the current stock price, delegate to the stock_analysis_agent.\\\\n\" \\\\n\"3. If you need to search for information, delegate to the search_agent.\\\\n\" \\\\n\"Analyze the user\\'s query and delegate or handle it appropriately. If unsure, ask for clarification. Only use tools or delegate as described.\" sub_agents = search_agent stock_analysis_agent output_key = \"last_assistant_response\"\\n```\\n\\nThe root agent\\'s instruction clearly defines its role and how it should delegate tasks to its sub-agents. It\\'s designed to:\\n\\n* Provide detailed company reports\\n* Delegate stock price queries to the stock analysis agent\\n* Delegate search queries to the search agent\\n* Ask for clarification when needed\\n\\n### Running the Crew\\n\\nThe main function sets up the session and runs the agent pipeline:\\n\\n```\\nasync def async_main # Initialize services session_service = InMemorySessionService artifacts_service = InMemoryArtifactService # Create session session = session_service create_session state = app_name = APP_NAME user_id = USER_ID session_id = SESSION_ID # Get user query query = input\"Enter your query:\\\\n\" \\\\n content = types Content role = \\'user\\' parts = types Part text = query # Initialize tools from MCP servers search_tools search_exit_stack = await return_sse_mcp_tools_search stocks_tools stocks_exit_stack = await return_sse_mcp_tools_stocks # Create and run the agent pipeline runner = Runner app_name = APP_NAME agent = root_agent artifact_service = artifacts_service session_service = session_service # Process events and get final response events_async = runner run_async session_id = session id user_id = session user_id new_message = content async for event in events_async if event is_final_response if event content and event content parts final_response_text = event content parts 0 text elif event actions and event actions escalate final_response_text =f\"Agent escalated: {event.error_message or \\'No specific message.\\'}\"{event.error_message or \\'No specific message.\\'}{event error_message or\\'No specific message.\\'} print colored text =f\"############# Final Response #############\\\\n\\\\n{final_response_text}\" \\\\n \\\\n{final_response_text}{final_response_text} color = \\'green\\' break else print event # Cleanup await stocks_exit_stack aclose await search_exit\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 7: LangGraph A2A MCP Example - YouTube ---\\nURL: https://www.youtube.com/watch?v=1LlX45CMc84\\n\\nSUMMARY:\\nLangGraph A2A MCP Example\\nNikita Sviridenko\\n86 subscribers\\n53 likes\\n3311 views\\n25 Apr 2025\\nLearn how to connect your LangGraph agents with other agents using Google\\'s new Agent-to-Agent (A2A) protocol and Model Context Protocol (MCP). \\n\\nTIMESTAMPS:\\n00:00 - Introduction to A2A Protocol and MCP\\n00:45 - Weather Check Demo Application\\n01:23 - Google Agentspace Platform Overview\\n02:41 - A2A in Action\\n08:49 - Code Overview\\n\\nLINKS:\\n- Full Example: https://github.com/n-sviridenko/langgraph-a2a-mcp-example\\n- LangGraph A2A Adapter: https://github.com/n-sviridenko/langgraph-a2a-adapter\\n- Google A2A Demo Web App: https://github.com/google/A2A/blob/main/demo/README.md\\n- LangChain MCP Adapters: https://github.com/langchain-ai/langchain-mcp-adapters\\n\\nABOUT ME:\\nMy name is Nikita Sviridenko. I build GenAI systems that push boundaries. On this channel, I share what\\'s actually possible with today\\'s cutting-edge AI  not theoretical concepts, but real implementations that break new ground.\\n\\nCOME SAY HI:\\nLinkedIn: https://www.linkedin.com/in/nikita-sviridenko/ \\nEmail: nikita.sviridenko@voypost.com\\n\\n--\\n\\nThanks for watching! \\n\\nHow useful is it? What else would you like to do with LangGraph? Leave a comment below.\\n15 comments\\n\\n\\nFULL CONTENT:\\n# LangGraph A2A MCP Example\\n## Nikita Sviridenko\\n86 subscribers\\n53 likes\\n\\n### Description\\n3311 views\\nPosted: 25 Apr 2025\\nLearn how to connect your LangGraph agents with other agents using Google\\'s new Agent-to-Agent (A2A) protocol and Model Context Protocol (MCP). \\n\\nTIMESTAMPS:\\n00:00 - Introduction to A2A Protocol and MCP\\n00:45 - Weather Check Demo Application\\n01:23 - Google Agentspace Platform Overview\\n02:41 - A2A in Action\\n08:49 - Code Overview\\n\\nLINKS:\\n- Full Example: https://github.com/n-sviridenko/langgraph-a2a-mcp-example\\n- LangGraph A2A Adapter: https://github.com/n-sviridenko/langgraph-a2a-adapter\\n- Google A2A Demo Web App: https://github.com/google/A2A/blob/main/demo/README.md\\n- LangChain MCP Adapters: https://github.com/langchain-ai/langchain-mcp-adapters\\n\\nABOUT ME:\\nMy name is Nikita Sviridenko. I build GenAI systems that push boundaries. On this channel, I share what\\'s actually possible with today\\'s cutting-edge AI  not theoretical concepts, but real implementations that break new ground.\\n\\nCOME SAY HI:\\nLinkedIn: https://www.linkedin.com/in/nikita-sviridenko/ \\nEmail: nikita.sviridenko@voypost.com\\n\\n--\\n\\nThanks for watching! \\n\\nHow useful is it? What else would you like to do with LangGraph? Leave a comment below.\\n\\n15 comments\\n### Transcript:\\nIntroduction to A2A Protocol and MCP Hey there. In this video, you\\'ll see how to\\nconnect your LangGraph agent with other agents through an A2A protocol. The new protocol that was\\nrecently introduced by Google. This protocol allows\\nagents talk to each other. Before it was also possible,\\nbut it was not standardized. So the idea of Google is to bring a\\nclarity to this and make it easier for different organizations or different teams\\nintegrating their agents and basically having a single ecosystem where agents\\ntalk to each other and do the work. I will also show you how to\\ncombine A2A and MCP so that you can also see the difference. Weather Check Demo Application And for this, we have a very simple\\napp that does the weather check. And in order to get the weather\\ninformation we use Travily , an online search engine that easily\\nintegrates with LLM for example, we ask for the weather in San\\nFrancisco and it goes and talks to Travily and gets the search results. And answers this question. So now it is 15 degrees, which\\nis pretty similar to Berlin. Actually, the promise from Google along\\nwith this protocol was introducing Google Agentspace Platform Overview an platform named Agentspace. It\\'s a new version of their\\nNotebookLM for enterprise. But on steroids. So they also allow you connecting custom\\nagents, and as I understood from their announcement, maybe I was wrong for you\\nto also double check, is that they will allow you to connect custom agents. Using this A2A protocol, and I already\\nrequested access to the Agentspace because currently it\\'s not yet available. In Germany, I think it, it\\'s\\ngenerally not available to everyone. You need to request the access. And once I will get the access, I\\nwill double check if it is compatible. But the idea is, yeah, is you\\nunderstood connecting different agents to your Google Workspace ecosystem. And being able to do nice\\nstuff in one single place. And because this thing is official the\\nprotocol and many players are already supporting it soon we\\'ll have lots of\\nother players also providing their own interfaces to connect agents there. That\\'s why it\\'s very important to\\nunderstand how it works and be able to deliver your agent in A2A-compatible\\nway, along with this announcement, they A2A in Action also shared a huge repo where they have\\nlots of different examples of how A2A works with different agents and stuff. You can check it out later on. The thing we will take from here\\nuntil we don\\'t have access to a proper Agentspace is their demo  web app that\\nalso allows connecting custom agents. I will skip the  setup instructions. You can check it out in the repo, but\\nbasically it\\'s already running on my end, and that\\'s how it looks like. So when you run it first, it\\'ll ask\\nyou to enter the API key from Google. This is needed for Gemini because this\\nexample uses Gemini in this main agent that will be talking to different agents\\nbecause the agent I will show you in this demo is just one of the agents\\nthat will be serving this main agent. If you come back to the architecture,\\nyou can also see this here. We are here now in the web\\nbrowser and are looking on the front end and the front end. Under the hood, it has a host agent,\\nand this host agent is driven by Gemini. And we can connect multiple\\nremote agents to this host agent. So the first thing you need\\nto do is to enter the API key. And once you enter the API\\nkey, you can go to the agents. And add a new one. When you use A2A, the only thing\\nyou need to enter in order for the agent to be discovered is\\nthe domain name of the agent. And then as per the protocol,\\nit expects to have an agent card and under a specific address. These details you can check in the Google. Documentation they provide\\nabout the protocol. It\\'s well described there, so we\\ncan just check everything here. But basically, once we enter this\\nURL, it will discover the agent. And because LangGraph is not compatible\\nwith this protocol, it has its own API what I\\'ve created is an adapter that\\nbasically proxies all the requests. That are A2A-compatible to the\\nLangGraph server, and it looks this way. So we have an A2A client, which will\\nbe basically this this demo host agent. We will be running from Google and\\nit\\'ll be connecting to our LangGraph agent that is running on the LangGraph\\nserver through a LangGraph A2A adapter. The adapter I created the repository\\nand the instructions on how to set up are all here in this repository. I will not be like going too deep\\ninto this, but basically this thing converts A2A compatible communication\\ninto the communication that LangGraph expects and the server, this adapter\\nis already running on my end here. And it\\'s running under this host and port. So if you just copied it and paste\\ninto the agent address field and click read, they have a button. You need to enter the\\ndomain without the scheme. So not http://.., et cetera, but just. Four zeros and then the port. So once it do this, it\\nfetches the agent card. And from the agent card it discovers\\nwhat is this agent about what kind of stuff it can do, skills et cetera. All these details you can\\nfind in the protocol, but basically we just click save. And now if we go to the chats,\\nthe conversations, we create a new one and we can ask the same\\nquestion, what the weather in sf. Also if we come back to the studio\\nso we can see now we still have this, We still have our own old thread. That was nine minutes\\nago with the weather. If we will ask this question\\nagain already through our client, basically here and click send. It starts talking to the agent. Now if we see here, it\\nalso started the thread, and we get the reply. So this reply is basically\\ncoming back from. LangGraph from the agent we have here. It\\'s also a bit edited because\\nof the logic on this level, but the idea is that this agent was\\nonly able to do this by connecting the agent through this protocol. And this way it can\\nconnect many other agents. And the promise from Google is,\\nI believe is basically being able to do this in their Agentspace. Which will speed up the things a\\nlot and make everything much nicer in terms of the experience compared\\nto what we have at the moment. The other things you can also check out\\nhere are the tasks because this protocol has exposes this term as a task and\\nagents can be given different tasks. And here you can basically\\nsee was it completed what was the latest output, et cetera. You also have different events. What was actually happening, how the task\\nwas worked on, when it was completed. And this all is coming from LangGraph\\nand the way it currently works. So every task you say an individual\\nrun on LangGraph, basically this thing. Every conversation which we have\\nhere is a LangGraph thread in the context of A two A is named a session. So for example, if we will say something else, it\\'ll also go to the same graph thread\\nwe have here so we can already see. And it does the second run. Which is basically the second task, and if you come back to the code,\\nso if you take a look inside of Code Overview the agent, it\\'s pretty simple. It has a Travily server,\\nwhich exposes an MCP server. The only tool, which is the search\\nto find something on the internet, it has the agent the graph. And this graph is loaded asynchronously. \\'cause first we need to\\npull the tools from Travily. Basically I use the adapters from\\nfrom LangChain that expose, MCP, like they create an MCP client and wrap\\nit in a tool so that I can easily communicate with an MCP server. In this example, it\\'s a part of the\\npository, but you can also check many other MCP servers that are available\\nonline and easily connect to them, for example, to the server from GitHub or\\nfrom Notion, basically from any tool. There is a nice website where we can. Discover lots of different MCP servers. So the idea is to basically reuse\\nthe logic that was already built by someone instead of every time\\ncreating your own tool and focus only on the logic on your agent level. So if we come back to the repository as\\nI said, we have the server is accessed through the tools, and the tools are. Injected into the agent. And in the agent we have a tool node,\\nwhich is basically the node that executes the tool and validates the outcome. And if something is wrong, it\\'ll, we\\ntry the tool and the actual agent node that decides what to call this pattern. They can also check on\\nthe website of LangChain. They have lots of. Examples of the way you can call\\nthe tools, and that\\'s basically it. You\\'ll find all the instructions\\non how to set everything up locally in this repository, and the\\nadapter you\\'ll find on my GitHub.\\n\\n--------------------------------------------------------------------------------\\n\\n\\n--- SOURCE 8: LangGraph - LangSmith ---\\nURL: https://smith.langchain.com/public/31eca7c9-beae-42a3-bef4-5bce9488d7be/r\\n\\nSUMMARY:\\n### Sources [1] MCP Protocol Specification: https://www.claudemcp.com/specification [2] Lifecycle  Model Context Protocol: https://modelcontextprotocol.info/specification/draft/basic/lifecycle/ [3] Transports  Model Context Protocol: https://modelcontextprotocol.io/specification/2025-03-26/basic/transports [4] Core Architecture  Model Context Protocol: https://modelcontextprotocol.io/docs/concepts/architecture [5] Architecture  Model Context Protocol Specification: https://spec.modelcontextprotocol.io/specification/2025-03-26/architecture/ ============================================================ Section 2: Ecosystem Spotlight: Notable MCP Servers ============================================================ Description: Survey official, partnermaintained, and community MCP servers that showcase the protocols versatility, highlighting practical usecases and implementation details developers can replicate. ### Sources [1] Example Servers  Model Context Protocol: https://modelcontextprotocol.io/examples [2] Model Context Protocol Servers Repository: https://github.com/madhukarkumar/anthropic-mcp-servers [3] Microsoft partners with Anthropic to create official C# SDK for Model Context Protocol: https://devblogs.microsoft.com/blog/microsoft-partners-with-anthropic-to-create-official-c-sdk-for-model-context-protocol ============================================================ Section 3: Agent2Agent (A2A) Protocol and Comparison with MCP ============================================================ Description: Introduce Googles A2A protocol, summarize its design goals and primitives, and provide a focused comparison with MCPemphasizing how the two standards complement each other in agentic systems.\\n\\nFULL CONTENT:\\nPublished Time: Thu, 04 Sep 2025 18:34:22 GMT\\n\\nLangGraph - LangSmith\\n\\n===============\\n\\n[](https://docs.smith.langchain.com/)[](https://docs.smith.langchain.com/)[](https://www.langchain.com/contact-sales)\\n\\n[LangGraph](https://smith.langchain.com/public/31eca7c9-beae-42a3-bef4-5bce9488d7be/r/f35f82bd-5b57-45da-9f96-98af3e465734?trace_id=f35f82bd-5b57-45da-9f96-98af3e465734&start_time=2025-04-23T18%3A11%3A48.519303)\\n\\n[PENDING](https://smith.langchain.com/o/null/settings/payments)\\n\\n###### #### Trace\\n\\nWaterfall\\n\\n\\n\\nLangGraph\\n\\n71.90s\\n\\n80,263\\n\\nhuman_feedback\\n\\n0.00s\\n\\nbuild_section_with_web_research\\n\\n49.24s\\n\\ngenerate_queries\\n\\n4.71s\\n\\nChatOpenAI o3\\n\\n4.66s\\n\\nsearch_web\\n\\n8.66s\\n\\ntavily_search\\n\\n8.65s\\n\\ntavily_search_async\\n\\n8.65s\\n\\nwrite_section\\n\\n35.85s\\n\\nChatOpenAI o3\\n\\n30.77s\\n\\nChatOpenAI o3\\n\\n5.03s\\n\\nbuild_section_with_web_research\\n\\n51.40s\\n\\ngenerate_queries\\n\\n13.76s\\n\\nChatOpenAI o3\\n\\n13.71s\\n\\nsearch_web\\n\\n4.94s\\n\\ntavily_search\\n\\n4.93s\\n\\ntavily_search_async\\n\\n4.93s\\n\\nwrite_section\\n\\n32.69s\\n\\nChatOpenAI o3\\n\\n24.41s\\n\\nChatOpenAI o3\\n\\n8.23s\\n\\nbuild_section_with_web_research\\n\\n49.25s\\n\\ngenerate_queries\\n\\n4.71s\\n\\nChatOpenAI o3\\n\\n4.66s\\n\\nsearch_web\\n\\n6.88s\\n\\nSome runs have been hidden. [Show 41 hidden runs](https://smith.langchain.com/public/31eca7c9-beae-42a3-bef4-5bce9488d7be/r)\\n\\nLangGraph\\n\\nID\\n-------------\\n\\nRun in Studio\\n\\nRun Metadata\\n\\nInput\\n\\ninput\\n\\ngoto\\n\\n[]\\n\\ngraph\\n\\nnull\\n\\nresume\\n\\ntrue\\n\\nupdate\\n\\nnull\\n\\nOutput\\n\\nfeedback on report plan\\n\\nLooks great! Just do one section related to Agent2Agent (A2A) protocol, introducing it and comparing to MCP.\\n\\nfinal report\\n\\n# Introduction Large language models excel at reasoning, but without structured access to the outside world they remain isolated. The Model Context Protocol (MCP) bridges this gap, defining an open, vendorneutral way for models to tap files, databases, APIs, and other tools through simple JSONRPC exchanges. This report walks developers through the protocols architecture, surveys realworld MCP servers that showcase its flexibility, and contrasts MCP with Googles emerging AgenttoAgent (A2A) standard. By the end, you should know when, why, and how to weave MCP into your own agentic systems. ## MCP Architectural Overview for Developers MCP uses a clienthostserver model: a host process spawns isolated clients, and every client keeps a 1to1, stateful session with a single server that exposes prompts, resources, and tools through JSONRPC 2.0 messages[1][5]. A session passes through three phasesinitialize, operation, shutdown. The client begins with an initialize request that lists its protocolVersion and capabilities; the server replies with a compatible version and its own capabilities. After the clients initialized notification, both sides may exchange requests, responses, or oneway notifications under the agreed capabilities[2]. Two official transports exist. Stdio is ideal for local child processes, while HTTP(SSE/streamable HTTP) supports multiclient, remote scenarios. Both must preserve JSONRPC framing, and servers should validate Origin headers, bind to localhost where possible, and apply TLS or authentication to block DNSrebind or similar attacks[1][3]. To integrate MCP, developers can: 1) implement a server that registers needed primitives and advertises them in initialize.result.capabilities; 2) validate all inputs and set reasonable timeouts; 3) or consume existing servers via SDKsselect a transport, send initialize, then invoke or subscribe to tools/resources exactly as negotiated[4][5]. ### Sources [1] MCP Protocol Specification: [https://www.claudemcp.com/specification](https://www.claudemcp.com/specification) [2] Lifecycle  Model Context Protocol: [https://modelcontextprotocol.info/specification/draft/basic/lifecycle/](https://modelcontextprotocol.info/specification/draft/basic/lifecycle/) [3] Transports  Model Context Protocol: [https://modelcontextprotocol.io/specification/2025-03-26/basic/transports](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports) [4] Core Architecture  Model Context Protocol: [https://modelcontextprotocol.io/docs/concepts/architecture](https://modelcontextprotocol.io/docs/concepts/architecture) [5] Architecture  Model Context Protocol Specification: [https://spec.modelcontextprotocol.io/specification/2025-03-26/architecture/](https://spec.modelcontextprotocol.io/specification/2025-03-26/architecture/) ## Ecosystem Spotlight: Notable MCP Servers Hundreds of MCP servers now exist, spanning core data access, commercial platforms, and hobby projectsproof that the protocol can wrap almost any tool or API [1][2]. Reference servers maintained by Anthropic demonstrate the basics. Filesystem, PostgreSQL, Git, and Slack servers cover file I/O, SQL queries, repository ops, and chat workflows. Developers can launch them in seconds with commands like `npx -y @modelcontextprotocol/server-filesystem` (TypeScript) or `uvx mcp-server-git` (Python) and then point any MCPaware client, such as Claude Desktop, at the spawned process [1]. Platform vendors are adding firstparty connectors. Microsoft cites the GitHub MCP Server and a Playwright browserautomation server as popular examples that let C# or .NET apps drive code reviews or endtoend tests through a uniform interface [3]. Other partner serverse.g., Cloudflare for edge resources or Stripe for paymentsexpose full product APIs while still enforcing user approval through MCPs toolcalling flow [2]. Community builders rapidly fill remaining gaps. Docker and Kubernetes servers give agents controlled shell access; Snowflake, Neon, and Qdrant handle cloud databases; Todoist and Obsidian servers tackle personal productivity. Because every server follows the same JSONRPC schema and ships as a small CLI, developers can fork an existing TypeScript or Python implementation and swap in their own SDK calls to create new connectors in hours, not weeks [2]. ### Sources [1] Example Servers  Model Context Protocol: [https://modelcontextprotocol.io/examples](https://modelcontextprotocol.io/examples) [2] Model Context Protocol Servers Repository: [https://github.com/madhukarkumar/anthropic-mcp-servers](https://github.com/madhukarkumar/anthropic-mcp-servers) [3] Microsoft partners with Anthropic to create official C# SDK for Model Context Protocol: [https://devblogs.microsoft.com/blog/microsoft-partners-with-anthropic-to-create-official-c-sdk-for-model-context-protocol](https://devblogs.microsoft.com/blog/microsoft-partners-with-anthropic-to-create-official-c-sdk-for-model-context-protocol) ## AgenttoAgent (A2A) Protocol and Comparison with MCP Googles AgenttoAgent (A2A) protocol, announced in April 2025, gives autonomous agents a common way to talk directly across vendors and clouds[2]. Its goal is to let one client agent delegate work to a remote agent without sharing internal code or memory, enabling true multiagent systems. Discovery starts with a JSON Agent Card served at /.wellknown/agent.json, which lists version, skills and endpoints[3]. After discovery, the client opens a Taskan atomic unit that moves through states and exchanges Messages and multimodal Artifacts. HTTP request/response, ServerSent Events, or push notifications are chosen based on task length to stream progress safely[2]. Anthropics Model Context Protocol (MCP) tackles a different layer: it links a single language model to external tools and data through a HostClientServer triad, exposing Resources, Tools and Prompts over JSONRPC[1]. Communication is modeltotool, not agenttoagent. Google therefore calls A2A complementary to MCP: use MCP to give each agent the data and actions it needs; use A2A to let those empowered agents discover one another, coordinate plans and exchange results[1]. In practice, developers might pipe an A2A task that, midflow, invokes an MCP tool or serve an MCP connector as an A2A remote agent, showing the standards can interlock instead of compete. ### Sources [1] MCP vs A2A: Comprehensive Comparison of AI Agent Protocols: [https://www.toolworthy.ai/blog/mcp-vs-a2a-protocol-comparison](https://www.toolworthy.ai/blog/mcp-vs-a2a-protocol-comparison) [2] Google A2A vs MCP: The New Protocol Standard Developers Need to Know: [https://www.trickle.so/blog/google-a2a-vs-mcp](https://www.trickle.so/blog/google-a2a-vs-mcp) [3] A2A vs MCP: Comparing AI Standards for Agent Interoperability: [https://www.ikangai.com/a2a-vs-mcp-ai-standards/](https://www.ikangai.com/a2a-vs-mcp-ai-standards/) ## Conclusion Model Context Protocol (MCP) secures a models immediate tool belt, while Googles AgenttoAgent (A2A) protocol enables those empowered agents to find and hire one another. Their scopes differ but interlock, giving developers a layered recipe for robust, multiagent applications. | Aspect | MCP | A2A | | --- | --- | --- | | Layer | Modeltotool RPC | Agenttoagent orchestration | | Session start | `initialize` handshake | Task creation lifecycle | | Discovery | Clientsupplied server URI | `/.wellknown/agent.json` card | | Streaming | Stdio or HTTP/SSE | HTTP, SSE, or push | | Best fit | Embed filesystems, DBs, SaaS APIs into one agent | Delegate subtasks across clouds or vendors | Next steps: prototype an A2A task that internally calls an MCP PostgreSQL server; harden both layers with TLS and capability scoping; finally, contribute a new opensource MCP connector to accelerate community adoption.\\n\\nreport sections from research\\n\\n ============================================================ Section 1: MCP Architectural Overview for Developers ============================================================ Description: Explain core MCP concepts and architectureclients, servers, transports, message lifecycle, securityand outline how developers can implement or consume MCP integrations. Requires Research: True Content: ## MCP Architectural Overview for Developers MCP uses a clienthostserver model: a host process spawns isolated clients, and every client keeps a 1to1, stateful session with a single server that exposes prompts, resources, and tools through JSONRPC 2.0 messages[1][5]. A session passes through three phasesinitialize, operation, shutdown. The client begins with an initialize request that lists its protocolVersion and capabilities; the server replies with a compatible version and its own capabilities. After the clients initialized notification, both sides may exchange requests, responses, or oneway notifications under the agreed capabilities[2]. Two official transports exist. Stdio is ideal for local child processes, while HTTP(SSE/streamable HTTP) supports multiclient, remote scenarios. Both must preserve JSONRPC framing, and servers should validate Origin headers, bind to localhost where possible, and apply TLS or authentication to block DNSrebind or similar attacks[1][3]. To integrate MCP, developers can: 1) implement a server that registers needed primitives and advertises them in initialize.result.capabilities; 2) validate all inputs and set reasonable timeouts; 3) or consume existing servers via SDKsselect a transport, send initialize, then invoke or subscribe to tools/resources exactly as negotiated[4][5]. ### Sources [1] MCP Protocol Specification: [https://www.claudemcp.com/specification](https://www.claudemcp.com/specification) [2] Lifecycle  Model Context Protocol: [https://modelcontextprotocol.info/specification/draft/basic/lifecycle/](https://modelcontextprotocol.info/specification/draft/basic/lifecycle/) [3] Transports  Model Context Protocol: [https://modelcontextprotocol.io/specification/2025-03-26/basic/transports](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports) [4] Core Architecture  Model Context Protocol: [https://modelcontextprotocol.io/docs/concepts/architecture](https://modelcontextprotocol.io/docs/concepts/architecture) [5] Architecture  Model Context Protocol Specification: [https://spec.modelcontextprotocol.io/specification/2025-03-26/architecture/](https://spec.modelcontextprotocol.io/specification/2025-03-26/architecture/) ============================================================ Section 2: Ecosystem Spotlight: Notable MCP Servers ============================================================ Description: Survey official, partnermaintained, and community MCP servers that showcase the protocols versatility, highlighting practical usecases and implementation details developers can replicate. Requires Research: True Content: ## Ecosystem Spotlight: Notable MCP Servers Hundreds of MCP servers now exist, spanning core data access, commercial platforms, and hobby projectsproof that the protocol can wrap almost any tool or API [1][2]. Reference servers maintained by Anthropic demonstrate the basics. Filesystem, PostgreSQL, Git, and Slack servers cover file I/O, SQL queries, repository ops, and chat workflows. Developers can launch them in seconds with commands like `npx -y @modelcontextprotocol/server-filesystem` (TypeScript) or `uvx mcp-server-git` (Python) and then point any MCPaware client, such as Claude Desktop, at the spawned process [1]. Platform vendors are adding firstparty connectors. Microsoft cites the GitHub MCP Server and a Playwright browserautomation server as popular examples that let C# or .NET apps drive code reviews or endtoend tests through a uniform interface [3]. Other partner serverse.g., Cloudflare for edge resources or Stripe for paymentsexpose full product APIs while still enforcing user approval through MCPs toolcalling flow [2]. Community builders rapidly fill remaining gaps. Docker and Kubernetes servers give agents controlled shell access; Snowflake, Neon, and Qdrant handle cloud databases; Todoist and Obsidian servers tackle personal productivity. Because every server follows the same JSONRPC schema and ships as a small CLI, developers can fork an existing TypeScript or Python implementation and swap in their own SDK calls to create new connectors in hours, not weeks [2]. ### Sources [1] Example Servers  Model Context Protocol: [https://modelcontextprotocol.io/examples](https://modelcontextprotocol.io/examples) [2] Model Context Protocol Servers Repository: [https://github.com/madhukarkumar/anthropic-mcp-servers](https://github.com/madhukarkumar/anthropic-mcp-servers) [3] Microsoft partners with Anthropic to create official C# SDK for Model Context Protocol: [https://devblogs.microsoft.com/blog/microsoft-partners-with-anthropic-to-create-official-c-sdk-for-model-context-protocol](https://devblogs.microsoft.com/blog/microsoft-partners-with-anthropic-to-create-official-c-sdk-for-model-context-protocol) ============================================================ Section 3: Agent2Agent (A2A) Protocol and Comparison with MCP ============================================================ Description: Introduce Googles A2A protocol, summarize its design goals and primitives, and provide a focused comparison with MCPemphasizing how the two standards complement each other in agentic systems. Requires Research: True Content: ## AgenttoAgent (A2A) Protocol and Comparison with MCP Googles AgenttoAgent (A2A) protocol, announced in April 2025, gives autonomous agents a common way to talk directly across vendors and clouds[2]. Its goal is to let one client agent delegate work to a remote agent without sharing internal code or memory, enabling true multiagent systems. Discovery starts with a JSON Agent Card served at /.wellknown/agent.json, which lists version, skills and endpoints[3]. After discovery, the client opens a Taskan atomic unit that moves through states and exchanges Messages and multimodal Artifacts. HTTP request/response, ServerSent Events, or push notifications are chosen based on task length to stream progress safely[2]. Anthropics Model Context Protocol (MCP) tackles a different layer: it links a single language model to external tools and data through a HostClientServer triad, exposing Resources, Tools and Prompts over JSONRPC[1]. Communication is modeltotool, not agenttoagent. Google therefore calls A2A complementary to MCP: use MCP to give each agent the data and actions it needs; use A2A to let those empowered agents discover one another, coordinate plans and exchange results[1]. In practice, developers might pipe an A2A task that, midflow, invokes an MCP tool or serve an MCP connector as an A2A remote agent, showing the standards can interlock instead of compete. ### Sources [1] MCP vs A2A: Comprehensive Comparison of AI Agent Protocols: [https://www.toolworthy.ai/blog/mcp-vs-a2a-protocol-comparison](https://www.toolworthy.ai/blog/mcp-vs-a2a-protocol-comparison) [2] Google A2A vs MCP: The New Protocol Standard Developers Need to Know: [https://www.trickle.so/blog/google-a2a-vs-mcp](https://www.trickle.so/blog/google-a2a-vs-mcp) [3] A2A vs MCP: Comparing AI Standards for Agent Interoperability: [https://www.ikangai.com/a2a-vs-mcp-ai-standards/](https://www.ikangai.com/a2a-vs-mcp-ai-standards/)\\n\\ntopic\\n\\nOverview of Model Context Protocol (MCP), an Anthropicbacked open standard for integrating external context and tools with LLMs. Give an architectural overview for developers, tell me about interesting MCP servers, and compare to google Agent2Agent (A2A) protocol.\\n\\ncompleted sections\\n\\n0\\n\\ncontent\\n\\n## MCP Architectural Overview for Developers MCP uses a client...\\n\\ndescription\\n\\nExplain core MCP concepts and architectureclients, servers, tra...\\n\\nname\\n\\nMCP Architectural Overview for Developers\\n\\nresearch\\n\\ntrue\\n\\n1\\n\\ncontent\\n\\n## Ecosystem Spotlight: Notable MCP Servers Hundreds of MCP ser...\\n\\ndescription\\n\\nSurvey official, partnermaintained, and community MCP servers t...\\n\\nname\\n\\nEcosystem Spotlight: Notable MCP Servers\\n\\nresearch\\n\\ntrue\\n\\n2\\n\\ncontent\\n\\n## AgenttoAgent (A2A) Protocol and Comparison with MCP Goog...\\n\\ndescription\\n\\nIntroduce Googles A2A protocol, summarize its design goals and ...\\n\\nname\\n\\nAgent2Agent (A2A) Protocol and Comparison with MCP\\n\\nresearch\\n\\ntrue\\n\\n3\\n\\ncontent\\n\\n# Introduction Large language models excel at reasoning, but w...\\n\\ndescription\\n\\nBriefly introduce the Model Context Protocol (MCP) as an open st...\\n\\nname\\n\\nIntroduction\\n\\nresearch\\n\\nfalse\\n\\n4\\n\\ncontent\\n\\n## Conclusion Model Context Protocol (MCP) secures a models im...\\n\\ndescription\\n\\nDistill key takeaways from the architectural overview, ecosystem...\\n\\nname\\n\\nConclusion\\n\\nresearch\\n\\nfalse\\n\\nsections\\n\\n0\\n\\ncontent\\n\\n# Introduction Large language models excel at reasoning, but w...\\n\\ndescription\\n\\nBriefly introduce the Model Context Protocol (MCP) as an open st...\\n\\nname\\n\\nIntroduction\\n\\nresearch\\n\\nfalse\\n\\n1\\n\\ncontent\\n\\n## MCP Architectural Overview for Developers MCP uses a client...\\n\\ndescription\\n\\nExplain core MCP concepts and architectureclients, servers, tra...\\n\\nname\\n\\nMCP Architectural Overview for Developers\\n\\nresearch\\n\\ntrue\\n\\n2\\n\\ncontent\\n\\n## Ecosystem Spotlight: Notable MCP Servers Hundreds of MCP ser...\\n\\ndescription\\n\\nSurvey official, partnermaintained, and community MCP servers t...\\n\\nname\\n\\nEcosystem Spotlight: Notable MCP Servers\\n\\nresearch\\n\\ntrue\\n\\n3\\n\\ncontent\\n\\n## AgenttoAgent (A2A) Protocol and Comparison with MCP Goog...\\n\\ndescription\\n\\nIntroduce Googles A2A protocol, summarize its design goals and ...\\n\\nname\\n\\nAgent2Agent (A2A) Protocol and Comparison with MCP\\n\\nresearch\\n\\ntrue\\n\\n4\\n\\ncontent\\n\\n## Conclusion Model Context Protocol (MCP) secures a models im...\\n\\ndescription\\n\\nDistill key takeaways from the architectural overview, ecosystem...\\n\\nname\\n\\nConclusion\\n\\nresearch\\n\\nfalse\\n\\nFeedback\\n\\nStart Time\\n\\n04/23/2025, 06:11:48 PM\\n\\nEnd Time\\n\\n04/23/2025, 06:13:00 PM\\n\\nTime to First Token\\n\\nStatus\\n\\n success\\n\\nTotal tokens\\n\\n80,263 tokens\\n\\nLatency\\n\\n71.90s\\n\\nType\\n\\nChain\\n\\nTags\\n\\nFrom Example\\n\\n\\n--------------------------------------------------------------------------------\\n'}}\n",
      "\n",
      "\n",
      "{'gather_completed_sections': {'report_sections_from_research': '\\n============================================================\\nSection 1: MCP Architecture & Core Concepts\\n============================================================\\nDescription:\\nExplains MCPs host-client-server model, key primitives (resources, tools, prompts), message types (requests, results, notifications, errors), supported transports (stdio, HTTP/SSE), and security considerations so developers grasp the protocols building blocks.\\nRequires Research: \\nTrue\\n\\nContent:\\n## MCP Architecture & Core Concepts\\n\\nMCP follows a three-tier host  client  server pattern. The host application (IDE, chatbot, agent) spawns one client per server; each client maintains a stateful, JSON-RPC session with its paired server, turning the old MN integration maze into a simple M+N graph [1].\\n\\nServers advertise three primitives during the handshake:  \\n Tools  callable functions the model may trigger (model-controlled).  \\n Resources  read-only data the application decides to inject (app-controlled).  \\n Prompts  reusable templates the user can pick (user-controlled) [1][2].\\n\\nAll traffic uses JSON-RPC 2.0. Four message flavours keep the dialogue clear: requests, successful results, notifications (one-way), and error responses. A session begins with an initialize request, capability negotiation, then normal operation until either side closes the transport [2][3].\\n\\nTwo transports are standard. Stdio is fastest for local child processes; Streamable HTTP with optional Server-Sent Events lets remote servers push incremental results over a single connection [1][3].\\n\\nSecurity is handled in layers: fine-grained capability declarations restrict what each side may do; hosts must obtain explicit user consent before sharing data, invoking tools, or granting LLM sampling, and OAuth 2.1 is recommended for authenticating remote HTTP servers [2].\\n\\n### Sources  \\n[1] Model Context Protocol (MCP) an overview: https://www.philschmid.de/mcp-introduction  \\n[2] The Model Context Protocol (MCP)  A Complete Tutorial: https://medium.com/@nimritakoul01/the-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef  \\n[3] Architecture overview  Model Context Protocol: https://modelcontextprotocol.io/docs/learn/architecture\\n\\n\\n============================================================\\nSection 2: Implementing MCP: Developer Workflow & SDKs\\n============================================================\\nDescription:\\nDetails how developers build or consume MCP servers/clients, including available SDKs (Python, TypeScript, Java, Kotlin), local vs. remote deployment patterns, configuration in apps like Claude Desktop, and illustrative code snippets.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Implementing MCP: Developer Workflow & SDKs\\n\\nOfficial SDKs exist for Python, TypeScript, Java, Kotlin, C#, Go, Swift and more, all published in the modelcontextprotocol org and exposing the same JSON-RPC primitives [1].  \\n\\nTypical workflow  \\n1 ) Install the SDK (`pip install fastmcp`, `npm i @modelcontextprotocol/sdk`, etc.).  \\n2 ) Describe Resources and Tools in code.  \\n3 ) Run the server with a local or remote transport.\\n\\n```python\\nfrom fastmcp import FastMCP\\nmcp = FastMCP(\"Demo\")\\n\\n@mcp.resource(\"article://{id}\")      # read-only context\\ndef article(id: str) -> str: \\n\\n@mcp.tool()                          # callable action\\ndef add(a: int, b: int) -> int: return a + b\\n\\nmcp.run(transport=\"stdio\")           # local pipe\\n``` [2]\\n\\nDeployment patterns  \\n Local: `stdio` launches the server as a child process; hosts such as Claude Desktop automatically open the pipe. Point the app at your binary by editing `claude_desktop_config.json` (`\"command\": \"/path/to/server\"`) [3].  \\n Remote: switch to the single-endpoint Streamable HTTP transport for cloud or container use; it supersedes the older dual-channel SSE model and works cleanly behind load-balancers [3].\\n\\nBecause the transports are interchangeable, moving from a laptop prototype to a production micro-service is often a one-line change (`transport=\"streamhttp\"` or `WithHttpTransport()`), while MCP clients continue to auto-discover your tools and resources unchanged.\\n\\n### Sources\\n[1] Model Context Protocol Servers README: https://github.com/modelcontextprotocol/servers  \\n[2] The Only Guide You Will Ever Need For Model Context Protocol: https://www.analyticsvidhya.com/blog/2025/07/model-context-protocol-mcp-guide/  \\n[3] Building MCP Servers for Any Language: https://dev.to/yigit-konur/building-mcp-servers-for-any-language-including-kotlin-ruby-rust-java-go-typescript--2ofi\\n\\n\\n============================================================\\nSection 3: Ecosystem Snapshot: Notable MCP Servers\\n============================================================\\nDescription:\\nSurveys interesting open-source and commercial MCP servers (e.g., GitHub PR review, Filesystem, Postgres, Slack, Apify, Web Search) and categorizes them by function to show practical utility and integration patterns.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Ecosystem Snapshot: Notable MCP Servers  \\n\\nThe public registry already spans hundreds of servers, but a few work-horse groups dominate day-to-day agent workflows.  \\n\\n Version control: the official GitHub server exposes 70+ tools for pull-request review, workflow logs and issue triage, making code automation a popular first MCP use-case [1].  \\n\\n Databases: reference Postgres, BigQuery and Fireproof servers let assistants run safe SQL, inspect schema and even tune indexes, demonstrating a clear patternread-only by default with opt-in writes for production safety [1].  \\n\\n Communication: the Slack server turns channels, DMs and searches into callable tools, allowing an agent to summarise or reply inside team chat without custom bots [1].  \\n\\n Web search & scraping: Exas server provides real-time search APIs, while Apifys Actors server exposes 6 000+ web-automation micro-apps through a single MCP endpoint, giving agents broad reach with one integration [1][2].  \\n\\n Local context: the core Filesystem server delivers sandboxed read/write access to chosen folders, illustrating how hosts can supply private context without leaving the machine [3].  \\n\\nAcross categories, servers follow the same patterndeclare tools/prompts, speak JSON-RPC over stdio or SSE, and rely on the host to enforce consentmaking them easy to mix-and-match in production stacks.  \\n\\n### Sources  \\n[1] Awesome MCP Servers registry: https://www.codebolt.ai/registry/mcp-tools/385/  \\n[2] Apify blog  The state of MCP: https://blog.apify.com/what-is-model-context-protocol/  \\n[3] modelcontextprotocol/servers reference repo: https://github.com/modelcontextprotocol/servers\\n\\n\\n============================================================\\nSection 4: MCP vs. Google Agent-to-Agent (A2A) Protocol\\n============================================================\\nDescription:\\nIntroduces Googles A2A protocol and provides a focused comparison with MCP across architecture, standardization, interoperability, and use-case fit, highlighting when developers might choose one over the other.\\nRequires Research: \\nTrue\\n\\nContent:\\n## MCP vs. Google Agent-to-Agent (A2A) Protocol  \\n\\nGoogles A2A protocol lets autonomous agents talk as peers. It rides on familiar web techHTTP(S) plus JSON-RPC or gRPC, optional Server-Sent Eventsand adds Agent Cards for capability discovery and a task lifecycle that supports streaming updates and long-running work [1]. The design assumes each agent hides its internals yet must negotiate formats, share artifacts, and update status securely across company boundaries.  \\n\\nMCP tackles a different layer. It standardizes how one model or agent invokes **tools**APIs, databases, file systemsthrough typed schemas that feel like function calls, giving the model a single, structured port to external resources [2]. Think of MCP as tool wiring, not peer dialogue.  \\n\\nComparison:  \\n ArchitectureA2A = agent-to-agent, stateful conversation; MCP = agent-to-tool, stateless calls.  \\n StandardizationA2A defines discovery, security, and task states; MCP defines JSON schemas for tool inputs/outputs.  \\n InteroperabilityA2A bridges agents from any vendor; MCP solves the N  M problem of models versus APIs.  \\n\\nChoose MCP when one LLM needs safe, repeatable access to internal systems. Choose A2A when several specialized agents must divide work, stream progress, and present a unified answeroften using MCP internally for their own tool calls [3].  \\n\\n### Sources  \\n[1] Agent2Agent Protocol Official Specification: https://a2a-protocol.org/latest/specification/  \\n[2] A2A  MCP: Complementary Protocols for Agentic Systems: https://a2a-protocol.org/latest/topics/a2a-and-mcp/  \\n[3] MCP vs. A2A  Descope Blog: https://www.descope.com/blog/post/mcp-vs-a2a\\n\\n'}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Introduction', description='Briefly introduces the Model Context Protocol (MCP), its purpose in integrating external context and tools with LLMs, and outlines what the report will cover.', research=False, content='# Introduction\\n\\nLarge language models keep improving, yet they still need safe, structured ways to reach code, data, and other agents. The Model Context Protocol (MCP), backed by Anthropic, answers this need by giving hosts, clients, and servers a shared JSON-RPC language for exposing tools, resources, and prompts. This report explains MCPs architecture and security model, walks through developer workflows and cross-language SDKs, surveys notable servers from GitHub to Apify, and contrasts MCP with Googles Agent-to-Agent protocol so builders can pick the right standard.')]}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Conclusion', description='Summarizes key insights and presents a concise table distilling architectural differences, implementation tips, and ecosystem highlights discussed in the report.', research=False, content='## Conclusion\\n\\nMCP streamlines tool integration by collapsing the N  M tangle of APIs into a single, capability-negotiated pipe; its host  client  server triad, JSON-RPC framing, and pluggable stdio or StreamHTTP transports let developers expose GitHub PR review, Postgres, Slack, or Apify crawlers in minutes. Googles A2A, meanwhile, focuses higher up the stackwrapping whole agents behind cards, coordinating long-running tasks, and broadcasting progress. The matrix distills the decisive contrasts and practical takeaways.\\n\\n| Aspect | MCP | A2A |\\n| --- | --- | --- |\\n| Layer focus | Model/agent  tool call | Agent  agent collaboration |\\n| Session pattern | Stateful JSON-RPC; stateless tool invocations | Task lifecycle with streaming status |\\n| Discovery artifact | initialize handshake (tools, resources, prompts) | Agent Card (capabilities, auth) |\\n| Transport sweet spot | stdio for local, StreamHTTP for cloud | HTTP/gRPC + SSE across org boundaries |\\n| Example server | GitHub PR helper, Postgres SQL, Apify Actors | Research-agent delegating to summarizer agent |\\n| Dev tip | One-line swap between local and remote transports | Pair with MCP internally for tool calls |\\n\\nStart by prototyping an MCP server over stdio, graduate to StreamHTTP in production, and layer A2A only when multiple specialized agents must negotiate tasks together.')]}}\n",
      "\n",
      "\n",
      "{'compile_final_report': {'final_report': '# Introduction\\n\\nLarge language models keep improving, yet they still need safe, structured ways to reach code, data, and other agents. The Model Context Protocol (MCP), backed by Anthropic, answers this need by giving hosts, clients, and servers a shared JSON-RPC language for exposing tools, resources, and prompts. This report explains MCPs architecture and security model, walks through developer workflows and cross-language SDKs, surveys notable servers from GitHub to Apify, and contrasts MCP with Googles Agent-to-Agent protocol so builders can pick the right standard.\\n\\n## MCP Architecture & Core Concepts\\n\\nMCP follows a three-tier host  client  server pattern. The host application (IDE, chatbot, agent) spawns one client per server; each client maintains a stateful, JSON-RPC session with its paired server, turning the old MN integration maze into a simple M+N graph [1].\\n\\nServers advertise three primitives during the handshake:  \\n Tools  callable functions the model may trigger (model-controlled).  \\n Resources  read-only data the application decides to inject (app-controlled).  \\n Prompts  reusable templates the user can pick (user-controlled) [1][2].\\n\\nAll traffic uses JSON-RPC 2.0. Four message flavours keep the dialogue clear: requests, successful results, notifications (one-way), and error responses. A session begins with an initialize request, capability negotiation, then normal operation until either side closes the transport [2][3].\\n\\nTwo transports are standard. Stdio is fastest for local child processes; Streamable HTTP with optional Server-Sent Events lets remote servers push incremental results over a single connection [1][3].\\n\\nSecurity is handled in layers: fine-grained capability declarations restrict what each side may do; hosts must obtain explicit user consent before sharing data, invoking tools, or granting LLM sampling, and OAuth 2.1 is recommended for authenticating remote HTTP servers [2].\\n\\n### Sources  \\n[1] Model Context Protocol (MCP) an overview: https://www.philschmid.de/mcp-introduction  \\n[2] The Model Context Protocol (MCP)  A Complete Tutorial: https://medium.com/@nimritakoul01/the-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef  \\n[3] Architecture overview  Model Context Protocol: https://modelcontextprotocol.io/docs/learn/architecture\\n\\n## Implementing MCP: Developer Workflow & SDKs\\n\\nOfficial SDKs exist for Python, TypeScript, Java, Kotlin, C#, Go, Swift and more, all published in the modelcontextprotocol org and exposing the same JSON-RPC primitives [1].  \\n\\nTypical workflow  \\n1 ) Install the SDK (`pip install fastmcp`, `npm i @modelcontextprotocol/sdk`, etc.).  \\n2 ) Describe Resources and Tools in code.  \\n3 ) Run the server with a local or remote transport.\\n\\n```python\\nfrom fastmcp import FastMCP\\nmcp = FastMCP(\"Demo\")\\n\\n@mcp.resource(\"article://{id}\")      # read-only context\\ndef article(id: str) -> str: \\n\\n@mcp.tool()                          # callable action\\ndef add(a: int, b: int) -> int: return a + b\\n\\nmcp.run(transport=\"stdio\")           # local pipe\\n``` [2]\\n\\nDeployment patterns  \\n Local: `stdio` launches the server as a child process; hosts such as Claude Desktop automatically open the pipe. Point the app at your binary by editing `claude_desktop_config.json` (`\"command\": \"/path/to/server\"`) [3].  \\n Remote: switch to the single-endpoint Streamable HTTP transport for cloud or container use; it supersedes the older dual-channel SSE model and works cleanly behind load-balancers [3].\\n\\nBecause the transports are interchangeable, moving from a laptop prototype to a production micro-service is often a one-line change (`transport=\"streamhttp\"` or `WithHttpTransport()`), while MCP clients continue to auto-discover your tools and resources unchanged.\\n\\n### Sources\\n[1] Model Context Protocol Servers README: https://github.com/modelcontextprotocol/servers  \\n[2] The Only Guide You Will Ever Need For Model Context Protocol: https://www.analyticsvidhya.com/blog/2025/07/model-context-protocol-mcp-guide/  \\n[3] Building MCP Servers for Any Language: https://dev.to/yigit-konur/building-mcp-servers-for-any-language-including-kotlin-ruby-rust-java-go-typescript--2ofi\\n\\n## Ecosystem Snapshot: Notable MCP Servers  \\n\\nThe public registry already spans hundreds of servers, but a few work-horse groups dominate day-to-day agent workflows.  \\n\\n Version control: the official GitHub server exposes 70+ tools for pull-request review, workflow logs and issue triage, making code automation a popular first MCP use-case [1].  \\n\\n Databases: reference Postgres, BigQuery and Fireproof servers let assistants run safe SQL, inspect schema and even tune indexes, demonstrating a clear patternread-only by default with opt-in writes for production safety [1].  \\n\\n Communication: the Slack server turns channels, DMs and searches into callable tools, allowing an agent to summarise or reply inside team chat without custom bots [1].  \\n\\n Web search & scraping: Exas server provides real-time search APIs, while Apifys Actors server exposes 6 000+ web-automation micro-apps through a single MCP endpoint, giving agents broad reach with one integration [1][2].  \\n\\n Local context: the core Filesystem server delivers sandboxed read/write access to chosen folders, illustrating how hosts can supply private context without leaving the machine [3].  \\n\\nAcross categories, servers follow the same patterndeclare tools/prompts, speak JSON-RPC over stdio or SSE, and rely on the host to enforce consentmaking them easy to mix-and-match in production stacks.  \\n\\n### Sources  \\n[1] Awesome MCP Servers registry: https://www.codebolt.ai/registry/mcp-tools/385/  \\n[2] Apify blog  The state of MCP: https://blog.apify.com/what-is-model-context-protocol/  \\n[3] modelcontextprotocol/servers reference repo: https://github.com/modelcontextprotocol/servers\\n\\n## MCP vs. Google Agent-to-Agent (A2A) Protocol  \\n\\nGoogles A2A protocol lets autonomous agents talk as peers. It rides on familiar web techHTTP(S) plus JSON-RPC or gRPC, optional Server-Sent Eventsand adds Agent Cards for capability discovery and a task lifecycle that supports streaming updates and long-running work [1]. The design assumes each agent hides its internals yet must negotiate formats, share artifacts, and update status securely across company boundaries.  \\n\\nMCP tackles a different layer. It standardizes how one model or agent invokes **tools**APIs, databases, file systemsthrough typed schemas that feel like function calls, giving the model a single, structured port to external resources [2]. Think of MCP as tool wiring, not peer dialogue.  \\n\\nComparison:  \\n ArchitectureA2A = agent-to-agent, stateful conversation; MCP = agent-to-tool, stateless calls.  \\n StandardizationA2A defines discovery, security, and task states; MCP defines JSON schemas for tool inputs/outputs.  \\n InteroperabilityA2A bridges agents from any vendor; MCP solves the N  M problem of models versus APIs.  \\n\\nChoose MCP when one LLM needs safe, repeatable access to internal systems. Choose A2A when several specialized agents must divide work, stream progress, and present a unified answeroften using MCP internally for their own tool calls [3].  \\n\\n### Sources  \\n[1] Agent2Agent Protocol Official Specification: https://a2a-protocol.org/latest/specification/  \\n[2] A2A  MCP: Complementary Protocols for Agentic Systems: https://a2a-protocol.org/latest/topics/a2a-and-mcp/  \\n[3] MCP vs. A2A  Descope Blog: https://www.descope.com/blog/post/mcp-vs-a2a\\n\\n## Conclusion\\n\\nMCP streamlines tool integration by collapsing the N  M tangle of APIs into a single, capability-negotiated pipe; its host  client  server triad, JSON-RPC framing, and pluggable stdio or StreamHTTP transports let developers expose GitHub PR review, Postgres, Slack, or Apify crawlers in minutes. Googles A2A, meanwhile, focuses higher up the stackwrapping whole agents behind cards, coordinating long-running tasks, and broadcasting progress. The matrix distills the decisive contrasts and practical takeaways.\\n\\n| Aspect | MCP | A2A |\\n| --- | --- | --- |\\n| Layer focus | Model/agent  tool call | Agent  agent collaboration |\\n| Session pattern | Stateful JSON-RPC; stateless tool invocations | Task lifecycle with streaming status |\\n| Discovery artifact | initialize handshake (tools, resources, prompts) | Agent Card (capabilities, auth) |\\n| Transport sweet spot | stdio for local, StreamHTTP for cloud | HTTP/gRPC + SSE across org boundaries |\\n| Example server | GitHub PR helper, Postgres SQL, Apify Actors | Research-agent delegating to summarizer agent |\\n| Dev tip | One-line swap between local and remote transports | Pair with MCP internally for tool calls |\\n\\nStart by prototyping an MCP server over stdio, graduate to StreamHTTP in production, and layer A2A only when multiple specialized agents must negotiate tasks together.'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Approve the final plan and execute the report generation\n",
    "# This triggers the research and writing phases for all sections\n",
    "\n",
    "# The system will now:\n",
    "# 1. Research each section topic\n",
    "# 2. Generate content with citations\n",
    "# 3. Create introduction and conclusion\n",
    "# 4. Compile the final report\n",
    "\n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the final result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Introduction\n",
       "\n",
       "Large language models keep improving, yet they still need safe, structured ways to reach code, data, and other agents. The Model Context Protocol (MCP), backed by Anthropic, answers this need by giving hosts, clients, and servers a shared JSON-RPC language for exposing tools, resources, and prompts. This report explains MCPs architecture and security model, walks through developer workflows and cross-language SDKs, surveys notable servers from GitHub to Apify, and contrasts MCP with Googles Agent-to-Agent protocol so builders can pick the right standard.\n",
       "\n",
       "## MCP Architecture & Core Concepts\n",
       "\n",
       "MCP follows a three-tier host  client  server pattern. The host application (IDE, chatbot, agent) spawns one client per server; each client maintains a stateful, JSON-RPC session with its paired server, turning the old MN integration maze into a simple M+N graph [1].\n",
       "\n",
       "Servers advertise three primitives during the handshake:  \n",
       " Tools  callable functions the model may trigger (model-controlled).  \n",
       " Resources  read-only data the application decides to inject (app-controlled).  \n",
       " Prompts  reusable templates the user can pick (user-controlled) [1][2].\n",
       "\n",
       "All traffic uses JSON-RPC 2.0. Four message flavours keep the dialogue clear: requests, successful results, notifications (one-way), and error responses. A session begins with an initialize request, capability negotiation, then normal operation until either side closes the transport [2][3].\n",
       "\n",
       "Two transports are standard. Stdio is fastest for local child processes; Streamable HTTP with optional Server-Sent Events lets remote servers push incremental results over a single connection [1][3].\n",
       "\n",
       "Security is handled in layers: fine-grained capability declarations restrict what each side may do; hosts must obtain explicit user consent before sharing data, invoking tools, or granting LLM sampling, and OAuth 2.1 is recommended for authenticating remote HTTP servers [2].\n",
       "\n",
       "### Sources  \n",
       "[1] Model Context Protocol (MCP) an overview: https://www.philschmid.de/mcp-introduction  \n",
       "[2] The Model Context Protocol (MCP)  A Complete Tutorial: https://medium.com/@nimritakoul01/the-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef  \n",
       "[3] Architecture overview  Model Context Protocol: https://modelcontextprotocol.io/docs/learn/architecture\n",
       "\n",
       "## Implementing MCP: Developer Workflow & SDKs\n",
       "\n",
       "Official SDKs exist for Python, TypeScript, Java, Kotlin, C#, Go, Swift and more, all published in the modelcontextprotocol org and exposing the same JSON-RPC primitives [1].  \n",
       "\n",
       "Typical workflow  \n",
       "1 ) Install the SDK (`pip install fastmcp`, `npm i @modelcontextprotocol/sdk`, etc.).  \n",
       "2 ) Describe Resources and Tools in code.  \n",
       "3 ) Run the server with a local or remote transport.\n",
       "\n",
       "```python\n",
       "from fastmcp import FastMCP\n",
       "mcp = FastMCP(\"Demo\")\n",
       "\n",
       "@mcp.resource(\"article://{id}\")      # read-only context\n",
       "def article(id: str) -> str: \n",
       "\n",
       "@mcp.tool()                          # callable action\n",
       "def add(a: int, b: int) -> int: return a + b\n",
       "\n",
       "mcp.run(transport=\"stdio\")           # local pipe\n",
       "``` [2]\n",
       "\n",
       "Deployment patterns  \n",
       " Local: `stdio` launches the server as a child process; hosts such as Claude Desktop automatically open the pipe. Point the app at your binary by editing `claude_desktop_config.json` (`\"command\": \"/path/to/server\"`) [3].  \n",
       " Remote: switch to the single-endpoint Streamable HTTP transport for cloud or container use; it supersedes the older dual-channel SSE model and works cleanly behind load-balancers [3].\n",
       "\n",
       "Because the transports are interchangeable, moving from a laptop prototype to a production micro-service is often a one-line change (`transport=\"streamhttp\"` or `WithHttpTransport()`), while MCP clients continue to auto-discover your tools and resources unchanged.\n",
       "\n",
       "### Sources\n",
       "[1] Model Context Protocol Servers README: https://github.com/modelcontextprotocol/servers  \n",
       "[2] The Only Guide You Will Ever Need For Model Context Protocol: https://www.analyticsvidhya.com/blog/2025/07/model-context-protocol-mcp-guide/  \n",
       "[3] Building MCP Servers for Any Language: https://dev.to/yigit-konur/building-mcp-servers-for-any-language-including-kotlin-ruby-rust-java-go-typescript--2ofi\n",
       "\n",
       "## Ecosystem Snapshot: Notable MCP Servers  \n",
       "\n",
       "The public registry already spans hundreds of servers, but a few work-horse groups dominate day-to-day agent workflows.  \n",
       "\n",
       " Version control: the official GitHub server exposes 70+ tools for pull-request review, workflow logs and issue triage, making code automation a popular first MCP use-case [1].  \n",
       "\n",
       " Databases: reference Postgres, BigQuery and Fireproof servers let assistants run safe SQL, inspect schema and even tune indexes, demonstrating a clear patternread-only by default with opt-in writes for production safety [1].  \n",
       "\n",
       " Communication: the Slack server turns channels, DMs and searches into callable tools, allowing an agent to summarise or reply inside team chat without custom bots [1].  \n",
       "\n",
       " Web search & scraping: Exas server provides real-time search APIs, while Apifys Actors server exposes 6 000+ web-automation micro-apps through a single MCP endpoint, giving agents broad reach with one integration [1][2].  \n",
       "\n",
       " Local context: the core Filesystem server delivers sandboxed read/write access to chosen folders, illustrating how hosts can supply private context without leaving the machine [3].  \n",
       "\n",
       "Across categories, servers follow the same patterndeclare tools/prompts, speak JSON-RPC over stdio or SSE, and rely on the host to enforce consentmaking them easy to mix-and-match in production stacks.  \n",
       "\n",
       "### Sources  \n",
       "[1] Awesome MCP Servers registry: https://www.codebolt.ai/registry/mcp-tools/385/  \n",
       "[2] Apify blog  The state of MCP: https://blog.apify.com/what-is-model-context-protocol/  \n",
       "[3] modelcontextprotocol/servers reference repo: https://github.com/modelcontextprotocol/servers\n",
       "\n",
       "## MCP vs. Google Agent-to-Agent (A2A) Protocol  \n",
       "\n",
       "Googles A2A protocol lets autonomous agents talk as peers. It rides on familiar web techHTTP(S) plus JSON-RPC or gRPC, optional Server-Sent Eventsand adds Agent Cards for capability discovery and a task lifecycle that supports streaming updates and long-running work [1]. The design assumes each agent hides its internals yet must negotiate formats, share artifacts, and update status securely across company boundaries.  \n",
       "\n",
       "MCP tackles a different layer. It standardizes how one model or agent invokes **tools**APIs, databases, file systemsthrough typed schemas that feel like function calls, giving the model a single, structured port to external resources [2]. Think of MCP as tool wiring, not peer dialogue.  \n",
       "\n",
       "Comparison:  \n",
       " ArchitectureA2A = agent-to-agent, stateful conversation; MCP = agent-to-tool, stateless calls.  \n",
       " StandardizationA2A defines discovery, security, and task states; MCP defines JSON schemas for tool inputs/outputs.  \n",
       " InteroperabilityA2A bridges agents from any vendor; MCP solves the N  M problem of models versus APIs.  \n",
       "\n",
       "Choose MCP when one LLM needs safe, repeatable access to internal systems. Choose A2A when several specialized agents must divide work, stream progress, and present a unified answeroften using MCP internally for their own tool calls [3].  \n",
       "\n",
       "### Sources  \n",
       "[1] Agent2Agent Protocol Official Specification: https://a2a-protocol.org/latest/specification/  \n",
       "[2] A2A  MCP: Complementary Protocols for Agentic Systems: https://a2a-protocol.org/latest/topics/a2a-and-mcp/  \n",
       "[3] MCP vs. A2A  Descope Blog: https://www.descope.com/blog/post/mcp-vs-a2a\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "MCP streamlines tool integration by collapsing the N  M tangle of APIs into a single, capability-negotiated pipe; its host  client  server triad, JSON-RPC framing, and pluggable stdio or StreamHTTP transports let developers expose GitHub PR review, Postgres, Slack, or Apify crawlers in minutes. Googles A2A, meanwhile, focuses higher up the stackwrapping whole agents behind cards, coordinating long-running tasks, and broadcasting progress. The matrix distills the decisive contrasts and practical takeaways.\n",
       "\n",
       "| Aspect | MCP | A2A |\n",
       "| --- | --- | --- |\n",
       "| Layer focus | Model/agent  tool call | Agent  agent collaboration |\n",
       "| Session pattern | Stateful JSON-RPC; stateless tool invocations | Task lifecycle with streaming status |\n",
       "| Discovery artifact | initialize handshake (tools, resources, prompts) | Agent Card (capabilities, auth) |\n",
       "| Transport sweet spot | stdio for local, StreamHTTP for cloud | HTTP/gRPC + SSE across org boundaries |\n",
       "| Example server | GitHub PR helper, Postgres SQL, Apify Actors | Research-agent delegating to summarizer agent |\n",
       "| Dev tip | One-line swap between local and remote transports | Pair with MCP internally for tool calls |\n",
       "\n",
       "Start by prototyping an MCP server over stdio, graduate to StreamHTTP in production, and layer A2A only when multiple specialized agents must negotiate tasks together."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the final generated report\n",
    "# Retrieve the completed report from the graph's state and format it for display\n",
    "\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
